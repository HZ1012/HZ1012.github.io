---
layout:     post                    # 使用的布局（不需要改）
title:      数据不平衡               # 标题 
# subtitle:    #副标题
date:       2022-02-23              # 时间
author:     HZ                      # 作者
header-img: img/data science.jpg    #这篇文章标题背景图片
catalog: true                       # 是否归档
tags:                               #标签
    - 数据科学
---

>数据不平衡问题的介绍和解决办法

### 数据不平衡

为什么不平衡数据是机器学习中的一个问题？

大多数机器学习分类算法对预测类中的不平衡非常敏感。让我们考虑一个比我们的乳腺癌数据更极端的例子：假设我们有10个恶性和90个良性样本。在这样的数据集上经过训练和测试的机器学习模型现在可以预测所有样本的“良性”，并且仍然获得非常高的精度。不平衡的数据集将使预测模型偏向更常见的类！

面对这种情况，可以采取哪些措施来解决？

#### 重新采样数据集

过采样和欠采样背后的基本理论概念非常简单：

通过欠采样，我们从具有更多实例的类中随机选择一个样本子集，以匹配来自每个类的样本数量。 在我们的示例中，我们将从 458 个良性案例中随机挑选 241 个。 欠采样的主要缺点是我们从遗漏的样本中丢失了潜在的相关信息。

通过过采样，我们从具有较少实例的类中随机复制样本，或者根据我们拥有的数据生成额外的实例，以匹配每个类中的样本数量。 虽然我们避免使用这种方法丢失信息，但我们也冒着过度拟合模型的风险，因为我们更有可能在训练和测试数据中获得相同的样本，即测试数据不再独立于训练数据。 这会导致高估我们模型的性能和普遍性。

 允许这样做的一些算法包括变分自动编码器 (VAE)、SMOTE（合成少数过采样技术）或 MSMOTE（修改后的合成少数过采样技术）。

 但实际上，我们不应该简单地对训练数据进行过采样或欠采样，然后再运行模型。 **我们需要考虑交叉验证并独立对每个折叠进行过采样或欠采样，以获得对模型性能的诚实估计！**

ROSE:“ROSE 包提供了处理存在不平衡类的二元分类问题的功能。 人工平衡样本是根据平滑自举方法生成的，并允许在存在稀有类别的情况下帮助二元分类器的估计和准确性评估阶段。 还提供了对类别不平衡实施更传统补救措施的函数和评估准确性的不同指标。 这些是通过坚持、引导或交叉验证方法估计的。”

SMOTE:“这篇论文表明，我们对少数（异常）类进行过采样和对多数（正常）类进行欠采样的方法相结合，可以比仅对多数类进行欠采样获得更好的分类器性能（在 ROC 空间中）。 本文还表明，与改变 Ripper 中的损失率或朴素贝叶斯中的类先验相比，我们对少数类进行过采样和对多数类进行欠采样的方法相结合，可以获得更好的分类器性能（在 ROC 空间中）。 我们对少数类进行过采样的方法涉及创建合成的少数类示例。”

#### 从少数类收集更多数据

这个选项看起来微不足道，但它在适用时解决了问题。

#### 使用“足够”的正确算法

一些算法比其他算法更健壮。 掌握每种算法背后的理论将有助于您了解它们在各种情况下的优缺点。 请记住，机器学习算法是根据输入数据和手头的学习任务选择的。

#### 改变方法

与构建分类器不同，有时改变方法和范围是有益的； 一种选择是从“异常检测”的角度分析数据。 然后，可以将“one class SVM”应用于“局部异常因子 (LOF)”算法。

#### 使用惩罚模型

许多算法都有自己的惩罚版本。 通常，算法对所有错误分类都一视同仁，因此其想法是惩罚少数类的错误分类多于多数类。 训练期间犯的错误会带来额外的成本（这就是为什么它们被称为成本敏感分类器），但理论上，这些惩罚有助于模型提高对少数类的关注。 有时，惩罚被称为权重。 实现正确的惩罚矩阵可能很困难，有时对改善结果没有太大作用，因此请尝试多种模式，直到找到最适合自身情况的模式。
