---
layout:     post                    # 使用的布局（不需要改）
title:      精确率与召回率，ROC与PR曲线               # 标题 
# subtitle:    #副标题
date:       2022-02-23              # 时间
author:     HZ                      # 作者
header-img: img/data science.jpg    #这篇文章标题背景图片
catalog: true                       # 是否归档
tags:                               #标签
    - 数据科学
---

### 精确率与召回率，ROC与PR曲线
1. 　　True Positives,TP：预测为正样本，实际也为正样本的特征数

2. 　　False Positives,FP：预测为正样本，实际为负样本的特征数

3. 　　True Negatives,TN：预测为负样本，实际也为负样本的特征数

4. 　　False Negatives,FN：预测为负样本，实际为正样本的特征数

![img](https://images2015.cnblogs.com/blog/1042406/201610/1042406-20161024154443875-2037260202.jpg)

精确率（Precision）的定义在上图可以看出，是绿色半圆除以红色绿色组成的圆。严格的数学定义如下：

               <img src="https://latex.codecogs.com/svg.image?P&space;=&space;\frac{TP}{TP&space;&plus;&space;FP&space;}" title="P = \frac{TP}{TP + FP }" />

召回率(Recall)的定义也在图上能看出，是绿色半圆除以左边的长方形。严格的数学定义如下：

　　　         <img src="https://latex.codecogs.com/svg.image?R&space;=&space;\frac{TP}{TP&space;&plus;&space;FN&space;}" title="R = \frac{TP}{TP + FN }" /> 

特异性(specificity)的定义图上没有直接写明，这里给出，是右边长方形去掉红色半圆部分后除以右边的长方形。严格的数学定义如下：

                <img src="https://latex.codecogs.com/svg.image?S&space;=&space;\frac{TN}{FP&space;&plus;&space;TN&space;}" title="S = \frac{TN}{FP + TN }" />

有时也用一个F1值来综合评估精确率和召回率，它是精确率和召回率的调和均值。当精确率和召回率都高时,F1值也会高。严格的数学定义如下：

                <img src="https://latex.codecogs.com/svg.image?\frac{2}{F_1}&space;=&space;\frac{1}{P}&space;&plus;&space;\frac{1}{R}" title="\frac{2}{F_1} = \frac{1}{P} + \frac{1}{R}" />

有时候我们对精确率和召回率并不是一视同仁，比如有时候我们更加重视精确率。我们用一个参数ββ来度量两者之间的关系。如果β>1, 召回率有更大影响，如果β<1,精确率有更大影响。自然，当β=1的时候，精确率和召回率影响力相同，和F1形式一样。含有度量参数β的F1我们记为<img src="https://latex.codecogs.com/svg.image?F_\beta" title="F_\beta" />, 严格的数学定义如下：

　　　　        <img src="https://latex.codecogs.com/svg.image?F_\beta&space;=&space;\frac{(1&plus;\beta^2)*P*R}{\beta^2*P&space;&plus;&space;R}" title="F_\beta = \frac{(1+\beta^2)*P*R}{\beta^2*P + R}" />

此外还有灵敏度(true positive rate ,TPR)，它是所有实际正例中，正确识别的正例比例，它和召回率的表达式没有区别。严格的数学定义如下：

                <img src="https://latex.codecogs.com/svg.image?TPR&space;=&space;\frac{TP}{TP&space;&plus;&space;FN&space;}" title="TPR = \frac{TP}{TP + FN }" />

另一个是1-特异度(false positive rate, FPR)，它是实际负例中，错误的识别为正例的负例比例。严格的数学定义如下：

　　　　        <img src="https://latex.codecogs.com/svg.image?FPR&space;=&space;\frac{FP}{FP&space;&plus;&space;TN&space;}" title="FPR = \frac{FP}{FP + TN }" />

我们熟悉了精确率， 召回率和特异性，以及TPR和FPR，后面的ROC曲线和PR曲线就好了解了。

以TPR为y轴，以FPR为x轴，我们就直接得到了RoC曲线。从FPR和TPR的定义可以理解，TPR越高，FPR越小，我们的模型和算法就越高效。也就是画出来的RoC曲线越靠近左上越好。如下图左图所示。从几何的角度讲，RoC曲线下方的面积越大越大，则模型越优。所以有时候我们用RoC曲线下的面积，即AUC（Area Under Curve）值来作为算法和模型好坏的标准

![img](https://images2015.cnblogs.com/blog/1042406/201610/1042406-20161024164359046-1869944207.png)

以精确率为y轴，以召回率为x轴，我们就得到了PR曲线。仍然从精确率和召回率的定义可以理解，精确率越高，召回率越高，我们的模型和算法就越高效。也就是画出来的PR曲线越靠近右上越好。如上图右图所示

使用ROC曲线和PR曲线，我们就能很方便的评估我们的模型的分类能力的优劣了

补充：J指数（又称尤登的J统计）为敏感性+特异性-1。接近1的值成为最佳值。（往往用在类别不平衡数据集的判别）
