---
layout:     post                    # 使用的布局（不需要改）
title:      分类回归集成包caret（2）            # 标题 
subtitle:   caret包中文介绍指南 #副标题
date:       2022-02-24              # 时间
author:     HZ                      # 作者
header-img: img/bg-1st.jpg    #这篇文章标题背景图片
catalog: true                       # 是否归档
tags:                               #标签
    - R应用
---

### 标签的训练模型

以下是模型类型或相关特征的基本列表。 这些列表中的所有内容都值得商榷。 例如：随机森林理论上使用特征选择但实际上可能不会，支持向量机使用 L2 正则化等。

- [接受案例权重](https://topepo.github.io/caret/train-models-by-tag.html#Accepts_Case_Weights)
- [Bagging](https://topepo.github.io/caret/train-models-by-tag.html#Bagging)
- [贝叶斯模型](https://topepo.github.io/caret/train-models-by-tag.html#Bayesian_Model)
- [仅二进制预测变量](https://topepo.github.io/caret/train-models-by-tag.html#Binary_Predictors_Only)
- [Boosting](https://topepo.github.io/caret/train-models-by-tag.html#Boosting)
- [仅分类预测变量](https://topepo.github.io/caret/train-models-by-tag.html#Categorical_Predictors_Only)
- [成本敏感学习](https://topepo.github.io/caret/train-models-by-tag.html#Cost_Sensitive_Learning)
- [判别分析](https://topepo.github.io/caret/train-models-by-tag.html#Discriminant_Analysis)
- [距离加权判别](https://topepo.github.io/caret/train-models-by-tag.html#Distance_Weighted_Discrimination)
- [集成模型](https://topepo.github.io/caret/train-models-by-tag.html#Ensemble_Model)
- [特征提取](https://topepo.github.io/caret/train-models-by-tag.html#Feature_Extraction)
- [特征选择包装器](https://topepo.github.io/caret/train-models-by-tag.html#Feature_Selection_Wrapper)
- [高斯过程](https://topepo.github.io/caret/train-models-by-tag.html#Gaussian_Process)
- [广义加性模型](https://topepo.github.io/caret/train-models-by-tag.html#Generalized_Additive_Model)
- [广义线性模型](https://topepo.github.io/caret/train-models-by-tag.html#Generalized_Linear_Model)
- [处理丢失的预测数据](https://topepo.github.io/caret/train-models-by-tag.html#Handle_Missing_Predictor_Data)
- [隐式特征选择](https://topepo.github.io/caret/train-models-by-tag.html#Implicit_Feature_Selection)
- [核方法](https://topepo.github.io/caret/train-models-by-tag.html#Kernel_Method)
- [L1 正则化](https://topepo.github.io/caret/train-models-by-tag.html#L1_Regularization)
- [L2 正则化](https://topepo.github.io/caret/train-models-by-tag.html#L2_Regularization)
- [线性分类器](https://topepo.github.io/caret/train-models-by-tag.html#Linear_Classifier)
- [线性回归](https://topepo.github.io/caret/train-models-by-tag.html#Linear_Regression)
- [逻辑回归](https://topepo.github.io/caret/train-models-by-tag.html#Logic_Regression)
- [逻辑斯蒂回归](https://topepo.github.io/caret/train-models-by-tag.html#Logistic_Regression)
- [混合模型](https://topepo.github.io/caret/train-models-by-tag.html#Mixture_Model)
- [模型树](https://topepo.github.io/caret/train-models-by-tag.html#Model_Tree)
- [多元自适应回归样条](https://topepo.github.io/caret/train-models-by-tag.html#Multivariate_Adaptive_Regression_Splines)
- [神经网络](https://topepo.github.io/caret/train-models-by-tag.html#Neural_Network)
- [斜树](https://topepo.github.io/caret/train-models-by-tag.html#Oblique_Tree)
- [顺序结果](https://topepo.github.io/caret/train-models-by-tag.html#Ordinal_Outcomes)
- [偏最小二乘法](https://topepo.github.io/caret/train-models-by-tag.html#Partial_Least_Squares)
- [病人规则归纳法](https://topepo.github.io/caret/train-models-by-tag.html#Patient_Rule_Induction_Method)
- [多项式模型](https://topepo.github.io/caret/train-models-by-tag.html#Polynomial_Model)
- [原型模型](https://topepo.github.io/caret/train-models-by-tag.html#Prototype_Models)
- [分位数回归](https://topepo.github.io/caret/train-models-by-tag.html#Quantile_Regression)
- [径向基函数](https://topepo.github.io/caret/train-models-by-tag.html#Radial_Basis_Function)
- [随机森林](https://topepo.github.io/caret/train-models-by-tag.html#Random_Forest)
- [正则化](https://topepo.github.io/caret/train-models-by-tag.html#Regularization)
- [相关向量机](https://topepo.github.io/caret/train-models-by-tag.html#Relevance_Vector_Machines)
- [岭回归](https://topepo.github.io/caret/train-models-by-tag.html#Ridge_Regression)
- [稳健的方法](https://topepo.github.io/caret/train-models-by-tag.html#Robust_Methods)
- [稳健模型](https://topepo.github.io/caret/train-models-by-tag.html#Robust_Model)
- [ROC 曲线](https://topepo.github.io/caret/train-models-by-tag.html#ROC_Curves)
- [基于规则的模型](https://topepo.github.io/caret/train-models-by-tag.html#Rule_Based_Model)
- [自组织映射](https://topepo.github.io/caret/train-models-by-tag.html#Self_Organising_Maps)
- [字符串内核](https://topepo.github.io/caret/train-models-by-tag.html#String_Kernel)
- [支持向量机](https://topepo.github.io/caret/train-models-by-tag.html#Support_Vector_Machines)
- [支持类概率](https://topepo.github.io/caret/train-models-by-tag.html#Supports_Class_Probabilities)
- [文本挖掘](https://topepo.github.io/caret/train-models-by-tag.html#Text_Mining)
- [基于树的模型](https://topepo.github.io/caret/train-models-by-tag.html#Tree_Based_Model)
- [仅限两类](https://topepo.github.io/caret/train-models-by-tag.html#Two_Class_Only)

#### 按标签相似性聚类的模型

此页面显示了train可以访问的所有模型的网络图。 有关如何制作此可视化的详细信息，请参阅 Revolutions 博客（此页面已使用 networkD3 包更新了代码）。 总之，该包通过一组标签（例如“Bagging”、“L1 正则化”等）对每个模型进行注释。 使用这些信息，我们可以对彼此相似的模型进行聚类。

绿色圆圈是仅用于回归的模型，蓝色仅用于分类，橙色是“双重用途”。 将鼠标悬停在圆圈上以获取 caret 包使用的模型名称和模型代码，刷新屏幕将重新配置布局。 您可能需要向左移动一个节点才能看到整个名称。 图中未显示 43 个没有连接的模型。

### 并行处理

在这个包中，重采样是使用调整参数优化预测模型的主要方法。 为此，使用训练集的许多替代版本来训练模型并预测保留集。 此过程会重复多次，以获得可推广到新数据集的性能估计。 每个重采样数据集都独立于其他数据集，因此没有正式要求模型必须按顺序运行。 如果具有多个处理器或内核的计算机可用，则计算可以分布在这些“工人”之间以提高计算效率。  caret 利用 R 中的并行处理框架之一来做到这一点。  foreach 包允许使用多种不同的技术顺序或并行运行 R 代码，例如多核或 Rmpi 包（有关可用选项的摘要和描述，请参见 Schmidberger 等，2009）。 有几个 R 包与 foreach 一起使用来实现这些技术，例如 doMC（用于多核）或 doMPI（用于 Rmpi）。

这篇博文对并行处理的好处进行了相当全面的研究。

 要使用多个 worker 调整预测模型，插入caret包函数（例如 train、rfe 或 sbf）中的函数语法不会改变。 一个单独的函数用于“注册”并行处理技术并指定要使用的工人数量。 例如，要在同一台机器上使用具有五个内核的 doParallel) 包，需要加载包并注册它们：

```R
library(doParallel)
cl <- makePSOCKcluster(5)
registerDoParallel(cl)

## 然后所有后续模型并行运行
model <- train(y ~ ., data = training, method = "rf")

## 完成后：
stopCluster(cl)
```

与 foreach 关联的其他包的语法非常相似。 请注意，随着工作人员数量的增加，所需的内存也会增加。 例如，使用 5 个 worker 将在内存中保留总共六个版本的数据。 如果数据很大或计算模型要求很高，如果所需的内存量超过可用的物理量，则性能可能会受到影响。 此外，对于 rfe 和 sbf，这些函数可能会为某些模型调用 train。 在这种情况下，注册 $M$ 个工人实际上会调用 $M^2$个总进程。

这是否有助于减少拟合模型的时间？ 一个中等大小的数据集（4331 行和 8 行）使用不同数量的工人对多个模型进行了多次建模。 随机森林与 2000 棵树一起使用，并调整了超过 10 个 mtry 值。 在每个模型拟合期间也进行了变量重要性计算。 还运行了线性判别分析，以及对成本敏感的径向基函数支持向量机（调整了 15 个成本值）。 所有模型都使用 10 倍交叉验证的 5 次重复进行调整。 结果如下图所示。  y 轴对应于总执行时间（包括模型调整和最终模型拟合）与工作人员数量的关系。 随机森林显然花费了最长的训练时间，并且 LDA 模型的计算效率非常高。 总时间（以分钟为单位）随着工人数量的增加而减少，但稳定在七名工人左右。 

该图的数据以随机方式生成，因此运行顺序不应有偏差。 右下面板显示加速，即连续时间除以并行时间。 例如，加速为 3 表示并行版本比顺序版本快三倍。 并行化充其量可以实现线性加速； 也就是说，对于 M 个 worker，并行时间为 1/M。 对于这些模型，在使用四五个工人之前，加速接近线性。 在此之后，性能略有提高。 由于 LDA 的计算效率已经很高，因此与其他模型相比，加速趋于平稳。 虽然不是线性的，但执行时间的减少是有帮助的 - 近 10 小时的模型拟合减少到大约 90 分钟。

![img](https://topepo.github.io/caret/premade/parallel.png)

请注意，由于底层代码结构，某些模型，尤其是使用 RWeka 包的模型，可能无法并行运行。

train、rfe、sbf、bag 和 avNNet 在它们各自的控制文件中被赋予了一个额外的参数，称为 allowParallel，默认为 TRUE。 当为 TRUE 时，如果注册了并行后端（例如 doMC），则代码将并行执行。 当allowParallel = FALSE 时，并行后端总是被忽略。 用例是当 rfe 或 sbf 调用 train. 如果使用具有 P 个处理器的并行后端，则这些功能的组合将创建 $P^2$进程。 由于某些操作比其他操作更能从并行化中受益，因此用户可以将计算资源集中用于特定功能。

train用来提高计算效率的另一个“技巧”是使用子模型；单个模型拟合可以产生多个调谐参数的预测。例如，在大多数增强模型的实现中，在B增强迭代上训练的模型可以为小于B的迭代生成模型预测。假设在以下网格上调整了gbm模型：

```R
## 生成参数网格
gbmGrid <-  expand.grid(interaction.depth = c(1, 5, 9),
                        n.trees = (1:15)*100,
                        shrinkage = 0.1,
                        n.minobsinnode = 20)
```

实际上，仅训练 3 个模型的创建对象，并从这些对象导出其他预测。 此技巧用于以下模型：ada、AdaBag、AdaBoost.M1、bagEarth、blackboost、blasso、BstLm、bstSm、bstTree、C5.0、C5.0Cost、cubist、earth、enet、foba、gamboost、gbm、glmboost  ，glmnet，kernelpls，lars，lars2，套索，lda2，leapBackward，leapForward，leapSeq，LogitBoost，pam，partDSA，pcr，PenalizedLDA，pls，relaxo，rfRules，rotationForest，rotationForestCp，rpart，rpart2，simplspcost，spikeCost  ，widekernelpls，xgbTree。

### 随机超参数搜索

在 train 中优化调整参数的默认方法是使用网格搜索。 这种方法通常是有效的，但在有许多调整参数的情况下，它可能效率低下。 **另一种方法是结合使用网格搜索和racing。 另一种方法是使用随机选择的调整参数组合来在较小程度上覆盖参数空间**。

在许多模型中，这有助于在相对较短的时间内找到合理的调整参数值。 但是，在某些模型中，小搜索字段中的效率可以抵消其他优化。 例如，caret中的许多模型利用“子模型技巧”，其中评估 M 个调整参数组合，可能远少于 M 个模型拟合所需的数量。 当使用简单的网格搜索时，最好利用这种方法。 因此，**对以下型号代码使用随机搜索可能效率低下**：

`ada`, `AdaBag`, `AdaBoost.M1`, `bagEarth`, `blackboost`, `blasso`, `BstLm`, `bstSm`, `bstTree`, `C5.0`, `C5.0Cost`, `cubist`, `earth`, `enet`, `foba`, `gamboost`, `gbm`, `glmboost`, `glmnet`, `kernelpls`, `lars`, `lars2`, `lasso`, `lda2`, `leapBackward`, `leapForward`, `leapSeq`, `LogitBoost`, `pam`, `partDSA`, `pcr`, `PenalizedLDA`, `pls`, `relaxo`, `rfRules`, `rotationForest`, `rotationForestCp`, `rpart`, `rpart2`, `rpartCost`, `simpls`, `spikeslab`, `superpc`, `widekernelpls`, `xgbDART`, `xgbTree`.

最后，很多被train包裹的模型参数很少。 参数的平均数量为 2。

要使用随机搜索，trainControl 中提供了另一个称为search的选项。 此参数的可能值为“grid”和“random”。 caret中包含的内置模型包含生成随机调整参数组合的代码。 唯一组合的总数由要训练的 tuneLength 选项指定。

同样，我们将使用来自上一个训练页面的声纳数据，通过查看总共 30 个调整参数组合来演示具有正则化判别分析的方法：

```R
library(mlbench)
data(Sonar)

library(caret)
set.seed(998)
inTraining <- createDataPartition(Sonar$Class, p = .75, list = FALSE)
training <- Sonar[ inTraining,]
testing  <- Sonar[-inTraining,]

fitControl <- trainControl(method = "repeatedcv",
                           number = 10,
                           repeats = 10,
                           classProbs = TRUE,
                           summaryFunction = twoClassSummary,
                           search = "random")

set.seed(825)
rda_fit <- train(Class ~ ., data = training, 
                  method = "rda",
                  metric = "ROC",
                  tuneLength = 30,
                  trControl = fitControl)
rda_fit

## Regularized Discriminant Analysis 
## 
## 157 samples
##  60 predictor
##   2 classes: 'M', 'R' 
## 
## No pre-processing
## Resampling: Cross-Validated (10 fold, repeated 10 times) 
## Summary of sample sizes: 141, 142, 141, 142, 141, 142, ... 
## Resampling results across tuning parameters:
## 
##   gamma       lambda       ROC        Sens       Spec     
##   0.03177874  0.767664044  0.8662029  0.7983333  0.7600000
##   0.03868192  0.499283304  0.8526513  0.8120833  0.7600000
##   0.11834801  0.974493793  0.8379266  0.7780556  0.7428571
##   0.12391186  0.018063038  0.8321825  0.8112500  0.7233929
##   0.13442487  0.868918547  0.8590501  0.8122222  0.7528571
##   0.19249104  0.335761243  0.8588070  0.8577778  0.7030357
##   0.23568481  0.064135040  0.8465402  0.8372222  0.7026786
##   0.23814584  0.986270274  0.8363070  0.7623611  0.7532143
##   0.25082994  0.674919744  0.8700918  0.8588889  0.7010714
##   0.28285931  0.576888058  0.8706250  0.8650000  0.6871429
##   0.29099029  0.474277013  0.8681548  0.8687500  0.6844643
##   0.29601805  0.002963208  0.8465476  0.8419444  0.6973214
##   0.31717364  0.943120266  0.8440030  0.7863889  0.7444643
##   0.33633553  0.283586169  0.8650794  0.8626389  0.6878571
##   0.41798776  0.881581948  0.8540253  0.8076389  0.7346429
##   0.45885413  0.701431940  0.8704588  0.8413889  0.7026786
##   0.48684373  0.545997273  0.8713442  0.8638889  0.6758929
##   0.48845661  0.377704420  0.8700818  0.8783333  0.6566071
##   0.51491517  0.592224877  0.8705903  0.8509722  0.6789286
##   0.53206420  0.339941226  0.8694320  0.8795833  0.6523214
##   0.54020648  0.253930177  0.8673239  0.8747222  0.6546429
##   0.56009903  0.183772303  0.8652059  0.8709722  0.6573214
##   0.56472058  0.995162379  0.8354911  0.7550000  0.7489286
##   0.58045730  0.773613530  0.8612922  0.8262500  0.7089286
##   0.67085142  0.287354882  0.8686062  0.8781944  0.6444643
##   0.69503284  0.348973440  0.8694742  0.8805556  0.6417857
##   0.72206263  0.653406920  0.8635937  0.8331944  0.6735714
##   0.76035804  0.183676074  0.8642560  0.8769444  0.6303571
##   0.86234436  0.272931617  0.8545412  0.8588889  0.6030357
##   0.98847635  0.580160726  0.7383358  0.7097222  0.6169643
## 
## ROC was used to select the optimal model using the largest value.
## The final values used for the model were gamma = 0.4868437 and lambda
##  = 0.5459973.
```

目前只有 ggplot 方法（而不是基本的绘图方法）。 此函数随机搜索的结果取决于调整参数的数量和类型。 在这种情况下，它会生成连续参数的散点图。

```R
ggplot(rda_fit) + theme(legend.position = "top")
```

![img](https://topepo.github.io/caret/random/random_plot-1.svg)

### 类不平衡的子抽样

在分类问题中，观察到的类别频率的差异会对模型拟合产生重大的负面影响。 解决这种类不平衡的一种技术是以减轻问题的方式对训练数据进行子采样。 用于此目的的抽样方法示例如下：

* 下采样：随机子集训练集中的所有类，以便它们的类频率与最不流行的类相匹配。 例如，假设训练集样本的 80% 是第一类，其余 20% 是第二类。 下采样将随机采样第一个类，使其与第二个类的大小相同（因此只有总训练集的 40% 用于拟合模型）。 caret包含一个函数 (downSample) 来执行此操作。
* 上采样：随机抽样（替换）少数类，使其与多数类的大小相同。 caret包含一个函数 (upSample) 来执行此操作。
* 混合方法：SMOTE 和 ROSE 等技术对多数类进行下采样并在少数类中合成新数据点。 有两个包（DMwR 和 ROSE）可以实现这些程序。

请注意，这种类型的抽样**不同于将数据拆分为训练集和测试集**。 你永远不会想要人为地平衡测试集； 它的类别频率应该与人们在“野外”看到的一致。 此外，上述过程**独立于重采样方法，例如交叉验证和bootstrap**。

在实践中，可以采用训练集，并在模型拟合之前对数据进行采样。 这种方法有两个问题:

* 首先，在模型调整期间，重采样期间生成的保持样本也会被浏览，并且可能无法反映未来预测将遇到的类别不平衡。 这可能会导致对性能的过度乐观估计。
* 其次，二次抽样过程可能会导致更多的模型不确定性。 在不同的子样本下，模型结果会有所不同吗？ 如上所述，重采样统计更有可能使模型看起来比实际更有效。

另一种方法是在通常的**重采样过程中包含二次采样**。 这也被提倡用于预处理和特征选择步骤。 这两个缺点是它可能会增加计算时间，并且还可能以其他方式使分析复杂化（请参阅下面有关陷阱的部分）。

#### 子采样技术

为了说明这些方法，让我们使用此方法模拟一些类不平衡的数据。 我们将模拟一个训练和测试集，其中每个包含 10000 个样本和大约 5.9% 的少数类率：

```R
library(caret)

set.seed(2969)
imbal_train <- twoClassSim(10000, intercept = -20, linearVars = 20)
imbal_test  <- twoClassSim(10000, intercept = -20, linearVars = 20)
table(imbal_train$Class)

## intercept控制类别不平衡程度
## Class1 Class2 
##   9411    589
```

让我们在模型调整之前创建不同版本的训练集：

```R
set.seed(9560)
down_train <- downSample(x = imbal_train[, -ncol(imbal_train)],
                         y = imbal_train$Class)
table(down_train$Class)   
## 
## Class1 Class2 
##    589    589

set.seed(9560)
up_train <- upSample(x = imbal_train[, -ncol(imbal_train)],
                     y = imbal_train$Class)                         
table(up_train$Class) 
## 
## Class1 Class2 
##   9411   9411
library(DMwR)

set.seed(9560)
smote_train <- SMOTE(Class ~ ., data  = imbal_train)                         
table(smote_train$Class) 
## 
## Class1 Class2 
##   2356   1767
library(ROSE)

set.seed(9560)
rose_train <- ROSE(Class ~ ., data  = imbal_train)$data                         
table(rose_train$Class) 
## 
## Class1 Class2 
##   4939   5061
```

对于这些数据，我们将使用袋装分类法，并使用5个重复的10倍CV估计ROC曲线下的面积。

```R
ctrl <- trainControl(method = "repeatedcv", repeats = 5,
                     classProbs = TRUE,
                     summaryFunction = twoClassSummary)

set.seed(5627)
orig_fit <- train(Class ~ ., data = imbal_train, 
                  method = "treebag",
                  nbagg = 50,
                  metric = "ROC",
                  trControl = ctrl)

set.seed(5627)
down_outside <- train(Class ~ ., data = down_train, 
                      method = "treebag",
                      nbagg = 50,
                      metric = "ROC",
                      trControl = ctrl)

set.seed(5627)
up_outside <- train(Class ~ ., data = up_train, 
                    method = "treebag",
                    nbagg = 50,
                    metric = "ROC",
                    trControl = ctrl)

set.seed(5627)
rose_outside <- train(Class ~ ., data = rose_train, 
                      method = "treebag",
                      nbagg = 50,
                      metric = "ROC",
                      trControl = ctrl)

set.seed(5627)
smote_outside <- train(Class ~ ., data = smote_train, 
                       method = "treebag",
                       nbagg = 50,
                       metric = "ROC",
                       trControl = ctrl
```

我们将整理重采样结果并创建一个包装器来估计测试集性能：

```R
outside_models <- list(original = orig_fit,
                       down = down_outside,
                       up = up_outside,
                       SMOTE = smote_outside,
                       ROSE = rose_outside)

outside_resampling <- resamples(outside_models)

test_roc <- function(model, data) {
  library(pROC)
  roc_obj <- roc(data$Class, 
                 predict(model, data, type = "prob")[, "Class1"],
                 levels = c("Class2", "Class1"))
  ci(roc_obj)
  }

outside_test <- lapply(outside_models, test_roc, data = imbal_test)
outside_test <- lapply(outside_test, as.vector)
outside_test <- do.call("rbind", outside_test)
colnames(outside_test) <- c("lower", "ROC", "upper")
outside_test <- as.data.frame(outside_test)

summary(outside_resampling, metric = "ROC")

## 
## Call:
## summary.resamples(object = outside_resampling, metric = "ROC")
## 
## Models: original, down, up, SMOTE, ROSE 
## Number of resamples: 50 
## 
## ROC 
##               Min.   1st Qu.    Median      Mean   3rd Qu.      Max. NA's
## original 0.9098237 0.9298348 0.9386021 0.9394130 0.9493394 0.9685873    0
## down     0.9095558 0.9282175 0.9453907 0.9438384 0.9596021 0.9836254    0
## up       0.9989350 0.9999980 1.0000000 0.9998402 1.0000000 1.0000000    0
## SMOTE    0.9697171 0.9782214 0.9834234 0.9817476 0.9857071 0.9928255    0
## ROSE     0.8782985 0.8941488 0.8980313 0.8993135 0.9056404 0.9203092    0

inside_test
##              lower       ROC     upper
## original 0.9130010 0.9247957 0.9365905
## down     0.9354534 0.9419704 0.9484875
## up       0.9353945 0.9431074 0.9508202
## SMOTE    0.9465262 0.9524213 0.9583164
## ROSE     0.9369170 0.9448367 0.9527563
```

ROC曲线下区域的训练集和测试集估计值似乎没有相关性。根据重采样结果，可以推断，向上采样几乎是完美的，而ROSE的表现相对较差。上采样表现如此出色的原因是，多数类中的样本是重复的，并且在模型构建和保持集中都有很大的潜力。本质上，这里的坚持并不是真正独立的样本。

实际上，所有的采样方法都是一样的（基于测试集）。无抽样的基本模型拟合的统计数据彼此相当一致（重抽样为0.939，测试集为0.925）。

#### 重采样期间的子采样

最新版本的 caret 允许用户在使用 train 时**指定子采样，以便在重采样内进行**。 上面显示的所有四种方法都可以使用简单的语法通过基本包访问。 如果您想使用自己的技术，或者想更改 SMOTE 或 ROSE 的某些参数，下面的最后一节将展示如何使用自定义子采样。

启用子采样的方法是在 trainControl 中使用另一个称为sampling的选项。 最基本的语法是使用带有采样方法名称的字符串，可以是“down”、“up”、“smote”或“rose”。 请注意，您需要安装 DMwR 和 ROSE 软件包才能分别使用 SMOTE 和 ROSE。

 一种复杂情况与预处理有关。 子采样应该在预处理之前还是之后？ 例如，如果您对数据进行下采样并使用 PCA 进行信号提取，是否应该从整个训练集估计负载？ 由于正在使用整个训练集，因此估计可能会更好，**但子样本可能会捕获 PCA 空间的一小部分。 没有任何明显的答案**。

默认行为是在预处理之前对数据进行二次采样。 这可以很容易地改变，下面给出了一个例子。

现在让我们重新运行我们的袋装树模型，同时在交叉验证内部进行采样：

```R
ctrl <- trainControl(method = "repeatedcv", repeats = 5,
                     classProbs = TRUE,
                     summaryFunction = twoClassSummary,
                     ## 新的选项:
                     sampling = "down")

set.seed(5627)
down_inside <- train(Class ~ ., data = imbal_train,
                     method = "treebag",
                     nbagg = 50,
                     metric = "ROC",
                     trControl = ctrl)

## 现在只需更改该选项
ctrl$sampling <- "up"

set.seed(5627)
up_inside <- train(Class ~ ., data = imbal_train,
                   method = "treebag",
                   nbagg = 50,
                   metric = "ROC",
                   trControl = ctrl)

ctrl$sampling <- "rose"

set.seed(5627)
rose_inside <- train(Class ~ ., data = imbal_train,
                     method = "treebag",
                     nbagg = 50,
                     metric = "ROC",
                     trControl = ctrl)

ctrl$sampling <- "smote"

set.seed(5627)
smote_inside <- train(Class ~ ., data = imbal_train,
                      method = "treebag",
                      nbagg = 50,
                      metric = "ROC",
                      trControl = ctrl)

## 
## Call:
## summary.resamples(object = inside_resampling, metric = "ROC")
## 
## Models: original, down, up, SMOTE, ROSE 
## Number of resamples: 50 
## 
## ROC 
##               Min.   1st Qu.    Median      Mean   3rd Qu.      Max. NA's
## original 0.9098237 0.9298348 0.9386021 0.9394130 0.9493394 0.9685873    0
## down     0.9140294 0.9381766 0.9453610 0.9438490 0.9492917 0.9684522    0
## up       0.8887678 0.9308075 0.9393226 0.9392084 0.9517913 0.9679569    0
## SMOTE    0.9203876 0.9453453 0.9520074 0.9508721 0.9596354 0.9746933    0
## ROSE     0.9305013 0.9442821 0.9489859 0.9511117 0.9572416 0.9756750    0

inside_test

##              lower       ROC     upper
## original 0.9130010 0.9247957 0.9365905
## down     0.9354534 0.9419704 0.9484875
## up       0.9353945 0.9431074 0.9508202
## SMOTE    0.9465262 0.9524213 0.9583164
## ROSE     0.9369170 0.9448367 0.9527563
```

 下图显示了ROC曲线下区域的差异以及此处所示方法的测试集结果。对每个重采样重复子采样过程，产生与测试集更一致的结果。

![img](https://topepo.github.io/caret/sampling/samp_insode_plot-1.svg)

#### 难题

用户应该意识到，在进行二次采样时，可能会发生一些事情，从而导致代码中出现问题。如前所述，**与预处理相关的采样时间就是这样一个问题**。其他的是：

* 因子变量中稀疏表示的类别可能变成零方差预测值，或者可能完全从模型中抽样。
* 进行采样的基本功能（例如SMOTE、downSample等）以非常不同的方式运行，这可能会影响结果。例如，SMOTE和ROSE将把预测变量输入参数转换为数据帧（即使从矩阵开始）。
* 目前，子采样不支持样本权重。
* 如果使用tuneLength指定搜索网格，请了解用于确定网格的数据尚未采样。在大多数情况下，这无关紧要，但如果网格创建过程受样本大小的影响，则最终可能会使用次优的调整网格。
* 对于某些需要更多样本而非参数的模型，减少样本大小可能会使您无法拟合模型。

#### 使用自定义子采样技术

用户可以创建自己类型的子采样过程。为此，可在trainControl的采样参数中使用替代语法。之前，我们使用了一个简单的字符串作为此参数的值。指定参数的另一种方法是使用具有三个（命名）元素的列表：

* name值是打印train对象时使用的字符串。它可以是任何字符串。
* func元素是执行子采样的函数。它应该有称为x和y的参数，分别包含预测值和结果数据。函数应该返回一个包含同名元素的列表。
* first元素是单个逻辑值，指示相对于预处理是否应首先进行子采样。值FALSE表示子采样函数将接收x和y的采样版本。

例如，使用简单向下采样时，采样参数的列表版本如下所示：

```R
down_inside$control$sampling
## $name
## [1] "down"
## 
## $func
## function(x, y)
##     downSample(x, y, list = TRUE)
## 
## $first
## [1] TRUE
```

作为另一个示例，假设我们希望使用SMOTE，但使用10个最近邻，而不是默认的5个。为此，我们可以围绕SMOTE函数创建一个简单的包装器，并调用此函数：

```R
smotest <- list(name = "SMOTE with more neighbors!",
                func = function (x, y) {
                  library(DMwR)
                  dat <- if (is.data.frame(x)) x else as.data.frame(x)
                  dat$.y <- y
                  dat <- SMOTE(.y ~ ., data = dat, k = 10)
                  list(x = dat[, !grepl(".y", colnames(dat), fixed = TRUE)], 
                       y = dat$.y)
                  },
                first = TRUE)
```

然后，控制对象将是：

```R
ctrl <- trainControl(method = "repeatedcv", repeats = 5,
                     classProbs = TRUE,
                     summaryFunction = twoClassSummary,
                     sampling = smotest)
```

### 在训练集中使用recipes

R 中的建模函数让您可以使用公式、x/y 接口或两者来指定模型。 公式很好，因为它们会为您处理很多细节（例如虚拟变量、交互等），因此您不必弄脏手。 它们工作得很好，但也有局限性。 他们最大的问题是并非所有建模函数都有公式接口（尽管 train 有助于解决这个问题）。

recipes是指定模型项的第三种方法，但也允许用于编码、操作和转换数据的一组广泛的预处理选项。 它们涵盖了许多公式无法自然完成的技术。

可以以类似于创建 dplyr 或 ggplot2 的方式逐步构建recipes。 包网站提供了如何使用包的示例并列出了可能的技术（称为步骤）。 然后可以使用recipes代替formula进行训练。

#### 为什么要学习这个？

这里有两个原因： 

* 更通用的数据预处理工具 插入符号的预处理工具有很多选项，但列表并不详尽，它们只会按特定顺序调用。 如果您想要更广泛的选项集，能够编写自己的预处理工具，或者按照您想要的顺序调用它们，那么您可以使用配方来做到这一点。

* 使用附加数据来衡量性能 在大多数建模函数中，包括train，大多数变量被指定为预测变量或结果。 对于recipes，有更多选择。 例如，当您计算模型的执行情况时，您可能希望数据集的特定列可用，例如：

  * 如果需要不同的分层变量（例如患者、邮政编码等）来进行正确的汇总或辅助 
  * 可能需要数据来根据模型结果计算预期的损益。

  为了正确获取这些数据，需要以与所有其他数据相同的方式提供和处理它们。 这意味着它们应该像所有其他数据一样被子或重新采样。 recipes让你做到这一点。

#### 一个例子

QSARdata 包包含几个化学数据集。 这些数据集包含不同潜在药物（此处称为“化合物”）的行。 对于每种化合物，都会测量一些重要的特性。 此插图将使用 AquaticTox 数据。 结果被称为“活动”，是**衡量化合物对人的危害程度的指标**。 我们希望在研发的药物发现阶段预测这一点。为此，根据化合物分子式计算一组分子描述符。 这些有很多不同类型，我们将使用二维 MOE 描述符集。 首先，让我们加载包并将数据放在一起：

```R
library(caret)
library(recipes)
library(dplyr)
library(QSARdata)

data(AquaticTox)
tox <- AquaticTox_moe2D
ncol(tox)
## [1] 221
## 将结果变量添加到数据框
tox$Activity <- AquaticTox_Outcome$Activity
```

我们将根据这些数据建立一个模型来预测活动。 一些注意事项：

* 化学描述符的一个共同方面是它们高度相关。 许多描述符通常测量同一事物的某些变化。 例如，在这些数据中，有 56 个潜在的预测因子可以测量不同的表面积。 通过**预过滤预测变量和/或使用降维技术来降低这些数据的维数可能是一个好主意**。
* 其他描述符是对分子某些类型方面的计数。 例如，一个预测变量是溴原子的数量。 绝大多数化合物缺乏溴，**这导致前面讨论的接近零方差的情况。 预先过滤这些可能是个好主意**。

此外，为了证明recipes的实用性，假设我们可以根据潜在药物的可制造性对它们进行评分。 我们可能想在整个数据集上建立一个模型，但**只对可以合理制造的化合物进行评估**。 为了说明，我们假设，随着化合物分子量的增加，其可制造性会降低。 为此，我们创建了一个新变量（可制造性manufacturability），它既不是结果也不是预测变量，但需要计算性能。

```R
tox <- tox %>%
  select(-Molecule) %>%
  ## 假设可制造性与化合物的分子量有关##
  mutate(manufacturability  = 1/moe2D_Weight) %>%
  mutate(manufacturability = manufacturability/sum(manufacturability))
```

对于此分析，我们将**使用基于可制造性列的权重来计算 RMSE，以便难处理的化合物对 RMSE 的影响较小**。

```R
model_stats <- function(data, lev = NULL, model = NULL) {
  
  stats <- defaultSummary(data, lev = lev, model = model)
  
  wt_rmse <- function (pred, obs, wts, na.rm = TRUE) 
  sqrt(weighted.mean((pred - obs)^2, wts, na.rm = na.rm))
  
  res <- wt_rmse(pred = data$pred,
                 obs = data$obs, 
                 wts = data$manufacturability)
  c(wRMSE = res, stats)
}
```

没有办法使用默认的 train 方法或使用 train.formula 来包含这个额外的变量。

现在，让我们逐步创建一个recipe。 首先，我们将使用公式方法来声明结果和预测变量，但更改可制造性变量的分析角色，使其仅在总结模型拟合时可用。

```R
tox_recipe <- recipe(Activity ~ ., data = tox) %>%
  add_role(manufacturability, new_role = "performance var")

tox_recipe

## Data Recipe
## 
## Inputs:
## 
##             role #variables
##          outcome          1
##  performance var          1
##        predictor        221
```

使用这个新角色，可制造性列将在执行汇总函数时可用，并且数据集的适当行将在重采样期间公开。 例如，如果要在执行模型期间调试 model_stats 函数，则data对象可能如下所示：

```
Browse[1]> head(data)
    obs manufacturability rowIndex     pred
1  3.40       0.002770707        3 3.376488
2  3.75       0.002621364       27 3.945456
3  3.57       0.002697900       33 3.389999
4  3.84       0.002919528       39 4.023662
5  4.41       0.002561416       53 4.482736
6  3.98       0.002838804       54 3.965465
```

多个变量可以具有此角色，以便可以使用多个列。

现在让我们在recipe中添加一些步骤.首先，我们删除稀疏和不平衡的预测变量：

### 自适应重采样

模型可以从调整中显着受益，但事先很少知道最佳值。  train 可用于定义可能点的网格，重采样可用于为每个调整参数组合生成良好的性能估计。 然而，在标称重采样过程中，在选择哪些参数好哪些参数差之前，会为所有重采样计算所有调整参数组合。

 caret包含以一种专注于最佳设置附近的值的方式自适应地重新采样调整参数网格的能力。 See [this paper](http://arxiv.org/abs/1405.6974) for the details.

为了说明这一点，我们将使用前一页中的声纳数据。

```R
library(mlbench)
data(Sonar)
library(caret)
set.seed(998)
inTraining <- createDataPartition(Sonar$Class, p = .75, list = FALSE)
training <- Sonar[ inTraining,]
testing  <- Sonar[-inTraining,]
```

我们将使用与之前相同的调整策略但随机搜索来调整支持向量机模型：

```R
svmControl <- trainControl(method = "repeatedcv",
                           number = 10, repeats = 10,
                           classProbs = TRUE,
                           summaryFunction = twoClassSummary,
                           search = "random")
set.seed(825)
svmFit <- train(Class ~ ., data = training,
                method = "svmRadial", 
                trControl = svmControl, 
                preProc = c("center", "scale"),
                metric = "ROC",
                tuneLength = 15)
```

使用这种方法，最佳调整参数是 RBF 内核参数为 0.0301，成本值为 9.091958。 要使用自适应过程，trainControl 选项需要一些额外的参数：

* min 是将用于每个调整参数的最小重采样数。 默认值为 5，增加它会降低自适应重采样产生的加速，但也会增加找到好的模型的可能性
* alpha 是用于删除参数设置的置信水平。 迄今为止，该值还没有显示出太大的影响。
* method是线性模型的“gls”或布拉德利-特里模型的“BT”。 当您期望模型做得很好（例如，ROC 曲线下的区域接近 1）或有大量调整参数设置时，后者可能更有用。
* complete 是一个逻辑值，它指定如果 train 在重采样结束之前找到最佳解决方案，它是否应该生成完整的重采样集。 如果您想知道最佳参数设置并且不太关心估计的性能值，则此处的值 FALSE 是合适的。

 新代码如下。 回想一下，在模型拟合之前设置随机数种子将确保相同的重采样以及相同的随机网格。

```R
adaptControl <- trainControl(method = "adaptive_cv",
                             number = 10, repeats = 10,
                             adaptive = list(min = 5, alpha = 0.05, 
                                             method = "gls", complete = TRUE),
                             classProbs = TRUE,
                             summaryFunction = twoClassSummary,
                             search = "random")

set.seed(825)
svmAdapt <- train(Class ~ ., data = training,
                  method = "svmRadial", 
                  trControl = adaptControl, 
                  preProc = c("center", "scale"),
                  metric = "ROC",
                  tuneLength = 15)
```

搜索在重采样的第 14 次迭代中完成了调整参数，并且比原始分析快 1.5 倍。 此处，最佳调整参数是 RBF 内核参数为 0.0301，成本值为 9.091958。 这些与之前的设置很接近，导致 ROC 曲线下面积的差异为 0，而自适应方法使用的模型少了 1295 个。

**请记住，此方法是实验性的**，因此请将任何问题或错误报告发送给包维护者。

### 变量重要性

可变重要性评估函数可以分为两组：使用模型信息的和不使用模型信息的。 使用基于模型的方法的优点是与模型性能更紧密地联系在一起，并且它可能能够将预测变量之间的相关结构合并到重要性计算中。 不管重要性是如何计算的：对于大多数分类模型，每个预测器对每个类别都有一个单独的变量重要性（分类树、袋装树和提升树除外。

除非将 varImp.train 的 scale 参数设置为 FALSE，否则所有重要度量都将缩放到最大值 100。

#### 模型特定指标

以下方法可用于估算每个变量对模型的贡献：

线性模型：使用每个模型参数的t统计量的绝对值。

随机森林：来自R软件包：“对于每棵树，记录数据包外部分的预测精度。然后，在排列每个预测变量之后也会执行相同的操作。然后在所有树上平均两个精度之间的差异，并用标准误差进行标准化。对于回归，MSE根据每个树的现成数据计算，然后在排列变量后计算相同的MSE。通过标准误差对差异进行平均和归一化。如果变量的标准误差等于0，则不进行除法。”

偏最小二乘法：此处的变量重要性度量基于绝对回归系数的加权和。权重是PLS组件数量平方和减少的函数，并针对每个结果单独计算。因此，系数的贡献与平方和的减少成比例加权。

递归分区：将归因于每次拆分的每个变量的损失函数（例如均方误差）的减少量制成表格，并返回总和。 此外，由于可能存在重要但未在拆分中使用的候选变量，因此也会在每个拆分中列出排名靠前的竞争变量。 这可以使用 rpart.control 中的 maxcompete 参数关闭。 当响应是一个因素时，此方法当前不提供特定于类的重要性度量。

袋装树：将与单个树相同的方法应用于所有自举树，并返回总重要性提升树：此方法使用与单个树相同的方法，但对每次提升迭代的重要性求和（请参阅 gbm 包小插图 ）。

多元自适应回归样条：MARS模型包括一个向后消除特征选择例程，用于查看广义交叉验证（GCV）估计误差的减少情况。varImp函数跟踪每个预测值的模型统计数据（如GCV）的变化，并在每个预测值的特征添加到模型时累积统计数据的减少。此总减少量用作可变重要性度量。如果预测变量从未在任何MARS基函数中使用过，则其重要性值为零。有三种统计数据可用于估算MARS模型中的可变重要性。使用varImp（object，value=“gcv”）跟踪添加术语时广义交叉验证统计数据的减少。然而，在某些情况下，模型中保留的术语会导致GCV增加。MARS的负变量重要性值设置为零。未包含在最终修剪模型中的具有非零重要性的术语也列为零。或者，使用varImp（object，value=“rss”）在添加项时监视剩余平方和（rss）的变化，这永远不会是负数。此外，选项varImp（object，value=“nsubsets”）返回每个变量在子集中涉及的次数（在最终的修剪模型中）。2008年6月之前，varImp使用内部函数来估计MARS模型的重要性。目前，它是earth包中evimp函数的包装器。

最近收缩质心：类质心和整体质心之间的差异用于衡量变量影响（请参阅 pamr.predict）。 类质心与数据整体中心的差异越大，类之间的间隔就越大。 当将 pamrtrained 类的对象提供给 varImp 时，必须提供训练集预测。

Cubist： Cubist 输出包含变量使用统计信息。 它给出了在条件和/或线性模型中使用每个变量的次数百分比。 请注意，此输出可能与 summary.cubist 的输出中显示的规则不一致。 在树的每次拆分时，Cubist 都会保存一个线性模型（在特征选择之后），该模型允许包含当前拆分中使用的每个变量或它上面的任何拆分的项。  Quinlan (1992) 讨论了一种平滑算法，其中每个模型预测都是父模型和子模型沿树的线性组合。 因此，最终预测是从初始节点到终端节点的所有线性模型的函数。  Cubist 输出中显示的百分比反映了预测中涉及的所有模型（与输出中显示的终端模型相反）。 这里使用的变量重要性是规则条件和模型中使用的线性组合。

#### 独立于模型的指标

如果没有模型特定的方法来估计重要性（或在 varImp 中使用参数 useModel = FALSE），则使用“过滤器”方法单独评估每个预测变量的重要性。

对于分类，对每个预测变量进行 ROC 曲线分析。 对于两类问题，对预测变量数据应用一系列截止值来预测类别。 计算每个临界值的灵敏度和特异性，并计算 ROC 曲线。 梯形规则用于计算 ROC 曲线下的面积。 该区域用作变量重要性的度量。 对于多类结果，问题被分解为所有成对问题，并为每个类对计算曲线下面积（即第 1 类与第 2 类、第 2 类与第 3 类等）。 对于特定类别，相关成对 AUC 曲线下的最大面积用作变量重要性度量。

对于回归，评估每个预测变量与结果之间的关系。 参数 nonpara 用于选择模型拟合技术。 当 nonpara = FALSE 时，拟合线性模型并使用预测变量斜率的 t 值的绝对值。 否则，loess平滑器将在结果和预测变量之间拟合。 该模型的 $R^2$统计量是针对仅截距空模型计算的。 该数字作为变量重要性的相对度量返回。

#### 例子

在模型训练网站上，有几个模型适合示例数据。 **提升树模型有一个内置的变量重要性分数，但支持向量机或正则化判别分析模型都没有**。

```R
gbmImp <- varImp(gbmFit3, scale = FALSE)
gbmImp

## 
##   only 20 most important variables shown (out of 60)
## 
##     Overall
## V11  21.308
## V12  11.896
## V36   9.810
## V52   9.793
## V51   9.324
## V46   5.536
## V13   5.005
## V9    4.396
## V31   4.356
## V37   4.233
## V48   4.109
## V3    3.814
## V23   3.554
## V5    3.544
## V1    3.491
## V43   3.347
## V45   3.110
## V17   3.064
## V27   2.941
## V54   2.819
```

该函数会自动将重要性分数缩放到 0 到 100 之间。使用 scale = FALSE 可避免此标准化步骤。

要获得每个预测变量的 ROC 曲线下面积，可以使用 filterVarImp 函数。 为每个类计算 ROC 曲线下的面积。

```R
roc_imp <- filterVarImp(x = training[, -ncol(training)], y = training$Class)
head(roc_imp)
```

或者，对于没有实现（或存在）内置重要性分数的模型，仍然可以使用 varImp 来获取分数。 对于 SVM 分类模型，默认行为是计算 ROC 曲线下的面积。

```R
roc_imp2 <- varImp(svmFit, scale = FALSE)
roc_imp2

## ROC curve variable importance
## 
##   only 20 most important variables shown (out of 60)
## 
##     Importance
## V11     0.7758
## V12     0.7586
## V9      0.7320
## V13     0.7291
## V10     0.7187
## V52     0.7074
## V46     0.7034
## V49     0.7022
## V51     0.6892
## V45     0.6813
## V47     0.6806
## V48     0.6704
## V1      0.6695
## V4      0.6636
## V5      0.6601
## V6      0.6511
## V2      0.6470
## V36     0.6460
## V3      0.6443
## V44     0.6417
```

对于从 varImp.train 生成的重要性分数，可以使用绘图方法来**可视化**结果。 在下图中，顶部选项用于使图像更具可读性。

```R
plot(gbmImp, top = 20)
```

![img](https://topepo.github.io/caret/varimp/varImp_gbm_plot-1.svg)

### 其他模型函数

#### 另一个 k-最近邻函数

knn3 是用于 k-近邻分类的函数。 这个特定的实现是对 knn C 代码的修改，并返回所有类的投票信息（knn 只返回获胜类的概率）。 有一个公式界面通过

```R
knn3(formula, data)
## or by passing the training data directly
##x 是矩阵或数据框，y 是因子向量
knn3(x, y)
```

还有print和predict方法。

对于 mlbench 包中的 Sonar 数据，我们可以拟合一个 11-最近邻模型：

```R
library(caret)
library(mlbench)
data(Sonar)
set.seed(808)
inTrain <- createDataPartition(Sonar$Class, p = 2/3, list = FALSE)
## 将预测变量和类保存在不同的对象中
sonarTrain <- Sonar[ inTrain, -ncol(Sonar)]
sonarTest  <- Sonar[-inTrain, -ncol(Sonar)]

trainClass <- Sonar[ inTrain, "Class"]
testClass  <- Sonar[-inTrain, "Class"]

centerScale <- preProcess(sonarTrain)
centerScale

## 由 139 个样本和 60 个变量创建
## 
## Pre-processing:
##   - centered (60)
##   - ignored (0)
##   - scaled (60)

training <- predict(centerScale, sonarTrain)
testing <- predict(centerScale, sonarTest)

knnFit <- knn3(training, trainClass, k = 11)
knnFit

## 11-nearest neighbor model
## Training set outcome distribution:
## 
##  M  R 
## 74 65

predict(knnFit, head(testing), type = "prob")

##               M         R
## [1,] 0.45454545 0.5454545
## [2,] 0.81818182 0.1818182
## [3,] 0.63636364 0.3636364
## [4,] 0.09090909 0.9090909
## [5,] 0.54545455 0.4545455
## [6,] 0.45454545 0.5454545
```

类似地，caret 包含一个 k 最近邻回归函数 knnreg。 它返回邻居的平均结果。

#### 偏最小二乘判别分析

plsda 函数是 pls 包中 plsr 函数的包装器，它不需要公式接口并且**可以将因子结果作为参数**。 这些类被分解为虚拟变量（每个类一个）。 这些 0/1 虚拟变量通过偏最小二乘法建模。

从这个模型中，有两种方法可以计算类别预测和概率：

* 可以在每个样本的基础上使用 softmax 技术对分数进行归一化，使它们更像“概率”（即它们总和为 1 并且介于 0 和 1 之间）。对于每个类 X 的模型预测向量 , softmax 类概率计算为. 预测类只是具有最大模型预测的类, 或者等效地, 最大类概率. 这是 plsda 的默认行为.
* 贝叶斯规则可以应用于模型预测以形成后验概率。 在这里，训练集的模型预测与训练集结果一起用于为每个类别创建条件分布。 当预测新样本时，原始模型预测会通过这些条件分布运行，以生成每个类（以及先验）的后验概率。 可以通过指定 probModel = "Bayes" 来使用贝叶斯规则。 附加参数prior，可用于设置类的先验概率。

使用贝叶斯规则的优点是使用完整的训练集直接计算类别概率（与仅使用当前样本分数的 softmax 函数不同）。 这创建了更现实的概率估计，但缺点是必须为 ncomp 的每个值创建单独的贝叶斯模型，这更耗时。

对于声纳数据集，我们可以使用每种技术拟合两个 PLS 模型并预测测试集的类别概率。

```R
plsFit <- plsda(training, trainClass, ncomp = 20)
plsFit

## 偏最小二乘分类，采用核算法。
## softmax 函数用于计算类概率。
plsBayesFit <- plsda(training, trainClass, ncomp = 20,
                     probMethod = "Bayes")
plsBayesFit

## 偏最小二乘分类，采用核算法。
## 贝叶斯规则用于计算类概率。

predict(plsFit, head(testing), type = "prob")

## , , ncomp20
## 
##             M         R
## 2  0.02774255 0.9722574
## 5  0.47710154 0.5228985
## 8  0.89692329 0.1030767
## 11 0.06002366 0.9399763
## 13 0.07292981 0.9270702
## 14 0.60530446 0.3946955
```

与 plsda 类似，caret 也包含一个允许使用稀疏 PLS 进行分类的函数 splsda。 为每个类创建一个虚拟矩阵，并与 spls 包中的 spls 函数一起使用。  plsda 和 splsda 使用相同的方法来估计类别概率。

#### 袋装 MARS 和 FDA

多元自适应回归样条 (MARS) 模型，如分类/回归树，是不稳定的预测变量 (Breiman, 1996)。 这意味着训练数据中的小扰动可能会导致显着不同的模型。 袋装树和随机森林是利用这些不稳定性改进树模型的有效方法。  caret 包含一个函数 bagEarth，它通过 Earth 函数拟合 MARS 模型。 有公式和非公式接口。

此外，灵活的判别分析是线性判别分析的推广，可以使用非线性特征作为输入。 一种方法是使用 MARS 类型的特征对样本进行分类。 函数 bagFDA 拟合一组bootstrap样本的 FDA 模型，并聚合预测以减少噪声。

此函数已被弃用，取而代之的是 bag 函数。

#### 装袋

bag 函数为装袋分类和回归模型提供了一个通用平台。 与 rfe 和 sbf 一样，它是开放的，模型是通过声明模型拟合和预测代码的函数来指定的（并且包中存在几个内置函数集）。 功能 bagControl 具有指定功能的选项（更多详细信息如下）。

该函数还有一些非标准特性：

* 参数 var 可以在每次装袋迭代时启用预测变量的随机采样。 这是为了以与随机森林相同的精神去关联袋装模型（尽管这里对整个模型进行了一次采样）。 默认是使用每个模型的所有预测变量。
* bagControl 函数有一个名为 downSample 的逻辑参数，它对于具有严重类不平衡的分类模型很有用。  Bootstrapped 数据集被减少，以便频率较大的类的样本大小与少数类的样本大小相同。

* 如果 foreach 包的并行后端已加载并注册，则可以并行训练袋装模型。

该函数的控制函数需要以下参数：

The `fit` Function：

输入： 

x：训练集预测数据的数据框。

y：训练集结果。

... 从 train 传递给此函数的参数 输出是与训练模型和预测所需的任何其他对象对应的对象。 来自 MASS 包的线性判别分析模型的一个简单示例是：

```R
function(x, y, ...) {
   library(MASS)
   lda(x, y, ...)
}
```

The `pred` Function

这应该是一个为新样本生成预测变量的函数。
    输入： 

object：由 fit 模块生成的对象。

x：预测数据的矩阵或数据框。

输出是数字向量（用于回归）、用于分类的因子（或字符）向量或类概率的矩阵/数据框。 对于分类，最好平均类概率而不是使用类预测的投票。 再次使用 lda 示例：

```R
## predict.lda returns the class and the class probabilities
## We will average the probabilities, so these are saved
function(object, x) predict(object, x)$posterior

## function(object, x) predict(object, x)$posterior
```

The `aggregate` Function

这应该是一个函数，它从组成模型中获取预测并将它们转换为每个样本的单个预测。略

### 衡量模型效果

#### 回归衡量

函数 postResample 可用于估计数值结果的均方根误差 (RMSE)、简单 $R^2$ 和平均绝对误差 (MAE)。 例如：

```R
library(mlbench)
data(BostonHousing)

set.seed(280)
bh_index <- createDataPartition(BostonHousing$medv, p = .75, list = FALSE)
bh_tr <- BostonHousing[ bh_index, ]
bh_te <- BostonHousing[-bh_index, ]

set.seed(7279)
lm_fit <- train(medv ~ . + rm:lstat,
                data = bh_tr, 
                method = "lm")
bh_pred <- predict(lm_fit, bh_te)

lm_fit
## Linear Regression 
## 
## 381 samples
##  13 predictor
## 
## No pre-processing
## Resampling: Bootstrapped (25 reps) 
## Summary of sample sizes: 381, 381, 381, 381, 381, 381, ... 
## Resampling results:
## 
##   RMSE      Rsquared   MAE     
##   4.374098  0.7724562  2.963927
## 
## Tuning parameter 'intercept' was held constant at a value of TRUE
```

```r
postResample(pred = bh_pred, obs = bh_te$medv)
##      RMSE  Rsquared       MAE 
## 4.0927043 0.8234427 2.8163731
```

关于如何通过caret计算 R2 的说明：它采用直接方法计算观察值和预测值（即 R）之间的相关性并对值求平方。 当模型较差时，这可能导致该估计量与从线性回归模型导出的更广为人知的估计值之间存在差异。 最值得注意的是，相关方法不会产生 $R^2$ 的负值（理论上无效）。 可以在 Kvalseth 1985 中找到这些和其他估计量的比较。

#### 预测类别的衡量

在继续之前，让我们组成一些测试集数据：

```
set.seed(144)
true_class <- factor(sample(paste0("Class", 1:2), 
                            size = 1000,
                            prob = c(.2, .8), replace = TRUE))
true_class <- sort(true_class)
class1_probs <- rbeta(sum(true_class == "Class1"), 4, 1)
class2_probs <- rbeta(sum(true_class == "Class2"), 1, 2.5)
test_set <- data.frame(obs = true_class,
                       Class1 = c(class1_probs, class2_probs))
test_set$Class2 <- 1 - test_set$Class1
test_set$pred <- factor(ifelse(test_set$Class1 >= .5, "Class1", "Class2"))
```

我们希望这个模型能够很好地处理这些数据：

```R
ggplot(test_set, aes(x = Class1)) + 
  geom_histogram(binwidth = .05) + 
  facet_wrap(~obs) + 
  xlab("Probability of Class #1")
```

根据概率的典型 50% 截止值生成预测类，我们可以计算混淆矩阵，它显示了观察到的和预测的类的交叉表。 confusionMatrix函数可用于生成这些结果：

```
confusionMatrix(data = test_set$pred, reference = test_set$obs)

## Confusion Matrix and Statistics
## 
##           Reference
## Prediction Class1 Class2
##     Class1    183    141
##     Class2     13    663
##                                           
##                Accuracy : 0.846           
##                  95% CI : (0.8221, 0.8678)
##     No Information Rate : 0.804           
##     P-Value [Acc > NIR] : 0.0003424       
##                                           
##                   Kappa : 0.6081          
##                                           
##  Mcnemar's Test P-Value : < 2.2e-16       
##                                           
##             Sensitivity : 0.9337          
##             Specificity : 0.8246          
##          Pos Pred Value : 0.5648          
##          Neg Pred Value : 0.9808          
##              Prevalence : 0.1960          
##          Detection Rate : 0.1830          
##    Detection Prevalence : 0.3240          
##       Balanced Accuracy : 0.8792          
##                                           
##        'Positive' Class : Class1          
## 
```

对于两个类，此函数假定与事件对应的类是第一类级别（但这可以使用positive参数进行更改。

请注意，此处显示了许多统计数据。  “无信息率”是最大比例的观察类（在这个测试集中，2 类数据比 1 类数据多）。 还计算假设检验以评估整体准确率是否大于最大类别的准确率。 此外，“阳性事件”的流行率是根据数据（除非作为参数传入）、检测率（真实事件也被预测为事件的比率）和检测流行率（预测事件的流行率）计算的 .

如果事件的流行与测试集中看到的不同，则可以使用prevalence选项对此进行调整。

![img](https://topepo.github.io/caret/premade/cm.jpg)

当有三个或更多类时，confusionMatrix 会显示混淆矩阵和一组“**一对多**”的结果。 例如，在三类问题中，第一类的敏感性是针对第二类和第三类（以此类推）中的所有样本计算的。

混淆矩阵矩阵根据敏感性和特异性来确定错误。 在信息检索的情况下，准确率和召回率可能更合适。 在这种情况下，可以使用选项mode来获取这些统计信息：

```R
confusionMatrix(data = test_set$pred, reference = test_set$obs, mode = "prec_recall")

## Confusion Matrix and Statistics
## 
##           Reference
## Prediction Class1 Class2
##     Class1    183    141
##     Class2     13    663
##                                           
##                Accuracy : 0.846           
##                  95% CI : (0.8221, 0.8678)
##     No Information Rate : 0.804           
##     P-Value [Acc > NIR] : 0.0003424       
##                                           
##                   Kappa : 0.6081          
##                                           
##  Mcnemar's Test P-Value : < 2.2e-16       
##                                           
##               Precision : 0.5648          
##                  Recall : 0.9337          
##                      F1 : 0.7038          
##              Prevalence : 0.1960          
##          Detection Rate : 0.1830          
##    Detection Prevalence : 0.3240          
##       Balanced Accuracy : 0.8792          
##                                           
##        'Positive' Class : Class1          
## 
```

同样，positive参数可用于控制哪个因子水平与“找到”或“重要”文档或样本相关联。

有单独的函数称为`sensitivity`, `specificity`, `posPredValue`, `negPredValue`, `precision`, `recall`, and `F_meas`.。

此外，还可以使用confusionMatrix.train 获得训练集的重采样估计。 对于每次重采样迭代，都会从保留样本中创建一个混淆矩阵，并且可以汇总这些值以诊断模型拟合问题。

这些值是重采样期间保留样本落在混淆矩阵中的百分比。 有几种方法可以对这些值进行归一化。 有关详细信息，请参阅 ?confusionMatrix.train。

train 使用的默认性能函数是 postResample，它生成准确率和 Kappa 统计信息：

```R
postResample(pred = test_set$pred, obs = test_set$obs)

##  Accuracy     Kappa 
## 0.8460000 0.6081345
```

如下所示，另一个名为 twoClassSummary 的函数可**用于使用默认概率截止值获取灵敏度和特异性**。 另一个函数 multiClassSummary 可以在有三个或更多类但都需要每个类的类概率时进行类似的计算。

##### 类概率的衡量

对于具有两个类别的数据，有专门的函数来衡量模型性能。 首先，twoClassSummary 函数计算 ROC 曲线下的面积以及 50% 截止值下的特异性和灵敏度。 请注意：

* 此函数使用第一类级别来定义感兴趣的“事件”。 要改变这一点，请使用函数的 lev 选项
* 每个类别概率的数据中必须有列（与结果的类别级别命名相同）

```R
twoClassSummary(test_set, lev = levels(test_set$obs))

##       ROC      Sens      Spec 
## 0.9560044 0.9336735 0.8246269
```

一个类似的函数可以用来得到类似的precision-recall值和precision-recall曲线下的面积：

```R
prSummary(test_set, lev = levels(test_set$obs))
```

此功能需要安装 MLmetrics 包。

 对于多类问题，还有其他函数可用于计算性能。 一，mnLogLoss 根据**类别概率计算多项式对数似然的负值（越小越好）**。 这可用于优化调整参数，但可能导致结果与其他度量（例如精度或 ROC 曲线下的面积）不一致，尤其是当其他度量接近其最佳可能值时。 该函数具有与上述其他函数类似的参数。 这是上面的两类数据：

```R
mnLogLoss(test_set, lev = levels(test_set$obs))
##  logLoss 
## 0.370626
```

此外，函数 multiClassSummary 计算许多相关指标： 

* 使用预测类别的总体准确度和 Kappa 统计量 
* 多项式对数损失的负数（如果类概率可用） 
* “one versus all”统计量的平均值，例如敏感性、特异性 、ROC 曲线下的面积等。

##### 提升曲线(Lift Curves)

![[公式]](https://www.zhihu.com/equation?tex=Lift%3D%5Cfrac%7B%5Cfrac%7BTP%7D%7BTP%2BFP%7D%7D%7B%5Cfrac%7BTP%2BFN%7D%7BTP%2BFP%2BTN%2BFN%7D%7D%3D%5Cfrac%7BPRE%7D%7B%E6%AD%A3%E4%BE%8B%E5%8D%A0%E6%AF%94%7D%5C%5C)

根据以上公式可知，**Lift指标可以这样理解：**在不使用模型的情况下，我们用先验概率估计正例的比例，即上式子分母部分，以此作为正例的命中率；利用模型后，我们不需要从整个样本中来挑选正例，只需要从我们预测为正例的那个样本的子集 ![[公式]](https://www.zhihu.com/equation?tex=TP%2BFP) 中挑选正例，这时正例的命中率为 ![[公式]](https://www.zhihu.com/equation?tex=PRE) ，后者除以前者即可得提升值**Lift。**

另一方面，lift函数可用于评估可以捕获一定百分比的命中的概率阈值。 该函数需要一组样本概率预测（不是来自训练集）和真实的类别标签。 例如，我们可以使用 twoClassSim 函数模拟两类样本，并将一组模型拟合到训练集：

```R
set.seed(2)
lift_training <- twoClassSim(1000)
lift_testing  <- twoClassSim(1000)

ctrl <- trainControl(method = "cv", classProbs = TRUE,
                     summaryFunction = twoClassSummary)

set.seed(1045)
fda_lift <- train(Class ~ ., data = lift_training,
                  method = "fda", metric = "ROC",
                  tuneLength = 20,
                  trControl = ctrl)
set.seed(1045)
lda_lift <- train(Class ~ ., data = lift_training,
                  method = "lda", metric = "ROC",
                  trControl = ctrl)

library(C50)
set.seed(1045)
c5_lift <- train(Class ~ ., data = lift_training,
                 method = "C5.0", metric = "ROC",
                 tuneLength = 10,
                 trControl = ctrl,
                 control = C5.0Control(earlyStopping = FALSE))

## Generate the test set results
lift_results <- data.frame(Class = lift_testing$Class)
lift_results$FDA <- predict(fda_lift, lift_testing, type = "prob")[,"Class1"]
lift_results$LDA <- predict(lda_lift, lift_testing, type = "prob")[,"Class1"]
lift_results$C5.0 <- predict(c5_lift, lift_testing, type = "prob")[,"Class1"]
head(lift_results)
```

lift函数进行计算，相应的plot函数用于绘制升力曲线（尽管有些人称之为增益曲线）。  value 参数创建参考线：

```R
trellis.par.set(caretTheme())
lift_obj <- lift(Class ~ FDA + LDA + C5.0, data = lift_results)
plot(lift_obj, values = 60, auto.key = list(columns = 3,
                                            lines = TRUE,
                                            points = FALSE))
```

还有一个用于lift对象的 ggplot 方法：

```R
ggplot(lift_obj, values = 60)
```

![img](https://topepo.github.io/caret/performance/perf_lift_obj_gg-1.svg)

从中我们可以看到，要找到 60% 的命中，可以对略多于 30% 的数据进行采样（按概率预测排序时）。  LDA 模型的表现比其他两个模型差一些。

##### 校准曲线(Calibration Curves)

校准曲线可用于表征预测的类别概率与观察到的事件率的一致性。

  gbm 包、rms 包（和其他）中的其他函数也可以生成校准曲线。 该函数的格式与lift函数非常相似： 

```R
trellis.par.set(caretTheme())
cal_obj <- calibration(Class ~ FDA + LDA + C5.0,
                       data = lift_results,
                       cuts = 13)
plot(cal_obj, type = "l", auto.key = list(columns = 3,
                                          lines = TRUE,
                                          points = FALSE))
```

![img](https://topepo.github.io/caret/performance/perf_calib_obj-1.svg)

还有一个 ggplot 方法可以显示子集内部比例的置信区间：

```R
ggplot(cal_obj)
```

![img](https://topepo.github.io/caret/performance/perf_calib_gg-1.svg)

### 特征选择概述

#### Models with Built-In Feature Selection

许多可以使用 caret 的 train 函数访问的模型生成的预测方程不一定使用所有预测变量。 这些模型被认为具有内置特征选择：

```R
ada`, `AdaBag`, `AdaBoost.M1`, `adaboost`, `bagEarth`, `bagEarthGCV`, `bagFDA`, `bagFDAGCV`, `bartMachine`, `blasso`, `BstLm`, `bstSm`, `C5.0`, `C5.0Cost`, `C5.0Rules`, `C5.0Tree`, `cforest`, `chaid`, `ctree`, `ctree2`, `cubist`, `deepboost`, `earth`, `enet`, `evtree`, `extraTrees`, `fda`, `gamboost`, `gbm_h2o`, `gbm`, `gcvEarth`, `glmnet_h2o`, `glmnet`, `glmStepAIC`, `J48`, `JRip`, `lars`, `lars2`, `lasso`, `LMT`, `LogitBoost`, `M5`, `M5Rules`, `msaenet`, `nodeHarvest`, `OneR`, `ordinalNet`, `ordinalRF`, `ORFlog`, `ORFpls`, `ORFridge`, `ORFsvm`, `pam`, `parRF`, `PART`, `penalized`, `PenalizedLDA`, `qrf`, `ranger`, `Rborist`, `relaxo`, `rf`, `rFerns`, `rfRules`, `rotationForest`, `rotationForestCp`, `rpart`, `rpart1SE`, `rpart2`, `rpartCost`, `rpartScore`, `rqlasso`, `rqnc`, `RRF`, `RRFglobal`, `sdwd`, `smda`, `sparseLDA`, `spikeslab`, `wsrf`, `xgbDART`, `xgbLinear`, `xgbTree
```

 许多函数都有一个称为predictors的辅助方法，该方法返回一个向量，指示最终模型中使用了哪些预测器。

**在许多情况下，使用具有内置特征选择的这些模型将比在模型外部搜索正确预测变量的算法更有效**。 内置特征选择通常将预测器搜索算法与参数估计相结合，并且通常使用单个目标函数（例如错误率或可能性）进行优化。

##### 特征选择方法

除了具有内置特征选择的模型外，大多数减少预测变量数量的方法可以分为两大类。 使用 John、Kohavi 和 Pfleger (1994) 的术语：

* 包装方法使用添加和/或删除预测变量的过程评估多个模型，以找到最大化模型性能的最佳组合。 本质上，包装器方法是一种搜索算法，它将预测器视为输入，并利用模型性能作为要优化的输出。  caret 具有基于递归特征消除、遗传算法和模拟退火的包装方法。
* 过滤器方法评估预测模型之外的预测变量的相关性，然后仅对通过某些标准的预测变量进行建模。 例如，对于分类问题，可以单独评估每个预测器，以检查它与观察到的类之间是否存在合理的关系。 只有具有重要关系的预测变量才会包含在分类模型中。  Saeys、Inza 和 Larranaga (2007) 调查了过滤方法。  caret 有一个使用单变量过滤器的通用框架。

这两种方法都有优点和缺点。 过滤器方法通常比包装器方法计算效率更高，但选择标准与模型的有效性没有直接关系。 此外，大多数过滤器方法分别评估每个预测器，因此，可能会选择冗余（即高度相关）的预测器，并且变量之间的重要相互作用将无法量化。 包装器方法的缺点是评估了许多模型（这可能还需要参数调整），从而增加了计算时间。 与包装器过度配合的风险也增加了。
