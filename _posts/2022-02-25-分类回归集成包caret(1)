---
layout:     post                    # 使用的布局（不需要改）
title:      R包caret(1)            # 标题 
subtitle:   caret包中文使用指南 #副标题
date:       2022-02-24              # 时间
author:     HZ                      # 作者
header-img: img/bg-1st.jpg    #这篇文章标题背景图片
catalog: true                       # 是否归档
tags:                               #标签
    - R应用
---

### caret包简短介绍

caret 包（Classification And REgression Training 的缩写）包含简化复杂回归和分类问题的模型训练过程的功能。 该包使用了许多 R 包，但尽量不在包启动时加载它们（通过删除正式的包依赖项，包启动时间可以大大减少）。

安装caret使用

```R
install.packages("caret", dependencies = c("Depends", "Suggests"))
```

以确保安装了所有需要的软件包。

该包的主要帮助页面位于 https://topepo.github.io/caret/ 此处，有扩展示例和先前在包小插图中找到的大量信息。

 caret 有几个函数试图简化模型构建和评估过程，以及特征选择和其他技术。包中的主要工具之一是 train 函数，它可用于:

* 评估模型调整参数对性能的影响
* 使用重采样从这些参数中选择“最佳”模型
* 从训练集中估计模型性能

几乎可以自定义此过程的每个步骤（例如重采样技术、选择最佳参数等）。 为了演示此功能，将使用 mlbench 包中的声纳数据。

声纳数据由在 60 个预测器上收集的 208 个数据点组成。 目标是预测金属圆柱体的 M 类或岩石的 R 类）。

首先，我们将数据分成两组：训练集和测试集。 为此，使用 createDataPartition 函数： 

```R
library(caret)
library(mlbench)
data(Sonar)

set.seed(107)
inTrain <- createDataPartition(
  y = Sonar$Class,
  ## the outcome data are needed
  p = .75,
  ## The percentage of data in the
  ## training set
  list = FALSE
)
## The format of the results

## The output is a set of integers for the rows of Sonar
## that belong in the training set.
str(inTrain)
```

默认情况下，createDataPartition 对数据进行分层随机拆分。 对数据进行分区：

```R
training <- Sonar[ inTrain,]
testing  <- Sonar[-inTrain,]

nrow(training)
#> [1] 157
nrow(testing)
#> [1] 51
```

要使用上述算法调整模型，可以使用 train 函数。 有关此功能的更多详细信息，请访问 https://topepo.github.io/caret/model-training-and-tuning.html。 在这里，偏最小二乘判别分析 (PLSDA) 模型将在应保留的 PLS 组件数量上进行调整。 执行此操作的最基本语法是：

```R
plsFit <- train(
  Class ~ .,
  data = training,
  method = "pls", ## 偏最小二乘判别分析
  ## 将训练集和所有未来样本的预测变量居中并进行缩放。
  preProc = c("center", "scale")
)
```

但是，我们可能希望通过几种方式对其进行自定义：

* 扩展函数评估的 PLS 模型集。 默认情况下，该函数将调整每个调整参数的三个值。
* 使用的重采样类型。 默认情况下使用简单的引导程序。 我们将让函数使用 10 倍交叉验证的 3 次重复。
* 衡量绩效的方法。 如果未指定，则计算总体准确度和 Kappa 统计量。 对于回归模型，计算均方根误差和 $R^2$。 在这里，函数将被更改以估计 ROC 曲线下的面积、敏感性和特异性

要更改调整参数的候选值，可以使用 tuneLength 或 tuneGrid 参数。  train 函数可以生成一组候选参数值，tuneLength 参数**控制要评估的参数值**。 在 PLS 的情况下，该函数使用从 1 到 tuneLength 的整数序列。 如果我们想计算 1 到 15 之间的所有整数，设置 tuneLength = 15 可以实现这一点。 当需要特定值时使用 tuneGrid 参数。 使用数据框，其中每行是一个调整参数设置，每列是一个调整参数。 下面用一个例子来说明这一点。

```R
plsFit <- train(
  Class ~ .,
  data = training,
  method = "pls",
  preProc = c("center", "scale"),
  ## added:
  tuneLength = 15
)
```

为了修改重采样方法，使用了 trainControl 函数。  option 方法控制重采样的类型，默认为“boot”。 另一种方法“repeatedcv”用于指定重复的 K 折交叉验证（并且参数 repeats 控制重复次数）。  K 由 number 参数控制，默认为 10。新的语法是：

```R
ctrl <- trainControl(method = "repeatedcv", repeats = 3)
## traubControl控制重采样的方式

plsFit <- train(
  Class ~ .,
  data = training,
  method = "pls",
  preProc = c("center", "scale"),
  tuneLength = 15,
  ## added:
  trControl = ctrl
)
```

最后，为了选择不同的性能度量，trainControl 提供了额外的参数。  summaryFunction 参数用于传入一个函数，该函数采用观察值和预测值并估计一些性能度量。 包中已包含两个这样的函数：defaultSummary 和 twoClassSummary。 后者将计算特定于两类问题的度量，例如 ROC 曲线下的面积、敏感性和特异性。 由于 ROC 曲线基于预测的类别概率（不会自动计算），因此需要另一个选项。  classProbs = TRUE 选项用于包括这些计算。

最后，该函数将选择与最佳结果相关的调整参数。 由于我们使用自定义性能度量，因此还必须指定应该优化的标准。 在训练调用中，我们可以使用 metric = "ROC" 来做到这一点。

```R
ctrl <- trainControl(
  method = "repeatedcv", 
  repeats = 3,
  classProbs = TRUE, 
  summaryFunction = twoClassSummary
)

set.seed(123)
plsFit <- train(
  Class ~ .,
  data = training,
  method = "pls",
  preProc = c("center", "scale"),
  tuneLength = 15,
  trControl = ctrl,
  metric = "ROC"
)
plsFit
#> Partial Least Squares 
#> 
#> 157 samples
#>  60 predictor
#>   2 classes: 'M', 'R' 
#> 
#> Pre-processing: centered (60), scaled (60) 
#> Resampling: Cross-Validated (10 fold, repeated 3 times) 
#> Summary of sample sizes: 141, 141, 142, 142, 141, 142, ... 
#> Resampling results across tuning parameters:
#> 
#>   ncomp  ROC    Sens   Spec 
#>    1     0.805  0.726  0.690
#>    2     0.848  0.750  0.801
#>    3     0.849  0.764  0.748
#>    4     0.836  0.765  0.736
#>    5     0.812  0.748  0.755
#>    6     0.789  0.724  0.699
#>    7     0.794  0.744  0.689
#>    8     0.801  0.739  0.698
#>    9     0.793  0.758  0.677
#>   10     0.790  0.741  0.690
#>   11     0.787  0.742  0.710
#>   12     0.777  0.737  0.715
#>   13     0.772  0.738  0.700
#>   14     0.768  0.718  0.690
#>   15     0.768  0.715  0.690
#> 
#> ROC was used to select the optimal model using
#>  the largest value.
#> The final value used for the model was ncomp = 3.
```

在此输出中，结果网格是对性能的平均重采样估计。 底部的注释告诉用户发现 3 个 PLS 组件是最佳的。 基于此值，最终的 PLS 模型使用此规范拟合整个数据集，这是用于预测未来样本的模型。

该包具有多个用于可视化结果的功能。 这样做的一种方法是训练对象的 ggplot 函数。 命令 ggplot(plsFit) 产生了如图所示的结果，并显示了重新采样的性能值与 PLS 组件数量之间的关系。

```R
ggplot(plsFit)
```

要预测新样本，可以使用 predict.train。 对于分类模型，默认行为是计算预测类。 选项 type = "prob" 可用于从模型计算类概率。 例如：

```R
plsClasses <- predict(plsFit, newdata = testing)
str(plsClasses)
#>  Factor w/ 2 levels "M","R": 2 1 1 1 2 2 1 2 2 2 ...
plsProbs <- predict(plsFit, newdata = testing, type = "prob")
head(plsProbs)
#>        M     R
#> 6  0.288 0.712
#> 8  0.648 0.352
#> 9  0.659 0.341
#> 15 0.529 0.471
#> 26 0.430 0.570
#> 27 0.492 0.508
```

caret 包含一个函数来计算模型拟合的混淆矩阵和相关统计数据：

```R
confusionMatrix(data = plsClasses, testing$Class)
#> Confusion Matrix and Statistics
#> 
#>           Reference
#> Prediction  M  R
#>          M 21  7
#>          R  6 17
#>                                         
#>                Accuracy : 0.745         
#>                  95% CI : (0.604, 0.857)
#>     No Information Rate : 0.529         
#>     P-Value [Acc > NIR] : 0.00131       
#>                                         
#>                   Kappa : 0.487         
#>                                         
#>  Mcnemar's Test P-Value : 1.00000       
#>                                         
#>             Sensitivity : 0.778         
#>             Specificity : 0.708         
#>          Pos Pred Value : 0.750         
#>          Neg Pred Value : 0.739         
#>              Prevalence : 0.529         
#>          Detection Rate : 0.412         
#>    Detection Prevalence : 0.549         
#>       Balanced Accuracy : 0.743         
#>                                         
#>        'Positive' Class : M             
#> 
```

为了将另一个模型拟合到数据中，可以通过最少的更改调用 train。 可用模型列表可以在 https://topepo.github.io/caret/available-models.html 或 https://topepo.github.io/caret/train-models-by-tag.html 找到。 例如，要为这些数据拟合正则化判别模型，可以使用以下语法：

```R
## To illustrate, a custom grid is used
rdaGrid = data.frame(gamma = (0:4)/4, lambda = 3/4)
set.seed(123)
rdaFit <- train(
  Class ~ .,
  data = training,
  method = "rda",
  tuneGrid = rdaGrid,
  trControl = ctrl,
  metric = "ROC"
)
rdaFit
#> Regularized Discriminant Analysis 
#> 
#> 157 samples
#>  60 predictor
#>   2 classes: 'M', 'R' 
#> 
#> No pre-processing
#> Resampling: Cross-Validated (10 fold, repeated 3 times) 
#> Summary of sample sizes: 141, 141, 142, 142, 141, 142, ... 
#> Resampling results across tuning parameters:
#> 
#>   gamma  ROC    Sens   Spec 
#>   0.00   0.778  0.723  0.682
#>   0.25   0.887  0.864  0.786
#>   0.50   0.876  0.851  0.730
#>   0.75   0.863  0.830  0.710
#>   1.00   0.734  0.680  0.636
#> 
#> Tuning parameter 'lambda' was held constant at a
#>  value of 0.75
#> ROC was used to select the optimal model using
#>  the largest value.
#> The final values used for the model were gamma =
#>  0.25 and lambda = 0.75.
rdaClasses <- predict(rdaFit, newdata = testing)
confusionMatrix(rdaClasses, testing$Class)
#> Confusion Matrix and Statistics
#> 
#>           Reference
#> Prediction  M  R
#>          M 25  5
#>          R  2 19
#>                                         
#>                Accuracy : 0.863         
#>                  95% CI : (0.737, 0.943)
#>     No Information Rate : 0.529         
#>     P-Value [Acc > NIR] : 5.01e-07      
#>                                         
#>                   Kappa : 0.723         
#>                                         
#>  Mcnemar's Test P-Value : 0.45          
#>                                         
#>             Sensitivity : 0.926         
#>             Specificity : 0.792         
#>          Pos Pred Value : 0.833         
#>          Neg Pred Value : 0.905         
#>              Prevalence : 0.529         
#>          Detection Rate : 0.490         
#>    Detection Prevalence : 0.588         
#>       Balanced Accuracy : 0.859         
#>                                         
#>        'Positive' Class : M             
#> 
```

这些模型在重采样结果方面如何比较？  resamples 函数可用于收集、汇总和对比重采样结果。 由于随机数种子在调用 `train} 之前被初始化为相同的值，因此每个模型使用相同的折叠。 组装它们：

```R
resamps <- resamples(list(pls = plsFit, rda = rdaFit))
summary(resamps)
#> 
#> Call:
#> summary.resamples(object = resamps)
#> 
#> Models: pls, rda 
#> Number of resamples: 30 
#> 
#> ROC 
#>      Min. 1st Qu. Median  Mean 3rd Qu.  Max. NA's
#> pls 0.679   0.787  0.823 0.849   0.938 0.984    0
#> rda 0.750   0.847  0.889 0.887   0.940 1.000    0
#> 
#> Sens 
#>      Min. 1st Qu. Median  Mean 3rd Qu. Max. NA's
#> pls 0.556   0.625  0.750 0.764   0.875    1    0
#> rda 0.625   0.757  0.875 0.864   1.000    1    0
#> 
#> Spec 
#>      Min. 1st Qu. Median  Mean 3rd Qu. Max. NA's
#> pls 0.429   0.714  0.714 0.748   0.857    1    0
#> rda 0.500   0.714  0.750 0.786   0.875    1    0
```

有几个函数可以将这些结果可视化。 例如，可以使用以下方法创建 Bland-Altman 类型的图:

```R
xyplot(resamps, what = "BlandAltman")
```

结果看起来很相似。 由于对于每个重采样都有成对的结果，因此可以使用配对 t 检验来评估 ROC 曲线下的平均重采样面积是否存在差异。  diff.resamples 函数可用于计算：

```R
diffs <- diff(resamps)
summary(diffs)
#> 
#> Call:
#> summary.diff.resamples(object = diffs)
#> 
#> p-value adjustment: bonferroni 
#> Upper diagonal: estimates of the difference
#> Lower diagonal: p-value for H0: difference = 0
#> 
#> ROC 
#>     pls      rda    
#> pls          -0.0378
#> rda 0.000544        
#> 
#> Sens 
#>     pls      rda 
#> pls          -0.1
#> rda 0.000172     
#> 
#> Spec 
#>     pls   rda    
#> pls       -0.0387
#> rda 0.136
```

结果看起来很相似。由于每次重采样都有配对结果，因此可以使用配对t检验来评估ROC曲线下的平均重采样面积是否存在差异。diff.resamples函数可用于计算：

```R
diffs <- diff(resamps)
summary(diffs)
#> 
#> Call:
#> summary.diff.resamples(object = diffs)
#> 
#> p-value adjustment: bonferroni 
#> Upper diagonal: estimates of the difference
#> Lower diagonal: p-value for H0: difference = 0
#> 
#> ROC 
#>     pls      rda    
#> pls          -0.0378
#> rda 0.000544        
#> 
#> Sens 
#>     pls      rda 
#> pls          -0.1
#> rda 0.000172     
#> 
#> Spec 
#>     pls   rda    
#> pls       -0.0387
#> rda 0.136
```

根据该分析，模型之间的差异为-0.038 ROC单位（RDA模型略高），该差异的双侧p值为5e-04。

### 预处理

#### 零和近零方差预测变量

在某些情况下，数据生成机制可以创建只有一个唯一值的预测变量（即“零方差预测变量”）。 对于许多模型（不包括基于树的模型），这可能会导致模型崩溃或拟合不稳定。

同样，预测变量可能只有少数出现频率非常低的唯一值。 例如，在耐药性数据中，nR11 描述符（11 元环的数量）数据有几个非常不平衡的独特数值：

```R
data(mdrr)
data.frame(table(mdrrDescr$nR11))
##   Var1 Freq
## 1    0  501
## 2    1    4
## 3    2   23
```

当数据被分成交叉验证/引导子样本或少数样本可能对模型产生不当影响时，这些预测变量可能会成为零方差预测变量。 在建模之前，**可能需要识别和消除这些“接近零方差”的预测变量**。

为了识别这些类型的预测变量，可以计算以下两个指标： 

* 最普遍的值在第二个最频繁的值上的频率（称为“频率比”），对于表现良好的预测变量，该频率接近 1，对于高度不平衡的数据
* “唯一值的百分比”非常大 是唯一值的数量除以随着数据粒度增加而接近零的样本总数（乘以 100） 

**如果频率比大于预先指定的阈值并且唯一值百分比小于阈值， 我们可能会认为预测变量接近零方差。**

我们不想错误地识别具有低粒度但均匀分布的数据，例如来自离散均匀分布的数据。 使用这两个标准不会错误地检测到此类预测因子。

查看 MDRR 数据，nearZeroVar 函数可用于识别接近零方差的变量(saveMetrics 参数可用于显示详细信息，通常默认为 FALSE)

```R
nzv <- nearZeroVar(mdrrDescr, saveMetrics= TRUE)
nzv[nzv$nzv,][1:10,]

dim(mdrrDescr)
## 除去近零方差预测变量
nzv <- nearZeroVar(mdrrDescr)
filteredDescr <- mdrrDescr[, -nzv]
dim(filteredDescr)
```

默认情况下，nearZeroVar 将返回标记为有问题的变量的位置。

#### 识别相关预测变量

虽然有一些模型在相关预测变量（例如 pls）上茁壮成长，但其他模型可能会受益于降低预测变量之间的相关性水平。

 给定一个相关矩阵，findCorrelation 函数使用以下算法来标记要移除的预测变量：

```R
descrCor <-  cor(filteredDescr)
highCorr <- sum(abs(descrCor[upper.tri(descrCor)]) > .999)
```

对于之前的 MDRR 数据，有 65 个描述符几乎完全相关（|correlation| > 0.999），例如原子组成的总信息指数（IAC）和总信息含量指数（0阶邻域对称性）（  TIC0)（相关性 = 1）。 下面的代码块显示了删除绝对相关性高于 0.75 的描述符的效果。

```R
descrCor <- cor(filteredDescr)
summary(descrCor[upper.tri(descrCor)])
##删去高相关
highlyCorDescr <- findCorrelation(descrCor, cutoff = .75)
filteredDescr <- filteredDescr[,-highlyCorDescr]
descrCor2 <- cor(filteredDescr)
summary(descrCor2[upper.tri(descrCor2)])
```

#### 线性依赖

函数 findLinearCombos 使用矩阵的 QR 分解来枚举线性组合集（如果存在）。 例如，考虑以下矩阵，它可能由双向实验布局的非满秩参数化产生：

```R
ltfrDesign <- matrix(0, nrow=6, ncol=6)
ltfrDesign[,1] <- c(1, 1, 1, 1, 1, 1)
ltfrDesign[,2] <- c(1, 1, 1, 0, 0, 0)
ltfrDesign[,3] <- c(0, 0, 0, 1, 1, 1)
ltfrDesign[,4] <- c(1, 0, 0, 1, 0, 0)
ltfrDesign[,5] <- c(0, 1, 0, 0, 1, 0)
ltfrDesign[,6] <- c(0, 0, 1, 0, 0, 1)
```

请注意，第二列和第三列加起来就是第一列。 同样，第四列、第五列和第六列加起来就是第一列。  findLinearCombos 将返回一个枚举这些依赖项的列表。 对于每个线性组合，它将从矩阵中逐步删除列并测试是否已解决依赖关系。  findLinearCombos 还将返回一个列位置向量，可以删除列位置以消除线性依赖关系：

```R
comboInfo <- findLinearCombos(ltfrDesign)
comboInfo

## $linearCombos
## $linearCombos[[1]]
## [1] 3 1 2
## 
## $linearCombos[[2]]
## [1] 6 1 4 5
## 
## 
## $remove
## [1] 3 6

ltfrDesign[, -comboInfo$remove]
```

当使用大量二元化学指纹来描述分子结构时，可能会出现这些类型的依赖性。

#### preProcess函数

preProcess 类可用于预测变量的许多操作，包括居中和缩放。 函数 preProcess 估计每个操作所需的参数，predict.preProcess 用于将它们应用于特定的数据集。 这个函数也可以是调用train函数时的接口。
    在接下来的几节中描述了几种类型的技术，然后使用另一个示例来演示如何使用多种方法。 请注意，在所有情况下，preProcess 函数都会从特定数据集（例如训练集）中**估计它需要的任何内容，然后将这些转换应用于任何数据集，而无需重新计算值**

#### 居中和缩放

在下面的示例中，MDRR 数据的一半用于估计预测变量的位置和规模。 函数 preProcess 实际上并不预处理数据。  predict.preProcess 用于**预处理此数据集和其他数据集**。

```R
set.seed(96)
inTrain <- sample(seq(along = mdrrClass), length(mdrrClass)/2)

training <- filteredDescr[inTrain,]
test <- filteredDescr[-inTrain,]
trainMDRR <- mdrrClass[inTrain]
testMDRR <- mdrrClass[-inTrain]

preProcValues <- preProcess(training, method = c("center", "scale"))

trainTransformed <- predict(preProcValues, training)
testTransformed <- predict(preProcValues, test)
```

预处理选项“scale”将数据缩放到零和一之间的区间。

#### 插补

preProcess 可用于仅根据训练集中的信息来估算数据集。 这样做的一种方法是使用 **K 最近邻**。 对于任意样本，在训练集中找到 K 个最近邻，并使用这些值（例如使用平均值）估算预测器的值。 无论method参数中的内容如何，使用这种方法都会自动触发 preProcess 来居中和缩放数据。 或者，**袋装树也可用于插补**。 对于数据中的每个预测变量，使用训练集中的所有其他预测变量创建一个袋装树。 当新样本具有缺失的预测值时，使用袋装模型来预测该值。 虽然理论上这是一种更强大的插补方法，但计算成本远高于最近邻技术。

#### 转换预测变量

在某些情况下，需要使用主成分分析 (PCA) 将数据转换为较小的子空间，其中新变量彼此不相关。  preProcess 类可以通过在方法参数中包含“pca”来应用此转换。 这样做也会强制缩放预测变量。 请注意，当请求 PCA 时，predict.preProcess 会将列名称更改为 PC1、PC2 等。

类似地，独立分量分析 (ICA) 也可用于查找新变量，这些变量是原始集合的线性组合，因此分量是独立的（而不是 PCA 中的不相关）。 新变量将被标记为 IC1、IC2 等。

“空间符号”转换（Serneels 等人，2006 年）将预测变量的数据投影到 p 维的单位圆，其中 p 是预测变量的数量。 本质上，数据向量除以其范数。 在应用此转换之前，应将预测变量居中并按比例缩放。

```R
library(AppliedPredictiveModeling)
transparentTheme(trans = .4)

plotSubset <- data.frame(scale(mdrrDescr[, c("nC", "X4v")])) 
xyplot(nC ~ X4v,
       data = plotSubset,
       groups = mdrrClass, 
       auto.key = list(columns = 2))  
```

在空间符号之后：

```R
transformed <- spatialSign(plotSubset)
transformed <- as.data.frame(transformed)
xyplot(nC ~ X4v, 
       data = transformed, 
       groups = mdrrClass, 
       auto.key = list(columns = 2)) 
```

如果数据大于零，另一个选项“BoxCox”将估计预测变量上的 Box-Cox 变换。

```R
preProcValues2 <- preProcess(training, method = "BoxCox")
trainBC <- predict(preProcValues2, training)
testBC <- predict(preProcValues2, test)
preProcValues2
```

NA 值对应于无法转换的预测变量。 此转换要求数据大于零。 两个类似的变换，Manly (1976) 的 Yeo-Johnson 和指数变换也可以用于 preProcess。

#### 放一起

在应用预测建模中有一个案例研究，其中预测了高性能计算环境中作业的执行时间。 数据是：

```R
library(AppliedPredictiveModeling)
data(schedulingData)
str(schedulingData)
```

数据是分类和数字预测变量的混合。 假设我们想对连续预测变量使用 Yeo-Johnson 变换，然后将它们居中并进行缩放。 **我们还假设我们将运行一个基于树的模型，因此我们可能希望将因子保留为因子（而不是创建虚拟变量）**。 我们在除最后一列之外的所有列上运行该函数，这是结果。

```R
pp_hpc <- preProcess(schedulingData[, -8], 
                     method = c("center", "scale", "YeoJohnson"))
pp_hpc

## Created from 4331 samples and 7 variables
## 
## Pre-processing:
##   - centered (5)
##   - ignored (2)
##   - scaled (5)
##   - Yeo-Johnson transformation (5)
## 
## Lambda estimates for Yeo-Johnson transformation:
## -0.08, -0.03, -1.05, -1.1, 1.44

transformed <- predict(pp_hpc, newdata = schedulingData[, -8])
head(transformed)

##   Protocol  Compounds InputFields Iterations NumPending         Hour Day
## 1        E  1.2289592  -0.6324580 -0.0615593  -0.554123  0.004586516 Tue
## 2        E -0.6065826  -0.8120473 -0.0615593  -0.554123 -0.043733201 Tue
## 3        E -0.5719534  -1.0131504 -2.7894869  -0.554123 -0.034967177 Thu
## 4        E -0.6427737  -1.0047277 -0.0615593  -0.554123 -0.964170752 Fri
## 5        E -0.5804713  -0.9564504 -0.0615593  -0.554123 -0.902085020 Fri
## 6        E -0.5804713  -0.9564504 -0.0615593  -0.554123  0.698108782 Wed
```

输出中标记为“已忽略”的两个预测变量是两个因子预测变量。 这些没有改变，但数字预测变量被转换。 但是，待处理作业数量的预测变量具有非常稀疏且不平衡的分布：

```
mean(schedulingData$NumPending == 0)
## [1] 0.7561764
```

对于其他一些模型，这可能是一个问题（特别是如果我们重新采样或下采样数据）。 在运行预处理计算之前，我们可以添加一个过滤器来检查零方差或接近零方差的预测变量：

```R
pp_no_nzv <- preProcess(schedulingData[, -8], 
                        method = c("center", "scale", "YeoJohnson", "nzv"))
pp_no_nzv
##结果：
## Created from 4331 samples and 7 variables
## 
## Pre-processing:
##   - centered (4)
##   - ignored (2)
##   - removed (1)
##   - scaled (4)
##   - Yeo-Johnson transformation (4)
## 
## Lambda estimates for Yeo-Johnson transformation:
## -0.08, -0.03, -1.05, 1.44

predict(pp_no_nzv, newdata = schedulingData[1:6, -8])
```

请注意，一个预测变量被标记为“已删除”，并且处理后的数据缺少稀疏预测变量。

#### 类别距离计算

caret 包含根据到类质心的距离生成新的预测变量的函数（类似于线性判别分析的工作原理）。 对于因子变量的每个级别，计算类质心和协方差矩阵。 对于新样本，计算到每个类质心的马哈拉诺比斯距离，**并可用作额外的预测变量。 当真正的决策边界实际上是线性的时，这对非线性模型很有帮助**。

如果类中的预测变量多于样本，则 classDist 函数具有称为 pca 的参数，并保留允许使用每个类中的主成分分析的参数，以避免奇异协方差矩阵的问题。

 然后使用 predict.classDist 生成类距离。 默认情况下，会记录距离，但这可以通过 predict.classDist 的 trans 参数进行更改。

例如，我们可以使用 MDRR 数据。

```R
centroids <- classDist(trainBC, trainMDRR)
distances <- predict(centroids, testBC)
distances <- as.data.frame(distances)
head(distances)

##                dist.Active dist.Inactive
## ACEPROMAZINE      3.787139      3.941234
## ACEPROMETAZINE    4.306137      3.992772
## MESORIDAZINE      3.707296      4.324115
## PERIMETAZINE      4.079938      4.117170
## PROPERICIAZINE    4.174101      4.430957
## DUOPERONE         4.355328      6.000025
```

此图显示了保留样本的类距离的散点图矩阵：

```R
xyplot(dist.Active ~ dist.Inactive,
       data = distances, 
       groups = testMDRR, 
       auto.key = list(columns = 2))
```

![img](https://topepo.github.io/caret/preprocess/pp_splom-1.svg)

#### 补充：preProcess的细节

在所有情况下，使用 x 中的数据估计转换和操作，并使用这些值将这些操作应用于新数据； 使用 predict 函数时**不会重新计算任何内容**。

Box-Cox (method = "BoxCox")、Yeo-Johnson (method = "YeoJohnson") 和指数变换 (method = "expoTrans") 在这里被“重新利用”：它们被用来转换预测变量。  Box-Cox 变换是为变换响应变量而开发的，而另一种方法 Box-Tidwell 变换是用于估计预测变量数据的变换。 然而，Box-Cox 方法更简单，计算效率更高，并且对于估计幂变换同样有效。  Yeo-Johnson 变换类似于 Box-Cox 模型，但可以容纳具有零和/或负值的预测变量（而 Box-Cox 变换的预测变量值必须严格为正）。  Manly (1976) 的指数变换也可用于正数据或负数据。

method = "center" 从预测变量值中减去预测变量数据的平均值（再次从 x 中的数据），而 method = "scale" 除以标准偏差。

“范围”转换将数据缩放到范围边界内。 如果新样本的值大于或小于训练集中的值，则值将超出此范围。

在计算中忽略非数字的预测变量（包括方法“zv'”和“nzv'”）。

method = "zv" 标识具有单个值（即具有零方差）的数字预测器列，并将它们从进一步的计算中排除。 类似地，method = "nzv" 通过应用 nearZeroVar 排除“接近零方差”预测变量来执行相同的操作。 选项 freqCut 和 uniqueCut 可用于修改过滤器。

method = "corr" 试图过滤掉高度相关的预测变量。 请参阅查找相关性。

对于分类，method = "conditionalX" 检查以结果为条件的每个预测变量的分布。 如果任何类别中只有一个唯一值，则预测变量将被排除在进一步的计算之外（请参阅 checkConditionalX 示例）。 当结果不是一个因素时，不执行此计算。 当在通过train重采样时使用此操作可能会很耗时。

这些操作按以下顺序应用：零方差滤波器、近零方差滤波器、相关滤波器、Box-Cox/Yeo-Johnson/指数变换、居中、缩放、范围、插补、PCA、ICA 然后是空间符号。 这与 4.76 版之前的插入符号版本（首先进行插补）不同，如果使用装袋进行插补，则不向后兼容。

如果请求 PCA 但没有居中和缩放，则值仍将居中和缩放。 同样，当请求 ICA 时，数据会自动居中和缩放。

k-最近邻插补是通过在训练集中找到k个最近的样本（欧几里得距离）来进行的。 通过装袋进行的插补适合每个预测器的装袋树模型（作为所有其他预测器的函数）。 这种方法简单、准确并且可以接受缺失值，但计算成本要高得多。 通过中位数进行插补采用训练集中每个预测变量的中位数，并使用它们来填充缺失值。 这种方法简单、快速并且接受缺失值，但独立处理每个预测变量，并且可能不准确。

如果同时请求 PCA 和 ICA，则会引发警告。 由 fastICA 包实现的 ICA 在找到 ICA 分数之前自动进行 PCA 分解。

除非调用 method = "zv" 或 method = "nzv"，否则该函数将抛出 x 中任何数值变量少于两个唯一值的错误。

非数字数据不会被预处理，它们的值将在预测函数生成的数据框中。 请注意，当使用 PCA 或 ICA 时，非数字列在预测时可能处于不同的位置。

### 数据拆分

#### 基于结果的简单拆分

函数 createDataPartition 可用于创建数据的平衡拆分。 如果此函数的 y 参数是一个因子，则**随机抽样发生在每个类中，并应保留数据的整体类分布**。 例如，要创建虹膜数据的单个 80/20% 拆分：

```R
library(caret)
set.seed(3456)
trainIndex <- createDataPartition(iris$Species, p = .8, 
                                  list = FALSE, 
                                  times = 1)
head(trainIndex)
##      Resample1
## [1,]         1
## [2,]         2
## [3,]         3
## [4,]         5
## [5,]         6
## [6,]         7

irisTrain <- iris[ trainIndex,]
irisTest  <- iris[-trainIndex,]
```

list = FALSE 避免将数据作为列表返回。 这个函数还有一个参数，times，可以一次创建多个分割； 数据索引在整数向量列表中返回。 同样，createResample 可用于制作简单的bootstrap样本，createFolds 可用于从一组数据生成平衡的交叉验证分组。

#### 基于预测变量的拆分

此外，函数 maxDissim 可用于使用最大相异性方法（Willett，1999）创建子样本。 假设有一个有 m 个样本的数据集 A 和一个有 n 个样本的更大的数据集 B。 我们可能想要从 B 创建一个与 A 相比(内容)不同的子样本。为此，对于 B 中的每个样本，该函数计算 A 中每个点之间的 m 个不相似性。 B 中最不相似的点被添加到 A 并且该过程继续。  R中有很多方法可以计算相异度。  caret 使用proxy包。 有关可用措施的列表，请参阅该包的手册。 此外，有很多方法可以计算哪个样本“最不相似”。 参数 obj 可用于指定任何返回标量度量的函数。  caret 包括两个函数 minDiss 和 sumDiss，分别可用于最大化最小差异和总差异。

例如，下图显示了 Cox2 数据的两个化学描述符的散点图。 使用 5 种化合物的初始随机样本，我们可以从数据中再选择 20 种化合物，以便新化合物与指定的最初 5 种化合物最不相似。 图中的面板显示了使用距离度量和评分函数的几种组合的结果。 对于这些数据，距离测量比确定哪些化合物最不相似的评分方法的影响要小。

```R
library(mlbench)
data(BostonHousing)

testing <- scale(BostonHousing[, c("age", "nox")])
set.seed(5)
## A random sample of 5 data points
startSet <- sample(1:dim(testing)[1], 5)
samplePool <- testing[-startSet,]
start <- testing[startSet,]
newSamp <- maxDissim(start, samplePool, n = 20)
head(newSamp)
## [1] 460 142 491 156 498  82
```

下面的可视化显示了数据集（小点）、起始样本（较大的蓝点）以及其他 20 个样本的添加顺序。

![img](https://topepo.github.io/caret/premade/MaxDissim.gif)

#### 时间序列的数据拆分

在某些情况下，在（重新）采样期间应考虑数据中的重要定性因素。 例如：

* 在临床试验中，纵向或重复测量数据可能存在医院间差异
* 对于纵向或重复测量数据，受试者（或一般独立实验单元）在数据集中可能有多行等。

可能有兴趣确保这些组不包含在训练和测试集中，因为这可能会使测试集性能更乐观。 此外，当一个或多个特定组被保留时，重新采样可能会捕获模型的“坚固性”。 **在多个站点记录临床数据的示例中，重采样性能估计部分衡量模型跨站点的可扩展性**。

要根据组拆分数据，可以使用 groupKFold：

```R
set.seed(3527)
subjects <- sample(1:20, size = 80, replace = TRUE)
table(subjects)

## subjects
##  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 
##  2  3  2  5  3  5  4  5  4  4  2  5  4  2  3  3  6  7  8  3

folds <- groupKFold(subjects, k = 15) 
```

folds 中的结果可以用作 trainControl 函数的 index 参数的输入。

该图显示了每个主题如何在建模集和保持集之间进行划分。 请注意，由于在创建折叠时 k 小于 20，因此有一些模型的坚持不是一个主题。

![img](https://topepo.github.io/caret/splitting/Split_group_plot-1.svg)

### 模型训练和调优

#### 模型训练和参数调优

caret 包有几个试图简化模型构建和评估过程的功能。

train 函数可用于评估，使用重采样，模型调整参数对性能的影响在这些参数中选择“最佳”模型从训练集中估计模型性能首先，必须选择特定模型。 目前，有 238 个可以使用caret符号； 有关详细信息，请参阅[训练模型列表](https://topepo.github.io/caret/available-models.html)或[按标签训练模型](https://topepo.github.io/caret/train-models-by-tag.html)。 在这些页面上，列出了可以优化的调整参数。 也可以创建用户定义的模型。

调整模型的第一步（下面算法中的第 1 行）是选择一组要评估的参数。 例如，如果拟合偏最小二乘 (PLS) 模型，则必须指定要评估的 PLS 分量数。

一旦定义了模型和调整参数值，还应指定重采样的类型。 目前，train 可以使用 k 折交叉验证（一次或重复）、留一法交叉验证和bootstrap（简单估计或 632 规则）重采样方法。 重采样后，该过程会生成性能测量的配置文件，可用于指导用户选择应选择哪些调整参数值。 默认情况下，该函数会自动选择与最佳值相关的调整参数，尽管可以使用不同的算法（请参阅下面的详细信息）。

#### 一个例子

声纳数据在 mlbench 包中可用。 在这里，我们加载数据：

```R
library(mlbench)
data(Sonar)
str(Sonar[, 1:10])
```

函数 createDataPartition 可用于将数据的分层随机样本创建为训练集和测试集：

```R
library(caret)
set.seed(998)
inTraining <- createDataPartition(Sonar$Class, p = .75, list = FALSE)
training <- Sonar[ inTraining,]
testing  <- Sonar[-inTraining,]
```

#### 基本参数调整

默认情况下，简单bootstrap重采样用于上述算法中的第 3 行。 其他可用的，例如重复 K 折交叉验证，留一法等。 函数 trainControl 可用于指定重采样的类型：

```R
fitControl <- trainControl(## 10-fold CV
                           method = "repeatedcv",
                           number = 10,
                           ## repeated ten times
                           repeats = 10)
```

有关 trainControl 的更多信息在下面的部分中给出。

训练的前两个参数分别是预测数据对象和结果数据对象。 第三个参数 method 指定模型的类型（请参阅[训练模型列表](https://topepo.github.io/caret/available-models.html)或[按标签训练模型](https://topepo.github.io/caret/train-models-by-tag.html)）。 为了说明这一点，我们将通过 gbm 包拟合一个提升树模型。 使用重复交叉验证拟合此模型的基本语法如下所示：

```R
set.seed(825)
gbmFit1 <- train(Class ~ ., data = training, 
                 method = "gbm", 
                 trControl = fitControl,
                 ## This last option is actually one
                 ## for gbm() that passes through
                 verbose = FALSE)
gbmFit1
```

对于梯度提升机 (GBM) 模型，主要有三个调优参数： 

* 迭代次数，即树，（gbm 函数中称为 n.trees）
* 树的复杂度，称为interaction.depth
* 学习率：算法的速度 适应，称为shrinkage
* 在节点中开始分裂的最小训练集样本数 (n.minobsinnode) 该模型测试的默认值显示在前两列中（shrinkage和 n.minobsinnode 未显示，因为网格集 候选模型都对这些调整参数使用单个值）。 标有“Accuracy”的列是交叉验证迭代的平均总体一致率。 一致性标准偏差也是从交叉验证结果中计算出来的。  “Kappa”列是 Cohen 的（未加权的）Kappa 统计量在重采样结果中的平均值。  train 适用于特定模型（请参阅 train Model List 或 train Models By Tag）。 对于这些模型，train 可以自动创建调整参数网格。 默认情况下，如果 p 是调整参数的数量，则网格大小为 3^p。 再举一个例子，正则化判别分析 (RDA) 模型有两个参数（gamma 和 lambda），这两个参数都在 0 和 1 之间。 默认训练网格将在这个二维空间中产生九种组合。

​    下一节将介绍 train 中的其他功能。

#### 关于再现性的说明

许多模型在估计参数的阶段使用随机数。 此外，重采样索引是使用随机数选择的。 有两种主要方法可以控制随机性以确保可重复的结果。

* 有两种方法可以确保在训练调用之间使用相同的重采样。 第一个是在调用 train 之前使用 set.seed。 随机数的第一个用途是创建重采样信息。 或者，如果您想使用数据的特定拆分，可以使用 trainControl 函数的 index 参数。 这将在下面简要讨论。

* 在重采样中创建模型时，还可以设置种子。 虽然在调用 train 之前设置种子可以保证使用相同的随机数，但在使用并行处理时不太可能出现这种情况（取决于使用的技术）。 为了设置模型拟合种子，trainControl 有一个名为seeds的附加参数可以使用。 此参数的值是用作种子的整数向量列表。  trainControl 的帮助页面描述了此选项的适当格式。

  如何使用随机数在很大程度上取决于包作者。 在极少数情况下，底层模型函数不控制随机数种子，尤其是在使用 C 代码进行计算的情况下。 另外，请注意某些包在加载时会加载随机数（直接或通过命名空间），这可能会影响可重复性。

#### 自定义调整过程

有几种方法可以自定义选择调整/复杂性参数和构建最终模型的过程。

##### 预处理选项

如前所述，train 可以在模型拟合之前以各种方式对数据进行预处理。 自动使用功能 preProcess。 此函数可用于居中和缩放、插补（参见下文详细信息）、通过主成分分析或独立成分分析应用空间符号变换和特征提取。

了指定应该进行什么预处理，train 函数有一个名为 preProcess 的参数。 此参数采用通常会传递给 preProcess 函数的方法参数的方法字符串。  preProcess 函数的附加选项可以通过 trainControl 函数传递。

这些处理步骤将在使用 predict.train、extractPrediction 或 extractProbs 生成的任何预测期间应用（请参阅本文档后面的详细信息）。 预处理不会应用于直接使用 object$finalModel 对象的预测。

对于插补，目前实现了三种方法：

* k-最近邻采用具有缺失值的样本，并在训练集中找到 k 个最接近的样本。 该预测器的 k 个训练集值的平均值用作原始数据的替代。 在计算到训练集样本的距离时，计算中使用的预测变量是该样本没有缺失值且训练集中没有缺失值的预测变量。
* 另一种方法是使用训练集样本为每个预测器拟合一个袋装树模型。 这通常是一个相当准确的模型，可以处理缺失值。 当样本的预测变量需要插补时，其他预测变量的值通过袋装树馈送，并将预测用作新值。 该模型可能具有显着的计算成本。
* 预测器训练集值的中位数可用于估计缺失数据。

如果训练集中存在缺失值，PCA 和 ICA 模型仅使用完整样本。

##### 交替调谐网格

用户可以指定调谐参数网格。 参数 tuneGrid 可以采用包含每个调整参数列的数据框。 列名应该与拟合函数的参数相同。 对于前面提到的 RDA 示例，名称将是 gamma 和 lambda。  train 将在行中的每个值组合上调整模型。

对于 boosted 树模型，我们可以固定学习率并评估 n.trees 的三个以上值：

```R
gbmGrid <-  expand.grid(interaction.depth = c(1, 5, 9), 
                        n.trees = (1:30)*50, 
                        shrinkage = 0.1,
                        n.minobsinnode = 20)
                        
nrow(gbmGrid)

set.seed(825)
gbmFit2 <- train(Class ~ ., data = training, 
                 method = "gbm", 
                 trControl = fitControl, 
                 verbose = FALSE, 
                 ## Now specify the exact models 
                 ## to evaluate:
                 tuneGrid = gbmGrid)
gbmFit2
```

另一种选择是使用可能的调整参数组合的随机样本，即“随机搜索”[(pdf)](http://www.jmlr.org/papers/volume13/bergstra12a/bergstra12a.pdf). This functionality is described on [this page](https://topepo.github.io/caret/random-hyperparameter-search.html).

要使用随机搜索，请在调用 trainControl 时使用选项 search = "random"。 在这种情况下，tuneLength 参数定义了将被评估的参数组合的总数。

##### 绘制重采样配置文件

plot 函数可用于检查性能估计与调整参数之间的关系。 例如，函数的简单调用显示了第一个性能度量的结果：

```R
trellis.par.set(caretTheme())
plot(gbmFit2)  
```

可以使用 metric 选项显示其他性能指标：

```R
trellis.par.set(caretTheme())
plot(gbmFit2, metric = "Kappa")
```

也可以使用其他类型的绘图。 有关更多详细信息，请参阅 ?plot.train。 下面的代码显示了结果的热图：

```R
trellis.par.set(caretTheme())
plot(gbmFit2, metric = "Kappa", plotType = "level",
     scales = list(x = list(rot = 90)))
```

也可以使用 ggplot 方法：

```R
ggplot(gbmFit2)  
```

还有一些绘图函数可以更详细地表示重新采样的估计值。 有关更多详细信息，请参阅 ?xyplot.train。

从这些图中，可能需要一组不同的调谐参数。 要在不重新启动整个过程的情况下更改最终值，可以使用 update.train 重新拟合最终模型。 见 ?update.train

##### trainControl 函数

函数 trainControl 生成进一步控制模型创建方式的参数，可能的方法：

* 重采样方法：“boot”、“cv”、“LOOCV”、“LGOCV”、“repeatedcv”、“timeslice”、“none”和“oob”。 最后一个值，即袋外估计，只能用于随机森林、袋装树、袋装地球、袋装灵活判别分析或条件树森林模型。 不包括 GBM 模型（gbm 包维护者表示，根据模型 OOB 误差估计和提升树来选择调整参数值不是一个好主意）。 此外，对于留一法交叉验证，重采样的性能度量没有给出不确定性估计。
* number 和 repeats：数字控制 K 折交叉验证中的折叠次数或用于引导和离开组交叉验证的重采样迭代次数。 重复仅适用于重复的 K 折交叉验证。 假设method = "repeatedcv", number = 10 and repeats = 3, 那么三个单独的10折交叉验证被用作重采样方案。
* verboseIter：打印训练日志的逻辑。
* returnData：将数据保存到名为 trainingData 的槽中的逻辑。
* p：对于离开组交叉验证：训练百分比 
* 对于 method = "timeslice"，trainControl 具有选项 initialWindow、horizon 和 fixedWindow，用于控制交叉验证如何用于时间序列数据。
* classProbs：一个逻辑值，确定在重新采样期间是否应该为保留的样本计算类概率。
* index 和 indexOut：包含每个重采样迭代元素的可选列表。 每个列表元素都是在该迭代中用于训练或应该保留的样本行。 当未指定这些值时，train 将生成它们。
* summaryFunction：用于计算替代性能摘要的函数。
* selectionFunction：选择最佳调整参数的函数。 和例子
* PCAthresh、ICAcomp 和 k：这些都是传递给 preProcess 函数（使用时）的选项。
* returnResamp：包含以下值之一的字符串：“all”、“final”或“none”。 这指定了要保存多少重新采样的性能度量。
* allowParallel：控制train是否应使用并行处理的逻辑（如果可用）。

这里没有讨论其他几个选项。

##### 替代性能指标

用户可以更改用于确定最佳设置的指标。 默认情况下，为回归计算 RMSE、R2 和平均绝对误差 (MAE)，而为分类计算准确度和 Kappa。 同样默认情况下，参数值是分别使用 RMSE 和准确性选择的，分别用于回归和分类。  train 函数的 metric 参数允许用户控制使用哪个最优标准。 例如，**在一类中样本百分比较低的问题中，使用 metric = "Kappa" 可以提高最终模型的质量。**

如果这些参数都不令人满意，用户还可以计算自定义性能指标。  trainControl 函数有一个名为 summaryFunction 的参数，它指定一个用于计算性能的函数。 该函数应具有以下参数：

data 是数据框或矩阵的参考，其中列称为 obs 和 pred 用于观察和预测的结果值（回归的数字数据或分类的字符值）。 目前，类概率不会传递给函数。 数据中的值是单个调整参数组合的保留预测（及其相关参考值）。 如果 trainControl 对象的 classProbs 参数设置为 TRUE，则数据中将出现包含类概率的附加列。 这些列的名称与类级别相同。 此外，如果在调用 train 中指定了权重，则数据集中也会有一个名为 weights 的列。 此外，如果使用了 train 的recipe方法（参见文档的这一部分），模型中未使用的其他变量也将包括在内。 这可以通过在“"performance var" recipe中添加一个角色来实现。 本网站的recipe部分给出了一个示例。

lev 是一个字符串，其中包含从训练数据中提取的结果因子级别。 对于回归，NULL 值被传递到函数中。

model 是正在使用的模型的字符串（即传递给 train 的方法参数的值）。

函数的输出应该是具有非空名称的数字汇总度量向量。 默认情况下，train 根据预测的类别评估分类模型。 可选地，类概率也可用于衡量性能。 要在重采样过程中获得预测的类概率，trainControl 中的参数 classProbs 必须设置为 TRUE。 这将概率列合并到每个重采样生成的预测中（每个类有一列，列名是类名）。

如上一节所示，自定义函数可用于计算重采样的平均性能分数。 另一个内置函数 twoClassSummary 将计算 ROC 曲线下的**灵敏度、特异性和面积**：

```R
head(twoClassSummary)
##                                                                                                                   ## 1 function (data, lev = NULL, model = NULL)             ## 2 {                                                      ## 3     lvls <- levels(data$obs)                          ## 4     if (length(lvls) > 2)                             ## 5         stop(paste("Your outcome has", length(lvls), "levels. The twoClassSummary() function isn't appropriate."))
## 6     requireNamespaceQuietStop("ModelMetrics")
```

要使用此标准重建提升树模型，我们可以使用以下代码查看调整参数与 ROC 曲线下面积之间的关系：

```R
fitControl <- trainControl(method = "repeatedcv",
                           number = 10,
                           repeats = 10,
                           ## Estimate class probabilities
                           classProbs = TRUE,
                           ## Evaluate performance using 
                           ## the following function
                           summaryFunction = twoClassSummary)

set.seed(825)
gbmFit3 <- train(Class ~ ., data = training, 
                 method = "gbm", 
                 trControl = fitControl, 
                 verbose = FALSE, 
                 tuneGrid = gbmGrid,
                 ## 指定要优化的指标
                 metric = "ROC")
gbmFit3
```

在这种情况下，与最佳调整参数相关的 ROC 曲线下的平均面积在 100 次重采样中为 0.922。

##### 选择最终模型

自定义调整过程的另一种方法是修改用于选择“最佳”参数值的算法，给定性能数字。 默认情况下，train 函数选择具有最大性能值（或最小，对于回归模型中的均方误差）的模型。 可以使用其他选择模型的方案。  Breiman 等人 (1984) 为简单的基于树的模型提出了“一个标准错误规则”。 在这种情况下，识别出具有最佳性能值的模型，并使用重采样来估计性能的标准误差。 **使用的最终模型是（经验上的）最佳模型的一个标准误差范围内的最简单模型**。 对于简单的树，这是有道理的，因为随着这些模型越来越针对训练数据，它们将开始过度拟合。

train 允许用户指定用于选择最终模型的替代规则。 参数 selectionFunction 可用于提供一个函数来通过算法确定最终模型。 包中有三个现有函数：best 是选择最大/最小值，oneSE 试图捕捉 Breiman 等人 (1984) 的精神，并且tolerance选择在最佳值的某个百分比容差范围内最不复杂的模型。 有关更多详细信息，请参阅 ?best。

可以使用用户定义的函数，只要它们具有以下参数：

* x 是包含调整参数及其相关性能指标的数据框。 每行对应一个不同的调整参数组合。
* metric 一个字符串，指示应该优化哪个性能指标（这是直接从 train.metric 参数传入的）。
* maximize是一个单一的逻辑值，指示性能指标的较大值是否更好（这也直接从调用传递到训练）。

该函数应输出一个整数，指示选择了 x 中的哪一行。

举个例子，如果我们根据整体精度选择之前的 boosted 树模型，我们会选择：n.trees = 1450，interaction.depth = 5，shrinkage = 0.1，n.minobsinnode = 20。 该图相当紧凑，准确度值从 0.863 到 0.922 不等。 一个不太复杂的模型（例如更少、更浅的树）也可能产生可接受的准确性。

 tolerance函数可用于基于 $ (x-x_{best})/x_{best}\times 100$（百分比差异）找到不太复杂的模型(返回坐标索引)。 例如，要根据 2% 的性能损失选择参数值： 

```R
whichTwoPct <- tolerance(gbmFit3$results, metric = "ROC", 
                         tol = 2, maximize = TRUE)  
cat("best model within 2 pct of best:\n")
## best model within 2 pct of best:
gbmFit3$results[whichTwoPct,1:6]
##    shrinkage interaction.depth n.minobsinnode n.trees       ROC      Sens
## 32       0.1                 5             20     100 0.9139707 0.8645833
```

这表明我们可以得到一个不太复杂的模型，其 ROC 曲线下的面积为 0.914（与“选择最佳”值 0.922 相比）。

这些函数的主要问题与从最简单到复杂的模型排序有关。 在某些情况下，这很容易（例如简单的树、偏最小二乘法），但在这种模型的情况下，模型的排序是主观的。 例如，使用 100 次迭代且树深度为 2 的提升树模型是否比使用 50 次迭代且深度为 8 的模型更复杂？ 该包对ordering做出了一些选择。 在提升树的情况下，该包假设增加迭代次数比增加树深度更快地增加复杂性，因此模型按迭代次数排序，然后按深度排序。 有关特定模型的更多示例，请参阅 ?best。

##### 提取预测和类别概率

如前所述，train 函数生成的对象在 finalModel 子对象中包含“优化”模型。 可以像往常一样根据这些对象进行预测。 在某些情况下，例如 pls 或 gbm 对象，可能需要**指定优化拟合的附加参数**。 在这些情况下，训练对象使用参数优化的结果来预测新样本。 例如，如果使用 predict.gbm 创建预测，则用户必须直接指定树的数量（没有默认值）。 此外，对于二元分类，此函数的预测采用类别之一的概率的形式，因此需要额外的步骤将其转换为因子向量。  predict.train 自动处理这些细节（和其他模型）。

此外，R 中模型预测的标准语法很少。例如，为了获得类概率，许多预测方法都有一个名为 type 的参数，用于指定是否应该生成类或概率。 不同的包使用不同的类型值，例如“prob”、“posterior”、“response”、“probability”或“raw”。 在其他情况下，使用完全不同的语法。

对于predict.train，类型选项被标准化为“class”和“prob”（底层代码将这些选项与每个模型的适当选项相匹配）。例如：

```R
predict(gbmFit3, newdata = head(testing))
## [1] R M R M R M
## Levels: M R
predict(gbmFit3, newdata = head(testing), type = "prob")
##              M            R
## 1 3.215213e-02 9.678479e-01
## 2 1.000000e+00 3.965815e-08
## 3 6.996088e-13 1.000000e+00
## 4 9.070652e-01 9.293483e-02
## 5 2.029754e-03 9.979702e-01
## 6 9.999662e-01 3.377548e-05
```

##### 探索和比较重采样分布

###### 模型内

有几个lattice函数可用于探索特定模型的调整参数与重采样结果之间的关系：

* xyplot 和 stripplot 可用于绘制重采样统计数据与（数字）调整参数的关系。
* 直方图和密度图也可用于查看调整参数中调整参数的分布。

例如，以下语句创建一个密度图：

```R
trellis.par.set(caretTheme())# lattice中的语法
densityplot(gbmFit3, pch = "|")
```

请注意，如果您有兴趣绘制跨多个调整参数的重采样结果，则应在控制对象中使用选项 resamples = "all"。

###### 模型间

caret 包还包括通过重采样分布来表征模型（使用 train、sbf 或 rfe 生成）之间差异的函数。 这些功能基于 Hothorn 等人的工作。  (2005) 和 Eugster 等人 (2008)。

首先，支持向量机模型适合声纳数据。 使用 preProc 参数对数据进行居中和缩放。 请注意，在与用于提升树模型的种子相同的模型之前设置了相同的随机数种子。 这确保使用相同的重采样集，这在我们比较模型之间的重采样配置文件时会派上用场。

```R
set.seed(825)
svmFit <- train(Class ~ ., data = training, 
                 method = "svmRadial", 
                 trControl = fitControl, 
                 preProc = c("center", "scale"),
                 tuneLength = 8,
                 metric = "ROC")
svmFit     

## Support Vector Machines with Radial Basis Function Kernel 
## 
## 157 samples
##  60 predictor
##   2 classes: 'M', 'R' 
## 
## Pre-processing: centered (60), scaled (60) 
## Resampling: Cross-Validated (10 fold, repeated 10 times) 
## Summary of sample sizes: 141, 142, 141, 142, 141, 142, ... 
## Resampling results across tuning parameters:
## 
##   C      ROC        Sens       Spec     
##    0.25  0.8438318  0.7373611  0.7230357
##    0.50  0.8714459  0.8083333  0.7316071
##    1.00  0.8921354  0.8031944  0.7653571
##    2.00  0.9116171  0.8358333  0.7925000
##    4.00  0.9298934  0.8525000  0.8201786
##    8.00  0.9318899  0.8684722  0.8217857
##   16.00  0.9339658  0.8730556  0.8205357
##   32.00  0.9339658  0.8776389  0.8276786
## 
## Tuning parameter 'sigma' was held constant at a value of 0.01181293
## ROC was used to select the optimal model using the largest value.
## The final values used for the model were sigma = 0.01181293 and C = 16.
```

此外，还拟合了正则化判别分析模型。

```R
set.seed(825)
rdaFit <- train(Class ~ ., data = training, 
                 method = "rda", 
                 trControl = fitControl, 
                 tuneLength = 4,
                 metric = "ROC")
rdaFit    
## Regularized Discriminant Analysis 
## 
## 157 samples
##  60 predictor
##   2 classes: 'M', 'R' 
## 
## No pre-processing
## Resampling: Cross-Validated (10 fold, repeated 10 times) 
## Summary of sample sizes: 141, 142, 141, 142, 141, 142, ... 
## Resampling results across tuning parameters:
## 
##   gamma      lambda     ROC        Sens       Spec     
##   0.0000000  0.0000000  0.6426029  0.9311111  0.3364286
##   0.0000000  0.3333333  0.8543564  0.8076389  0.7585714
##   0.0000000  0.6666667  0.8596577  0.8083333  0.7766071
##   0.0000000  1.0000000  0.7950670  0.7677778  0.6925000
##   0.3333333  0.0000000  0.8509276  0.8502778  0.6914286
##   0.3333333  0.3333333  0.8650372  0.8676389  0.6866071
##   0.3333333  0.6666667  0.8698115  0.8604167  0.6941071
##   0.3333333  1.0000000  0.8336930  0.7597222  0.7542857
##   0.6666667  0.0000000  0.8600868  0.8756944  0.6482143
##   0.6666667  0.3333333  0.8692981  0.8794444  0.6446429
##   0.6666667  0.6666667  0.8678547  0.8355556  0.6892857
##   0.6666667  1.0000000  0.8277133  0.7445833  0.7448214
##   1.0000000  0.0000000  0.7059797  0.6888889  0.6032143
##   1.0000000  0.3333333  0.7098313  0.6830556  0.6101786
##   1.0000000  0.6666667  0.7129489  0.6672222  0.6173214
##   1.0000000  1.0000000  0.7193031  0.6626389  0.6296429
## 
## ROC was used to select the optimal model using the largest value.
## The final values used for the model were gamma = 0.3333333 and lambda
##  = 0.6666667.
```

鉴于这些模型，我们能否对它们的性能差异做出统计陈述？ 为此，我们首先使用resamples收集重采样结果。

```R
resamps <- resamples(list(GBM = gbmFit3,
                          SVM = svmFit,
                          RDA = rdaFit))
resamps
## 
## Call:
## resamples.default(x = list(GBM = gbmFit3, SVM = svmFit, RDA = rdaFit))
## 
## Models: GBM, SVM, RDA 
## Number of resamples: 100 
## Performance metrics: ROC, Sens, Spec 
## Time estimates for: everything, final model fit
summary(resamps)
## 
## Call:
## summary.resamples(object = resamps)
## 
## Models: GBM, SVM, RDA 
## Number of resamples: 100 
## 
## ROC 
##          Min.  1st Qu.    Median      Mean   3rd Qu. Max. NA's
## GBM 0.6964286 0.874504 0.9375000 0.9216270 0.9821429    1    0
## SVM 0.7321429 0.905878 0.9464286 0.9339658 0.9821429    1    0
## RDA 0.5625000 0.812500 0.8750000 0.8698115 0.9392361    1    0
## 
## Sens 
##          Min.   1st Qu.    Median      Mean 3rd Qu. Max. NA's
## GBM 0.5555556 0.7777778 0.8750000 0.8776389       1    1    0
## SVM 0.5000000 0.7777778 0.8888889 0.8730556       1    1    0
## RDA 0.4444444 0.7777778 0.8750000 0.8604167       1    1    0
## 
## Spec 
##          Min.   1st Qu.    Median      Mean   3rd Qu. Max. NA's
## GBM 0.4285714 0.7142857 0.8571429 0.8133929 1.0000000    1    0
## SVM 0.4285714 0.7142857 0.8571429 0.8205357 0.9062500    1    0
## RDA 0.1428571 0.5714286 0.7142857 0.6941071 0.8571429    1    0
```

请注意，在这种情况下，选项 resamples = "final" 应该是用户在控制对象中定义的。

有几种点阵图方法可用于可视化重采样分布：密度图、盒须图、散点图矩阵和汇总统计的散点图。 例如： 

```R
theme1 <- trellis.par.get()
theme1$plot.symbol$col = rgb(.2, .2, .2, .4)
theme1$plot.symbol$pch = 16
theme1$plot.line$col = rgb(1, 0, 0, .7)
theme1$plot.line$lwd <- 2
trellis.par.set(theme1)
bwplot(resamps, layout = c(3, 1))
```

![img](https://topepo.github.io/caret/basic/train_resample_box-1.svg)

```R
trellis.par.set(caretTheme())
dotplot(resamps, metric = "ROC")
```

![img](https://topepo.github.io/caret/basic/train_resample_ci-1.svg)

```R
trellis.par.set(theme1)
xyplot(resamps, what = "BlandAltman")
```

![img](https://topepo.github.io/caret/basic/train_resample_ba-1.svg)

```R
splom(resamps)
```

![img](https://topepo.github.io/caret/basic/train_resample_scatmat-1.svg)

其他可视化在 densityplot.resamples 和 parallel.resamples 中可用 

由于模型适用于相同版本的训练数据(预先设定好种子就行)，因此推断模型之间的差异是有意义的。 通过这种方式，我们减少了可能存在的重采样内相关性。 我们可以计算差异，然后**使用简单的 t 检验来评估模型之间没有差异的零假设**。

```R
difValues <- diff(resamps)
difValues
## 
## Call:
## diff.resamples(x = resamps)
## 
## Models: GBM, SVM, RDA 
## Metrics: ROC, Sens, Spec 
## Number of differences: 3 
## p-value adjustment: bonferroni
summary(difValues)
## 
## Call:
## summary.diff.resamples(object = difValues)
## 
## p-value adjustment: bonferroni 
## Upper diagonal: estimates of the difference
## Lower diagonal: p-value for H0: difference = 0
## 
## ROC 
##     GBM       SVM       RDA     
## GBM           -0.01234   0.05182
## SVM 0.3388               0.06415
## RDA 5.988e-07 2.638e-10         
## 
## Sens 
##     GBM    SVM      RDA     
## GBM        0.004583 0.017222
## SVM 1.0000          0.012639
## RDA 0.5187 1.0000           
## 
## Spec 
##     GBM       SVM       RDA      
## GBM           -0.007143  0.119286
## SVM 1                    0.126429
## RDA 5.300e-07 1.921e-10

trellis.par.set(theme1)
bwplot(difValues, layout = c(3, 1))
```

![img](https://topepo.github.io/caret/basic/train_diff_box-1.svg)

```R
trellis.par.set(caretTheme())
dotplot(difValues)
```

![img](https://topepo.github.io/caret/basic/train_diff_ci-1.svg)

##### 没有参数调整的拟合模型

在模型调整值已知的情况下，train 可用于将模型拟合到整个训练集，而无需任何重采样或参数调整。 可以使用 trainControl 中的 method = "none" 选项。 例如：

```R
fitControl <- trainControl(method = "none", classProbs = TRUE)

set.seed(825)
gbmFit4 <- train(Class ~ ., data = training, 
                 method = "gbm", 
                 trControl = fitControl, 
                 verbose = FALSE, 
                 ## Only a single model can be passed to the
                 ## function when no resampling is used:
                 tuneGrid = data.frame(interaction.depth = 4,
                                       n.trees = 100,
                                       shrinkage = .1,
                                       n.minobsinnode = 20),
                 metric = "ROC")
gbmFit4

## Stochastic Gradient Boosting 
## 
## 157 samples
##  60 predictor
##   2 classes: 'M', 'R' 
## 
## No pre-processing
## Resampling: None
```

请注意，plot.train、resample、confusionMatrix.train 和其他几个函数将不适用于此对象，但 predict.train 和其他函数将适用：

```R
predict(gbmFit4, newdata = head(testing))
## [1] R M R R M M
## Levels: M R
predict(gbmFit4, newdata = head(testing), type = "prob")
## 1 0.264671996 0.73532800
## 2 0.960445979 0.03955402
## 3 0.005731862 0.99426814
## 4 0.298628996 0.70137100
## 5 0.503935367 0.49606463
## 6 0.813716635 0.18628336
```
