---
layout:     post                    # 使用的布局（不需要改）
title:      R包caret(1)            # 标题 
subtitle:   caret包中文使用指南 #副标题
date:       2022-02-24              # 时间
author:     HZ                      # 作者
header-img: img/bg-1st.jpg    #这篇文章标题背景图片
catalog: true                       # 是否归档
tags:                               #标签
    - R应用
---

### caret包简短介绍

caret 包（Classification And REgression Training 的缩写）包含简化复杂回归和分类问题的模型训练过程的功能。 该包使用了许多 R 包，但尽量不在包启动时加载它们（通过删除正式的包依赖项，包启动时间可以大大减少）。

安装caret使用

```R
install.packages("caret", dependencies = c("Depends", "Suggests"))
```

以确保安装了所有需要的软件包。

该包的主要帮助页面位于 https://topepo.github.io/caret/ 此处，有扩展示例和先前在包小插图中找到的大量信息。

 caret 有几个函数试图简化模型构建和评估过程，以及特征选择和其他技术。包中的主要工具之一是 train 函数，它可用于:

* 评估模型调整参数对性能的影响
* 使用重采样从这些参数中选择“最佳”模型
* 从训练集中估计模型性能

几乎可以自定义此过程的每个步骤（例如重采样技术、选择最佳参数等）。 为了演示此功能，将使用 mlbench 包中的声纳数据。

声纳数据由在 60 个预测器上收集的 208 个数据点组成。 目标是预测金属圆柱体的 M 类或岩石的 R 类）。

首先，我们将数据分成两组：训练集和测试集。 为此，使用 createDataPartition 函数： 

```R
library(caret)
library(mlbench)
data(Sonar)

set.seed(107)
inTrain <- createDataPartition(
  y = Sonar$Class,
  ## the outcome data are needed
  p = .75,
  ## The percentage of data in the
  ## training set
  list = FALSE
)
## The format of the results

## The output is a set of integers for the rows of Sonar
## that belong in the training set.
str(inTrain)
```

默认情况下，createDataPartition 对数据进行分层随机拆分。 对数据进行分区：

```R
training <- Sonar[ inTrain,]
testing  <- Sonar[-inTrain,]

nrow(training)
#> [1] 157
nrow(testing)
#> [1] 51
```

要使用上述算法调整模型，可以使用 train 函数。 有关此功能的更多详细信息，请访问 https://topepo.github.io/caret/model-training-and-tuning.html。 在这里，偏最小二乘判别分析 (PLSDA) 模型将在应保留的 PLS 组件数量上进行调整。 执行此操作的最基本语法是：

```R
plsFit <- train(
  Class ~ .,
  data = training,
  method = "pls", ## 偏最小二乘判别分析
  ## 将训练集和所有未来样本的预测变量居中并进行缩放。
  preProc = c("center", "scale")
)
```

但是，我们可能希望通过几种方式对其进行自定义：

* 扩展函数评估的 PLS 模型集。 默认情况下，该函数将调整每个调整参数的三个值。
* 使用的重采样类型。 默认情况下使用简单的引导程序。 我们将让函数使用 10 倍交叉验证的 3 次重复。
* 衡量绩效的方法。 如果未指定，则计算总体准确度和 Kappa 统计量。 对于回归模型，计算均方根误差和 $R^2$。 在这里，函数将被更改以估计 ROC 曲线下的面积、敏感性和特异性

要更改调整参数的候选值，可以使用 tuneLength 或 tuneGrid 参数。  train 函数可以生成一组候选参数值，tuneLength 参数**控制要评估的参数值**。 在 PLS 的情况下，该函数使用从 1 到 tuneLength 的整数序列。 如果我们想计算 1 到 15 之间的所有整数，设置 tuneLength = 15 可以实现这一点。 当需要特定值时使用 tuneGrid 参数。 使用数据框，其中每行是一个调整参数设置，每列是一个调整参数。 下面用一个例子来说明这一点。

```R
plsFit <- train(
  Class ~ .,
  data = training,
  method = "pls",
  preProc = c("center", "scale"),
  ## added:
  tuneLength = 15
)
```

为了修改重采样方法，使用了 trainControl 函数。  option 方法控制重采样的类型，默认为“boot”。 另一种方法“repeatedcv”用于指定重复的 K 折交叉验证（并且参数 repeats 控制重复次数）。  K 由 number 参数控制，默认为 10。新的语法是：

```R
ctrl <- trainControl(method = "repeatedcv", repeats = 3)
## traubControl控制重采样的方式

plsFit <- train(
  Class ~ .,
  data = training,
  method = "pls",
  preProc = c("center", "scale"),
  tuneLength = 15,
  ## added:
  trControl = ctrl
)
```

最后，为了选择不同的性能度量，trainControl 提供了额外的参数。  summaryFunction 参数用于传入一个函数，该函数采用观察值和预测值并估计一些性能度量。 包中已包含两个这样的函数：defaultSummary 和 twoClassSummary。 后者将计算特定于两类问题的度量，例如 ROC 曲线下的面积、敏感性和特异性。 由于 ROC 曲线基于预测的类别概率（不会自动计算），因此需要另一个选项。  classProbs = TRUE 选项用于包括这些计算。

最后，该函数将选择与最佳结果相关的调整参数。 由于我们使用自定义性能度量，因此还必须指定应该优化的标准。 在训练调用中，我们可以使用 metric = "ROC" 来做到这一点。

```R
ctrl <- trainControl(
  method = "repeatedcv", 
  repeats = 3,
  classProbs = TRUE, 
  summaryFunction = twoClassSummary
)

set.seed(123)
plsFit <- train(
  Class ~ .,
  data = training,
  method = "pls",
  preProc = c("center", "scale"),
  tuneLength = 15,
  trControl = ctrl,
  metric = "ROC"
)
plsFit
#> Partial Least Squares 
#> 
#> 157 samples
#>  60 predictor
#>   2 classes: 'M', 'R' 
#> 
#> Pre-processing: centered (60), scaled (60) 
#> Resampling: Cross-Validated (10 fold, repeated 3 times) 
#> Summary of sample sizes: 141, 141, 142, 142, 141, 142, ... 
#> Resampling results across tuning parameters:
#> 
#>   ncomp  ROC    Sens   Spec 
#>    1     0.805  0.726  0.690
#>    2     0.848  0.750  0.801
#>    3     0.849  0.764  0.748
#>    4     0.836  0.765  0.736
#>    5     0.812  0.748  0.755
#>    6     0.789  0.724  0.699
#>    7     0.794  0.744  0.689
#>    8     0.801  0.739  0.698
#>    9     0.793  0.758  0.677
#>   10     0.790  0.741  0.690
#>   11     0.787  0.742  0.710
#>   12     0.777  0.737  0.715
#>   13     0.772  0.738  0.700
#>   14     0.768  0.718  0.690
#>   15     0.768  0.715  0.690
#> 
#> ROC was used to select the optimal model using
#>  the largest value.
#> The final value used for the model was ncomp = 3.
```

在此输出中，结果网格是对性能的平均重采样估计。 底部的注释告诉用户发现 3 个 PLS 组件是最佳的。 基于此值，最终的 PLS 模型使用此规范拟合整个数据集，这是用于预测未来样本的模型。

该包具有多个用于可视化结果的功能。 这样做的一种方法是训练对象的 ggplot 函数。 命令 ggplot(plsFit) 产生了如图所示的结果，并显示了重新采样的性能值与 PLS 组件数量之间的关系。

```R
ggplot(plsFit)
```

要预测新样本，可以使用 predict.train。 对于分类模型，默认行为是计算预测类。 选项 type = "prob" 可用于从模型计算类概率。 例如：

```R
plsClasses <- predict(plsFit, newdata = testing)
str(plsClasses)
#>  Factor w/ 2 levels "M","R": 2 1 1 1 2 2 1 2 2 2 ...
plsProbs <- predict(plsFit, newdata = testing, type = "prob")
head(plsProbs)
#>        M     R
#> 6  0.288 0.712
#> 8  0.648 0.352
#> 9  0.659 0.341
#> 15 0.529 0.471
#> 26 0.430 0.570
#> 27 0.492 0.508
```

caret 包含一个函数来计算模型拟合的混淆矩阵和相关统计数据：

```R
confusionMatrix(data = plsClasses, testing$Class)
#> Confusion Matrix and Statistics
#> 
#>           Reference
#> Prediction  M  R
#>          M 21  7
#>          R  6 17
#>                                         
#>                Accuracy : 0.745         
#>                  95% CI : (0.604, 0.857)
#>     No Information Rate : 0.529         
#>     P-Value [Acc > NIR] : 0.00131       
#>                                         
#>                   Kappa : 0.487         
#>                                         
#>  Mcnemar's Test P-Value : 1.00000       
#>                                         
#>             Sensitivity : 0.778         
#>             Specificity : 0.708         
#>          Pos Pred Value : 0.750         
#>          Neg Pred Value : 0.739         
#>              Prevalence : 0.529         
#>          Detection Rate : 0.412         
#>    Detection Prevalence : 0.549         
#>       Balanced Accuracy : 0.743         
#>                                         
#>        'Positive' Class : M             
#> 
```

为了将另一个模型拟合到数据中，可以通过最少的更改调用 train。 可用模型列表可以在 https://topepo.github.io/caret/available-models.html 或 https://topepo.github.io/caret/train-models-by-tag.html 找到。 例如，要为这些数据拟合正则化判别模型，可以使用以下语法：

```R
## To illustrate, a custom grid is used
rdaGrid = data.frame(gamma = (0:4)/4, lambda = 3/4)
set.seed(123)
rdaFit <- train(
  Class ~ .,
  data = training,
  method = "rda",
  tuneGrid = rdaGrid,
  trControl = ctrl,
  metric = "ROC"
)
rdaFit
#> Regularized Discriminant Analysis 
#> 
#> 157 samples
#>  60 predictor
#>   2 classes: 'M', 'R' 
#> 
#> No pre-processing
#> Resampling: Cross-Validated (10 fold, repeated 3 times) 
#> Summary of sample sizes: 141, 141, 142, 142, 141, 142, ... 
#> Resampling results across tuning parameters:
#> 
#>   gamma  ROC    Sens   Spec 
#>   0.00   0.778  0.723  0.682
#>   0.25   0.887  0.864  0.786
#>   0.50   0.876  0.851  0.730
#>   0.75   0.863  0.830  0.710
#>   1.00   0.734  0.680  0.636
#> 
#> Tuning parameter 'lambda' was held constant at a
#>  value of 0.75
#> ROC was used to select the optimal model using
#>  the largest value.
#> The final values used for the model were gamma =
#>  0.25 and lambda = 0.75.
rdaClasses <- predict(rdaFit, newdata = testing)
confusionMatrix(rdaClasses, testing$Class)
#> Confusion Matrix and Statistics
#> 
#>           Reference
#> Prediction  M  R
#>          M 25  5
#>          R  2 19
#>                                         
#>                Accuracy : 0.863         
#>                  95% CI : (0.737, 0.943)
#>     No Information Rate : 0.529         
#>     P-Value [Acc > NIR] : 5.01e-07      
#>                                         
#>                   Kappa : 0.723         
#>                                         
#>  Mcnemar's Test P-Value : 0.45          
#>                                         
#>             Sensitivity : 0.926         
#>             Specificity : 0.792         
#>          Pos Pred Value : 0.833         
#>          Neg Pred Value : 0.905         
#>              Prevalence : 0.529         
#>          Detection Rate : 0.490         
#>    Detection Prevalence : 0.588         
#>       Balanced Accuracy : 0.859         
#>                                         
#>        'Positive' Class : M             
#> 
```

这些模型在重采样结果方面如何比较？  resamples 函数可用于收集、汇总和对比重采样结果。 由于随机数种子在调用 `train} 之前被初始化为相同的值，因此每个模型使用相同的折叠。 组装它们：

```R
resamps <- resamples(list(pls = plsFit, rda = rdaFit))
summary(resamps)
#> 
#> Call:
#> summary.resamples(object = resamps)
#> 
#> Models: pls, rda 
#> Number of resamples: 30 
#> 
#> ROC 
#>      Min. 1st Qu. Median  Mean 3rd Qu.  Max. NA's
#> pls 0.679   0.787  0.823 0.849   0.938 0.984    0
#> rda 0.750   0.847  0.889 0.887   0.940 1.000    0
#> 
#> Sens 
#>      Min. 1st Qu. Median  Mean 3rd Qu. Max. NA's
#> pls 0.556   0.625  0.750 0.764   0.875    1    0
#> rda 0.625   0.757  0.875 0.864   1.000    1    0
#> 
#> Spec 
#>      Min. 1st Qu. Median  Mean 3rd Qu. Max. NA's
#> pls 0.429   0.714  0.714 0.748   0.857    1    0
#> rda 0.500   0.714  0.750 0.786   0.875    1    0
```

有几个函数可以将这些结果可视化。 例如，可以使用以下方法创建 Bland-Altman 类型的图:

```R
xyplot(resamps, what = "BlandAltman")
```

结果看起来很相似。 由于对于每个重采样都有成对的结果，因此可以使用配对 t 检验来评估 ROC 曲线下的平均重采样面积是否存在差异。  diff.resamples 函数可用于计算：

```R
diffs <- diff(resamps)
summary(diffs)
#> 
#> Call:
#> summary.diff.resamples(object = diffs)
#> 
#> p-value adjustment: bonferroni 
#> Upper diagonal: estimates of the difference
#> Lower diagonal: p-value for H0: difference = 0
#> 
#> ROC 
#>     pls      rda    
#> pls          -0.0378
#> rda 0.000544        
#> 
#> Sens 
#>     pls      rda 
#> pls          -0.1
#> rda 0.000172     
#> 
#> Spec 
#>     pls   rda    
#> pls       -0.0387
#> rda 0.136
```

结果看起来很相似。由于每次重采样都有配对结果，因此可以使用配对t检验来评估ROC曲线下的平均重采样面积是否存在差异。diff.resamples函数可用于计算：

```R
diffs <- diff(resamps)
summary(diffs)
#> 
#> Call:
#> summary.diff.resamples(object = diffs)
#> 
#> p-value adjustment: bonferroni 
#> Upper diagonal: estimates of the difference
#> Lower diagonal: p-value for H0: difference = 0
#> 
#> ROC 
#>     pls      rda    
#> pls          -0.0378
#> rda 0.000544        
#> 
#> Sens 
#>     pls      rda 
#> pls          -0.1
#> rda 0.000172     
#> 
#> Spec 
#>     pls   rda    
#> pls       -0.0387
#> rda 0.136
```

根据该分析，模型之间的差异为-0.038 ROC单位（RDA模型略高），该差异的双侧p值为5e-04。

### 预处理

#### 零和近零方差预测变量

在某些情况下，数据生成机制可以创建只有一个唯一值的预测变量（即“零方差预测变量”）。 对于许多模型（不包括基于树的模型），这可能会导致模型崩溃或拟合不稳定。

同样，预测变量可能只有少数出现频率非常低的唯一值。 例如，在耐药性数据中，nR11 描述符（11 元环的数量）数据有几个非常不平衡的独特数值：

```R
data(mdrr)
data.frame(table(mdrrDescr$nR11))
##   Var1 Freq
## 1    0  501
## 2    1    4
## 3    2   23
```

当数据被分成交叉验证/引导子样本或少数样本可能对模型产生不当影响时，这些预测变量可能会成为零方差预测变量。 在建模之前，**可能需要识别和消除这些“接近零方差”的预测变量**。

为了识别这些类型的预测变量，可以计算以下两个指标： 

* 最普遍的值在第二个最频繁的值上的频率（称为“频率比”），对于表现良好的预测变量，该频率接近 1，对于高度不平衡的数据
* “唯一值的百分比”非常大 是唯一值的数量除以随着数据粒度增加而接近零的样本总数（乘以 100） 

**如果频率比大于预先指定的阈值并且唯一值百分比小于阈值， 我们可能会认为预测变量接近零方差。**

我们不想错误地识别具有低粒度但均匀分布的数据，例如来自离散均匀分布的数据。 使用这两个标准不会错误地检测到此类预测因子。

查看 MDRR 数据，nearZeroVar 函数可用于识别接近零方差的变量(saveMetrics 参数可用于显示详细信息，通常默认为 FALSE)

```R
nzv <- nearZeroVar(mdrrDescr, saveMetrics= TRUE)
nzv[nzv$nzv,][1:10,]

dim(mdrrDescr)
## 除去近零方差预测变量
nzv <- nearZeroVar(mdrrDescr)
filteredDescr <- mdrrDescr[, -nzv]
dim(filteredDescr)
```

默认情况下，nearZeroVar 将返回标记为有问题的变量的位置。

#### 识别相关预测变量

虽然有一些模型在相关预测变量（例如 pls）上茁壮成长，但其他模型可能会受益于降低预测变量之间的相关性水平。

 给定一个相关矩阵，findCorrelation 函数使用以下算法来标记要移除的预测变量：

```R
descrCor <-  cor(filteredDescr)
highCorr <- sum(abs(descrCor[upper.tri(descrCor)]) > .999)
```

对于之前的 MDRR 数据，有 65 个描述符几乎完全相关（|correlation| > 0.999），例如原子组成的总信息指数（IAC）和总信息含量指数（0阶邻域对称性）（  TIC0)（相关性 = 1）。 下面的代码块显示了删除绝对相关性高于 0.75 的描述符的效果。

```R
descrCor <- cor(filteredDescr)
summary(descrCor[upper.tri(descrCor)])
##删去高相关
highlyCorDescr <- findCorrelation(descrCor, cutoff = .75)
filteredDescr <- filteredDescr[,-highlyCorDescr]
descrCor2 <- cor(filteredDescr)
summary(descrCor2[upper.tri(descrCor2)])
```

#### 线性依赖

函数 findLinearCombos 使用矩阵的 QR 分解来枚举线性组合集（如果存在）。 例如，考虑以下矩阵，它可能由双向实验布局的非满秩参数化产生：

```R
ltfrDesign <- matrix(0, nrow=6, ncol=6)
ltfrDesign[,1] <- c(1, 1, 1, 1, 1, 1)
ltfrDesign[,2] <- c(1, 1, 1, 0, 0, 0)
ltfrDesign[,3] <- c(0, 0, 0, 1, 1, 1)
ltfrDesign[,4] <- c(1, 0, 0, 1, 0, 0)
ltfrDesign[,5] <- c(0, 1, 0, 0, 1, 0)
ltfrDesign[,6] <- c(0, 0, 1, 0, 0, 1)
```

请注意，第二列和第三列加起来就是第一列。 同样，第四列、第五列和第六列加起来就是第一列。  findLinearCombos 将返回一个枚举这些依赖项的列表。 对于每个线性组合，它将从矩阵中逐步删除列并测试是否已解决依赖关系。  findLinearCombos 还将返回一个列位置向量，可以删除列位置以消除线性依赖关系：

```R
comboInfo <- findLinearCombos(ltfrDesign)
comboInfo

## $linearCombos
## $linearCombos[[1]]
## [1] 3 1 2
## 
## $linearCombos[[2]]
## [1] 6 1 4 5
## 
## 
## $remove
## [1] 3 6

ltfrDesign[, -comboInfo$remove]
```

当使用大量二元化学指纹来描述分子结构时，可能会出现这些类型的依赖性。

#### preProcess函数

preProcess 类可用于预测变量的许多操作，包括居中和缩放。 函数 preProcess 估计每个操作所需的参数，predict.preProcess 用于将它们应用于特定的数据集。 这个函数也可以是调用train函数时的接口。
    在接下来的几节中描述了几种类型的技术，然后使用另一个示例来演示如何使用多种方法。 请注意，在所有情况下，preProcess 函数都会从特定数据集（例如训练集）中**估计它需要的任何内容，然后将这些转换应用于任何数据集，而无需重新计算值**

#### 居中和缩放

在下面的示例中，MDRR 数据的一半用于估计预测变量的位置和规模。 函数 preProcess 实际上并不预处理数据。  predict.preProcess 用于**预处理此数据集和其他数据集**。

```R
set.seed(96)
inTrain <- sample(seq(along = mdrrClass), length(mdrrClass)/2)

training <- filteredDescr[inTrain,]
test <- filteredDescr[-inTrain,]
trainMDRR <- mdrrClass[inTrain]
testMDRR <- mdrrClass[-inTrain]

preProcValues <- preProcess(training, method = c("center", "scale"))

trainTransformed <- predict(preProcValues, training)
testTransformed <- predict(preProcValues, test)
```

预处理选项“scale”将数据缩放到零和一之间的区间。

#### 插补

preProcess 可用于仅根据训练集中的信息来估算数据集。 这样做的一种方法是使用 **K 最近邻**。 对于任意样本，在训练集中找到 K 个最近邻，并使用这些值（例如使用平均值）估算预测器的值。 无论method参数中的内容如何，使用这种方法都会自动触发 preProcess 来居中和缩放数据。 或者，**袋装树也可用于插补**。 对于数据中的每个预测变量，使用训练集中的所有其他预测变量创建一个袋装树。 当新样本具有缺失的预测值时，使用袋装模型来预测该值。 虽然理论上这是一种更强大的插补方法，但计算成本远高于最近邻技术。

#### 转换预测变量

在某些情况下，需要使用主成分分析 (PCA) 将数据转换为较小的子空间，其中新变量彼此不相关。  preProcess 类可以通过在方法参数中包含“pca”来应用此转换。 这样做也会强制缩放预测变量。 请注意，当请求 PCA 时，predict.preProcess 会将列名称更改为 PC1、PC2 等。

类似地，独立分量分析 (ICA) 也可用于查找新变量，这些变量是原始集合的线性组合，因此分量是独立的（而不是 PCA 中的不相关）。 新变量将被标记为 IC1、IC2 等。

“空间符号”转换（Serneels 等人，2006 年）将预测变量的数据投影到 p 维的单位圆，其中 p 是预测变量的数量。 本质上，数据向量除以其范数。 在应用此转换之前，应将预测变量居中并按比例缩放。

```R
library(AppliedPredictiveModeling)
transparentTheme(trans = .4)

plotSubset <- data.frame(scale(mdrrDescr[, c("nC", "X4v")])) 
xyplot(nC ~ X4v,
       data = plotSubset,
       groups = mdrrClass, 
       auto.key = list(columns = 2))  
```

在空间符号之后：

```R
transformed <- spatialSign(plotSubset)
transformed <- as.data.frame(transformed)
xyplot(nC ~ X4v, 
       data = transformed, 
       groups = mdrrClass, 
       auto.key = list(columns = 2)) 
```

如果数据大于零，另一个选项“BoxCox”将估计预测变量上的 Box-Cox 变换。

```R
preProcValues2 <- preProcess(training, method = "BoxCox")
trainBC <- predict(preProcValues2, training)
testBC <- predict(preProcValues2, test)
preProcValues2
```

NA 值对应于无法转换的预测变量。 此转换要求数据大于零。 两个类似的变换，Manly (1976) 的 Yeo-Johnson 和指数变换也可以用于 preProcess。

#### 放一起

在应用预测建模中有一个案例研究，其中预测了高性能计算环境中作业的执行时间。 数据是：

```R
library(AppliedPredictiveModeling)
data(schedulingData)
str(schedulingData)
```

数据是分类和数字预测变量的混合。 假设我们想对连续预测变量使用 Yeo-Johnson 变换，然后将它们居中并进行缩放。 **我们还假设我们将运行一个基于树的模型，因此我们可能希望将因子保留为因子（而不是创建虚拟变量）**。 我们在除最后一列之外的所有列上运行该函数，这是结果。

```R
pp_hpc <- preProcess(schedulingData[, -8], 
                     method = c("center", "scale", "YeoJohnson"))
pp_hpc

## Created from 4331 samples and 7 variables
## 
## Pre-processing:
##   - centered (5)
##   - ignored (2)
##   - scaled (5)
##   - Yeo-Johnson transformation (5)
## 
## Lambda estimates for Yeo-Johnson transformation:
## -0.08, -0.03, -1.05, -1.1, 1.44

transformed <- predict(pp_hpc, newdata = schedulingData[, -8])
head(transformed)

##   Protocol  Compounds InputFields Iterations NumPending         Hour Day
## 1        E  1.2289592  -0.6324580 -0.0615593  -0.554123  0.004586516 Tue
## 2        E -0.6065826  -0.8120473 -0.0615593  -0.554123 -0.043733201 Tue
## 3        E -0.5719534  -1.0131504 -2.7894869  -0.554123 -0.034967177 Thu
## 4        E -0.6427737  -1.0047277 -0.0615593  -0.554123 -0.964170752 Fri
## 5        E -0.5804713  -0.9564504 -0.0615593  -0.554123 -0.902085020 Fri
## 6        E -0.5804713  -0.9564504 -0.0615593  -0.554123  0.698108782 Wed
```

输出中标记为“已忽略”的两个预测变量是两个因子预测变量。 这些没有改变，但数字预测变量被转换。 但是，待处理作业数量的预测变量具有非常稀疏且不平衡的分布：

```
mean(schedulingData$NumPending == 0)
## [1] 0.7561764
```

对于其他一些模型，这可能是一个问题（特别是如果我们重新采样或下采样数据）。 在运行预处理计算之前，我们可以添加一个过滤器来检查零方差或接近零方差的预测变量：

```R
pp_no_nzv <- preProcess(schedulingData[, -8], 
                        method = c("center", "scale", "YeoJohnson", "nzv"))
pp_no_nzv
##结果：
## Created from 4331 samples and 7 variables
## 
## Pre-processing:
##   - centered (4)
##   - ignored (2)
##   - removed (1)
##   - scaled (4)
##   - Yeo-Johnson transformation (4)
## 
## Lambda estimates for Yeo-Johnson transformation:
## -0.08, -0.03, -1.05, 1.44

predict(pp_no_nzv, newdata = schedulingData[1:6, -8])
```

请注意，一个预测变量被标记为“已删除”，并且处理后的数据缺少稀疏预测变量。

#### 类别距离计算

caret 包含根据到类质心的距离生成新的预测变量的函数（类似于线性判别分析的工作原理）。 对于因子变量的每个级别，计算类质心和协方差矩阵。 对于新样本，计算到每个类质心的马哈拉诺比斯距离，**并可用作额外的预测变量。 当真正的决策边界实际上是线性的时，这对非线性模型很有帮助**。

如果类中的预测变量多于样本，则 classDist 函数具有称为 pca 的参数，并保留允许使用每个类中的主成分分析的参数，以避免奇异协方差矩阵的问题。

 然后使用 predict.classDist 生成类距离。 默认情况下，会记录距离，但这可以通过 predict.classDist 的 trans 参数进行更改。

例如，我们可以使用 MDRR 数据。

```R
centroids <- classDist(trainBC, trainMDRR)
distances <- predict(centroids, testBC)
distances <- as.data.frame(distances)
head(distances)

##                dist.Active dist.Inactive
## ACEPROMAZINE      3.787139      3.941234
## ACEPROMETAZINE    4.306137      3.992772
## MESORIDAZINE      3.707296      4.324115
## PERIMETAZINE      4.079938      4.117170
## PROPERICIAZINE    4.174101      4.430957
## DUOPERONE         4.355328      6.000025
```

此图显示了保留样本的类距离的散点图矩阵：

```R
xyplot(dist.Active ~ dist.Inactive,
       data = distances, 
       groups = testMDRR, 
       auto.key = list(columns = 2))
```

![img](https://topepo.github.io/caret/preprocess/pp_splom-1.svg)

#### 补充：preProcess的细节

在所有情况下，使用 x 中的数据估计转换和操作，并使用这些值将这些操作应用于新数据； 使用 predict 函数时**不会重新计算任何内容**。

Box-Cox (method = "BoxCox")、Yeo-Johnson (method = "YeoJohnson") 和指数变换 (method = "expoTrans") 在这里被“重新利用”：它们被用来转换预测变量。  Box-Cox 变换是为变换响应变量而开发的，而另一种方法 Box-Tidwell 变换是用于估计预测变量数据的变换。 然而，Box-Cox 方法更简单，计算效率更高，并且对于估计幂变换同样有效。  Yeo-Johnson 变换类似于 Box-Cox 模型，但可以容纳具有零和/或负值的预测变量（而 Box-Cox 变换的预测变量值必须严格为正）。  Manly (1976) 的指数变换也可用于正数据或负数据。

method = "center" 从预测变量值中减去预测变量数据的平均值（再次从 x 中的数据），而 method = "scale" 除以标准偏差。

“范围”转换将数据缩放到范围边界内。 如果新样本的值大于或小于训练集中的值，则值将超出此范围。

在计算中忽略非数字的预测变量（包括方法“zv'”和“nzv'”）。

method = "zv" 标识具有单个值（即具有零方差）的数字预测器列，并将它们从进一步的计算中排除。 类似地，method = "nzv" 通过应用 nearZeroVar 排除“接近零方差”预测变量来执行相同的操作。 选项 freqCut 和 uniqueCut 可用于修改过滤器。

method = "corr" 试图过滤掉高度相关的预测变量。 请参阅查找相关性。

对于分类，method = "conditionalX" 检查以结果为条件的每个预测变量的分布。 如果任何类别中只有一个唯一值，则预测变量将被排除在进一步的计算之外（请参阅 checkConditionalX 示例）。 当结果不是一个因素时，不执行此计算。 当在通过train重采样时使用此操作可能会很耗时。

这些操作按以下顺序应用：零方差滤波器、近零方差滤波器、相关滤波器、Box-Cox/Yeo-Johnson/指数变换、居中、缩放、范围、插补、PCA、ICA 然后是空间符号。 这与 4.76 版之前的插入符号版本（首先进行插补）不同，如果使用装袋进行插补，则不向后兼容。

如果请求 PCA 但没有居中和缩放，则值仍将居中和缩放。 同样，当请求 ICA 时，数据会自动居中和缩放。

k-最近邻插补是通过在训练集中找到k个最近的样本（欧几里得距离）来进行的。 通过装袋进行的插补适合每个预测器的装袋树模型（作为所有其他预测器的函数）。 这种方法简单、准确并且可以接受缺失值，但计算成本要高得多。 通过中位数进行插补采用训练集中每个预测变量的中位数，并使用它们来填充缺失值。 这种方法简单、快速并且接受缺失值，但独立处理每个预测变量，并且可能不准确。

如果同时请求 PCA 和 ICA，则会引发警告。 由 fastICA 包实现的 ICA 在找到 ICA 分数之前自动进行 PCA 分解。

除非调用 method = "zv" 或 method = "nzv"，否则该函数将抛出 x 中任何数值变量少于两个唯一值的错误。

非数字数据不会被预处理，它们的值将在预测函数生成的数据框中。 请注意，当使用 PCA 或 ICA 时，非数字列在预测时可能处于不同的位置。
