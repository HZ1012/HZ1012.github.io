---
layout:     post                    # 使用的布局（不需要改）
title:      时间序列的R实现            # 标题 
subtitle:   《Forecasting: Principles and Practice，3rd》中文版整理 #副标题
date:       2022-02-26              # 时间
author:     HZ                      # 作者
header-img: img/time series.jpg  #这篇文章标题背景图片
catalog: true                       # 是否归档
tags:                               #标签
    - 统计学习
    - 数学建模
---

前言：时间序列分析是统计学习中的重要分支，在商业分析、数据挖掘中具有重要作用。R语言作为强大的数据分析工具在时间序列方面也具有其过人之处。但现有中文教材在R实践时间序列方面仍过于老旧。
《Forecasting: Principles and Practice》（Rob J Hyndman and George Athanasopoulos）是讲解时间序列并基于R实现的强大有用书籍，现已更新到第三版，但是中文版仍只有第二版，笔者于2020年暑期阅览该书第三版，提炼并总结了该书中的重要知识翻译出来。
另一方面，在金融时间序列分析问题中需要掌握到一些更深的知识，笔者适度补充《金融时间序列分析》（李东风）中部分章节知识，希望为各位同仁提供更方便的学习途径。

### 时间序列

#### tssibble 简短使用指南

tsibble 包将 tidyverse 扩展到时间数据。 建立在 tibble 之上的 tsibble（或 tbl_ts）是一个面向数据和模型的对象。 与 R 中传统的时间序列对象（例如 ts、zoo 和 xts）相比，tsibble 保留了时间索引作为基本数据列，并使异构数据结构成为可能。 除了类似 tibble 的表示之外，还引入了由单个或多个变量组成的键，以随着时间的推移唯一地标识观察单位（索引）。  tsibble 包旨在管理时态数据并在流畅的工作流程中完成分析。

上下文语义：索引和键

tsibble() 创建一个 tsibble 对象，而 as_tsibble() 是一种 S3 方法，用于将其他对象强制转换为 tsibble。 向量/矩阵作为基础的对象，例如 ts 和 mts，可以使用 as_tsibble() 自动转换为 tsibble，无需任何规范。 如果它是一个 tibble 或数据帧， as_tsibble() 需要更多的设置来声明索引和关键变量。

nycflights13 包中包含的天气数据包含 2013 年纽约市三个站点（即 JFK、LGA 和 EWR）的每小时气象记录（如温度、湿度和降水）。 由于 time_hour 是唯一涉及时间戳的列，因此 as_tsibble() 将其默认为索引变量； 或者，可以通过参数 index = time_hour 指定索引以禁用详细消息。

除了索引，tsibble 需要“key”，它定义了随时间测量的主题或个人。 在这个例子中，原始变量是标识符，它被传递给 as_tsibble() 中的参数键。 每个观察都应由有效 tsibble 中的索引和键唯一标识。 其他——温度、湿度和降水——被称为测量变量。 创建 tsibble 时，将首先对键进行排序，然后是从过去到最近排列时间。

根据相应的时间表示自动获得一个间隔：

- `integer`/`numeric`/`ordered`: either “unit” or “year” (`Y`)
- `yearquarter`/`yearqtr`: “quarter” (`Q`)
- `yearmonth`/`yearmon`: “month” (`M`)
- `yearweek`: “week” (`W`)
- `Date`: “day” (`D`)
- `difftime`: “week” (`W`), “day” (D), “hour” (`h`), “minute” (`m`), “second” (`s`)
- `POSIXct`/`hms`: “hour” (`h`), “minute” (`m`), “second” (`s`), “millisecond” (`us`), “microsecond” (`ms`)
- `nanotime`: “nanosecond” (`ns`)

也就是说，每月间隔的 tsibble 期望索引列中的 `yearmonth`/`yearmon` 类。  `Date` 和 `POSIXct` 都不提供每月的 tsibble。

 打印显示以数据为中心并提供上下文信息，例如数据维度、时间间隔和基于时间的单位数。 上面显示了 `weather_tsbl` 的一小时间隔（`[1h]`）和作为键的 `origin [3]` 以及表中的三个时间序列。

数据管道

这种整洁的数据表示最自然地支持将数据操作视为构建块，形成基于时间的上下文中“数据管道”的一部分。 熟悉 tidyverse 的用户会发现执行常见的时间分析任务更容易。 例如， index_by() 在时间上下文中是 group_by() 的对应物，但它只对时间索引进行分组。  index_by() + summarise() 用于总结每个站点的每日高点和低点。 结果，索引从索引 time_hour 更新为间隔一天的日期； 为每日最高和最低温度创建和计算两个新变量。

不规则的时间间隔

请注意，tsibble 可以根据其时间表示（参见 ?tsibble）很好地处理从几秒到几年的规则间隔时间数据。 默认情况下，选项常规在 as_tsibble() 中设置为 TRUE。 将regular 指定为FALSE 可为以不规则时间间隔收集的数据创建tsibble。 下面显示了纽约航班的预定日期时间：

#### 基础知识

时间序列模式：

##### 趋势：

当数据长期增加或减少时，存在趋势。它不必是线性的。有时我们会将趋势称为“改变方向”，当它可能从增加趋势变为减少趋势时。图2.2显示了抗糖尿病药物销售数据的趋势。

季节性：

当时间序列受到季节性因素（如一年中的时间或一周中的某一天）的影响时，就会出现季节性模式。季节性总是一个固定且已知的周期。抗糖尿病药物的月销售额（图2.2）显示了季节性，部分原因是日历年末药物成本的变化。

周期性：当数据呈现出非固定频率的上升和下降时，发生周期性。这些波动通常是由经济状况引起的，通常与“商业周期”有关。这些波动的持续时间通常至少为2年。

许多人把周期性行为和季节性行为混淆起来，但它们实际上是完全不同的。如果波动不是固定频率的，那么它们是周期性的；如果频率是不变的，并且与日历的某些方面相关，那么模式是季节性的。一般来说，周期的平均长度比季节性模式的长度长，周期的大小往往比季节性模式的大小变化更大。

许多时间序列包括趋势、周期和季节性。在选择预测方法时，我们首先需要识别数据中的时间序列模式，然后选择能够正确捕获模式的方法。

##### 自相关：

ACF()

正如相关性衡量两个变量之间线性关系的程度一样，自相关衡量时间序列滞后值之间的线性关系。

有几个自相关系数，对应于滞后图中的每个面板。 例如，$r_{1}$ 测量$y_{t}$和$y_{t-1}$ 之间的关系，$r_{2}$ 测量$y_{t}$和$y_{t-2}$ 之间的关系，依此类推,$r_{k}$的值可以写为

​                                              $$r_{k} = \frac{\sum\limits_{t=k+1}^T (y_{t}-\bar{y})(y_{t-k}-\bar{y})} {\sum\limits_{t=1}^T (y_{t}-\bar{y})^2}$$

当数据具有趋势时，小滞后的自相关往往较大且为正，因为时间上邻近的观测值的值也邻近。 因此，趋势时间序列的 ACF 往往具有正值，随着滞后的增加而缓慢减小

当数据是季节性的时，季节性滞后（季节性周期的倍数）的自相关将大于其他滞后

当数据既是趋势数据又是季节性数据时，您会看到这些影响的组合。 图 中绘制的 a10 数据显示了趋势和季节性。 其 ACF 如图 2.21 所示。 随着滞后时间的增加，ACF 的缓慢下降是由于趋势，而“扇贝”形状是由于季节性。

![ACF of monthly Australian antidiabetic drug sales.](https://otexts.com/fpp3/fpp_files/figure-html/acfa10-1.png)

##### 白噪声：

不显示自相关的时间序列称为白噪声

![Autocorrelation function for the white noise series.](https://otexts.com/fpp3/fpp_files/figure-html/wnoiseacf-1.png)

对于白噪声序列，我们期望每个自相关接近于零。 当然，它们不会完全等于零，因为存在一些随机变化。 对于白噪声序列，我们预计 ACF 中 95% 的尖峰位于 $\pm 2/\sqrt{T}$内，其中 T 是时间序列的长度。 通常将这些边界绘制在 ACF 的图形上（上面的蓝色虚线）。 如果一个或多个大尖峰在这些范围之外，或者超过 5% 的尖峰在这些范围之外，则该系列可能不是白噪声



#### 时序分解

时间序列数据可以表现出多种模式，将时间序列分成几个部分通常很有帮助，每个部分代表一个基础模式类别。

前文我们讨论了三种类型的时间序列模式：趋势、季节性和周期。 当我们将时间序列分解为组件时，我们通常将趋势和周期合并为一个趋势周期组件（为简单起见，通常简称为趋势）。 因此，我们可以将时间序列视为由三个部分组成：**趋势周期部分、季节性部分和剩余部分**（包含时间序列中的任何其他部分）。 对于某些时间序列（例如，那些至少每天观察到的时间序列），对应于不同的季节周期，可能有不止一个季节成分。

##### 调整和转换

调整历史数据通常可以得到更简单的时间序列。 在这里，我们处理四种调整：日历调整、人口调整、通货膨胀调整和数学变换。 这些调整和转换的目的是**通过移除已知的变异源或使整个数据集的模式更加一致来简化历史数据中的模式**。 更简单的模式通常更容易建模并导致更准确的预测。

日历调整:

在季节性数据中看到的一些变化可能是由于简单的日历效应。 在这种情况下，在进行任何进一步分析之前去除变异通常要容易得多。

 例如:如果您正在研究零售店的每月总销售额，那么除了一年中的季节性变化之外，由于每个月的交易日数不同，月份之间也会存在差异。 通过计算每个月每个交易日的平均销售额，而不是当月的总销售额，很容易消除这种变化。 然后我们有效地消除了日历变化。

人口调整:

任何受人口变化影响的数据都可以调整为人均数据。 也就是说，考虑每人（或每千人，或每百万人）的数据而不是总数。 

例如，如果您正在研究一段时间内特定区域的医院床位数量，如果您通过考虑每千人的床位数量来消除人口变化的影响，则结果会更容易解释。 然后您可以查看床位数量是否真正增加，或者增加是否完全是由于人口增加。 床位总数可能增加，但每千人床位数量减少。 当人口增长快于病床数量时，就会发生这种情况。**对于大多数受人口变化影响的数据，最好使用人均数据而不是总数**。

通货膨胀调整:

受货币价值影响的数据最好在建模前进行调整。 例如，由于通货膨胀，新房的平均成本在过去几十年中会增加。 今年 20 万美元的房子和 20 年前 20 万美元的房子不一样。 出于这个原因，通常会调整金融时间序列，以便所有价值都以特定年份的美元价值表示。 例如，房价数据可能以 2000 美元表示。

为了进行这些调整，使用了价格指数。 如果$z_{t}$表示价格指数，$y_{t}$表示$t$年的原始房价，则$x_{t} = y_{t}/z_{t} * z_{2000}$给出了 2000 年美元价值的调整后的房价。 价格指数通常由政府机构构建。 对于消费品，常见的价格指数是消费者价格指数（CPI）。

数学变换：

如果数据显示随序列水平增加或减少的变化，则转换可能很有用。 例如，对数变换通常很有用。 如果我们将原始观测值表示为$y_{1},\dots,y_{T}$，将变换后的观测值表示为$w_{1}, \dots, w_{T}$，那么$ w_ {t} = log ( y _{t} ) $。 对数很有用，因为它们是可解释的：对数值的变化是原始尺度上的相对（或百分比）变化。 因此，如果使用对数基数10，那么对数刻度上的增加1对应于原始刻度上的 10 乘法。 如果原始系列的任何值为零或负数，则对数是不可能的。

有时也使用其他转换（尽管它们不太容易解释）。 例如，可以使用平方根和立方根。 这些被称为幂变换，因为它们可以写成$w_{t} = y_{t}^p$的形式。

一个有用的变换族，包括对数和幂变换，是 Box-Cox 变换族 (Box & Cox, 1964)，它依赖于参数 λ，定义如下：

​                           $$\begin{equation}  w_t  =    \begin{cases}      \log(y_t) & \text{if $\lambda=0$};  \\      (\text{sign}(y_t)|y_t|^\lambda-1)/\lambda & \text{otherwise}.    \end{cases}    \end{equation}$$

一个好的 λ 值可以使整个系列的季节性变化的大小大致相同，guerrero 特征（Guerrero，1993）可用于为您选择 lambda 值 下图选择 λ = 0.12

![image-20210820204858624](数模整理.assets/image-20210820204858624.png)

features()

##### 时间序列组件

如果我们假设一个加法分解，那么我们可以写：$y_{t} = S_{t} + T_{t} + R_t$

其中 y t 是数据，S t 是季节性分量，T t 是趋势周期分量，R t 是剩余分量，均在 t 期间。 或者，乘法分解将写为：$y_{t} = S_{t} \times T_{t} \times R_t.$

如果季节性波动的幅度或趋势周期周围的变化不随时间序列的水平而变化，则加法分解是最合适的。 当季节性模式的变化或趋势周期周围的变化似乎与时间序列的水平成正比时，乘法分解更合适。 乘法分解在经济时间序列中很常见。

使用乘法分解的替代方法是首先转换数据，直到序列中的变化随着时间的推移看起来稳定，然后使用加法分解。 当使用对数变换时，这等效于使用乘法分解，因为:

$y_{t} = S_{t} \times T_{t} \times R_t \quad\text{is equivalent to}\quad  \log y_{t} = \log S_{t} + \log T_{t} + \log R_t.$

季节性调整数据：

如果从原始数据中去除季节性成分，则结果值就是“季节性调整”数据。

 对于加法分解，季节性调整数据由$y_{t}-S_{t}$给出，对于乘法数据，使用$ y _{t} / S_{t} $获得季节性调整值。

如果季节性变化不是主要关注点，则季节性调整序列可能有用。 例如，月度失业数据通常会进行季节性调整，以突出由于经济基本状态而不是季节性变化引起的变化。 离校生找工作造成的失业增加是季节性变化的，而经济衰退造成的失业增加是非季节性的。 大多数研究失业数据的经济分析师对非季节性变化更感兴趣。 **因此，就业数据（以及许多其他经济系列）通常会进行季节性调整**。

注：季节性调整的系列包含剩余部分以及趋势周期。 因此，它们并不“平稳”，“衰退”或“上涨”可能会产生误导。 **如果目的是寻找系列中的转折点，并解释方向的任何变化，那么最好使用趋势周期组件而不是季节性调整数据**。

##### 经典分解

经典的分解方法起源于 1920 年代。 这是一个相对简单的过程，是大多数其他时间序列分解方法的起点。 有两种形式的经典分解：加法分解和乘法分解。 下面描述了具有季节性周期 m 的时间序列（例如，对于季度数据，m = 4，对于每月数据，m = 12，对于具有每周模式的每日数据，m = 7）。

在经典分解中，**假设季节性成分每年都是恒定的**。 对于乘性季节性，构成季节性分量的 m 值有时称为“季节性指数”。

加法分解:

步骤 1 如果 m 是偶数，则使用 2 × m -MA 计算趋势周期分量 $\hat{T}_t$。 如果 m 是奇数，则使用 m -MA 计算趋势周期分量$\hat{T}_t$。

步骤 2 计算去趋势序列：$y_t - \hat{T}_t$。

步骤 3 要估计每个季节的季节性成分，只需平均该季节的去趋势值。 

例如，对于月度数据，3 月份的季节性成分是数据中所有去趋势的 3 月份值的平均值。 然后调整这些季节性分量值以确保它们加起来为零。 季节性成分是通过将这些月度值串在一起获得的，然后为每一年的数据复制序列。 这给出了$\hat{S}_t$。

步骤 4 通过减去估计的季节性和趋势周期分量来计算剩余分量：$\hat{R}_t = y_t - \hat{T}_t - \hat{S}_t$

乘法分解：

经典的乘法分解与此类似，只是减法被除法代替。

评论：

虽然经典分解仍然被广泛使用，但不推荐使用，因为现在有几种更好的方法。 下面总结了经典分解的一些问题：

* 对于前几个和最后几个观察，趋势周期的估计是不可用的。 例如，如果 m = 12 ，则没有前六个或最后六个观测值的趋势周期估计。 因此，也没有对相同时间段的剩余部分进行估计。
* 趋势周期估计倾向于过度平滑数据中的快速上升和下降。
* 经典分解方法假设季节性成分年复一年地重复。 对于许多系列，这是一个合理的假设，但对于一些较长的系列则不然。 例如，随着空调变得更加普及，电力需求模式随着时间的推移而发生了变化。 在许多地方，几十年前的季节性使用模式在冬季（由于供暖）需求最大，而当前的季节性模式在夏季（由于空调）需求最大。 经典分解方法无法捕捉这些随时间的季节性变化。
* 有时，少数时期的时间序列值可能特别不寻常。 例如，每月的航空客运量可能受到劳资纠纷的影响，使纠纷期间的客流量与平时不同。 经典方法对这些异常值并不稳健。

##### 官方统计机构方法

官方统计机构（如美国人口普查局和澳大利亚统计局）负责大量官方经济和社会时间序列。 这些机构制定了自己的分解程序，用于季节性调整。 他们中的大多数使用 X-11 方法的变体，或 SEATS 方法，或两者的组合。

**这些方法专门设计用于处理季度和月度数据**，这是官方统计机构处理的最常见的系列。 他们不会处理其他类型的季节性，例如每日数据、每小时数据或每周数据。 我们将使用这组方法的最新实现，称为“X-13ARIMA-SEATS”。

X-11:

X-11 方法起源于美国人口普查局，并由加拿大统计局进一步发展。 它基于经典分解，但包括许多额外的步骤和功能，以克服上一节中讨论的经典分解的缺点。 特别是，趋势周期估计可用于包括终点在内的所有观察，并且允许季节性成分随时间缓慢变化。

  X-11 还处理交易日变化、假期影响和已知预测因素的影响。 有加法和乘法分解的方法。 该过程是完全自动的，并且往往对时间序列中的异常值和水平变化具有高度鲁棒性。  X-11 方法的详细信息在 Dagum & Bianconcini (2016) 中有描述。

SEATS：

“SEATS”代表“ARIMA 时间序列中的季节性提取”。 这个程序是在西班牙银行开发的，现在被世界各地的政府机构广泛使用。 Dagum & Bianconcini (2016) 中提供了对该方法的完整讨论。

`seasonal` package 

##### STL分解

STL 是一种用于分解时间序列的通用且稳健的方法。  STL 是“使用 Loess 进行季节和趋势分解”的首字母缩写，而 loess 是一种估计非线性关系的方法。  STL 方法是由 R. B. Cleveland 等人开发的(1990)。

STL 与经典分解以及 SEATS 和 X-11 方法相比有几个优点： 

* 与 SEATS 和 X-11 不同，STL 将处理任何类型的季节性，而不仅仅是月度和季度数据。
* 季节性分量可以随时间变化，变化的速度可以由用户控制。
* 用户也可以控制趋势周期的平滑度。
* 它可以对异常值具有鲁棒性（即，用户可以指定鲁棒分解），以便偶尔出现的异常观察不会影响趋势周期和季节性分量的估计。 然而，它们会影响剩余部分。

另一方面，STL 也有一些缺点。 特别是它不会自动处理交易日或日历变化，它只提供用于附加分解的工具。

乘法分解可以通过首先记录数据，然后反向转换组件来获得。 可以使用 0 < λ < 1 的数据的 Box-Cox 变换获得加法和乘法之间的分解。  λ = 0 值给出乘法分解，而 λ = 1 给出加法分解。

STL()

#### 时序特征

我们已经看到了一些时间序列特征。 例如，前文讨论的自相关可以被视为时间序列的特征——它们是从该序列计算的数值汇总。 我们在上一章中看到的另一个特征是 Box-Cox 变换参数的 Guerrero 估计——同样，这是一个从时间序列计算的数字。

`feasts` package

##### ACF特征

自相关上文中讨论过。 一个系列的所有自相关都可以被认为是该系列的特征。 我们还可以总结自相关以产生新特征； 例如，前十个平方自相关系数的总和是一个有用的总结，无论滞后如何，序列中有多少自相关。

我们还可以计算不同时期之间序列变化的自相关。 也就是说，我们“区分”数据并创建一个由连续观察之间的差异组成的新时间序列。 然后我们可以计算这个新的差分序列的自相关。 有时再次应用相同的差分操作很有用，因此我们计算差异的差异。 这个双差分序列的自相关可以提供有用的信息。

另一种相关方法是计算系列的季节性差异。 例如，如果我们有月度数据，我们将计算连续的 1 月、连续的 2 月等之间的差异。 这使我们能够查看该系列如何在几年之间而不是几个月之间发生变化。 同样，季节性差异序列的自相关可能会提供有用的信息。

##### STL特征

时间序列分解可用于衡量时间序列中趋势和季节性的强度。 回想一下，分解写为$y_t = T_t + S_{t} + R_t,$其中 T t 是平滑趋势分量，S t 是季节性分量，R t 是余数分量。 

对于强趋势数据，经季节性调整的数据应该比剩余部分具有更多的变化。 因此 Var ( R t ) /Var ( T t + R t ) 应该相对较小。 但是对于趋势很小或没有趋势的数据，两个方差应该大致相同。 因此，我们将趋势强度定义为：

​                                    $$F_T = \max\left(0, 1 - \frac{\text{Var}(R_t)}{\text{Var}(T_t+R_t)}\right).$$

这将给出 0 和 1 之间趋势强度的度量。因为余数的方差有时可能甚至大于季节性调整数据的方差，将 F T 的最小可能值设置为零。

季节性强度的定义类似，但针对去趋势数据而不是季节性调整数据： 

​                                   $$F_S = \max\left(0, 1 - \frac{\text{Var}(R_t)}{\text{Var}(S_{t}+R_t)}\right).$$

季节性强度$F_S$接近 0 的系列几乎没有季节性，而季节性强的系列将具有接近 1 的$ F_S$，因为 Var ( R t ) 将远小于 Var ( S t + R t )。

这些度量可能很有用，例如，当您拥有大量时间序列，并且您需要找到最具趋势或最具季节性的序列时。 

feat_stl() 

##### 其他特征

features()

- `coef_hurst` 将计算时间序列的 Hurst 系数，这是“长记忆”的度量。 具有长记忆力的序列对于许多滞后将具有显着的自相关性。

- `feat_spectral` 将计算时间序列的（香农）谱熵，这是对序列预测难易程度的度量。 具有强烈趋势和季节性（因此易于预测）的序列的熵接近于 0。噪声非常大（因此难以预测）的序列的熵接近于 1。

- `box_pierce` 给出用于测试时间序列是否为白噪声的 Box-Pierce 统计量，以及相应的 p 值。 该测试在[残差诊断](#残差诊断)中讨论。

- `ljung_box`给出用于测试时间序列是否为白噪声的 Ljung-Box 统计量，以及相应的 p 值。 该测试在[残差诊断](#残差诊断)中讨论。

- 第 k 个偏自相关测量在去除观测值之间的影响后相隔 k 周期的观测值之间的关系。 所以第一个偏自相关 (k=1) 与第一个自相关相同，因为在连续观测之间没有要删除的内容。 部分自相关在[非季节性 ARIMA 模型](#非季节性 ARIMA 模型)中讨论。

  The `feat_pacf` 函数包含几个涉及偏自相关的特征，包括原始序列、一阶差分序列和二阶差分序列的前五个偏自相关的平方和。 对于季节性数据，它还包括第一个季节性滞后的偏自相关。.

- `unitroot_kpss` 给出用于检验序列是否平稳的 Kwiatkowski-Phillips-Schmidt-Shin (KPSS) 统计量，以及相应的 p 值。 该测试在[平稳性和差分](#平稳性和差分)讨论。

- `unitroot_pp`给出用于检验序列是否非平稳的 Phillips-Perron 统计量，以及相应的 p 值。

- `unitroot_ndiffs` - 根据 KPSS 测试给出导致平稳序列所需的差异数量。 

- `unitroot_nsdiffs` 给出使序列平稳所需的季节性差异数。 这在[平稳性和差分](#平稳性和差分)讨论。

- `var_tiled_mean` 给出“平铺均值”的方差（即连续非重叠观测块的均值）。 默认图块长度为 10（对于非季节性数据）或季节性周期的长度。 这有时称为“稳定性”功能。

- `var_tiled_var` 给出“平铺方差”的方差（即连续非重叠观测块的方差）。 这有时被称为“块状”特征。

- `shift_level_max` 找到时间序列的两个连续滑动窗口之间的最大均值偏移。 这对于查找时间序列中的突然跳跃或下降很有用。

- `shift_level_index` 给出发生最大均值偏移的索引。

- `shift_var_max` 找到时间序列的两个连续滑动窗口之间的最大方差偏移。 这对于**发现时间序列波动性的突然变化很有用**。

- `shift_var_index` - 给出发生最大均值偏移的索引 -`shift_kl_max` 找到时间序列的两个连续滑动窗口之间的最大分布偏移（基于 Kulback-Leibler 散度）。 这对于查找时间序列分布的突然变化很有用。

- `shift_kl_index` 给出最大 KL 偏移发生处的索引。

- `n_crossing_points` 计算时间序列穿过中位数的次数。

- `longest_flat_spot` 计算序列相对不变的数据部分的数量。

- `stat_arch_lm` 返回基于 Engle (1982) 的拉格朗日乘数 (LM) 检验的自回归条件异方差性 (ARCH) 的统计量。

- `guerrero` 使用 Guerrero 方法计算 Box-Cox 变换的最佳 λ 值（在[调整和转换](#调整和转换)中讨论）。

#### 时序预测知识

##### 简单预测方法

一些预测方法极其简单且非常有效。使用四种简单的预测方法作为基准。

平均法：

MEAN()

在这里，所有未来值的预测等于历史数据的平均值（或“平均值”）。 如果我们让历史数据用 y 1 , … , y T 表示，那么我们可以把预测写成：

​                                       $\hat{y}_{T+h|T} = \bar{y} = (y_{1}+\dots+y_{T})/T.$

朴素法：

对于朴素预测，我们只需将所有预测设置为最后一次观察的值。 即 $\hat{y}_{T+h|T} = y_{T}.$

这种方法对于许多经济和金融时间序列非常有效。

因为当数据遵循随机游走时，朴素预测是最佳的，所以这些也称为随机游走预测，可以使用 RW() 函数代替 NAIVE。

季节性朴素方法:

类似的方法对于高度季节性的数据很有用。 在这种情况下，我们将每个预测设置为等于一年中同一季节（例如，上一年的同一个月）的最后一个观测值。 形式上，时间 T + h 的预测写为 

​                                        $\hat{y}_{T+h|T} = y_{T+h-m(k+1)},$

其中 m = 季节性周期，k 是 ( h − 1 ) / m 的整数部分（即时间T + h之前预测期的完整年数 )。 这看起来比实际更复杂。 例如，对于月度数据，所有未来 2 月值的预测等于最后观察到的 2 月值。 对于季度数据，所有未来 Q2 值的预测等于最后观察到的 Q2 值（其中 Q2 表示第二季度）。 类似的规则适用于其他月份和季度以及其他季节性时期。

漂移法:

Naïve 方法的一个变体是允许预测随时间增加或减少，其中随时间的变化量（称为漂移）设置为历史数据中看到的平均变化。 因此，时间 $T + h$ 的预测由 

​              $$\hat{y}_{T+h|T} = y_{T} + \frac{h}{T-1}\sum_{t=2}^T (y_{t}-y_{t-1}) = y_{T} + h \left( \frac{y_{T} -y_{1}}{T-1}\right).$$

这相当于在第一次和最后一次观察之间画一条线，并将其外推到未来。

有时，这些简单方法之一将是可用的最佳预测方法； 但在许多情况下，这些方法将作为基准而不是选择的方法。 也就是说，我们开发的任何预测方法都会与这些简单的方法进行比较，以确保新方法优于这些简单的替代方法。 如果不是，则新方法不值得考虑。

##### 拟合值和残差

时间序列中的每个观察都可以使用所有先前的观察进行预测。 我们将这些拟合值称为 $\hat{y}_{t|t-1}$，表示基于观测值 y 1 , … , y t − 1 的 y t 预测。 我们经常使用这些，有时我们会去掉部分下标，只写  $\hat{y}_{t}$而不是 $\hat{y}_{t|t-1}$ 。

时间序列模型中的“残差”是拟合模型后剩下的。 残差等于观测值与相应拟合值之间的差值： $e_{t} = y_{t}-\hat{y}_{t}.$

如果模型中使用了变换，那么查看变换尺度上的残差通常很有用。 我们称这些为“创新残余”。 例如，假设我们对数据的对数进行建模， w t = log ( y t ) 。 然后创新残差由$w_t - \hat{w}_t$ 给出，而常规残差由 $y_{t}-\hat{y}_{t}$给出。  如果未使用转换，则创新残差与常规残差相同，在这种情况下，我们将简单地称其为“残差”。

augment()

##### 残差诊断

一个好的预测方法将产生具有以下特性的创新残差： 

1. 创新残差是不相关的。 如果创新残差之间存在相关性，那么残差中就有信息可用于计算
2. 创新残差的均值为零。 如果它们的均值不为零，则预测有偏差。

任何不满足这些性质的预测方法都可以改进。 但是，这并不意味着不能改进满足这些属性的预测方法。 对于同一个数据集，可能有几种不同的预测方法，所有这些方法都满足这些属性。 检查这些属性对于查看方法是否使用所有可用信息很重要，但这不是选择预测方法的好方法。

如果不满足这些属性中的任何一个，则可以修改预测方法以提供更好的预测。 调整偏差很容易：如果残差的均值为 m，那么只需从所有预测中减去 m，偏差问题就解决了。 解决相关性问题比较困难，我们要到#才会解决它

 除了这些基本属性之外，残差还具有以下两个属性是有用的（但不是必需的)。

1. 创新残差具有恒定的方差。 这被称为“同方差性”。
2. 创新残差呈正态分布。

这两个属性使预测区间的计算更容易。 然而，不满足这些性质的预测方法不一定能得到改进。 有时应用 Box-Cox 变换可能对这些属性有所帮助，但除此之外，您通常无法确保您的创新残差具有恒定方差和正态分布。 相反，需要另一种获得预测区间的方法。 我们将在后文展示如何处理非正态创新残差。

自相关的 Portmanteau 检验：

除了查看 ACF 图之外，我们还可以通过将一整套 r k 值视为一个组来对自相关进行更正式的测试，而不是单独处理每个值

回想一下，r k 是滞后 k 的自相关。 当我们查看 ACF 图以查看每个尖峰是否在要求的范围内时，我们隐含地进行了多个假设检验，每个假设检验都有很小的概率给出误报。 当完成足够多的这些测试时，很可能至少有一个会给出误报，因此我们可以得出结论，残差具有一些剩余的自相关性，而实际上它们没有。

 为了克服这个问题，我们测试第一个 ℓ 自相关是否与白噪声过程的预期显著不同。 对一组自相关的测试称为 portmanteau 测试，来自法语单词，描述了携带多件衣服的手提箱或衣架。

 一种这样的测试是 Box-Pierce 测试，它基于以下统计量 

​                                                   $$Q = T \sum_{k=1}^\ell r_k^2,$$

其中 ℓ 是所考虑的最大滞后，T 是观察次数。 如果每个 r k 接近于零，那么 Q 就会很小。 如果某些 r k 值很大（正或负），则 Q 会很大。 我们建议对非季节性数据使用 ℓ = 10，对季节性数据使用 ℓ = 2 m，其中 m 是季节性周期。 但是，当 ℓ 较大时测试效果不佳，因此如果这些值大于 T / 5 ，则使用 ℓ = T / 5

一个相关的（更准确的）测试是 Ljung-Box 测试，它基于:

​                                     $$Q^* = T(T+2) \sum_{k=1}^\ell (T-k)^{-1}r_k^2.$$

同样，Q ∗ 的大值表明自相关不是来自白噪声序列。

多大是太大？ 如果自相关确实来自白噪声序列，那么 Q 和 Q ∗ 都将具有 ( ℓ − K ) 自由度的 $\chi^2$分布，其中 K 是模型中的参数数量。 如果它们是根据原始数据（而不是模型的残差）计算的，则设置 K = 0 。
    

对于 Google 股票价格示例，Naïve 方法没有参数，因此在这种情况下 K = 0。 在代码中，lag = ℓ 和 dof = K。

##### 分布预测和预测区间

预测分布：

我们使用概率分布表示预测中的不确定性。 它描述了使用拟合模型观察可能的未来值的概率。 点预测是该分布的均值。 大多数时间序列模型产生正态分布的预测——也就是说，我们假设未来可能值的分布遵循正态分布。 我们将在本节后面介绍正态分布的几种替代方案。

预测区间：$\hat{y}_{T+h|T} \pm c \hat\sigma_h$

预测区间的价值在于它们表达了预测中的不确定性。 如果我们只生成点预测，则无法判断预测的准确程度。 然而，如果我们也产生预测区间，那么很明显每个预测有多少不确定性。 因此，如果没有伴随的预测区间，点预测几乎没有价值。

一步预测区间:

当提前一步预测时，预测分布的标准差可以用下式给出的残差的标准差来估计$\begin{equation}  \hat{\sigma} = \sqrt{\frac{1}{T-K}\sum_{t=1}^T e_t^2} \end{equation}$,其中 K 是预测方法中估计的参数数量。

多步预测区间:

预测区间的一个共同特征是它们的长度通常随着预测范围的增加而增加。 我们预测得越远，与预测相关的不确定性就越大，因此预测区间越宽。 也就是说，σ h 通常随 h 增加（尽管有一些非线性预测方法不具有此属性）。

为了产生一个预测区间，有必要估计 σ h 。 如前所述，对于一步预测 (h = 1)，上式 提供了对预测标准偏差 σ 1 的良好估计。 对于多步预测，需要更复杂的计算方法。 这些计算假设残差不相关。

基准方法：对于四种基准方法，可以在不相关残差的假设下从数学上推导出预测标准差。 hilo()

来自bootstrapped残差的预测区间：

当残差的正态分布是不合理的假设时，一种替代方法是使用bootstrapped法，它仅假设残差与恒定方差不相关。

该方法基于对过去残差的采样预测未来残差，进而预测未来数值反复这样做，我们获得了许多可能的未来。 要查看其中一些，我们可以使用 generate() 函数。

注意，预测分布现在表示为样本路径的模拟。 因为没有正态性假设，所以预测区间不是对称的。

##### 分解预测

时间序列分解可能是生成预测的有用步骤。

假设加法分解，分解后的时间序列可以写成$y_t = \hat{S}_t + \hat{A}_t,$其中 $\hat{A}_t = \hat{T}_t+\hat{R}_{t}$ 是季节性调整的分量。 或者，如果使用乘法分解，我们可以写成 $y_t = \hat{S}_t  \hat{A}_t,$其中 $\hat{A}_t = \hat{T}_t+\hat{R}_{t}$。

为了预测分解的时间序列，我们分别预测季节性分量$\hat{S}_t$和季节性调整分量 $\hat{A}_t$。 **通常假设季节性分量是不变的，或者变化极其缓慢**，因此只需取估计分量的最后一年就可以进行预测。 换句话说，季节性朴素方法用于季节性成分。

为了预测经季节性调整的成分，可以使用任何非季节性预测方法。 例如，可以使用 Drift 方法或 Holt# 方法或非季节性 ARIMA #模型。

decomposition_model()允许通过任何加法分解计算预测，使用其他模型函数来预测分解的每个组件

##### 评估点预测准确性

使用真实预测来评估预测准确性非常重要。 因此，残差的大小并不是真实预测误差可能有多大的可靠指标。 预测的准确性只能通过考虑模型在拟合模型时未使用的新数据上的表现来确定。

测试集的大小通常约为总样本的 20%，尽管此值取决于样本的长度以及您想要预测的提前程度。 理想情况下，测试集应至少与所需的最大预测范围一样大。 应注意以下几点:

* 一个很好地拟合训练数据的模型不一定能很好地预测。
* 使用具有足够参数的模型总是可以获得完美的拟合。
* 模型过度拟合数据与无法识别数据中的系统模式一样糟糕。

filter()用于提取时序数据中的一部分，slice()允许使用索引从每个组中选择一个子集

尺度相关误差：

预测误差与数据的尺度相同。 因此，仅基于 e t 的准确度度量取决于尺度，不能用于在涉及不同单位的系列之间进行比较。

两种最常用的尺度相关度量基于绝对误差或平方误差：

​         $$\begin{align*}
  \text{Mean absolute error: MAE} & = \text{mean}(|e_{t}|),\\
  \text{Root mean squared error: RMSE} & = \sqrt{\text{mean}(e_{t}^2)}.
\end{align*}$$

在比较应用于单个时间序列或具有相同单位的多个时间序列的预测方法时，MAE 很受欢迎，因为它易于理解和计算。 最小化 MAE 的预测方法将导致对中位数的预测，而最小化 RMSE 将导致对均值的预测。 因此，RMSE 也被广泛使用，尽管更难以解释。

百分比误差:

百分比误差由$p_{t} = 100 e_{t}/y_{t}$给出。 百分比误差具有无单位的优点，因此**经常用于比较数据集之间的预测性能**。 最常用的度量是：平均绝对百分比误差：$\text{Mean absolute percentage error: MAPE} = \text{mean}(|p_{t}|).$

如果$y_{t}=0$对于感兴趣期间的任何 t，则基于百分比误差的度量具有无限或未定义的缺点，并且如果任何 接$y_{t}$近于零，则具有极值。 另一个经常被忽视的百分比误差问题是他们假设测量单位有一个有意义的零.例如，在测量华氏或摄氏温度预测的准确性时，百分比误差没有意义，因为温度有一个任意的零点。

它们还有一个缺点，那就是它们对负错误的惩罚比对正错误的惩罚更重。 这一观察导致使用 Armstrong (1978, p. 348) 提出的所谓的“对称”MAPE (sMAPE)，该方法用于 M3 预测竞赛。 它由$\text{sMAPE} = \text{mean}\left(200|y_{t} - \hat{y}_{t}|/(y_{t}+\hat{y}_{t})\right).$定义。

但是，如果 y t 接近于零，则$\hat{y}_{t}$也可能接近于零。 因此，该度量仍然涉及除以接近于零的数字，从而使计算不稳定。 此外，sMAPE 的值可能为负，因此它根本不是“绝对百分比误差”的衡量标准。

Hyndman & Koehler (2006) 建议不要使用 sMAPE。 将它包含在这里只是因为它被广泛使用，尽管我们不会在本书中使用它。

比例误差:

比例误差由 Hyndman & Koehler (2006) 提出，作为比较不同单位的系列预测准确度时使用百分比误差的替代方法。 他们建议根据简单预测方法的训练 MAE 来缩放误差。

对于非季节性时间序列，定义比例误差的一种有用方法是使用朴素预测： 

​                                       $q_{j} = \frac{\displaystyle e_{j}}    {\displaystyle\frac{1}{T-1}\sum_{t=2}^T |y_{t}-y_{t-1}|}.$

因为分子和分母都涉及原始数据尺度上的值，所以 q j 与数据尺度无关。 如果缩放误差来自比在训练数据上计算的平均一步朴素预测更好的预测，则缩放误差小于 1。 相反，如果预测比在训练数据上计算的平均一步朴素预测差，则它大于 1。

对于季节性时间序列，可以使用季节性朴素预测定义缩放误差：

​                                     $$q_{j} = \frac{\displaystyle e_{j}}    {\displaystyle\frac{1}{T-m}\sum_{t=m+1}^T |y_{t}-y_{t-m}|}.$$

自然的有：$\text{MASE} = \text{mean}(|q_{j}|).$ $\text{RMSSE} = \sqrt{\text{mean}(q_{j}^2)},$

accuracy() 自动从数据中提取相关时期以匹配预测

##### 评估分布预测准确性

前面测量了所有测量点预测的准确性。 在评估分布预测时，我们需要使用其他一些度量。

分位数分数：

假设我们对未来时间 t 的概率为 p 的分位数预测感兴趣，并用$f_{p,t}$表示。 也就是说，我们期望观测值 y t 小于$f_{p,t}$的概率为 p 。 例如，第 10 个百分位数将是$f_{0.10,t}$。 如果 y t 表示在时间 t 的观察，那么分位数分数是:

​                      $$Q_{p,t} = \begin{cases}  2(1 - p) \big(f_{p,t} - y_{t}\big), & \text{if $y_{t} < f_{p,t}$}\\  2p \big(y_{t} - f_{p,t}\big), & \text{if $y_{t} \ge f_{p,t}$} \end{cases}$$

这有时被称为“pinball loss function”，因为它的图形类似于弹球桌上球的轨迹。 乘数 2 经常被省略，但包括它会使解释更容易一些。 $Q_{p,t}$的低值表示对分位数的更好估计。

分位数分数可以解释为绝对误差。 实际上，当 p = 0.5 时，分位数得分$Q_{0.5,t}$与绝对误差相同。 对于 p 的其他值，“误差”$(y_t - f_{p,t})$被加权以考虑它是正数还是负数的可能性。 如果 p > 0.5 ,$Q_{p,t}$在观测值大于估计分位数时比在观测值小于估计分位数时给出更重的惩罚。 当 p < 0.5 时，情况正好相反。

这可以使用带有 quantile_score() 函数的 precision() 轻松计算

Winkler Score:

**评估预测区间**（而不是几个分位数）通常是令人感兴趣的，Winkler（1972）提出的Winkler分数就是为了这个目的而设计的。如果100（1− α）%时间t的预测区间是$[\ell_{\alpha,t}, u_{\alpha,t}]$，则Winkler分数定义为间隔长度加上惩罚（如果观察值在间隔之外）：

$$W_{\alpha,t} = \begin{cases}  (u_{\alpha,t} - \ell_{\alpha,t}) + \frac{2}{\alpha} (\ell_{\alpha,t} - y_t) & \text{if } y_t < \ell_{\alpha,t} \\  (u_{\alpha,t} - \ell_{\alpha,t})   & \text{if }  \ell_{\alpha,t} \le y_t \le u_{\alpha,t} \\  (u_{\alpha,t} - \ell_{\alpha,t}) + \frac{2}{\alpha} (y_t - u_{\alpha,t}) & \text{if } y_t > u_{\alpha,t}.  \end{cases}$$

对于区间内的观察，Winkler分数只是区间的长度。因此，低分数与狭窄的时间间隔有关。但是，如果观察值落在间隔之外，则应用惩罚，惩罚与观察值在间隔之外的距离成比例。

通常构造预测区间通过设置$\ell_{\alpha,t} = f_{\alpha/2,t}$和$u_{\alpha,t} = f_{1-\alpha/2,t}$。如果我们加上相应的分位数分数并除以α，我们得到Winkler分数：

​                                $$W_{\alpha,t} = (Q_{\alpha/2,t} + Q_{1-\alpha/2,t})/\alpha.$$

这可以使用带有 quantile_score() 函数的winkler_score()轻松计算

连续排序概率得分：

我们通常对整个预测分布感兴趣，而不是特定的分位数或预测区间。在这种情况下，我们可以对p的所有值的分位数分数进行平均，以获得连续排名的概率分数或CRPS（Gneiting&Katzfuss，2014）。

在Google股票价格示例中，我们可以计算测试集中所有天的平均CRPS值。CRPS值有点像从整个预测分布计算的加权绝对误差，其中加权考虑了概率。

使用技能分数的无尺度比较：

与点预测一样，能够在不同尺度的系列中比较几种方法的分布预测准确性是很有用的。 对于点预测，我们为此使用了比例误差。 另一种方法是使用技能分数。 这些可用于点预测精度和分布预测精度。

使用技能分数，我们计算相对于某些基准方法的预测准确性度量。 例如，如果我们使用 Naïve 方法作为基准，并使用 Drift 方法计算预测，我们可以计算 Drift 方法相对于 Naïve 方法的 CRPS 技能分数为：

​                                             $$\frac{\text{CRPS}_{\text{Naïve}} - \text{CRPS}_{\text{Drift}}}{\text{CRPS}_{\text{Naïve}}}.$$

这给出了漂移方法优于基于 CRPS 的朴素方法的比例。 使用accuracy()函数中的Skill_score() 。

 Skill_score() 函数可用于任何准确度度量。 例如，skill_score(MSE) 提供了一种跨不同系列比较 MSE 值的方法。 然而，重要的是测试集足够大以允许可靠地计算误差度量，尤其是在分母中。 出于这个原因，MASE 或 RMSSE 通常是点预测准确性的首选无标度度量

##### 时间序列交叉验证

一个更复杂的训练/测试集版本是时间序列交叉验证。**在这个过程中，有一系列测试集，每个测试集由一个单一的观察组成**。 相应的训练集仅包含在形成测试集的观察之前发生的观察。 因此，未来的观测不能用于构建预测。 由于不可能基于较小的训练集获得可靠的预测，因此不将最早的观察结果视为测试集。

下图说明了一系列训练和测试集，其中蓝色观测值构成训练集，橙色观测值构成测试集。

![img](https://otexts.com/fpp3/fpp_files/figure-html/cv1-1.svg)

预测准确度是通过对测试集求平均值来计算的。 这个过程有时被称为“对滚动预测原点的评估”，因为预测所基于的“原点”在时间上向前滚动。

对于时间序列预测，一步预测可能不如多步预测那么相关。 在这种情况下，可以修改基于滚动预测原点的交叉验证程序，以允许使用多步错误。 假设我们对产生良好的 4 步提前预测的模型感兴趣。 那么对应的图如下所示。

![img](https://otexts.com/fpp3/fpp_files/figure-html/cv4-1.svg)

stretch_tsibble()

选择最佳预测模型的一个好方法是找到使用时间序列交叉验证计算的具有最小 RMSE 的模型。

#### 判断性预测

使用判断进行预测在实践中很常见。 在许多情况下，判断性预测是唯一的选择，例如当完全缺乏历史数据时，或者当新产品正在推出时，或者当一个新的竞争对手进入市场时，或者在全新且独特的市场条件下。 例如，2012 年 12 月，澳大利亚政府在全球率先通过立法，禁止在烟盒上使用公司标志，并要求所有烟盒为深绿色。 由于没有历史先例，因此必须应用判断以预测此类政策的效果。

也有数据不完整或延迟一段时间后才可用的情况。 例如，中央银行在预测当前经济活动水平时包括判断，这一程序称为临近预报，因为 GDP 仅按季度提供。

该领域的研究表明，当预测者拥有 (i) 重要的领域知识和 (ii) 更及时、最新的信息时，判断预测的准确性会提高。 判断方法可以快速适应此类变化、信息或事件。

使用条件： 

(i) 没有可用数据，因此统计方法不适用，判断预测是唯一可行的方法；  

(ii) 可获得数据，生成统计预测，然后根据判断进行调整；  

(iii) 数据是可用的，统计和判断预测是独立生成的，然后再结合起来。 我们应该澄清，当数据可用时，应用统计方法（例如其他章节中讨论的方法）是更可取的，并且应始终作为起点。 统计预测通常优于仅使用判断来生成预测。 在本章的大部分内容中，我们将重点放在没有可用数据的第一种设置上，在最后一节中，我们将讨论统计预测的判断性调整。 我们将在#中讨论组合预测。

##### 注意限制

判断性预测是主观的，因此不能没有偏见或限制。

* 判断性预测可能不一致。 与每次都可以由相同的数学公式生成的统计预测不同，判断性预测在很大程度上依赖于人类的认知，并且容易受到其局限性的影响。 例如，有限的记忆可能会使最近发生的事件比实际情况更重要，并且可能会忽略更遥远过去的重大事件； 或有限的注意力可能会导致错过重要信息； 或者对因果关系的误解可能导致错误的推论。 此外，由于心理因素的影响，人类的判断可能会有所不同。 可以想象，某天一位处于积极心态中的经理做出可能趋于乐观的预测，而另一天处于消极心态下，则做出不太乐观的预测。
* 个人或政治议程可能会影响判断，因为目标和预测没有分开。 例如，如果销售经理知道她生成的预测将用于设置销售预期（目标），她可能倾向于将这些设置得较低以显示良好的绩效（即超出预期目标）。 即使在目标和预测完全分开的情况下，判断也可能受到乐观或一厢情愿的困扰。 例如，一个致力于推出新产品的团队极不可能预测到它的失败。 正如我们稍后将讨论的，这种乐观情绪可以在小组会议环境中得到加强。  “当心你的营销和销售同事的热情”。
* 在判断性预测中常见的另一个不良特性是锚定效应。 在这种情况下，后续预测趋于收敛或接近初始熟悉的参考点。 例如，通常以最后观察到的值作为参考点。 预测者受到先验信息的过度影响，因此在预测过程中给予更多的重视。 锚定可能导致保守主义和低估新的和更新的信息，从而产生系统性偏见。

##### 关键原则

在判断预测中使用系统和结构良好的方法有助于减少判断预测局限性的不利影响，我们在上一节中列出了其中的一些。 无论这种方法涉及一个人还是多个人，都应遵循以下原则。

1. **清晰简洁地设定预测任务** 在设定预测挑战和表达预测任务时需要小心。 每个人都清楚任务是什么很重要。 所有定义都应清晰、全面，避免含糊不清的表述。 此外，避免包含可能分散预测者注意力的情绪术语和不相关信息也很重要。 在随后的 Delphi 方法中，有时在设置预测任务之前进行初步的信息收集可能会很有用。

2. **实施系统方法** 通过使用系统方法进行判断性预测，包括与预测任务相关的信息类别清单，可以提高预测的准确性和一致性。 例如，确定哪些信息是重要的以及如何对这些信息进行加权是有帮助的。 在预测新产品的需求时，我们应该考虑哪些因素以及我们应该如何考虑这些因素？ 是否应该是价格、竞争的质量和/或数量、当时的经济环境、产品的目标人群？ 值得投入大量精力和资源来整合决策规则，从而形成最佳的系统方法。

3. **记录和证明**在系统方法中实施的决策规则和假设的形式化和记录可以促进一致性，因为相同的规则可以重复实施。 此外，要求预测者记录和证明他们的预测会导致问责，从而减少偏差。 此外，正式文件对接下来建议的系统评估过程有很大帮助。

4. **系统地评估预测** 系统地监控预测过程可以识别不可预见的违规行为。 特别是，保留预测记录，并在相应的观察结果可用时使用它们来获得反馈。 尽管作为预报员，您可能会尽力而为，但您所处的环境是动态的。 发生变化，您需要监控这些变化以评估决策规则和假设。 反馈和评估有助于预测者学习和提高他们的预测准确性。

5. **将预报员和用户分开** 如果预报任务是由预报用户执行的，例如那些负责实施与预报有关的行动计划的用户，则可能会妨碍预报的准确性。 我们应该在这里再次澄清，鉴于所有可用信息，包括历史数据和可能影响预测的任何未来事件的知识，预测就是尽可能准确地预测未来。 预报员和用户应明确分开。 一个经典案例是新产品的推出。 预测应该是对新产品销量的合理估计，这可能与管理层为实现公司财务目标而预期或希望的销量大不相同。 在这种情况下，预报员可能会向用户提供现实检查。

   预报员将预报彻底传达给潜在用户非常重要。 用户可能会感到与预测疏远和脱节，并且可能对它们没有充分的信心。 解释和澄清过程并证明导致预测的基本假设的合理性将为用户提供一些保证。

   使用和实施预测的方式显然取决于管理决策。 例如，管理层可能决定向上调整预测（过于乐观），因为预测可用于指导采购和库存水平。 在成本效益分析表明持有过剩库存的成本远低于销售损失的成本后，可以做出这样的决定。 这种类型的调整应该是设定目标或计划供应的一部分，而不是预测过程的一部分。 相比之下，如果将预测用作目标，则可以将其设置得较低，以便更容易超过。 再次重申，**设定目标与制定预测不同，两者不应混淆**。

##### The Delphi method

德尔菲法是兰德公司的奥拉夫·赫尔默和诺曼·达尔基在 1950 年代发明的，目的是解决特定的军事问题。 该方法依赖于一个关键假设，即群体的预测通常比个人的预测更准确。  Delphi 方法的目标是以结构化的迭代方式从一组专家构建共识预测。 指定一名协调人以实施和管理该过程。  Delphi 方法通常包括以下阶段： 

1. 组建专家小组。
2. 设置预测任务/挑战并分发给专家。
3. 专家返回最初的预测和理由。 这些被编译和总结以提供反馈。
4. 向专家提供反馈，他们现在根据反馈审查他们的预测。 可以重复此步骤，直到达到令人满意的共识水平。
5. 最终预测是通过汇总专家的预测来构建的。

##### 类比预测

在实践中经常采用的一种有用的判断方法是类比预测。 一个常见的例子是通过评估过程为房屋定价。 估价师通过将房屋与该地区已售出的类似房产进行比较来估计房屋的市场价值。 相似度取决于所考虑的属性。 在房屋评估中，通常会考虑土地面积、住宅面积、卧室和浴室数量以及车库空间等属性。

结构化类比:

可以实施由专家小组组成的结构化方法，如 Green & Armstrong (2007) 所提议的那样。 这个概念类似于 Delphi 的概念； 然而，预测任务是通过考虑类比来完成的。 首先，任命一名协调人。 然后结构化方法涉及以下步骤。

1. 组建了一个可能对类似情况有经验的专家小组。
2. 任务/挑战被设置并分发给专家。
3. 专家尽可能多地识别和描述类比，并根据每个类比生成预测。
4. 专家列出每个类比与目标情况的异同，然后在一个尺度上对每个类比与目标情况的相似性进行评级。
5. 预测是由协调人使用一组规则得出的。 这可以是加权平均值，其中权重可以由专家对每个类比的排名分数来指导。

 与 Delphi 方法一样，专家的匿名性在不抑制创造力方面可能是一个优势，但可能会阻碍合作。 格林和阿姆斯特朗在他们的结果中发现专家之间的合作没有任何好处。 一个关键发现是，具有多个类比（超过两个）并且对类比有直接经验的专家生成了最准确的预测。

##### 情景预测

一种完全不同的判断性预测方法是基于场景的预测。 这种方法的目的是根据合理的场景生成预测。 与之前的两种方法（德尔福法和类比预测）相比，所得到的预测旨在成为可能的结果，每个基于情景的预测可能具有较低的发生概率。 这些情景是通过考虑所有可能的因素或驱动因素、它们的相对影响、它们之间的相互作用以及要预测的目标来生成的。

基于情景构建预测允许生成范围广泛的可能预测并识别一些极端情况。 例如，通常会呈现“最佳”、“中间”和“最差”案例场景，但也会生成许多其他场景。 考虑并记录这些截然不同的极端情况可以导致及早制定应急计划。

通过情景预测，决策者经常参与情景的生成。 虽然这可能会导致一些偏差，但它可以简化基于场景的预测的沟通，并有助于更好地了解结果。

##### 新产品预测

新产品的定义可能会有所不同。 它可能是已推出的全新产品、现有产品的变体（“新的和改进的”）、现有产品定价方案的变化，甚至是现有产品进入新市场。

由于无法获得历史数据，因此判断性预测通常是新产品预测的唯一可用方法。 我们已经概述的方法（Delphi，类比预测和情景预测）都适用于预测新产品的需求。

也可以使用其他更具体的方法。 以下三种在实践中常用的方法。 这些方法没有已经讨论过的方法结构化，因此可能会导致更多有偏差的预测。

* 销售人员综合 略

* 执行意见 略

* 客户意图 

  客户意图可用于预测对新产品或现有产品变体的需求。 问卷由客户填写，了解他们购买产品的意图。 使用结构化问卷，要求客户对他们购买产品的可能性进行评分； 例如，极有可能、可能、可能、不太可能、极不可能。

  需要解决调查设计挑战，例如收集代表性样本、应用具有时间和成本效益的方法以及处理不答复。 此外，在此调查设置中，我们必须牢记购买意愿之间和购买行为的关系 。 客户并不总是按照他们说的去做。 **许多研究发现购买意向和购买行为之间存在正相关关系； 然而，这些相关性的强度差异很大**。 推动这种变化的因素包括数据收集和产品发布的时间、产品“新”的定义以及行业类型。 行为理论告诉我们，如果在行为之前测量意图，则意图可以预测行为。意图和行为之间的时间会有所不同，这取决于它是全新的产品还是现有产品的变体。 此外，**与全新产品相比，现有产品和熟悉产品的变体的意图和行为之间的相关性更强**。

  无论使用哪种新产品预测方法，重要的是要彻底记录所做的预测及其背后的推理，以便在数据可用时能够对其进行评估。 

##### 判断调整

最后，我们考虑历史数据可用并用于生成统计预测的情况。 从业者通常会对这些预测进行判断性调整。 这些调整可以潜在地提供本章前面讨论过的判断性预测的所有优点。 **例如，它们为纳入统计模型中可能未考虑的因素提供了一种途径，例如促销、大型体育赛事、假期或尚未反映在数据中的近期事件**。 然而，这些优势只有在合适的条件下才能实现。 判断性调整，如判断性预测，带有偏见和局限性，我们必须实施有条不紊的策略以将它们最小化

谨慎使用调整:

从业者调整的频率比他们应该的要高得多，而且很多时候都是出于错误的原因。 通过调整统计预测，预测的用户会产生一种主人翁感和可信度。 用户通常不了解或不了解生成统计预测的机制（因为他们通常没有接受过这方面的培训）。 通过实施判断性调整，用户觉得他们对预测做出了贡献并完成了预测，现在他们可以将自己的直觉和解释与这些联系起来。 预测已经成为他们自己的预测。

判断性调整不应旨在纠正被认为被统计模型遗漏的数据中的系统模式。 这已被证明是无效的，因为预测人员倾向于读取嘈杂系列中不存在的模式。 统计模型在考虑数据模式方面要好得多，而判断性调整只会阻碍准确性。

当手头有重要的额外信息或强有力的证据表明需要进行调整时，判断性调整最有效。 只有当我们有重要的额外信息没有包含在统计模型中时，我们才应该进行调整。 因此，当它们的尺寸很大时，调整似乎是最准确的。 已经发现小调整（尤其是在促进乐观错觉的积极方向上）会阻碍准确性，应该避免。

应用结构化方法:

使用结构化和系统化方法将提高判断调整的准确性。 遵循上文中概述的关键原则至关重要。 特别是，必须记录和证明调整的合理性将使覆盖统计预测更具挑战性，并将防止不必要的调整。

由面板执行调整是很常见的。 使用 Delphi 设置具有很大的优势。 但是，如果在小组会议上进行调整，最好先考虑关键市场或产品的预测，因为小组成员在此过程中会感到疲倦。 随着会议的进行，往往会做出更少的调整。

#### 时间序列回归模型

TSLM()

##### 一些有用的预测变量

* 趋势

* 虚拟变量

  这种情况仍然可以在多元回归模型的框架内通过创建一个“虚拟变量”来处理，该虚拟变量取值 1 对应于“是”，取值 0 对应于“否”。 虚拟变量也称为“指标变量”。 虚拟变量也可用于解释数据中的异常值。 虚拟变量不是忽略异常值，而是消除其影响。 在这种情况下，虚拟变量为该观察值取值为 1，其他地方为 0。 一个例子是发生了特殊事件的情况。 例如，在预测到巴西的游客人数时，我们需要考虑 2016 年里约热内卢夏季奥运会的影响。

  如果有两个以上的类别，则可以使用多个虚拟变量（比类别总数少一个）对变量进行编码。 如果您将因子变量指定为预测变量，则 TSLM() 将自动处理这种情况。 通常不需要手动创建相应的虚拟变量。

* 季节性虚拟变量

  请注意，编码七个类别只需要六个虚拟变量。 这是因为第七个类别（在本例中为星期日）由截距捕获，并且在虚拟变量都设置为零时指定。


   许多初学者会尝试为第七类添加第七个虚拟变量。 这被称为“虚拟变量陷阱”，因为它会导致回归失败。 当还包括截距时，将有太多参数需要估计。 一般规则是使用比类别少一个虚拟变量。 所以对于季度数据，使用三个虚拟变量； 对于月度数据，使用 11 个虚拟变量； 对于每日数据，使用六个虚拟变量，依此类推。

   与虚拟变量相关的每个系数的解释是，它是该类别相对于省略类别的影响的度量。

* 干预变量

  通常需要对可能影响要预测的变量的干预进行建模。 例如，竞争对手的活动、广告支出、行业行动等等，都会产生影响。

  当效果仅持续一个时期时，我们使用“尖峰”变量。 这是一个虚拟变量，在干预期间取值为 1，在其他时间取值为 0。 尖峰变量相当于处理异常值的虚拟变量。

  其他干预措施具有直接和永久的效果。 如果干预导致水平移动（即从干预开始，序列的值突然且永久地改变），那么我们使用“阶跃”变量。 步长变量在干预前取值为零，从干预开始后取值为 1。

  另一种形式的永久效应是坡度的变化。 这里的干预是使用分段线性趋势处理的； 一种在干预时弯曲的趋势，因此是非线性的。 #

  1. 交易日

     一个月中的交易日数可能会有很大差异，并对销售数据产生重大影响。 为此，可以将每个月的交易天数作为预测指标。

     考虑到一周中不同天数的影响的替代方案具有以下预测因子： 

     $\begin{align*}  x_{1} &= \text{number of Mondays in month;} \\  x_{2} &= \text{number of Tuesdays in month;} \\        & \vdots \\  x_{7} &= \text{number of Sundays in month.} \end{align*}$

  2. 分布式滞后

     将广告支出作为预测因素通常很有用。 然而，由于广告的效果可以持续超出实际活动，我们需要包括广告支出的滞后值。 因此，可以使用以下预测器。

     $\begin{align*}  x_{1} &= \text{advertising for previous month;} \\  x_{2} &= \text{advertising for two months previously;} \\        & \vdots \\  x_{m} &= \text{advertising for $m$ months previously.} \end{align*}$

     通常要求系数随着滞后的增加而减小，尽管这超出了本章的范围。

  3. 复活节

     与大多数假期不同，因为它不是每年的同一天举行，其影响可持续数天。 在这种情况下，当假期在特定时间段内时，可以使用值为 1 的虚拟变量，否则为 0。

     对于月度数据，如果复活节在 3 月下降，则虚拟变量在 3 月取值为 1，如果在 4 月下降，虚拟变量在 4 月取值为 1。 当复活节从 3 月开始并在 4 月结束时，虚拟变量在月份之间按比例分配。(中国的春节类似)

  4. 傅立叶级数

     使用季节性虚拟变量的另一种方法是使用傅立叶项，尤其是对于**长季节性周期**。 让-巴蒂斯特·傅立叶 (Jean-Baptiste Fourier) 是一位出生于 1700 年代的法国数学家，他证明了一系列正确频率的正弦和余弦项可以近似于任何周期函数。 我们可以将它们用于季节性模式。

      如果 m 是季节性周期，则前几个傅立叶项由下式给出:

     $x_{1,t} = \sin\left(\textstyle\frac{2\pi t}{m}\right),  x_{2,t} = \cos\left(\textstyle\frac{2\pi t}{m}\right),  x_{3,t} = \sin\left(\textstyle\frac{4\pi t}{m}\right),$

     如果我们有每月的季节性，并且我们使用这些预测变量中的前 11 个，那么我们将得到与使用 11 个虚拟变量完全相同的预测。

     **对于傅立叶项，我们通常需要比虚拟变量更少的预测变量，尤其是当 m 很大时**。 这使得它们对于每周数据很有用，例如，其中 m ≈ 52 。 对于较短的季节性周期（例如，季度数据），与季节性虚拟变量相比，使用傅立叶项几乎没有优势。

      如果仅使用前两个傅立叶项$x_{1,t}$和$x_{2,t}$，则季节性模式将遵循简单的正弦波。 包含傅立叶项的回归模型通常称为调和回归，因为连续的傅立叶项代表前两个傅立叶项的谐波。

  ##### 选择预测变量

glance()

我们将这些值与其他模型的相应值进行比较。 对于 CV、AIC、AICc 和 BIC 度量，我们希望找到具有最低值的模型； 对于 Adjusted $R^2$ ，我们寻找具有最高值的模型。

虽然$R^{2}$被广泛使用，并且比其他度量存在的时间更长，但它倾向于选择过多的预测变量使其不太适合预测。

许多统计学家喜欢使用 BIC，因为它具有以下特性：如果存在真正的底层模型，BIC 会在给定足够数据的情况下选择该模型。 然而，在现实中，很少有真正的底层模型，即使有真正的底层模型，选择该模型也不一定会给出最好的预测（因为参数估计可能不准确）。

因此，建议使用 AICc、AIC 或 CV 统计数据之一，每个统计数据都以预测为目标。 如果 T 的值足够大，它们都会导致相同的模型。 

##### 回归预测

一些基本知识见回归章节，本节仅罗列与时序回归相关知识

事前与事后预测：

在对时间序列数据使用回归模型时，我们需要区分可以产生的不同类型的预测，这取决于计算预测时假设已知的内容。

事前预测是仅使用事先可获得的信息进行的预测。 例如，对样本结束后几个季度美国消费百分比变化的事前预测，应仅使用截至 2019 年第二季度（包括 2019 年第二季度）的可用信息。 这些是真实的预测，使用当时可用的任何信息提前做出。 因此，为了生成事前预测，该模型需要预测变量的预测。 为了获得这些，我们可以使用第 5.2 节中介绍的一种简单方法或第 8 章和第 9 章中更复杂的纯时间序列方法。或者，可以使用其他来源（例如政府机构）的预测。

事后预测是使用有关预测变量的后期信息进行的预测。 例如，消费的事后预测可以使用预测变量的实际观察，一旦这些已经被观察到。 这些不是真正的预测，但对研究预测模型的行为很有用。

事前预测和事后预测的比较评估有助于区分预测不确定性的来源。 这将显示预测错误是由于预测器的预测不佳还是由于预测模型不佳而出现的。

基于场景的预测：

在此设置中，预报员假设感兴趣的预测变量的可能场景。

 例如，美国政策制定者可能有兴趣比较当收入和储蓄分别持续增长 1% 和 0.5% 而就业率没有变化时，消费的预测变化与分别下降 1% 和 0.5% 的情况。  0.5%，对于样本结束后的四个季度中的每个季度。 结果预测计算如下，如图 7.18 所示。 我们应该注意到，基于情景的预测的预测区间不包括与预测变量的未来值相关的不确定性。 他们假设预测变量的值是预先知道的。

scenairos()

##### 多重共线性和预测

一个密切相关的问题是多重共线性，当多元回归中的两个或多个预测变量提供相似信息时，就会发生多重共线性。

当两个预测变量彼此高度相关（即它们的相关系数接近 +1 或 -1）时，就会发生这种情况。 在这种情况下，知道其中一个变量的值会告诉您很多关于另一个变量的值的信息。 因此，他们提供了类似的信息。 例如，脚的大小可用于预测身高，但在同一模型中包含左脚和右脚的大小不会使预测变得更好，尽管它也不会使预测变得更糟。

当预测变量的线性组合与预测变量的另一个线性组合高度相关时，也会出现多重共线性。 在这种情况下，了解第一组预测变量的值会告诉您很多有关第二组预测变量的值的信息。 因此，他们提供了类似的信息。

 当存在多重共线性时，与单个回归系数相关的不确定性会很大。 这是因为它们很难估计。 因此，对回归系数的统计检验（例如 t 检验）是不可靠的。  （在预测中，我们很少对此类测试感兴趣。）此外，不可能对每个单独的预测变量对预测的贡献做出准确的陈述。

注：**多重共线性**（Multicollinearity）是指[多变量](https://zh.wikipedia.org/wiki/一般线性模型)[线性回归](https://zh.wikipedia.org/wiki/線性回歸)中，[变量](https://zh.wikipedia.org/wiki/变量)之间由于存在高度相关关系而使[回归](https://zh.wikipedia.org/wiki/迴歸分析)估计不准确。在该情况下，多元回归的系数可能会因为模型或数据的微小变化发生剧烈改变。在样本数据集中，多重共线性不会影响模型整体的预测能力或[信度](https://zh.wikipedia.org/wiki/信度)，它只会影响单个预测值（predictor）的结果。**简而言之，一个包含有共线预测值的多元回归模型可以指示出模型整体的预测可靠程度，但可能无法对单个预测值给出有效结果，也可能无法判断哪些预测值是冗余的**。

如果未来预测变量的值超出预测变量的历史值范围，则预测将不可靠。 例如，假设您已经拟合了一个具有相互高度相关的预测变量 x 1 和 x 2 的回归模型，并假设训练数据中 x 1 的值介于 0 和 100 之间。然后基于 x 1 >  100 或 x 1 < 0 将不可靠。 当预测变量的未来值远远超出历史范围时，这总是有点危险，但当存在多重共线性时尤其成问题。

请注意，如果您使用的是优秀的统计软件，如果您对每个预测变量的具体贡献不感兴趣，并且如果您的预测变量的未来值在其历史范围内，则无需担心——多重共线性不是问题，除非存在完美的相关性。

#### 单位根过程

前面的AR、MA、ARMA主要应用于简单收益率和对数收益率。 对于价格序列， 一般其水平是缓慢变化的， 包括缓慢的增长趋势与一定的周期波动。 这样的序列不满足弱平稳的条件， 是非平稳时间序列。

典型的非平稳时间序列模型是**单位根(unit root)**非平稳时间序列。

##### 随机游走

考虑${p_t}$的模型:$\begin{align} p_t = p_{t-1} + \varepsilon_t, \ t=1,2,\dots \tag{7.1} \end{align}$

其中是零均值独立同分布白噪声列。 称是一个**随机游动**(random walk)。

上式表面上看是一个AR（1）模型，但是$\phi_1=1$不满足AR（1）的平稳性条件（$|\phi_1|<1$）,易得此模型不可预测

单位根过程的ACF估计是不相合的， 对单位根过程的样本作ACF图， 其衰减速度很慢很慢。

设$p_0=0$， 单位根过程${p_t}$有如下特点：

- $p_t$期望值等于0；
- 方差等于$\sigma^{2}t$，随线性增长，趋于无穷；
- 历史的扰动（新息）的影响不衰减；
- 预测只能用最后一个观测值作为预测， 预测均方误差趋于无穷。
- 样本ACF表现为基本不衰减，近似等于1。

##### 带漂移的随机游走

上面的随机游动模型的金融意义一般$p_t$是对数价格， 则$\varepsilon_t$是零均值的对数收益率。 实际的对数收益率常常是非零的，正数居多。 所以，模型可以推广为:$p_t = \mu + p_{t-1} + \varepsilon_t, \ t=1,2,\dots$,其中$\{ \varepsilon_t \}$仍为零均值独立同分布白噪声列。 常数$\mu$并不代表均值， 而是对数价格$p_t$的增长速度，称为模型的**漂移**(drift)

##### 固定趋势模型

设$\{ X_t \}$为弱平稳时间序列 令$Y_t = a + b t + X_t$

则$EY_t = (a + \mu_x) + bt$，$\text{Var}(Y_t) = \text{Var}(X_t) = \sigma_x^2$ ， 均值非常数所以$\{ Y_t \}$非平稳。 但是， 减去一个固定趋势$a + bt$后$\{ Y_t \}$就变成了平稳列， 这样的$\{ Y_t \}$与随机游动或者带漂移的随机游动有着本质的区别。

随机游动$p_t = p_{t+1} + \varepsilon_t$与固定趋势加扰动$Y_t = a + bt + X_t$都能呈现出缓慢的趋势变化。 区别在于：

- 随机游动的方差是线性增长的， 固定趋势的观测值方差不变；
- 随机游动的扰动的影响是永久的， 固定趋势的扰动的影响仅在一个时刻（如果扰动是白噪声） 或者很短时间（如果是扰动是线性时间序列）；
- 随机游动的趋势没有固定方向， 固定趋势的变化形状是固定的；
- 固定趋势模型减去一个固定的回归函数就可以变成平稳列， 随机游动减去任意的非随机函数都不能变平稳， 可以用差分运算变成平稳。

在AR和ARMA模型中， 常数项$\phi_0$与平稳均值有关。 但是在带漂移的随机游动模型中， 常数项$\mu$是每一步的平均增量，是固定线性趋势的斜率。 所以时间序列模型中的常数项可能会依模型的不同而具有迥然不同的含义。

将带漂移的随机游动模型中的白噪声替换成一个ARMA平稳列， 其主要的性质仍能保留。即$Y_t = Y_{t-1} + \mu + X_t$,详见：

##### 单位根检验

单位根非平稳列是金融中最常用的非平稳模型， 单位根非平稳列不能使用平稳列的模型来建模。 所以， 要建模的序列应该进行“单位根检验”。

对不带漂移的单位根过程， 考虑如下的基础模型：$\begin{align} p_t = \phi_1 p_{t-1} + \varepsilon_t  \end{align}$

其中$\{\varepsilon_t\}$是零均值独立同分布白噪声列。$|\phi_1| \leq 1$。 考虑如下零假设与对立假设：$H_0: \phi_1 = 1 \longleftrightarrow H_a: \phi_1 < 1$

这样的检验问题称为单位根检验问题。具体检验略 详见书

#### 指数平滑

ETS(R)

指数平滑是在 1950 年代后期提出的（Brown，1959 年；Holt，1957 年；Winters，1960 年），并推动了一些最成功的预测方法。 使用指数平滑方法生成的预测是过去观测值的加权平均值，随着观测值变老，权重呈指数衰减。 换句话说，观察越近，相关的权重就越高。 该框架可以快速生成可靠的预测，适用于广泛的时间序列，这是一个巨大的优势，对工业应用非常重要。

##### 简单指数平滑

最简单的指数平滑方法自然称为简单指数平滑 (SES)13。 这种方法适用于没有明显趋势或季节性模式的预测数据。

我们经常想要介于朴素和平均两个极端之间的东西。 例如，将更大的权重附加到最近的观察而不是来自遥远过去的观察可能是明智的。 这正是简单指数平滑背后的概念。 预测是使用加权平均值计算的，其中权重随着观测值来自更远的过去而呈指数下降——最小的权重与最旧的观测值相关联

$\begin{equation}
  \hat{y}_{T+1|T} = \alpha y_T + \alpha(1-\alpha) y_{T-1} + \alpha(1-\alpha)^2 y_{T-2}+ \cdots,   \tag{8.1}
\end{equation}$

其中 0 ≤ α ≤ 1 是平滑参数。 时间 T + 1 的提前一步预测是 y 1 , … , y T 序列中所有观测值的加权平均值。 权重降低的速率由参数 α 控制。

对于介于 0 和 1 之间的任何 α，随着时间的推移，附加到观测值的权重会呈指数下降，因此得名“指数平滑”。 如果 α 很小（即接近于 0），则对来自更远过去的观测值给予更大的权重。 如果 α 很大（即接近于 1），则对最近的观察给予更多的权重。 对于 α = 1 的极端情况，$\hat{y}_{T+1|T}=y_T$ ，并且预测等于朴素预测。

平坦预测 

简单指数平滑具有“平坦”预测函数：$\hat{y}_{T+h|T} = \hat{y}_{T+1|T}=\ell_T, \qquad h=2,3,\dots.$

也就是说，所有预测都采用相同的值，等于最后一个级别的组件。 请记住，这些预测仅适用于时间序列没有趋势或季节性成分的情况。

可以通过最小化 SSE 来估计任何指数平滑方法的未知参数和初始值,其中SSE:$\begin{equation} \text{SSE}=\sum_{t=1}^T(y_t - \hat{y}_{t|t-1})^2=\sum_{t=1}^Te_t^2. \tag{8.2} \end{equation}$

##### 有趋势方法

霍尔特线性趋势法：

Holt (1957) 扩展了简单指数平滑法以允许预测具有趋势的数据。 该方法涉及一个预测方程和两个平滑方程（一个用于水平，一个用于趋势）：

$\begin{align*}  \text{Forecast equation}&& \hat{y}_{t+h|t} &= \ell_{t} + hb_{t} \\  \text{Level equation}   && \ell_{t} &= \alpha y_{t} + (1 - \alpha)(\ell_{t-1} + b_{t-1})\\  \text{Trend equation}   && b_{t}    &= \beta^*(\ell_{t} - \ell_{t-1}) + (1 -\beta^*)b_{t-1}, \end{align*}$

预测函数不再是平坦的而是趋势的。  h 提前预测等于最后估计的水平加上最后估计的趋势值的 h 倍。 因此，预测是 h 的线性函数。

阻尼趋势法:

Holt 的线性方法生成的预测显示未来无限期的恒定趋势（增加或减少）。 经验证据表明，这些方法往往会过度预测，尤其是对于较长的预测范围。 受这一观察的启发，Gardner & McKenzie (1985) 引入了一个参数，该参数在未来的某个时间将趋势“抑制”为平坦线。 包括阻尼趋势的方法已被证明是非常成功的，并且可以说是当许多系列都需要自动预测时最流行的单个方法。算法：

$$\begin{align*}  \hat{y}_{t+h|t} &= \ell_{t} + (\phi+\phi^2 + \dots + \phi^{h})b_{t} \\  \ell_{t} &= \alpha y_{t} + (1 - \alpha)(\ell_{t-1} + \phi b_{t-1})\\  b_{t} &= \beta^*(\ell_{t} - \ell_{t-1}) + (1 -\beta^*)\phi b_{t-1}. \end{align*}$$

实际上， ϕ 很少小于 0.8，因为阻尼对较小的值有很强的影响。 接近 1 的 ϕ 值意味着无法将阻尼模型与非阻尼模型区分开来。 由于这些原因，我们通常将 ϕ 限制为最小值 0.8 和最大值 0.98。

```R
model(
    SES = ETS(value ~ error("A") + trend("N") + season("N")),
    Holt = ETS(value ~ error("A") + trend("A") + season("N")),
    Damped = ETS(value ~ error("A") + trend("Ad") +
                   season("N"))
  )
```

##### 季节性方法

Holt 和 Winters  扩展了 Holt 的方法来捕捉季节性。  Holt-Winters 季节性方法包括预测方程和三个平滑方程——一个用于水平$\ell_t$，一个用于趋势$b_t$，另一个用于季节性分量$s_t$ ，以及相应的平滑参数 α 、 β ∗ 和 γ 。

这种方法有两种变体，它们在季节性成分的性质上有所不同。 **当季节变化在整个系列中大致恒定时，加法方法是首选，而当季节变化与系列的水平成正比时，乘法方法是首选**。 在加法方法中，季节性分量以观测序列的尺度绝对值表示，而在水平方程中，通过减去季节性分量对序列进行季节性调整。 在每一年中，季节性成分加起来大约为零。 使用乘法方法时，季节性成分以相对项（百分比）表示，并通过除以季节性成分对序列进行季节性调整。 在每一年中，季节性分量的总和约为 m 。

加法公式：

$$\begin{align*}  \hat{y}_{t+h|t} &= \ell_{t} + hb_{t} + s_{t+h-m(k+1)} \\  \ell_{t} &= \alpha(y_{t} - s_{t-m}) + (1 - \alpha)(\ell_{t-1} + b_{t-1})\\  b_{t} &= \beta^*(\ell_{t} - \ell_{t-1}) + (1 - \beta^*)b_{t-1}\\  s_{t} &= \gamma (y_{t}-\ell_{t-1}-b_{t-1}) + (1-\gamma)s_{t-m}, \end{align*}$$

乘法公式：

$$\begin{align*}  \hat{y}_{t+h|t} &= (\ell_{t} + hb_{t})s_{t+h-m(k+1)} \\  \ell_{t} &= \alpha \frac{y_{t}}{s_{t-m}} + (1 - \alpha)(\ell_{t-1} + b_{t-1})\\  b_{t} &= \beta^*(\ell_{t}-\ell_{t-1}) + (1 - \beta^*)b_{t-1}                \\  s_{t} &= \gamma \frac{y_{t}}{(\ell_{t-1} + b_{t-1})} + (1 - \gamma)s_{t-m} \end{align*}$$

```R
model(
    additive = ETS(Trips ~ error("A") + trend("A") +
                                                season("A")),
    multiplicative = ETS(Trips ~ error("M") + trend("A") +
                                                season("M"))
  )
```

##### 指数平滑方法分类

指数平滑方法不限于我们目前介绍的那些。 通过考虑趋势和季节性成分组合的变化，可以使用九种指数平滑方法，如表 8.5 所示。 每种方法都由一对字母 (T,S) 标记，定义了“趋势”和“季节性”组件的类型。 例如，(A,M) 是具有加性趋势和乘性季节性的方法；  (Ad ,N) 是有阻尼趋势且无季节性的方法； 等等。

我们不考虑本书中的乘法趋势方法，因为它们往往会产生较差的预测。

表8.5

| Trend Component       | Seasonal Component |            |                  |
| :-------------------- | :----------------- | :--------- | :--------------- |
|                       | N                  | A          | M                |
|                       | (None)             | (Additive) | (Multiplicative) |
| N (None)              | (N,N)              | (N,A)      | (N,M)            |
| A (Additive)          | (A,N)              | (A,A)      | (A,M)            |
| Add (Additive damped) | (Add,N)            | (Add,A)    | (Add,M)          |

##### 不同状态空间

 每个模型都包含一个描述观测数据的测量方程，以及一些描述未观测到的成分或状态（水平、趋势、季节性）如何随时间变化的状态方程。 因此，这些被称为状态空间模型。

对于每种方法，存在两种模型：一种具有加性误差，另一种具有乘性误差。 如果模型使用相同的平滑参数值，则它们生成的点预测是相同的。 然而，它们会产生不同的预测区间。

 我们将每个状态空间模型标记为 ETS( ⋅ , ⋅ , ⋅ ) for (Error, Trend, Seasonal)。 这个标签也可以被认为是指数平滑。 使用与表 8.5 中相同的符号，每个分量的可能性是：Error = { A,M } ，Trend = { N,A,Ad } 和 Seasonal = { N,A,M } 

![img](https://otexts.com/fpp3/figs/statespacemodels-1.png)

##### 估计和模型选择

估计略

ETS 统计框架的一大优势是信息标准可用于模型选择。 前文中介绍的 AIC、AICc 和 BIC 可用于确定哪个 ETS 模型最适合给定的时间序列。

对于 ETS 模型，Akaike 的信息准则 (AIC) 定义为 ：$\text{AIC} = -2\log(L) + 2k$

修正小样本偏差的 AIC (AICc )定义为$$\text{AIC}_{\text{c}} = \text{AIC} + \frac{2k(k+1)}{T-k-1}$$

贝叶斯信息准则 (BIC) 是:$\text{BIC} = \text{AIC} + k[\log(T)-2].$

可能导致数值不稳定性的模型是 ETS(A,N,M)ETS(A,A,M)和ETS(A,Ad ,M)，由于除以状态方程中可能接近零的值。在选择模型时，我们通常不会考虑这些特定的组合。

 当数据严格为正时，具有乘法误差的模型很有用，但当数据包含零或负值时，模型在数值上不稳定。 因此，如果时间序列不是严格为正的，则不会考虑乘法误差模型。 在这种情况下，将仅应用六个完全可加模型。

 ETS() 函数可通过最小化 AICc 来选择模型

#### ARIMA 模型

ARIMA 模型提供了另一种时间序列预测方法。 指数平滑和 ARIMA 模型是时间序列预测中使用最广泛的两种方法，并为该问题提供了补充方法。 指数平滑模型基于对数据趋势和季节性的描述，而 ARIMA 模型旨在描述数据中的自相关。

在介绍 ARIMA 模型之前，我们必须首先讨论平稳性的概念和差分时间序列的技术。

##### 平稳性和差分

平稳时间序列是其统计属性不依赖于观察序列的时间的序列。 因此，具有趋势或季节性的时间序列不是平稳的——趋势和季节性会影响时间序列的价值 在不同的时间。 另一方面，白噪声序列是静止的——你观察它的时间并不重要，它在任何时间点看起来都应该是一样的。

有些情况可能会令人困惑——具有周期性行为（但没有趋势或季节性）的时间序列是平稳的。 这是因为循环的长度不是固定的，所以在我们观察序列之前，我们无法确定循环的波峰和波谷在哪里。

 **一般来说，一个平稳的时间序列在长期没有可预测的模式。 时间图将显示该系列大致水平（尽管可能存在某些循环行为），并具有恒定方差。**

![Which of these series are stationary? (a) Google closing stock price in 2015; (b) Daily change in the Google stock price in 2015; (c) Annual number of strikes in the US; (d) Monthly sales of new one-family houses sold in the US; (e) Annual price of a dozen eggs in the US (constant dollars); (f) Monthly total of pigs slaughtered in Victoria, Australia; (g) Annual total of Canadian Lynx furs traded by the Hudson Bay Company; (h) Quarterly Australian beer production; (i) Monthly Australian gas production.](https://otexts.com/fpp3/fpp_files/figure-html/stationary-1.png) (b) 和 (g) 作为固定序列。

差分：

在图 9.1 中，请注意（a）中 Google 股票价格是非平稳的，但（b）中每日变化是平稳的。 这显示了使非平稳时间序列平稳的一种方法 - 计算连续观察之间的差异。 这称为差分。

对数等变换有助于稳定时间序列的方差。 差分可以通过消除时间序列水平的变化来帮助稳定时间序列的平均值，从而消除（或减少）趋势和季节性。

除了数据的时间图外，ACF 图对于识别非平稳时间序列也很有用。 对于平稳时间序列，ACF 会相对较快地下降到零，而非平稳数据的 ACF 下降缓慢。 此外，对于非平稳数据，$r_1$的值通常很大且为正。

随机游走模型：

差分序列是原始序列中连续观测值之间的变化，可以写成$y'_t = y_t - y_{t-1}.$。

 差分序列将只有 T − 1 个值，因为不可能为第一次观测计算差异$y_1'$。

 当差分序列是白噪声时，原始序列的模型可以写成$y_t - y_{t-1} = \varepsilon_t,$，其中$\varepsilon_t$表示白噪声。 重新排列这会导致“随机游走”模型$y_t = y_{t-1} + \varepsilon_t.$ 。

随机游走模型广泛用于非平稳数据，尤其是金融和经济数据。 随机游走通常具有： 

* 长期明显的上升或下降趋势 
* 突然且不可预测的方向变化。

随机游走模型的预测与上次观察结果相同，因为未来的运动是不可预测的，并且上升或下降的可能性相同。 因此，随机游走模型支持在前文中提到的的朴素预测。

密切相关的模型允许差异具有非零均值。 然后$y_t - y_{t-1} = c + \varepsilon_t\quad\text{or}\quad {y_t = c + y_{t-1} + \varepsilon_t}\: .$

c 的值是连续观察之间变化的平均值。 如果 c 为正，则平均变化是$y_t$值的增加。 因此，$y_t$将趋于向上漂移。 但是，如果 c 为负，则$y_t$将趋于向下漂移。

这是漂移方法背后的模型，也在[简单预测模型](#简单预测模型)中讨论过。

二阶差分：

有时差分数据看起来不是平稳的，可能需要对数据进行第二次差分以获得平稳序列：$\begin{align*}  y''_{t}  &=  y'_{t}  - y'_{t - 1} \\           &= (y_t - y_{t-1}) - (y_{t-1}-y_{t-2})\\           &= y_t - 2y_{t-1} +y_{t-2}. \end{align*}$。
    

 在这种情况下，y ′′ t 将具有 T − 2 个值。 然后，我们将对原始数据的“变化中的变化”进行建模。 **在实践中，几乎没有必要超越二阶差分**。

季节性差异:

季节性差异是观测值与同一季节的前一个观测值之间的差异。 所以 $y'_t = y_t - y_{t-m},$，其中 m = 季节数。 这些也称为“滞后 m 差”，因为我们在 m 个周期滞后后减去观测值。

如果季节性差异数据似乎是白噪声，那么原始数据的合适模型是

 $y_t = y_{t-m}+\varepsilon_t.$

该模型的预测等于相关季节的最后一次观测。 也就是说，该模型给出了前文中介绍的季节性朴素预测。

在选择应用哪些差异时存在一定程度的主观性。 图 9.3 中的季节性差异数据与图 9.4 中的季节性差异数据没有表现出明显不同的行为。 在后一种情况下，我们本可以决定停止使用季节性差异数据，而不是进行额外的一轮差异化。 在前一种情况下，我们本可以认为数据不够平稳并进行额外一轮的差分。 下面讨论了一些正式的差分测试，但在建模过程中总会有一些选择，不同的分析师可能会做出不同的选择。

如果$y'_t = y_t - y_{t-m}$表示季节性差分序列，则两次差分序列为

$$\begin{align*} y''_t &= y'_t - y'_{t-1} \\      &= (y_t - y_{t-m}) - (y_{t-1} - y_{t-m-1}) \\      &= y_t -y_{t-1} - y_{t-m} + y_{t-m-1}\: \end{align*}$$

当应用季节性差分和一阶差分时，先做没有区别——结果是一样的。 但是，如果数据具有很强的季节性模式，我们建议先进行季节性差分，因为结果序列有时是平稳的，不需要进一步的一阶差分。 如果先进行一阶差分，仍然会存在季节性。

请注意，**应用比所需更多的差异会导致时间序列中并不真正存在的虚假动态或自相关。 因此，尽可能少地进行差异以获得平稳序列**。

重要的是，如果使用差分，差异是可解释的。 第一个差异是一次观察和下一次观察之间的变化。 季节性差异是一年与下一年之间的变化。 其他滞后不太可能有太多可解释的意义，应该避免。  

单位根检验 

更客观地确定是否需要差分的一种方法是使用单位根检验。 这些是平稳性的统计假设检验，旨在确定是否需要差分。

详细理论等见[单位根过程](#单位根过程)

有许多单位根检验可用，它们基于不同的假设，可能会导致相互矛盾的答案。 在我们的分析中，我们使用 Kwiatkowski-Phillips-Schmidt-Shin (KPSS) 测试（Kwiatkowski 等，1992）。 在这个测试中，原假设是数据是平稳的，我们寻找原假设为假的证据。 因此，小的 p 值（例如，小于 0.05）表明需要进行差分。 可以使用 unitroot_kpss() 函数计算测试。


##### 自回归模型

在前文介绍的多元回归模型中，我们使用预测变量的线性组合来预测感兴趣的变量。 在自回归模型中，我们使用变量过去值的线性组合来预测感兴趣的变量。 术语自回归表示它是变量对自身的回归。

因此，一个 p 阶自回归模型可以写成$y_{t} = c + \phi_{1}y_{t-1} + \phi_{2}y_{t-2} + \dots + \phi_{p}y_{t-p} + \varepsilon_{t},$ ，其中$\varepsilon_t$是白噪声。 这类似于多元回归，但使用$y_t$的滞后值作为预测变量。 我们将其称为 AR(p) 模型，即 p 阶自回归模型。

自回归模型在处理各种不同的时间序列模式方面非常灵活。  改变参数 ϕ 1 , … , ϕ p 会产生不同的时间序列模式。 误差项 $\varepsilon_t$的方差只会改变序列的尺度，而不是模式。

对于 AR(1) 模型：

* 当 ϕ 1 = 0 且 c = 0 时，y t 等价于白噪声； 
* 当 ϕ 1 = 1 且 c = 0 时，y t 等价于随机游走； 
* 当 ϕ 1 = 1 且 c ≠ 0 时，y t 等价于有漂移的随机游走； 
* 当 ϕ 1 < 0 时，y t 倾向于围绕均值振荡。

我们通常将自回归模型限制为固定数据，在这种情况下，需要对参数值进行一些限制。

* 对于 AR(1) 模型： − 1 < ϕ 1 < 1 。
* 对于 AR(2) 模型： − 1 < ϕ 2 < 1 , ϕ 1 + ϕ 2 < 1 , ϕ 2 − ϕ 1 < 1 。

当 p ≥ 3 时，限制要复杂得多。 在估计模型时，fable 包会处理这些限制。

##### 移动平均模型

移动平均模型不是在回归中使用预测变量的过去值，而是在类似回归的模型中使用过去的预测误差，$y_{t} = c + \varepsilon_t + \theta_{1}\varepsilon_{t-1} + \theta_{2}\varepsilon_{t-2} + \dots + \theta_{q}\varepsilon_{t-q},$

其中$\varepsilon_t$是白噪声。 我们将其称为 MA( q ) 模型，即 q 阶移动平均模型。 当然，我们没有观察到$\varepsilon_t的值，所以它并不是通常意义上的回归。

请注意，可以将$y_t$的每个值视为过去几个预测误差的加权移动平均值（尽管系数之和通常不会为 1）。 但是，不应将移动平均模型与我们在时序分解中讨论的移动平均平滑混淆。**移动平均模型用于预测未来值，而移动平均平滑用于估计过去值的趋势周期**。

MA模型的可逆性约束类似于平稳性约束。

   * 对于 MA(1) 模型：$-1<\theta_1<1$ 。
   * 对于 MA(2) 模型： $-1<\theta_2,1,~\theta_2+\theta_1 >-1,~\theta_1 -\theta_2 < 1$ 。

更复杂的条件适用于 q ≥ 3。 同样，在估计模型时，fable 包将处理这些约束。

##### 非季节性 ARIMA 模型

如果我们将差分与自回归和移动平均模型结合起来，我们就会得到一个非季节性的 ARIMA 模型。  ARIMA 是自回归积分移动平均线的首字母缩写词（在这种情况下，“积分”是差分的反义词）。 完整的模型可以写成:

$\begin{equation}  y'_{t} = c + \phi_{1}y'_{t-1} + \cdots + \phi_{p}y'_{t-p}     + \theta_{1}\varepsilon_{t-1} + \cdots + \theta_{q}\varepsilon_{t-q} + \varepsilon_{t},  \tag{9.1} \end{equation}$

其中$y_t'$是差分序列（它可能已经被差分多次）。 右侧的“预测器”包括 y t 的滞后值和滞后误差。 我们称其为 ARIMA( p , d , q ) 模型，其中

| p=   | order of the autoregressive part;      |
| ---- | -------------------------------------- |
| d=   | degree of first differencing involved; |
| q=   | order of the moving average part.      |

用于自回归和移动平均模型的相同平稳性和可逆性条件也适用于 ARIMA 模型。我们已经讨论过的许多模型都是 ARIMA 模型的特例，如图所示:

| White noise            | ARIMA(0,0,0) with no constant |
| ---------------------- | ----------------------------- |
| Random walk            | ARIMA(0,1,0) with no constant |
| Random walk with drift | ARIMA(0,1,0) with a constant  |
| Autoregression         | ARIMA(p,0,0)                  |
| Moving average         | ARIMA(0,0,q)                  |

$\begin{equation}   \begin{array}{c c c c}    (1-\phi_1B - \cdots - \phi_p B^p) & (1-B)^d y_{t} &= &c + (1 + \theta_1 B + \cdots + \theta_q B^q)\varepsilon_t\\    {\uparrow} & {\uparrow} & &{\uparrow}\\    \text{AR($p$)} & \text{$d$ differences} & & \text{MA($q$)}\\  \end{array} \end{equation}$

例子：

```R
fit <- global_economy %>%
  filter(Code == "EGY") %>%
  model(ARIMA(Exports))
report(fit)
```

了解 ARIMA 模型:

 ARIMA() 函数很有用，但任何自动化的东西都可能有点危险，即使您依赖自动程序为您选择模型，了解模型的行为也是值得的。

常数 c 对从这些模型获得的长期预测有重要影响。

* 如果 c = 0 和 d = 0 ，长期预测将为零。
* 如果 c = 0 和 d = 1 ，长期预测将变为非零常数。
* 如果 c = 0 和 d = 2 ，长期预测将遵循一条直线。
* 如果 c ≠ 0 且 d = 0 ，则长期预测将趋向于数据的均值。
* 如果 c ≠ 0 且 d = 1 ，则长期预测将遵循一条直线。
* 如果 c ≠ 0 且 d = 2 ，长期预测将遵循二次趋势。  （不推荐这样做，fable也不允许。）

d 的值也对预测区间有影响——d 的值越高，预测区间的大小增加得越快。 对于 d = 0 ，长期预测的标准差会趋向于历史数据的标准差，因此预测区间将基本相同。

如果数据显示循环，p 的值很重要。 要获得循环预测，必须使 p ≥ 2 以及参数的一些附加条件。 对于 AR(2) 模型，如果$\phi_1^2+4\phi_2<0$，就会出现循环行为。 在这种情况下，周期的平均周期为$\dfrac{2\pi}{\text{arc cos}(-\phi_1(1-\phi_2)/(4\phi_2))}.$

ACF 和 PACF 图:

通常无法仅从时间图中判断 p 和 q 的哪些值适合数据。 但是，有时可以使用 ACF 图和密切相关的 PACF 图来确定 p 和 q 的适当值。

回想一下，ACF 图显示了测量 y t 和 y t − k 之间关系的自相关性，其中 k 的不同值。 现在如果 y t 和 y t − 1 是相关的，那么 y t − 1 和 y t − 2 也一定是相关的。 然而，那么y t 和y t − 2 可能是相关的，仅仅因为它们都与y t − 1 相关，而不是因为y t − 2 中包含可用于预测y t 的任何新信息。

为了克服这个问题，我们可以使用偏自相关。 在去除滞后 1、2、3、…、k − 1 的影响后，它们测量 y t 和 y t − k 之间的关系。 所以第一个偏自相关与第一个自相关相同，因为它们之间没有任何东西可以去除。 每个偏自相关都可以估计为自回归模型中的最后一个系数。 具体而言，第 k 个偏自相关系数$\alpha_k$等于 AR( k ) 模型中$\phi k$的估计值。 在实践中，有比拟合所有这些自回归更有效的计算$\alpha_k$的算法，但它们给出相同的结果。偏自相关具有与普通自相关相同的 ± 1.96 / √ T 临界值

在一个命令中生成时间图、ACF 图和 PACF 图的一种便捷方法是使用 gg_tsdisplay()函数和 plot_type = "partial"。

如果数据来自 ARIMA( p , d ,0) 或 ARIMA(0, d , q ) 模型，则 ACF 和 PACF 图有助于确定 p 或 q 的值。 如果 p 和 q 均为正值，则绘图无助于找到合适的 p 和 q 值。

如果差分数据的 ACF 和 PACF 图显示以下模式，则数据可能遵循 ARIMA( p , d ,0) 模型：

* ACF 呈指数衰减或正弦曲线； 
* 在 PACF 的滞后 p 处有一个显着的尖峰，但没有超过滞后 p 。

如果差分数据的 ACF 和 PACF 图显示以下模式，则数据可能遵循 ARIMA(0, d , q ) 模型：

* PACF 呈指数衰减或正弦； 
* 在 ACF 中的滞后 q 处有一个显着的尖峰，但没有超出滞后 q 。

![ACF of Egyptian exports.](https://otexts.com/fpp3/fpp_files/figure-html/egyptacf-1.png)

![PACF of Egyptian exports.](https://otexts.com/fpp3/fpp_files/figure-html/egyptpacf-1.png)

在图 9.9 中，我们看到 ACF 中有一个衰减的正弦模式，在图 9.10 中，PACF 显示了滞后 4 处的最后一个显着峰值。这就是您对 ARIMA(4,0,0) 模型的期望。

我们还可以指定 ARIMA() 可以搜索的 pdq() 的特定值。 例如，要找到具有 p ∈ { 1 , 2 , 3 } , q ∈ { 0 , 1 , 2 } 和 d = 1 的最佳 ARIMA 模型，您可以使用 ARIMA(y ~ pdq(p=1:3, d  =1, q=0:2))。

##### 估计和顺序选择

最大似然估计:

一旦确定了模型阶数（即 p 、 d 和 q 的值），我们需要估计参数 c 、 ϕ 1 、... 、 ϕ p 、 θ 1 、... 、 θ q 。 当fable估计 ARIMA 模型时，它使用最大似然估计 (MLE)。 该技术找到使获得我们观察到的数据的概率最大化的参数值。 对于 ARIMA 模型，MLE 类似于通过最小化$\sum_{t=1}^T\varepsilon_t^2.$获得的最小二乘估计。
     

（对于第 7 章中考虑的回归模型，MLE 给出与最小二乘估计完全相同的参数估计。）请注意，ARIMA 模型的估计比回归模型复杂得多，并且不同的软件会因为使用不同的方法而给出略有不同的答案、估计和不同的优化算法。

在实践中，fable 包会报告数据的对数似然值； 即观测数据来自估计模型的概率的对数。 对于给定的 p 、 d 和 q 值，ARIMA() 将在寻找参数估计值时尝试最大化对数似然。

信息标准：

Akaike 的信息准则 (AIC) 可用于选择回归预测变量，也可用于确定 ARIMA 模型的阶数。 它可以写成 $\text{AIC} = -2 \log(L) + 2(p+q+k+1),$，其中 L 是数据的似然性，如果 c ≠ 0，则 k = 1，如果 c = 0，则 k = 0。 请注意，括号中的最后一项是模型中的参数数量（包括 $\sigma^2$ ，残差的方差）。

对于 ARIMA 模型，修正后的 AIC 可以写为:$\text{AICc} = \text{AIC} + \frac{2(p+q+k+1)(p+q+k+2)}{T-p-q-k-2},$

贝叶斯信息准则可以写成$\text{BIC} = \text{AIC} + [\log(T)-2](p+q+k+1).$

通过最小化 AIC、AICc 或 BIC 可以获得好的模型。 我们更喜欢使用 AICc。

重要的是要注意，这些信息标准往往不是选择模型的适当差分顺序 (d) 的良好指南，而仅适用于选择 p 和 q 的值。 **这是因为差分改变了计算似然的数据，使得具有不同差分阶数的模型之间的 AIC 值不具有可比性**。 所以我们需要使用一些其他的方法来选择 d ，然后我们可以使用 AICc 来选择 p 和 q 。

##### ARIMA建模

将 ARIMA 模型拟合到一组（非季节性）时间序列数据时，以下过程提供了一种有用的通用方法。

1. 绘制数据并识别任何不寻常的观察结果。
2. 如有必要，转换数据（使用 Box-Cox 转换）以稳定方差。
3. 如果数据是非平稳的，则取数据的一阶差分，直到数据平稳。
4. 检查 ACF/PACF：ARIMA( p , d , 0 ) 或 ARIMA( 0 , d , q ) 模型是否合适？
5. 尝试您选择的模型，并使用 AICc 搜索更好的模型。
6. 通过绘制残差的 ACF 并对残差进行组合检验来检查所选模型的残差。 如果它们看起来不像白噪声，请尝试修改模型。
7. 一旦残差看起来像白噪声，计算预测。
     Hyndman-Khandakar 算法（自动程序）只处理步骤 3-5。 因此，即使您使用它，您仍然需要自己处理其他步骤。

下图总结了该过程：

![General process for forecasting using an ARIMA model.](https://otexts.com/fpp3/figs/arimaflowchart.png)

注：

在非平稳 ARIMA 模型中包含一个常数等效于在预测中引入 d 阶多项式趋势。  （如果省略常数，则预测包括阶数为 d − 1 的多项式趋势。）当 d = 0 时，我们有一个特殊情况，即 μ 是 y t 的平均值。


 默认情况下，ARIMA() 函数将自动确定是否应包含常量。 对于 d = 0 或 d = 1 ，如果它提高了 AICc 值，将包括一个常数。 如果 d > 1，则始终忽略常数，因为在预测时二次或更高阶趋势特别危险。


 可以通过在模型公式中包含 0 或 1 来指定常量（如 lm() 中的截距）。 例如，要自动选择具有常量的 ARIMA 模型，您可以使用 ARIMA(y ~ 1 + ...)。 类似地，可以使用 ARIMA(y ~ 0 + ...) 排除常数。

##### 预测

ARIMA 模型的预测区间基于残差不相关且正态分布的假设。 如果这些假设中的任何一个不成立，则预测区间可能不正确。 因此，在生成预测区间之前，始终绘制残差的 ACF 和直方图以检查假设。

如果残差不相关但不是正态分布，则可以获得自举区间，如第 5.5 节所述。 这可以通过简单地在 forecast() 函数中添加 bootstrap=TRUE 来轻松实现。

 一般来说，ARIMA 模型的预测区间随着预测范围的增加而增加。 对于平稳模型（即 d = 0 ），它们会收敛，因此长期范围的预测区间基本上是相同的。 对于 d ≥ 1 ，预测区间将继续增长到未来。

与大多数预测区间计算一样，基于 ARIMA 的区间往往太窄。 发生这种情况是因为只考虑了误差的变化。 参数估计值和模型顺序也存在变化，这些变化未包括在计算中。 此外，计算假设已建模的历史模式将持续到预测期。

##### 季节性 ARIMA 模型

到目前为止，我们已经将注意力限制在非季节性数据和非季节性 ARIMA 模型上。 但是，ARIMA 模型还能够对范围广泛的季节性数据进行建模。

季节性 ARIMA 模型是通过在我们目前看到的 ARIMA 模型中包含额外的季节性项而形成的。 它是这样写的：



其中 m = 季节性周期（例如，每年的观测次数）。 我们对模型的季节性部分使用大写表示法，对模型的非季节性部分使用小写表示法。

 模型的季节性部分由与模型的非季节性组件相似的项组成，但涉及季节性周期的回移。 例如，ARIMA(1,1,1)(1,1,1)4 模型（没有常数）用于季度数据（ m = 4 ），可以写成$(1 - \phi_{1}B)~(1 - \Phi_{1}B^{4}) (1 - B) (1 - B^{4})y_{t} =  (1 + \theta_{1}B)~ (1 + \Theta_{1}B^{4})\varepsilon_{t}.$

ACF/PACF:

AR 或 MA 模型的季节性部分将在 PACF 和 ACF 的季节性滞后中看到。 例如，ARIMA(0,0,0)(0,0,1) 12 模型将显示： ACF 在滞后 12 处出现尖峰，但没有其他显着尖峰；  PACF 的季节性滞后呈指数衰减（即滞后 12、24、36……）。

类似地，ARIMA(0,0,0)(1,0,0) 12 模型将显示： ACF 季节性滞后的指数衰减；  PACF 中滞后 12 的单个显着峰值。

在考虑季节性 ARIMA 模型的适当季节性orders时，应将**注意力限制在季节性滞后上**。

建模过程与非季节性数据几乎相同，只是我们需要选择季节性 AR 和 MA 项以及模型的非季节性组件。 这个过程最好通过例子来说明。

例子：

我们将使用 2000 年 1 月至 2019 年 9 月的美国休闲和酒店业月度就业数据来描述季节性 ARIMA 建模，

```R
leisure <- us_employment %>%
  filter(Title == "Leisure and Hospitality",
         year(Month) > 2000) %>%
  mutate(Employed = Employed/1000) %>%
  select(Month, Employed)
autoplot(leisure, Employed) +
  labs(title = "US employment: leisure and hospitality",
       y="Number of people (millions)")
```

![Monthly US leisure and hospitality employment, 2000-2019.](https://otexts.com/fpp3/fpp_files/figure-html/usemployment1-1.png)

数据显然是非平稳的，具有很强的季节性和非线性趋势，所以我们首先取季节性差异。 

```R
leisure %>%
  gg_tsdisplay(difference(Employed, 12),
               plot_type='partial', lag=36) +
  labs(title="Seasonally differenced", y="")
```

这些显然也是非平稳的，因此我们在图 9.20 中进一步进行第一个差异。

```R
leisure %>%
  gg_tsdisplay(difference(Employed, 12) %>% difference(),
               plot_type='partial', lag=36) +
  labs(title = "Double differenced", y="")
```

![Double differenced Monthly US leisure and hospitality employment.](https://otexts.com/fpp3/fpp_files/figure-html/usemployment3-1.png)

我们现在的目标是根据图 9.20 所示的 ACF 和 PACF 找到合适的 ARIMA 模型。  ACF 滞后 2 处的显着峰值表明存在非季节性 MA(2) 分量。  ACF 滞后 12 处的显着峰值表明存在季节性 MA(1) 分量。 因此，我们从 ARIMA(0,1,2)(0,1,1) 12 模型开始，指示一阶差分、季节性差异以及非季节性 MA(2) 和季节性 MA(1) 分量。 如果我们从 PACF 开始，我们可能已经选择了 ARIMA(2,1,0)(0,1,1) 12 模型——使用 PACF 选择模型的非季节性部分，使用 ACF 选择 模型的季节性部分。 

我们还将包括一个自动选择的模型。 通过设置 stepwise=FALSE 和 approximation=FALSE，我们让 R 更加努力地找到一个好的模型。 这需要更长的时间，但只有一个系列要建模，因此花费的额外时间不是问题。

```R
fit <- leisure %>%
  model(
    arima012011 = ARIMA(Employed ~ pdq(0,1,2) + PDQ(0,1,1)),
    arima210011 = ARIMA(Employed ~ pdq(2,1,0) + PDQ(0,1,1)),
    auto = ARIMA(Employed, stepwise = FALSE, approx = FALSE)
  )
fit %>% pivot_longer(everything(), names_to = "Model name",
                     values_to = "Orders")
glance(fit) %>% arrange(AICc) %>% select(.model:BIC)
```

可以肯定的是，我们使用了 Ljung-Box 测试，它具有很大的 p 值，确认残差类似于白噪声。 请注意，**替代模型也通过了此测试**。

```R
augment(fit) %>% features(.innov, ljung_box, lag=24, dof=4)
forecast(fit, h=36) %>%
  filter(.model=='auto') %>%
  autoplot(leisure) +
  labs(title = "US employment: leisure and hospitality",
       y="Number of people (millions)")
```

注意：

当使用 AICc 值比较模型时，重要的是所有模型都具有相同的差分阶数。 然而，当使用测试集比较模型时，预测是如何产生的并不重要——比较总是有效的。 因此，在上表中，我们可以包括一些仅具有季节性差异的模型和一些具有一阶差分和季节性差分的模型，而在包含 AICc 值的较早表中，我们仅比较了具有季节性差异但没有一阶差分的模型。

 这里考虑的模型都没有通过所有的残差测试。 在实践中，我们通常会使用我们能找到的最好的模型，即使它没有通过所有的测试。

##### ARIMA vs ETS

普遍认为 ARIMA 模型比指数平滑更通用。 虽然线性指数平滑模型都是 ARIMA 模型的特例，但非线性指数平滑模型没有等效的 ARIMA 模型。 另一方面，也有许多没有指数平滑对应项的 ARIMA 模型。 特别是，所有 ETS 模型都是非平稳的，而一些 ARIMA 模型是平稳的。 图 9.27 显示了两个模型类之间的重叠。
![The ETS and ARIMA model classes overlap with the additive ETS models having equivalent ARIMA forms.](https://otexts.com/fpp3/fpp_files/figure-html/venn-1.png)

具有季节性或非阻尼趋势或两者兼有的 ETS 模型有两个单位根（即，它们需要两个差分水平才能使其平稳）。 所有其他 ETS 模型都有一个单位根（它们需要一级差分才能使其平稳）。

**AICc 可用于在同一类中的模型之间进行选择**。 例如，我们可以使用它在候选 ARIMA 模型之间选择 ARIMA 模型或在候选 ETS 模型之间选择 ETS 模型。 但是，它不能用于比较 ETS 和 ARIMA 模型，因为它们属于不同的模型类，并且可能性的计算方式不同。 下面的示例演示了在这些模型类之间进行选择。



#### 动态回归模型

##### 带有 ARIMA 误差的回归

如果公式中包含外生回归量，则函数 ARIMA() 将拟合具有 ARIMA 误差的回归模型。 正如前文中介绍的那样，特殊的 pdq() 指定了 ARIMA 误差模型的顺序。 如果指定了差分，则在估计模型之前将差分应用于回归模型中的所有变量。

ARIMA() 函数还可用于为误差选择最佳 ARIMA 模型。 这是通过不指定 pdq() 特殊来完成的。 是否需要差分是通过对使用普通最小二乘法估计的回归模型的残差应用 KPSS 检验来确定的。 如果需要差分，则对所有变量进行差分，并使用最大似然估计重新估计模型。 最终模型将根据原始变量表示，即使它已使用差分变量进行估计。

AICc 是为最终模型计算的，该值可用于确定最佳预测变量。 也就是说，应对所有要考虑的预测变量子集重复该过程，并选择具有最低 AICc 值的模型。

##### 预测

要使用具有 ARIMA 误差的回归模型进行预测，我们需要对模型的回归部分和模型的 ARIMA 部分进行预测，并将结果结合起来。 与普通回归模型一样，为了获得预测，我们首先需要预测预测变量。 当预测变量在未来已知时（例如，与日历相关的变量，如时间、星期几等），这很简单。 但是当预测变量本身未知时，我们必须对它们分别建模，或者为每个预测变量使用假设的未来值。

##### 随机和确定性趋势

有两种不同的方法可以对线性趋势进行建模。 

使用回归模型 $y_t = \beta_0 + \beta_1 t + \eta_t,$获得确定性趋势，其中 η t 是 ARMA 过程。 

使用模型$y_t = \beta_0 + \beta_1 t + \eta_t,$ 获得随机趋势，其中 η t 是 d = 1 的 ARIMA 过程。 在后一种情况下，我们可以对两边进行差分，使得 $y_t' = \beta_1 + \eta_t'$，其中 η ′ t 是一个 ARMA 过程。 换言之，$y_t = y_{t-1} + \beta_1 + \eta_t'$。

这类似于带有漂移的随机游走，但这里的误差项是一个 ARMA 过程，而不是简单的白噪声。

尽管这些模型看起来非常相似（它们仅在需要应用于 η t 的差异数量上有所不同），但它们的预测特征却大不相同。

有一个具有确定性趋势的隐含假设，即趋势的斜率不会随时间变化。 另一方面，随机趋势可能会发生变化，估计的增长率仅假设为历史时期的平均增长率，不一定是未来观察到的增长率。 因此，使用随机趋势进行预测更安全，尤其是对于较长的预测范围，因为预测区间允许未来增长的更大不确定性。

##### 动态谐波回归

当存在较长的季节性周期时，傅立叶项的动态回归通常比我们在本书中考虑的其他模型更好。例如，每日数据的年度季节性长度为 365，每周数据的季节性周期约为 52，而 半小时数据可以有多个季节性时段，其中最短的是时段 48 的每日模式。

ARIMA 和 ETS 模型的季节性版本设计用于较短的时间段，例如 12 为月度数据或 4 为季度数据。  ETS() 模型将季节性限制为最多 24 个周期，以允许每小时数据，但不允许数据具有更大的季节性周期。 问题是对于初始季节性状态有 m - 1 个参数需要估计，其中 m 是季节性周期。 所以对于大 m ，估计变得几乎不可能。

ARIMA() 函数将允许最多 m = 350 的季节性周期，但在实践中通常会在季节性周期超过 200 时耗尽内存。无论如何，高阶的季节性差分不会产生很多 意义——对于日常数据，它涉及将今天发生的事情与一年前发生的事情进行比较，并且没有限制季节性模式是平滑的。

 因此，对于此类时间序列，我们更喜欢调和回归方法，其中使用傅立叶项对季节性模式进行建模，并使用由 ARMA 误差处理的短期时间序列动态。

这种方法的优点是：

1. 它允许任何长度的季节性； 对于多于一个季节的数据，可以包含不同频率的傅里叶项；
2. 季节性模式的平滑度可以通过 K 控制，即傅立叶正弦和余弦对的数量——对于较小的 K 值，季节性模式更平滑； 
3. 短期动态很容易通过一个简单的 ARMA 误差处理。

 唯一真正的缺点（与季节性 ARIMA 模型相比）是**假设季节性是固定的——季节性模式不允许随时间变化**。 但在实践中，季节性通常非常恒定，因此除了长时间序列外，这不是一个大缺点。

#### 预测分层和分组的时间序列

时间序列通常可以通过各种感兴趣的属性自然地分解。 例如，自行车制造商销售的自行车总数可以按产品类型分类，如公路自行车、山地自行车和混合动力车。 这些中的每一个都可以分解为更细的类别。 例如混合动力自行车可以分为城市自行车、通勤自行车、舒适自行车和徒步自行车； 等等。 这些类别嵌套在较大的组类别中，因此时间序列的集合遵循分层聚合结构。 因此，我们将这些称为“分层时间序列”。 由于地理划分，经常会出现分层时间序列。 例如，自行车总销量可以按国家分类，然后在每个国家按州分类，在每个州按地区分类，依此类推，直到销售点级别。

当感兴趣的属性交叉而不是嵌套时，会出现替代聚合结构。 例如，自行车制造商可能对诸如车架尺寸、性别、价格范围等属性感兴趣。这些属性不会以独特的分层方式自然分解，因为这些属性没有嵌套。 我们将交叉属性的结果时间序列称为“分组时间序列”。 当感兴趣的属性既嵌套又交叉时，会出现更复杂的结构。 例如，自行车制造商自然会对按产品类型和地域划分的销售额感兴趣。 然后将产品分组和地理层次结构混合在一起。 我们在 11.1 节介绍了替代聚合结构。

所有分解和聚合系列通常都需要预测，并且很自然地希望预测以与数据相同的方式累加。 例如，区域销售的预测加起来应该与州销售的预测相加，而州销售的预测加起来又可以给出全国销售的预测。

在本节中，我们讨论预测以某种方式聚合的大量时间序列。 挑战在于我们需要在整个聚合结构中进行一致的预测。 也就是说，我们要求预测以与定义时间序列集合的层次结构或组的聚合结构一致的方式相加。

##### 分层和分组的时间序列

下图显示了一个简单的层次结构。 层次结构的顶部是“总计”，即数据的最聚合级别。  Total 系列的第 t 个观测值由 y t 表示，因为 t = 1 , … , T 。 总计被分解为两个系列，在层次结构的最底层又分别分为三个和两个系列。 在顶层之下，我们使用$y_{j,t}$表示与节点 j 对应的系列的第 t 个观测值。 例如，$y{A}{t}$表示节点 A 对应的序列的第 t 个观测值，$y{AB}{t}$表示节点 AB 对应的序列的第 t 个观测值，依此类推。

<img src="https://otexts.com/fpp3/figs/hts.png" alt="A two level hierarchical tree diagram." style="zoom:50%;" />

对于任何时间 t ，层次结构底层的观测值将与上述系列的观测值相加。

 例如，$\begin{equation}  y_{t}=y{AA}{t}+y{AB}{t}+y{AC}{t}+y{BA}{t}+y{BB}{t},  \tag{11.1} \end{equation}$

$\begin{equation}  y{A}{t}=y{AA}{t}+y{AB}{t}+y{AC}{t}\qquad \text{and} \qquad  y{B}{t}=y{BA}{t}+y{BB}{t}.  \tag{11.2} \end{equation}$

​     将(11.2)代入(11.1)，我们也得到$y_{t}=y{A}{t}+y{B}{t}$。

使用aggregate_key() 函数，我们可以创建层次结构时间序列，其中包含层次结构底部区域的过夜旅行，聚合到州，再聚合到全国总数。 使用父/子规范创建对应于嵌套结构的分层时间序列。

```R
tourism_hts <- tourism %>%
  aggregate_key(State / Region, Trips = sum(Trips))
```

分组时间序列

对于分组时间序列，数据结构不会以独特的分层方式自然分解。 下图显示了一个简单的分组结构。 分组结构的顶部是 Total，即数据的最聚合级别，同样由 y t 表示。  Total 可以按属性 (A, B) 分解，形成系列 y A , t 和 y B , t ，或按属性 (X, Y) 分解，形成系列 y X , t 和 y Y , t 。 在底层，数据按这两个属性进行分解。

<img src="https://otexts.com/fpp3/fpp_files/figure-html/GroupTree-1.png" alt="Alternative representations of a two level grouped structure." style="zoom:50%;" />



此示例显示分组结构存在替代聚合路径。 对于任何时间 t ，与层次结构一样，$\begin{equation*} y_{t}=y{AX}{t}+y{AY}{t}+y{BX}{t}+y{BY}{t}. \end{equation*}$

但是，对于分组结构的第一级，$\begin{equation} y{A}{t}=y{AX}{t}+y{AY}{t}\quad \quad y{B}{t}=y{BX}{t}+y{BY}{t} \tag{11.3} \end{equation}$,

但还有，

$\begin{equation} y{X}{t}=y{AX}{t}+y{BX}{t}\quad \quad y{Y}{t}=y{AY}{t}+y{BY}{t} \tag{11.4}. \end{equation}$

分组时间序列有时可以被认为是不强加唯一层次结构的层次时间序列，因为序列可以分组的顺序不是唯一的。

使用aggregate_key() 创建一个分组时间序列，现在使用语法attribute1*attribute2 交叉感兴趣的属性或分组（与用于分层时间序列的父/子语法相反）。 以下代码为具有交叉属性的监狱数据构建了一个分组的 tsibble：性别、法律地位和状态。

```
prison_gts <- prison %>%
  aggregate_key(Gender * Legal * State, Count = sum(Count)/1e3)
```

在 filter() 中使用 is_aggregated() 有助于探索或绘制图 11.7 底部面板中显示的主要组。 

混合分层和分组结构:

分解因素通常是嵌套的和交叉的。 例如，澳大利亚的旅游数据也可以按照旅游的四个目的进行分类：度假、商务、探亲访友和其他。 此分组变量不嵌套在任何地理变量中。 事实上，我们可以考虑按旅行目的为整个澳大利亚、每个州和每个地区划分过夜旅行。 我们将这种结构描述为与旅行目的“交叉”的“嵌套”地理层次结构。 使用aggregate_key() 可以通过简单地组合因素来指定。

```R
tourism_full <- tourism %>%
  aggregate_key((State/Region) * Purpose, Trips = sum(Trips))
```

##### 单层方法

传统上，分层或分组时间序列的预测涉及选择一个聚合级别并为该级别生成预测。 然后将它们汇总到更高级别，或分解为较低级别，以获得结构其余部分的一组连贯预测。

自下而上的方法:

生成连贯预测的一种简单方法是“自下而上”的方法。 这种方法涉及首先在底层为每个序列生成预测，然后将它们相加以生成结构中所有序列的预测。

 这种方法的一个优点是我们在结构的底层进行预测，因此不会因聚合而丢失信息。 另一方面，底层数据可能非常嘈杂，并且对建模和预测更具挑战性。

我们将使用 reconcile() 函数来指定我们要如何计算相干预测。

```R
data %>% aggregate_key() %>% model() %>%
  reconcile() %>% forecast()
```

从包含各个底层系列的 tsibble 对象（此处标记为数据）开始。

1. 在aggregate_key() 中定义聚合结构并构建一个包含聚合系列的tsibble 对象。
2. 在所有聚合级别为每个系列确定一个模型（）。
3. 在 reconcile() 中指定如何从所选模型生成一致预测。
4. 使用 forecast() 函数为整个聚合结构生成预测。

自上而下的方法:

自上而下的方法涉及首先生成对 Total 系列 y t 的预测，然后在层次结构中向下分解这些预测。

让 p 1 , … , p m 表示一组分解比例，这些比例决定如何分布 Total 系列的预测以获得结构底层每个系列的预测。

一旦生成了底层 h-step-ahead 预测，这些预测就会被聚合起来，为系列的其余部分生成连贯的预测。

可以使用 reconcile() 函数中的 top_down() 生成自上而下的预测。

可以指定几种可能的自顶向下方法。 两种最常见的自上而下方法根据数据的历史比例指定分解比例。 这些在 Gross & Sohl (1990) 的研究中表现良好:

1. 平均历史比例$p_j=\frac{1}{T}\sum_{t=1}^{T}\frac{y_{j,t}}{{y_t}}$
2. 历史平均值的比例$p_j={\sum_{t=1}^{T}\frac{y_{j,t}}{T}}\Big/{\sum_{t=1}^{T}\frac{y_t}{T}}$

这种自上而下的方法的一个便利属性是它们的简单性。 人们只需要为最聚合的顶级系列建模和生成预测。 一般来说，这些方法似乎对总体水平产生了相当可靠的预测，并且它们对于低计数数据很有用。

 另一方面，一个缺点是由于聚合导致信息丢失。 使用这种自上而下的方法，我们无法捕捉和利用各个系列的特征，例如时间动态、特殊事件、不同的季节性模式等。

预测比例:

因为用于分解的历史比例没有考虑这些比例如何随时间变化，基于历史比例的自上而下的方法往往比自下而上的方法在层次结构的较低级别产生更不准确的预测。 为了解决这个问题，可以使用基于预测而不是历史数据的比例（G. Athanasopoulos 等，2009）。

 考虑一个一级层次结构。 我们首先为所有系列生成 h-step-ahead 预测。 我们不直接使用这些预测，而且它们不连贯（它们加起来不正确）。 让我们称这些为“初始”预测。 我们计算每个在底层的提前 h 步初始预测与该级别所有提前 h 步初始预测的总和的比例。 我们将这些称为预测比例，我们使用它们来分解顶级 h 步提前初始预测，以便为整个层次结构生成连贯的预测。

 对于 K 级层次结构，对每个节点重复此过程，从顶层到底层。 应用此过程可得出以下获取预测比例的一般规则：$p_j=\prod^{K-1}_{\ell=0}\frac{\hat{y}_{j,h}^{(\ell)}}{\hat{S}_{j,h}^{(\ell+1)}}$

其中$j=1,2,\dots,m$, $\hat{y}_{j,h}^{(\ell)}$ 是对应于j以上$\ell$级节点的系列的 h 超前初始预测，以及$\hat{S}_{j,h}^{(\ell)}$是在节点 j 上ℓ 层且直接连接到该节点的节点下的 h 步提前初始预测的总和。这些预测比例分解了总序列的 h 步超前初始预测，以获得底层序列的 h 步超前连贯预测。

这种方法是通过设置 method = "forecast_proportions" 在 top_down() 函数中实现的。 因为这种方法往往比其他自顶向下方法更有效，所以当没有指定方法参数时，它是 top_down() 函数中的默认选择。

所有自上而下的方法的一个缺点是，即使基础预测是无偏的，它们也不会产生无偏的连贯预测（Hyndman 等，2011）。

中出方法:

中出方法结合了自下而上和自上而下的方法。 同样，它只能用于严格的分层聚合结构。

首先，选择“中间”级别并为该级别的所有系列生成预测。 对于中层以上的序列，使用自下而上的方法通过向上聚合“中层”预测来生成连贯的预测。 对于“中层”以下的系列，通过向下分解“中层”预测，使用自上而下的方法生成连贯的预测。

这种方法在 middle_out() 函数中通过 level 参数指定适当的中间层并使用 method 参数选择自上而下的方法来实现。

##### 预测协调 

假设我们预测所有序列而忽略任何聚合约束。 我们称这些为基础预测，并用$\hat y_{h}$表示，其中 h 是预测范围。 它们以与数据$y_t$相同的顺序堆叠。

那么对于分层结构或分组结构的所有连贯预测方法都可以表示为:

$\begin{equation}  \tilde{{y}}_h={S}{G}\hat{{y}}_h,   \end{equation}$

迄今为止所考虑的传统方法的局限性在于，它们仅使用来自单一聚合级别的基础预测，这些基础预测已被聚合或分解以获得所有其他级别的预测。 因此，他们使用有限的信息。 然而，一般来说，我们可以使用其他 G 矩阵，然后 S G 组合和协调所有基础预测以产生一致的预测。

 事实上，我们可以找到最优的 G 矩阵来给出最准确的协调预测。

MinT 最优对账方法：

我们需要找出预测中的错误。 维克拉马苏里亚等人 (2019) 表明 h-step-ahead 相干预测误差的方差-协方差矩阵由下式给出:

$\begin{equation*} {V}_h = \text{Var}[{y}_{T+h}-\tilde{{y}}_h]={S}{G}{W}_h{G}'{S}' \end{equation*}$

详细公式略，最佳协调预测：

 MinT 由 reconcile() 函数中的 min_trace() 实现。

 为了在实践中使用它，我们需要估计 W h ，即提前 h 步基础预测的预测误差方差。 这可能很困难，因此提供了四种简化的近似值，这些近似值在模拟和实践中都表现良好。

1. 为所有 h 设置 ${W}_h=k_h{I}$，其中 k h > 0 . 这是最简单的假设，意味着 G 独立于数据，提供了大量的计算节省。 然而，缺点是该规范没有考虑结构级别之间的规模差异，或系列之间的关系。

2. 为所有 h 设置 ${W}_h = k_h {W}_1$ ，其中 k h > 0 。 这里我们只假设误差协方差矩阵彼此成比例，我们直接估计完整的一步协方差矩阵 W 1 。 最明显和最简单的方法是使用样本协方差。 这是通过设置 method = "mint_cov" 在 min_trace() 中实现的。

   但是，对于底层序列 m 的数量与序列 T 的长度比较大的情况，这不是一个好的估计器。 相反，我们使用收缩估计器将样本协方差收缩为对角矩阵。 这是通过设置 method = "mint_shrink" 

method = "ols" method = "wls_var" method = "wls_struct" method = "mint_shrink"

总之，与任何其他现有方法不同，最佳调节预测是使用分层或分组结构中的所有可用信息生成的。 这很重要，因为特定的聚合级别或分组可能会揭示用户感兴趣且对建模很重要的数据特征。 这些特征在其他层次上可能完全隐藏或不易识别。

 例如，考虑第 11.1 节中介绍的澳大利亚旅游数据，其中层次结构遵循一个国家的地理划分，将其划分为州和地区。 一些地区将主要是夏季目的地，而其他地区可能是冬季目的地。 我们在图 11.4 中看到了北部和南部各州之间对比鲜明的季节性模式。 由于汇总，这些差异将在国家层面得到平滑。

与自下而上的方法相比，使用 OLS 和 MinT 协调基础预测会产生更准确的预测。 这种结果在应用中很常见，因为协调方法使用来自结构各个层次的信息，与使用有限信息的旧传统方法相比，可以产生更准确的连贯预测。 此外，调节通常可以改善几乎所有级别的不连贯的基本预测。

##### 一个例子

```R
tourism_full <- tourism %>%
  aggregate_key((State/Region) * Purpose, Trips = sum(Trips))

fit <- tourism_full %>%
  filter(year(Quarter) <= 2015) %>%
  model(base = ETS(Trips)) %>%
  reconcile(
    bu = bottom_up(base),
    ols = min_trace(base, method = "ols"),
    mint = min_trace(base, method = "mint_shrink"),
  )
fc <- fit %>% forecast(h = "2 years")
fc %>%
  filter(is_aggregated(Region), is_aggregated(Purpose)) %>%
  autoplot(
    tourism_full %>% filter(year(Quarter) >= 2011),
    level = NULL
  ) +
  labs(y = "Trips ('000)") +
  facet_wrap(vars(State), scales = "free_y")
fc %>%
  filter(is_aggregated(State), !is_aggregated(Purpose)) %>%
  autoplot(
    tourism_full %>% filter(year(Quarter) >= 2011),
    level = NULL
  ) +
  labs(y = "Trips ('000)") +
  facet_wrap(vars(Purpose), scales = "free_y")
#准确度度量
fc %>%
  filter(is_aggregated(State), is_aggregated(Purpose)) %>%
  accuracy(
    data = tourism_full,
    measures = list(rmse = RMSE, mase = MASE)
  ) %>%
  group_by(.model) %>%
  summarise(rmse = mean(rmse), mase = mean(mase))
```

注：要以这种方式生成自举预测区间，我们只需在 predict() 函数中设置 bootstrap = TRUE。

#### 先进预测方法

##### 复杂季节性

到目前为止，我们主要考虑了相对简单的季节性模式，例如季度和月度数据。 然而，更高频率的时间序列通常表现出更复杂的季节性模式。 例如，每日数据可能具有每周模式和年度模式。 每小时数据通常具有三种类型的季节性：每日模式、每周模式和年度模式。 即使是每周数据也很难预测，因为一年中没有完整的周数，因此年度模式的季节性周期平均为 365.25 / 7 ≈ 52.179。 到目前为止，我们考虑的大多数方法都无法处理这些季节性的复杂性。

我们不一定要在我们的模型中包括所有可能的季节性时期——只是那些可能出现在数据中的时期。 例如，如果我们只有 180 天的数据，我们可能会忽略年度季节性。 如果数据是对自然现象（例如温度）的测量，我们可能可以安全地忽略任何每周季节性。

具有多个季节性周期的 STL：

STL() 函数旨在处理多个季节性。 它将返回多个季节性成分，以及趋势和剩余成分。 在这种情况下，我们需要重新索引 tsibble 以避免缺失值，然后明确给出季节性周期。

具有多个季节性周期的动态谐波回归：

对于多个季节性，我们可以像在前面的章节中那样使用傅立叶项。 因为有多个季节性，我们需要为每个季节性周期添加傅立叶项。 在这种情况下，季节性周期为 169 和 845，因此傅立叶项的形式为

$\sin\left(\frac{2\pi kt}{169}\right), \quad  \cos\left(\frac{2\pi kt}{169}\right), \quad  \sin\left(\frac{2\pi kt}{845}\right), \quad  \text{and} \quad  \cos\left(\frac{2\pi kt}{845}\right),$

我们将拟合具有 ARIMA 误差结构的动态谐波回归模型。 可以选择每个季节期间的傅立叶项总数以最小化 AICc。 但是，对于高季节性时期，这往往会高估所需的术语数量，因此我们将使用更主观的选择，其中 10 个术语用于每日季节性，5 个用于每周季节性。 

例子：电力的预测

##### Prophet model

最近的一个提议是 Prophet 模型，可通过 [fable.prophet] 包获得。 该模型由 Facebook（S. J. Taylor & Letham，2018 年）引入，最初用于预测具有每周和每年季节性以及假日效应的每日数据。 后来扩展到涵盖更多类型的季节性数据。 **它最适用于具有强烈季节性和多个季节历史数据的时间序列**。

Prophet 可以被认为是一个非线性回归模型，形式为$y_t = g(t) + s(t) + h(t) + \varepsilon_t,$

其中 g ( t ) 描述分段线性趋势（或“增长项”）， s ( t ) 描述各种季节性模式， h ( t ) 捕捉假期效应，而 ε t 是白噪声误差项。

* 如果未明确指定，将自动选择分段线性趋势的节点（或变化点）。 或者，可以使用逻辑函数来设置趋势的上限。
* 季节性成分由相关时期的傅立叶项组成。 默认情况下，order 10 用于年度季节性，order 3 用于每周季节性。
* 假日效应被添加为简单的虚拟变量。
* 该模型使用贝叶斯方法进行估计，以允许自动选择变化点和其他模型特征。

Prophet 具有比我们之前考虑的 DHR 模型更快估计的优势，并且它是完全自动化的。 但是，正如这两个示例所说明的那样，它很少能提供比替代方法更好的预测准确性。

##### 向量自回归

到目前为止，我们考虑的模型的一个限制是它们强加了一种单向关系——预测变量受预测变量的影响，但反之则不然。 然而，在很多情况下也应该允许相反的情况——所有变量都会相互影响。 在前文中，根据个人可支配收入 (I t ) 的变化预测了个人消费支出 ( C t ) 的变化。 然而，在这种情况下，双向关系可能更合适：$I_t$的增加将导致$C_t$的增加，反之亦然。

在向量自回归 (VAR) 框架中允许这种反馈关系。 在这个框架中，所有变量都被对称对待。 它们都被建模，就好像它们都平等地相互影响。 在更正式的术语中，所有变量现在都被视为“内生的”。 为了表示这一点，我们现在改变符号并将所有变量写为 y s： $y_{1,t}$表示变量$y_1$的第 t 次观察.$y_{2,t}$表示变量 y 2 的第 t 次观察，依此类推。

VAR 模型是用于预测时间序列向量的单变量自回归模型的推广。 它包括系统中的每个变量一个方程。 每个方程的右侧包括一个常数和系统中所有变量的滞后。 为简单起见，我们将考虑一个滞后的两变量 VAR。 我们将二维 VAR(1) 模型写为

$\begin{align}  y_{1,t} &= c_1+\phi _{11,1}y_{1,t-1}+\phi _{12,1}y_{2,t-1}+\varepsilon_{1,t} \\  y_{2,t} &= c_2+\phi _{21,1}y_{1,t-1}+\phi _{22,1}y_{2,t-1}+\varepsilon_{2,t},  \end{align}$

其中ε 1 , t 和ε 2 , t 是可能同时相关的白噪声过程。 系数 $\phi_{ii,\ell}$捕捉变量 y i 的第 $\ell$个滞后对其自身的影响，而系数 ϕ i j , ℓ 捕捉变量 y j 的第 ℓ 个滞后对 y i 的影响。

如果序列是平稳的，我们通过直接将 VAR 拟合到数据（称为“水平 VAR”）来预测它们。 如果序列是非平稳的，我们取数据的差异以使它们平稳，然后拟合 VAR 模型（称为“差异中的 VAR”）。 在这两种情况下，模型都是使用最小二乘原理逐个方程估计的。 对于每个方程，通过最小化$e_{i,t}$值的平方和来估计参数。

另一种可能性超出了本节的范围，因此我们不在这里探讨，是该系列可能是非平稳但协整的，这意味着它们存在平稳的线性组合。 在这种情况下，应包括包含误差校正机制（通常称为向量误差校正模型）的 VAR 规范，(见下文协整分析)并应使用最小二乘估计的替代估计方法

预测是从 VAR 以递归方式生成的。  VAR 为系统中包含的每个变量生成预测。 为了说明这个过程，假设我们已经拟合了方程 中描述的二维 VAR(1) 模型，适用于时间 T 之前的所有观测值。 然后通过以下方式生成一步预测：

$\begin{align*}  \hat y_{1,T+1|T} &=\hat{c}_1+\hat\phi_{11,1}y_{1,T}+\hat\phi_{12,1}y_{2,T} \\  \hat y_{2,T+1|T} &=\hat{c}_2+\hat\phi _{21,1}y_{1,T}+\hat\phi_{22,1}y_{2,T}. \end{align*}$

使用 VAR 进行预测时，必须做出两个决定，即系统中应包含多少变量（由 K 表示）和多少滞后（由 p 表示）。 要在 VAR 中估计的系数数量等于$K+pK^2$（或每个方程 1 + p K）。 例如，对于 K = 5 个变量和 p = 3 个滞后的 VAR，每个方程有 16 个系数，总共需要估计 80 个系数。 需要估计的系数越多，进入预测的估计误差就越大。

在实践中，通常保持 K 较小并且仅包含彼此相关的变量，因此可用于相互预测。 信息标准通常用于选择要包括的滞后数。 使用 AICc 时应该小心，因为它倾向于选择大量的滞后； 相反，**对于 VAR 模型，我们经常使用 BIC 代替**。 该模型的更复杂版本是“稀疏 VAR”（其中许多系数设置为零）； 另一种方法是使用“收缩估计”（其中系数较小）。

 VAR 面临的一个批评是它们是无理论的； 也就是说，它们不是建立在对方程施加理论结构的经济理论之上。 假设每个变量都会影响系统中的每个其他变量，这使得对估计系数的直接解释变得困难。 尽管如此，VAR 在多种情况下还是很有用的：

1. 预测不需要明确解释的相关变量的集合； 
2. 测试一个变量是否对预测另一个变量有用（格兰杰因果检验的基础）； 
3. 脉冲响应分析，分析一个变量对另一个变量的突然但暂时的变化的响应； 
4. 预测误差方差分解，其中每个变量的预测方差的比例归因于其他变量的影响。

##### Bootstrapping and bagging

Bootstrapping time series：

在前文节中，我们引导时间序列的残差，以便使用模型模拟序列的未来值。

更一般地说，我们可以使用另一种类型的引导程序生成与我们观察到的序列相似的新时间序列。

首先，必要时对时间序列进行转换，然后使用 STL 将其分解为趋势、季节性和剩余部分。 然后我们获得剩余部分的混洗版本以获得引导的剩余系列。 因为 STL 余数序列中可能存在自相关，所以我们不能简单地使用 5.5 节中描述的重绘过程。 相反，我们使用“blocked bootstrap”，其中时间序列的连续部分被随机选择并连接在一起。 这些自举剩余序列被添加到趋势和季节性分量中，并反转转换以给出原始时间序列的变化。

袋装预测：

这些自举时间序列的一种用途是提高预测准确性。 如果我们从每个额外的时间序列中生成预测，并对结果预测进行平均，我们会得到比直接直接预测原始时间序列更好的预测。 这称为“装袋”，代表“引导程序聚合”。 

#### 多元时间序列

多元时间序列的一些计算使用蔡瑞胸(R.S. Tsay)教授的MTS扩展包

经济的全球一体化和信息传播的发展使得各国的金融市场相互关联， 一个市场的价格变动可以很快地扩散到另一个市场。 持有多个资产的投资者也希望了解多个资产的收益率之间的关系。 这些问题属于多元时间序列分析的范畴。

多元时间序列包含多个一元时间序列作为分量， 各个一元时间序列的采样时间点相同， 所以数据可以用矩阵形式表示， 每行为一个时间点， 每列为一个一元时间序列。 在R中可以保存为矩阵、数据框、ts或者xts时间序列对象。 设$\boldsymbol r_t = (r_{1t}, \dots, r_{kt})^T$表示$k$个资产在$t$时刻的对数收益率。

一元时间序列的某些方法可以推广到多元情形， 但是有些问题需要注意。 某些情况下需要提出新的模型和方法。

##### 基础知识

多元时间序列分析中一个重要概念是引导与滞后关系。 为此， 用互相关阵来衡量时间序列之间的线性关系的强度。 元弱平稳列的滞后的互协方差阵定义为

$\begin{aligned} \Gamma_l = (\Gamma_{ij}(l))_{k \times k} = E[ (\boldsymbol r_t - \boldsymbol\mu) (\boldsymbol r_{t-l} - \boldsymbol\mu)^T ] \end{aligned}$

这是一元时间序列的自协方差函数$\gamma_l$的推广. $\Gamma_l$仅依赖于滞后$l$而与时刻$t$无关。

$k$元弱平稳列的滞后的互相关阵 (Cross Correlation Matrix, CCM)定义为:

$\begin{aligned} \boldsymbol\rho_l = (\rho_{ij}(l))_{k\times k} = D^{-1} \Gamma_l D^{-1} \end{aligned}$

其中:$\begin{aligned} \rho_{ij}(l) = \text{corr}(r_{it}, r_{j, t-l}) = \frac{\Gamma_{ij}(l)}{\sqrt{\Gamma_{ii}(0) \Gamma_{jj}(0)}} \end{aligned}$是$r_{it}$和$r_{j,t-1}$的相关系数。

不同于一元时间序列的自协方差满足$\gamma_l = \gamma_{-l}$， 对$k$元时间序列有

$\begin{aligned} \Gamma_{ij}(l) =& \text{Cov}(r_{it}, r_{j,t-l})  = \text{Cov}(r_{j,t-l}, r_{i,t}) = \text{Cov}(r_{j,t}, r_{i,t+l}) \\ =& \text{Cov}(r_{j,t}, r_{i,t-(-l)}) = \Gamma_{ji}(-l) \end{aligned}$

即：$\begin{aligned} \Gamma_{-l} = \Gamma_l^T \end{aligned}$,对互相关阵$\boldsymbol\rho_l$也有$\begin{aligned}
\boldsymbol\rho_{-l} = \boldsymbol\rho_l^T
\end{aligned}$,所以只需要考虑:$\boldsymbol\rho_l, l \geq 0$

##### 时间序列之间线性依存性分类

![image-20210905224019529](数模整理.assets/image-20210905224019529.png)

##### 多元混成检验

Hosking(1980,1981), Li和McLeod(1981) 已经把一元的Ljung-Box白噪声检验推广到了多元的情形。 对一个多元序列，检验零假设：$\begin{aligned} H_0: \boldsymbol\rho_1 = \dots = \boldsymbol\rho_m = \boldsymbol 0 \end{aligned}$

对立假设是不全为零矩阵。 这可以检验多元时间序列$\boldsymbol r_t$为宽白噪声的零假设， 即$\boldsymbol r_t$为弱平稳列且无序列自相关， 可以有同步的分量间相关。

使用检验统计量:$\begin{aligned} Q_k(m) = T^2 \sum_{l=1}^m \frac{1}{T-l} \text{tr}( \hat\Gamma_l^T \hat\Gamma_0^{-1} \hat\Gamma_l \hat\Gamma_0^{-1}) \end{aligned}$

`MTS::mq()`计算多元混成检验：

$Q_k(m)$统计量是对$\boldsymbol {r_t}$的前$m$个互相关阵的一个联合检验， 如果结果显著， 就应该建立多元的均值模型描述序列分量之间的领先–滞后关系。 **最常用的是向量自回归(VAR)模型**

#### 协整分析和向量误差修正模型

线性回归分析是统计学的最常用的模型之一， 但是， 如果回归的自变量和因变量都是时间序列， 回归就不满足回归分析的基本假定： 模型误差项独立同分布。

比如，一元线性回归模型

$y_t = a + b x_t + e_t, \ t=1,2,\dots,n,$

需要假定$e_1, e_2, \dots, e_t$不相关， 零均值，方差同为$\sigma^2$，$x_1, x_2, \dots, x_n$非随机， 这时最小二乘估计是无偏估计。当极限存在， 有正极限时估计相合。

如果$e_t,x_t,y_t$之中有时间序列， 则回归可能不相合， 或者估计相合但是回归结果中的标准误差估计和假设检验有错误。

##### 协整分析概念

对于二元时间序列$\boldsymbol x_{t} = (x_{1t}, x_{2t})^T$， 如果$x_{1t}$和$x_{2t}$都是一元单位根过程， 但存在非零线性组合$\boldsymbol\beta = (\beta_1, \beta_2)$使得$z_t = \beta_1 x_{1t} + \beta_2 x_{2t}$弱平稳， 则称两个分量$x_{1t}$和$x_{2t}$存在**协整**关系（cointegration）， $(\beta_1, \beta_2)^T$称为$\boldsymbol x_t$的**协整向量**。 多个分量的多元时间序列可以类似地定义协整关系， 多元时可以有多个协整向量。

##### Engle和Granger两阶段法

考虑两个分量的多元时间序列$\boldsymbol r_t$。 为了检验协整性， 首先要用一元的单位根检验（如ADF检验）确认两个分量都是单位根过程， 并且差分之后就没有单位根，这样的单位根过程称为“单整”的， 或I(1)序列。

其次，将$x_{1t}$当作因变量，$x_{2t}$当作自变量， 作一元线性回归，得到残差$e_t$序列， 和回归系数$\beta 1$，方程为$x_{1t} = \beta_0 + \beta_1 x_{2t} + e_t$

根据([R. R. Engle and Granger 1987](https://www.math.pku.edu.cn/teachers/lidf/course/fts/ftsnotes/html/_ftsnotes/References.html#ref-EngleGranger1987:cointegration))的研究， 回归在协整关系成立时参数估计相合， 但是系数的估计非正态， 所以用线性最小二乘估计得到的点估计可用， 但是结果中的t检验和F检验结果无效。

为了验证协整关系是否成立， 只要对序列进行一元的单位根检验， 但是因为是回归残差， 其自由度有变化， 所以统计量p值的计算需要进行调整， ([Phillips and Ouliaris 1990](https://www.math.pku.edu.cn/teachers/lidf/course/fts/ftsnotes/html/_ftsnotes/References.html#ref-Phillips1990:coint))给出了利用回归残差进行协整检验的方法， 称为Phillips-Ouliaris协整检验。 如果经检验不存在单位根， 则称两个分量是协整的。

这样的检验方法称为Engle和Granger两阶段法， 利用([Phillips and Ouliaris 1990](https://www.math.pku.edu.cn/teachers/lidf/course/fts/ftsnotes/html/_ftsnotes/References.html#ref-Phillips1990:coint))方法计算这个检验称为Phillips-Ouliaris协整检验。 但是，这里的两阶段， 其实第二阶段指的是在多元情况下需要找出所有的协整向量， 这需要利用向量误差修正模型(VECM)。

R扩展包tseries中`po.test()`可以执行基于EG两阶段法步骤的Phillips-Ouliaris协整检验， 零假设是非协整， 对立假设是存在协整关系。 参见([Phillips and Ouliaris 1990](https://www.math.pku.edu.cn/teachers/lidf/course/fts/ftsnotes/html/_ftsnotes/References.html#ref-Phillips1990:coint))。

##### 误差修正模型

因为在协整系统中， 单位根非平稳分量的个数多于单位根的个数 （通过线性组合可以使得单位根非平稳的分量减少）， 所以如果对每个单位根非平稳分量计算差分， 虽然使得分量都平稳了， 但是会造成过度差分， 使得部分分量的ARMA模型的MA部分有单位根， 这样的模型平稳但不可逆， 不可逆的模型在估计和预测上比较困难。

([R. R. Engle and Granger 1987](https://www.math.pku.edu.cn/teachers/lidf/course/fts/ftsnotes/html/_ftsnotes/References.html#ref-EngleGranger1987:cointegration))讨论了协整系统的误差修正表示， 称为向量误差修正模型(VECM, vector error correction model)。

#### 格兰格因果性

##### 介绍

考虑两个时间序列之间的因果性。 这里的因果性指的是时间顺序上的关系， 如果$X_{t-1}, X_{t-2}, \dots$对有作用， 而$Y_{t-1}, Y_{t-2}, \dots$对$X_t$没有作用， 则称是的格兰格原因， 而不是的格兰格原因。 如果对有作用， 对也有作用， 则在没有进一步信息的情况下无法确定两个时间序列的因果性关系。

注意这种因果性与采样频率有关系， 在日数据或者月度数据中能发现的领先——滞后性质的因果关系， 到年度数据可能就以及混杂在以前变成同步的关系了。

([C. W. J. Granger 1969](https://www.math.pku.edu.cn/teachers/lidf/course/fts/ftsnotes/html/_ftsnotes/References.html#ref-Granger1969:causal))首先提出了时间序列之间因果关系的概念。 时间序列因果关系可以是假设没有因果关系， 然后检验能否否定， 这是([C. W. J. Granger 1969](https://www.math.pku.edu.cn/teachers/lidf/course/fts/ftsnotes/html/_ftsnotes/References.html#ref-Granger1969:causal))的方法； 也可以是首先建立有因果关系的模型， 然后检验其中表示因果关系的参数是否不显著， 这是利用VAR和VECM的方法。 后一种方法首先提出于([Sims 1972](https://www.math.pku.edu.cn/teachers/lidf/course/fts/ftsnotes/html/_ftsnotes/References.html#ref-Sims1972:cause))。

在具有因果性的情况下， 可以用来改善预测。 比如， 如果是的格兰格原因， 则可以利用的现在与过去值、 的现在与过去值去预测的将来值， 会比仅利用的值预测要好， 这是认为的已有值中包含了的已有值中缺少的信息， 而这些信息对预测的将来值是有作用的。 ([C. W. J. Granger 1969](https://www.math.pku.edu.cn/teachers/lidf/course/fts/ftsnotes/html/_ftsnotes/References.html#ref-Granger1969:causal))的检验方法就是针对这一点进行检验。

在经济与金融时间序列建模中考虑对影响的另一个原因是， 许多时间序列具有较强的正自相关性， 比如单位根过程或者特征根接近于单位圆的ARMA模型， 对于这样的两个时间序列， 如果以为因变量， 为自变量作线性回归， 可能发生虚假的回归， 即使两个序列之间独立， 但是回归结果可以是显著的。 这是因为，与之间的强序列相关性。 如果在回归中引入滞后项， 这样的虚假回归就可以被消除。 参见([Clive W. J. Granger and Newbold 1974](https://www.math.pku.edu.cn/teachers/lidf/course/fts/ftsnotes/html/_ftsnotes/References.html#ref-Granger1974:spurious-reg))。

从因果性的角度讲， 只有两个序列的新息（innovation）对另一个序列的影响才是有意义的。 参见([Schwert 1979](https://www.math.pku.edu.cn/teachers/lidf/course/fts/ftsnotes/html/_ftsnotes/References.html#ref-Schwert1979:causality))。

#### 一些实际的预测问题

##### 每周、每日和次日数据

尽管出于不同的原因，每周、每日和次日数据对于预测来说可能具有挑战性。

每周数据 

每周数据很难处理，因为季节性周期（一年中的周数）既大又非整数。 一年中的平均周数为 52.18。 我们考虑过的大多数方法都要求季节性周期为整数。 即使我们将其近似为 52，大多数方法也无法有效地处理如此大的季节性周期。

 最简单的方法是使用 STL 分解以及应用于季节性调整数据的非季节性方法（如第 3 章所述）。 最简单的方法是使用 STL 分解以及应用于季节性调整数据的非季节性方法（如第 3 章所述）。 以下是一个示例，使用了 1991 年 2 月至 2005 年 5 月期间供应的美国成品车用汽油产品（以每天百万桶计）的每周数据。

```R
my_dcmp_spec <- decomposition_model(
  STL(Barrels),
  ETS(season_adjust ~ season("N"))
)
us_gasoline %>%
  model(stl_ets = my_dcmp_spec) %>%
  forecast(h = "2 years") %>%
  autoplot(us_gasoline) +
  labs(y = "Millions of barrels per day",
       title = "Weekly US gasoline production")
```

另一种方法是使用[动态谐波回归模型](#动态谐波回归)。 在以下示例中，通过最小化 AICc 来选择傅立叶项的数量。  ARIMA 模型的阶次也是通过最小化 AICc 来选择的，尽管这是在 ARIMA() 函数中完成的。 **我们使用 PDQ(0,0,0) 来防止 ARIMA() 尝试使用季节性 ARIMA 组件处理季节性**。

```R
gas_dhr <- us_gasoline %>%
  model(dhr = ARIMA(Barrels ~ PDQ(0, 0, 0) + fourier(K = 6)))
  
gas_dhr %>%
  forecast(h = "2 years") %>%
  autoplot(us_gasoline) +
  labs(y = "Millions of barrels per day",
       title = "Weekly US gasoline production")
```

拟合模型有 6 对傅立叶项，可以写成:$y_t = bt + \sum_{j=1}^{6}    \left[      \alpha_j\sin\left(\frac{2\pi j t}{52.18}\right) +      \beta_j\cos\left(\frac{2\pi j t}{52.18}\right)    \right] +    \eta_t$

其中$\eta_t$是 ARIMA(0,1,1) 过程。 因为$\eta_t$是非平稳的，所以模型实际上是根据这个方程两边变量的差异来估计的。 有 12 个参数来捕捉季节性，而总自由度数为 14（另外两个来自 MA 参数和漂移参数）。

选择方法：

当季节性随时间变化时，STL 方法更可取。 

如果存在作为有用预测变量的协变量，则动态谐波回归方法更可取，因为这些变量可以作为额外的回归变量添加。

每日和次日数据：
每日和次日（例如每小时）数据由于不同的原因而具有挑战性——它们通常涉及多种季节性模式，因此我们需要使用一种方法来处理如此复杂的季节性。

当然，如果时间序列相对较短，以至于只存在一种季节性，那么可以使用我们在前几章中讨论过的单季节性方法之一（例如，ETS 或季节性 ARIMA 模型）  . 但是当时间序列足够长以至于某些较长的季节性周期变得明显时，就需要使用 STL、动态谐波回归或 Prophet，如上文所述。

然而，这些方法只允许有规律的季节性。 捕捉与复活节、身份证或农历新年等活动事件相关的季节性更加困难。 即使使用月度数据，这也可能很棘手，因为节日可能在 3 月或 4 月（复活节）、1 月或 2 月（农历新年）或一年中的任何时间（Id）。

处理移动假期效应的最佳方法是在模型中包含虚拟变量。 例如，**这可以在 ARIMA() 或 prophet() 函数中完成，但不能在 ETS() 中完成**。 事实上，prophet() 有一个特殊的holiday() 可以很容易地结合假日效果。

##### 计数的时间序列

本书中讨论的所有方法都假设数据具有连续的样本空间。 但数据通常以计数的形式出现。 例如，我们可能希望预测每天进入商店的顾客数量。 我们可以有 0 , 1 , 2 , ... 客户，但我们不能有 3.45693 个客户。

在实践中，只要我们的计数足够大，这很少有问题。 如果最小客户数至少为 100，那么连续样本空间 [ 100 , ∞ ) 和离散样本空间 { 100 , 101 , 102 , ... } 之间的差异对我们的预测没有明显影响。 但是，如果我们的数据包含小计数（ 0 , 1 , 2 , … ），那么我们需要使用更适合非负整数样本空间的预测方法。

 此类模型超出了本章的范围。 但是，有一种简单的方法可以在这种情况下使用，我们想提一下。 它是“克罗斯顿方法”，以其英国发明者约翰克罗斯顿的名字命名，并在克罗斯顿 (1972) 中首次描述。 其实这个方法也没有很好地处理数据的计数性质，但是它使用的太频繁了，值得了解一下。

使用 Croston 的方法，我们通过注意哪些时间段包含零值以及哪些时间段包含非零值，从原始时间序列构建两个新序列。 令$q_i$为第$i$个非零量，令$a_i$为$q_{i-1}$和 $q_i$之间的时间。  Croston 的方法涉及对两个新序列 a 和 q 进行单独的简单指数平滑预测。 因为该方法通常应用于物品需求的时间序列，所以 q 通常被称为“需求”和“到达间隔时间”。

如果$\hat{q}_{i+1|i}$和$\hat{a}_{i+1|i}$分别是第 (i + 1 ) 次需求和到达间隔时间的一步预测，基于直到需求 i 的数据，那么 Croston 的方法给出:

$\begin{align}  \hat{q}_{i+1|i} & = (1-\alpha_q)\hat{q}_{i|i-1} + \alpha_q q_i\\  \hat{a}_{i+1|i} & = (1-\alpha_a)\hat{a}_{i|i-1} + \alpha_a a_i.  \end{align}$

平滑参数$\alpha_a$和$\alpha_q$取值介于 0 和 1 之间。让 j 是最后观察到的正观察的时间。 那么在时间 T + h 时对需求的 h 步提前预测，由比率$\begin{equation}  \hat{y}_{T+h|T} = \hat{q}_{j+1|j}/\hat{a}_{j+1|j}. \end{equation}$给出

没有代数结果允许我们计算该方法的预测区间，因为该方法不对应于任何统计模型 (Shenstone & Hyndman, 2005)。

CROSTON() 函数使用 Croston 的方法生成预测。 两个平滑参数$\alpha_a$和$\alpha_q$是从数据中估计出来的。 这与克罗斯顿设想的方法不同。

##### 确保预测保持在限制范围内

通常希望预测为正值，或要求它们在某个指定范围 [a , b ] 内。 使用转换处理这两种情况都相对容易。

正向预测：

为了施加正面约束，我们可以简单地在对数尺度上工作。 例如，考虑一打鸡蛋的实际价格（1900-1993 年；以美分计）。 由于对数变换，预测分布被限制为保持正数，因此随着均值的降低，它们将逐渐变得更加偏斜。

```R
egg_prices <- prices %>% filter(!is.na(eggs))
egg_prices %>%
  model(ETS(log(eggs) ~ trend("A"))) %>%
  forecast(h = 50) %>%
  autoplot(egg_prices) +
  labs(title = "Annual egg prices",
       y = "$US (in cents adjusted for inflation) ")
```

预测受限于一个区间:

要了解如何处理受限于区间的数据，假设鸡蛋价格被限制在 a = 50 和 b = 400 之内。 然后我们可以使用缩放 logit 变换来变换数据，该变换将 ( a , b ) 映射到整条实线：$y = \log\left(\frac{x-a}{b-x}\right),$，其中 x 在原始尺度上，y 是变换后的数据。 为了反转变换，我们将使用$x  = \frac{(b-a)e^y}{1+e^y} + a.$。

这不是内置转换，因此我们需要首先设置转换函数。

```R
scaled_logit <- function(x, lower = 0, upper = 1) {
  log((x - lower) / (upper - x))
}
inv_scaled_logit <- function(x, lower = 0, upper = 1) {
  (upper - lower) * exp(x) / (1 + exp(x)) + lower
}
my_scaled_logit <- new_transformation(
                    scaled_logit, inv_scaled_logit)
egg_prices %>%
  model(
    ETS(my_scaled_logit(eggs, lower = 50, upper = 400)
          ~ trend("A"))
  ) %>%
  forecast(h = 50) %>%
  autoplot(egg_prices) +
  labs(title = "Annual egg prices",
       y = "$US (in cents adjusted for inflation) ")
```

此处会自动应用偏差调整，并且这些变换的预测区间具有与变换尺度上相同的覆盖概率，因为分位数在单调递增变换下得以保留。

由于转换，预测区间高于 50。 由于这种人为（且不切实际）的约束，预测分布变得极度偏斜。

##### 预测组合

提高预测准确性的一种简单方法是对同一时间序列使用几种不同的方法，并对结果预测进行平均。  50 多年前，John Bates 和 Clive Granger 撰写了一篇著名的论文（Bates & Granger，1969 年），表明组合预测通常会带来更好的预测准确性。 二十年后，Clemen (1989) 写道，结果几乎是一致的：结合多种预测可以提高预测准确性。 在许多情况下，只需对预测进行平均，就可以显着提高性能。

虽然已经有大量关于使用加权平均或其他一些更复杂的组合方法的研究，但使用简单的平均已经证明很难被击败。

例子：

```R
auscafe <- aus_retail %>%
  filter(stringr::str_detect(Industry, "Takeaway")) %>%
  summarise(Turnover = sum(Turnover))
train <- auscafe %>%
  filter(year(Month) <= 2013)
STLF <- decomposition_model(
  STL(log(Turnover) ~ season(window = Inf)),
  ETS(season_adjust ~ season("N"))
)
cafe_models <- train %>%
  model(
    ets = ETS(Turnover),
    stlf = STLF,
    arima = ARIMA(log(Turnover))
  ) %>%
  mutate(combination = (ets + stlf + arima) / 3)
cafe_fc <- cafe_models %>%
  forecast(h = "5 years")
```

请注意，我们通过简单地采用估计模型的线性函数在 mutate() 函数中形成了一个组合。 这种非常简单的语法将通过考虑所包含模型的预测误差之间的相关性自动适当地处理预测分布。

对区间的预测省略

##### 聚合的预测区间

一个常见的问题是使用适合分解数据的模型来预测多个时间段数据的聚合。 例如，我们可能有月度数据，但希望预测下一年的总数。 或者我们可能有每周数据，并希望预测接下来四个星期的总数。

如果点预测是均值，那么将它们相加可以很好地估计总数。 但是由于预测误差之间的相关性，预测区间更加棘手。

 一般的解决方案是使用模拟。 （例子见原书）

##### 倒推

有时“回溯”时间序列是有用的——即逆时预测。 尽管没有内置的 R 函数来执行此操作，但通过创建新的时间索引很容易实现。

##### 很长很短的时间序列

预测非常短的时间序列：

我们经常被问到可以使用多少数据点来拟合时间序列模型。 与几乎所有样本量问题一样，没有简单的答案。 它取决于要估计的模型参数的数量和数据中的随机性数量。 所需的样本大小随着要估计的参数数量和数据中的噪声量而增加。

 一些教科书提供了经验法则，给出了各种时间序列模型的最小样本量。 这些在理论或实践中具有误导性且未经证实。 此外，他们忽略了数据的潜在可变性，并且经常忽略要估计的参数数量。 例如，对于 ARIMA 建模通常给出的最小值 30 的幻数没有任何理由。 唯一的理论限制是我们需要比预测模型中的参数更多的观察。 然而，在实践中，我们通常需要比这更多的观察。

理想情况下，我们会测试我们选择的模型与一些更简单的方法相比是否在样本外表现良好。 然而，对于短序列，没有足够的数据允许为了测试目的而保留一些观察结果，甚至时间序列交叉验证也很难应用。  AICc 在这里特别有用，因为它是一步预测样本外 MSE 的代理。 选择具有最小 AICc 值的模型可以同时考虑参数数量和噪声量。

短序列往往发生的情况是 AICc 建议使用简单的模型，因为任何具有超过一两个参数的参数都会由于估计错误而产生较差的预测。 

预测很长的时间序列：

大多数时间序列模型不适用于很长的时间序列。 问题是真实数据并非来自我们使用的模型。 当观察的数量不是很大（比如大约 200）时，模型通常可以很好地作为生成数据的任何过程的近似值。 但最终我们将有足够的数据，真实过程和模型之间的差异开始变得更加明显。 另一个问题是参数的优化变得更加耗时，因为所涉及的观察次数较多。

如何处理这些问题取决于模型的目的。 可以使用更灵活和更复杂的模型，但这仍然假设模型结构将在整个数据周期内工作。 更好的方法通常是允许模型本身随时间变化。  **ETS 模型旨在通过允许趋势和季节性术语随时间演变来处理这种情况。 具有差分的 ARIMA 模型具有相似的属性。 但是动态回归模型不允许模型组件的任何演变**。

如果我们只对预测接下来的几次观察感兴趣，一种简单的方法是丢弃最早的观察结果，只对最近的观察结果拟合模型。 然后一个不灵活的模型可以很好地工作，因为没有足够的时间让关系发生实质性变化。

例如，我们将动态谐波回归模型拟合到 26 年的每周汽油产量。 假设季节性模式在近三年内保持不变可能是不现实的。 所以我们可以简单地将模型拟合到最近几年。

##### 预测训练集和测试集

通常，我们计算训练数据（“拟合值”）的一步预测和测试数据的多步预测。 然而，有时我们可能希望计算训练数据的多步预测，或测试数据的一步预测。

对训练数据的多步预测：

我们**通常将拟合值定义为对训练集的一步预测**，但类似的想法也可用于多步预测。 我们将说明使用 ARIMA 模型计算澳大利亚外卖食品支出的方法。 过去五年用于测试集，预测如图 13.9 所示。

```R
training <- auscafe %>% filter(year(Month) <= 2013)
test <- auscafe %>% filter(year(Month) > 2013)
cafe_fit <- training %>%
  model(ARIMA(log(Turnover)))
cafe_fit %>%
  forecast(h = 60) %>%
  autoplot(auscafe) +
  labs(title = "Australian food expenditure",
       y = "$ (billions)")
```

fitted() 函数有一个 h 参数，以允许在训练集上使用 h 步“拟合值”。 图 13.10 是对训练集的 12 步（一年）预测图。 由于该模型同时涉及季节性（滞后 12）和第一（滞后 1）差分，因此无法计算前几个观测值的这些预测。

```R
fits12 <- fitted(cafe_fit, h = 12)
training %>%
  autoplot(Turnover) +
  autolayer(fits12, .fitted, col = "#D55E00") +
  labs(title = "Australian food expenditure",
       y = "$ (billions)")
```

对测试数据的一步预测：

通常的做法是使用训练数据拟合模型，然后在测试数据集上评估其性能。 通常这样做的方式意味着对测试数据的比较使用不同的预测范围。 在上面的例子中，我们使用了测试数据的最后六十个观测值，并在训练数据上估计了我们的预测模型。 那么预测误差将是提前 1 步、2 步、……、60 步。 预测方差通常随着预测范围的增加而增加，因此**如果我们只是对测试集的绝对误差或平方误差进行平均，我们就是在将结果与不同的方差相结合**。

此问题的一种解决方案是在测试数据上获得 1 步错误。 也就是说，我们仍然使用训练数据来估计任何参数，但是当我们计算测试数据的预测时，我们使用每个观测之前的所有数据（训练和测试数据）。 所以我们的训练数据是时间 1, 2, … , T − 60 。 我们在这些数据上估计模型，然后计算$\hat{y}_{T-60+h|T-61+h}$，对于$h=1,\dots,T-1$。 因为没有使用测试数据来估计参数，所以这仍然给了我们一个“公平”的预测。

```R
cafe_fit %>%
  refit(test) %>%
  accuracy()
```

请注意，在这种情况下不会重新估计模型。 相反，先前获得的模型（并存储为 cafe_fit）将应用于测试数据。 因为模型没有重新估计，所以这里得到的“残差”实际上是一步预测误差。 因此，accuracy() 命令产生的结果实际上是在测试集上（尽管输出是“训练集”）。 **这种方法可用于比较来自不同模型的一步预测**。  

##### 处理异常值和缺失值

真实数据通常包含缺失值、异常观测值和其他杂乱的特征。 与他们打交道有时会很麻烦。

异常值:

异常值是与时间序列中的大多数观察结果非常不同的观察结果。 它们可能是错误，也可能只是不寻常。  （有关回归上下文中异常值的讨论，请参见第 7.3 节。）如果数据中存在极端异常值，我们在本书中考虑的任何方法都不会奏效。 在这种情况下，我们可能希望用缺失值或与大多数数据更一致的估计值来替换它们。

简单地替换异常值而不考虑它们发生的原因是一种危险的做法。 它们可能提供有关产生数据的过程的有用信息，在预测时应予以考虑。 但是，如果我们愿意假设异常值确实是错误，或者它们不会在预测期内发生，那么替换它们可以使预测任务更容易。

图 13.11 显示了南澳大利亚阿德莱德山地区的游客人数。  2002 年第四季度似乎有一个不寻常的观察结果。

```R
tourism %>%
  filter(
    Region == "Adelaide Hills", Purpose == "Visiting"
  ) %>%
  autoplot(Trips) +
  labs(title = "Quarterly overnight trips to Adelaide Hills",
       y = "Number of trips")
```

查找异常值的一种有用方法是将 STL() 应用于参数为robust=TRUE 的系列。 然后任何异常值都应该出现在剩余系列中。 图 13.11 中的数据几乎没有明显的季节性，因此我们将通过设置 period=1 来应用没有季节性成分的 STL。

```R
ah_decomp <- tourism %>%
  filter(
    Region == "Adelaide Hills", Purpose == "Visiting"
  ) %>%
  # Fit a non-seasonal STL decomposition
  model(
    stl = STL(Trips ~ season(period = 1), robust = TRUE)
  ) %>%
  components()
ah_decomp %>% autoplot()
```

在上面的例子中，异常值很容易识别。 在更具挑战性的情况下，使用剩余系列的箱线图会很有用。 我们可以从数据的中心 50% 中识别出大于 1.5 四分位距 (IQR) 的异常值。 如果余数呈正态分布，则每 1000 个观测值中将显示 7 个为“异常值”。 **更严格的规则是将离群值定义为距离中心 50% 的数据大于 3 个四分位距 (IQR) 的离群值**，这将使 500,000 个正态分布观测值中只有 1 个为离群值。 这是我们更喜欢使用的规则。

```R
outliers <- ah_decomp %>%
  filter(
    remainder < quantile(remainder, 0.25) - 3*IQR(remainder) |
    remainder > quantile(remainder, 0.75) + 3*IQR(remainder)
  )
outliers
```

这找到了我们从图 13.11 中怀疑的一个异常值。 类似的东西可以应用于完整数据集，以识别其他系列中的异常观察。

缺失值:

数据缺失的原因有很多，值得考虑的是，缺失是否会导致预测模型出现偏差。 例如，假设我们正在研究一家商店的销售数据，当商店关门时，公共假期会出现缺失值。 结果，第二天的销售额可能会增加。 如果我们的预测模型没有考虑到这一点，我们很可能会低估公众假期后第一天的销售额，但高估之后几天的销售额。 处理这种情况的一种方法是使用动态回归模型，其中虚拟变量指示当天是公共假期还是公共假期后的第二天。 没有自动化方法可以处理这种影响，因为它们取决于特定的预测环境。

在其他情况下，缺失可能本质上是随机的。 例如，有人可能忘记记录销售数字，或者数据记录设备可能出现故障。 如果缺失数据的时间不能为预测问题提供信息，则可以更轻松地处理缺失值。

最后，我们可能会删除一些不寻常的观察结果，从而在系列中创建缺失值。

有些方法允许缺失值没有任何问题。 例如，朴素预测方法继续有效，最近的非缺失值提供对未来时间段的预测。 同样，当历史数据中存在缺失值时，第 5.2 节中介绍的其他基准方法都会产生预测。  **ARIMA 模型、动态回归模型和 NNAR 模型等fable函数也将正常工作而不会导致错误**。 但是，其他建模函数不处理缺失值，包括 ETS() 和 STL()。

 当缺失值导致错误时，至少有两种方法可以处理该问题。 首先，**假设有足够长的观察序列来产生有意义的预测，我们可以只取最后一个缺失值之后的数据部分。 或者，我们可以通过首先拟合 ARIMA 模型，然后使用该模型对缺失的观测值进行插值来用估计值替换缺失值**。

我们将用 ARIMA 模型的估计替换图 13.12 中识别的异常值。

```R
ah_miss <- tourism %>%
  filter(
    Region == "Adelaide Hills",
    Purpose == "Visiting"
  ) %>%
  # Remove outlying observations
  anti_join(outliers) %>%
  # Replace with missing values
  fill_gaps()
ah_fill <- ah_miss %>%
  # Fit ARIMA model to the data containing missing values
  model(ARIMA(Trips)) %>%
  # Estimate Trips for all periods
  interpolate(ah_miss)
ah_fill %>%
  # Only show outlying periods
  right_join(outliers %>% select(-Trips))
```

interpolate() 函数使用 ARIMA 模型来估计序列中的任何缺失值。 现在可以使用不允许缺失值的函数对 ah_fill 数据进行建模。

```R
ah_fill %>%
  autoplot(Trips) +
  autolayer(ah_fill %>% filter_index("2002 Q3"~"2003 Q1"),
    Trips, colour="#D55E00") +
  labs(title = "Quarterly overnight trips to Adelaide Hills",
       y = "Number of trips")
```
