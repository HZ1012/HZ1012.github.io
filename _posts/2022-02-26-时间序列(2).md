---
layout:     post                    # 使用的布局（不需要改）
title:      时间序列（2）            # 标题 
# subtitle:   《Forecasting: Principles and Practice》中文整理 #副标题
date:       2022-02-24              # 时间
author:     HZ                      # 作者
header-img: img/time series.jpg    #这篇文章标题背景图片
catalog: true                       # 是否归档
tags:                               #标签
    - 统计学习
    - R应用
---

>本篇主要介绍了判断性预测、时序回归、单位根过程、指数平滑和ARIMA

#### 判断性预测

使用判断进行预测在实践中很常见。 在许多情况下，判断性预测是唯一的选择，例如当完全缺乏历史数据时，或者当新产品正在推出时，或者当一个新的竞争对手进入市场时，或者在全新且独特的市场条件下。 例如，2012 年 12 月，澳大利亚政府在全球率先通过立法，禁止在烟盒上使用公司标志，并要求所有烟盒为深绿色。 由于没有历史先例，因此必须应用判断以预测此类政策的效果。

也有数据不完整或延迟一段时间后才可用的情况。 例如，中央银行在预测当前经济活动水平时包括判断，这一程序称为临近预报，因为 GDP 仅按季度提供。

该领域的研究表明，当预测者拥有 (i) 重要的领域知识和 (ii) 更及时、最新的信息时，判断预测的准确性会提高。 判断方法可以快速适应此类变化、信息或事件。

使用条件： 

(i) 没有可用数据，因此统计方法不适用，判断预测是唯一可行的方法；  

(ii) 可获得数据，生成统计预测，然后根据判断进行调整；  

(iii) 数据是可用的，统计和判断预测是独立生成的，然后再结合起来。 我们应该澄清，当数据可用时，应用统计方法（例如其他章节中讨论的方法）是更可取的，并且应始终作为起点。 统计预测通常优于仅使用判断来生成预测。 在本章的大部分内容中，我们将重点放在没有可用数据的第一种设置上，在最后一节中，我们将讨论统计预测的判断性调整。 我们将在#中讨论组合预测。

##### 注意限制

判断性预测是主观的，因此不能没有偏见或限制。

* 判断性预测可能不一致。 与每次都可以由相同的数学公式生成的统计预测不同，判断性预测在很大程度上依赖于人类的认知，并且容易受到其局限性的影响。 例如，有限的记忆可能会使最近发生的事件比实际情况更重要，并且可能会忽略更遥远过去的重大事件； 或有限的注意力可能会导致错过重要信息； 或者对因果关系的误解可能导致错误的推论。 此外，由于心理因素的影响，人类的判断可能会有所不同。 可以想象，某天一位处于积极心态中的经理做出可能趋于乐观的预测，而另一天处于消极心态下，则做出不太乐观的预测。
* 个人或政治议程可能会影响判断，因为目标和预测没有分开。 例如，如果销售经理知道她生成的预测将用于设置销售预期（目标），她可能倾向于将这些设置得较低以显示良好的绩效（即超出预期目标）。 即使在目标和预测完全分开的情况下，判断也可能受到乐观或一厢情愿的困扰。 例如，一个致力于推出新产品的团队极不可能预测到它的失败。 正如我们稍后将讨论的，这种乐观情绪可以在小组会议环境中得到加强。  “当心你的营销和销售同事的热情”。
* 在判断性预测中常见的另一个不良特性是锚定效应。 在这种情况下，后续预测趋于收敛或接近初始熟悉的参考点。 例如，通常以最后观察到的值作为参考点。 预测者受到先验信息的过度影响，因此在预测过程中给予更多的重视。 锚定可能导致保守主义和低估新的和更新的信息，从而产生系统性偏见。

##### 关键原则

在判断预测中使用系统和结构良好的方法有助于减少判断预测局限性的不利影响，我们在上一节中列出了其中的一些。 无论这种方法涉及一个人还是多个人，都应遵循以下原则。

1. **清晰简洁地设定预测任务** 在设定预测挑战和表达预测任务时需要小心。 每个人都清楚任务是什么很重要。 所有定义都应清晰、全面，避免含糊不清的表述。 此外，避免包含可能分散预测者注意力的情绪术语和不相关信息也很重要。 在随后的 Delphi 方法中，有时在设置预测任务之前进行初步的信息收集可能会很有用。

2. **实施系统方法** 通过使用系统方法进行判断性预测，包括与预测任务相关的信息类别清单，可以提高预测的准确性和一致性。 例如，确定哪些信息是重要的以及如何对这些信息进行加权是有帮助的。 在预测新产品的需求时，我们应该考虑哪些因素以及我们应该如何考虑这些因素？ 是否应该是价格、竞争的质量和/或数量、当时的经济环境、产品的目标人群？ 值得投入大量精力和资源来整合决策规则，从而形成最佳的系统方法。

3. **记录和证明**在系统方法中实施的决策规则和假设的形式化和记录可以促进一致性，因为相同的规则可以重复实施。 此外，要求预测者记录和证明他们的预测会导致问责，从而减少偏差。 此外，正式文件对接下来建议的系统评估过程有很大帮助。

4. **系统地评估预测** 系统地监控预测过程可以识别不可预见的违规行为。 特别是，保留预测记录，并在相应的观察结果可用时使用它们来获得反馈。 尽管作为预报员，您可能会尽力而为，但您所处的环境是动态的。 发生变化，您需要监控这些变化以评估决策规则和假设。 反馈和评估有助于预测者学习和提高他们的预测准确性。

5. **将预报员和用户分开** 如果预报任务是由预报用户执行的，例如那些负责实施与预报有关的行动计划的用户，则可能会妨碍预报的准确性。 我们应该在这里再次澄清，鉴于所有可用信息，包括历史数据和可能影响预测的任何未来事件的知识，预测就是尽可能准确地预测未来。 预报员和用户应明确分开。 一个经典案例是新产品的推出。 预测应该是对新产品销量的合理估计，这可能与管理层为实现公司财务目标而预期或希望的销量大不相同。 在这种情况下，预报员可能会向用户提供现实检查。

   预报员将预报彻底传达给潜在用户非常重要。 用户可能会感到与预测疏远和脱节，并且可能对它们没有充分的信心。 解释和澄清过程并证明导致预测的基本假设的合理性将为用户提供一些保证。

   使用和实施预测的方式显然取决于管理决策。 例如，管理层可能决定向上调整预测（过于乐观），因为预测可用于指导采购和库存水平。 在成本效益分析表明持有过剩库存的成本远低于销售损失的成本后，可以做出这样的决定。 这种类型的调整应该是设定目标或计划供应的一部分，而不是预测过程的一部分。 相比之下，如果将预测用作目标，则可以将其设置得较低，以便更容易超过。 再次重申，**设定目标与制定预测不同，两者不应混淆**。

##### The Delphi method

德尔菲法是兰德公司的奥拉夫·赫尔默和诺曼·达尔基在 1950 年代发明的，目的是解决特定的军事问题。 该方法依赖于一个关键假设，即群体的预测通常比个人的预测更准确。  Delphi 方法的目标是以结构化的迭代方式从一组专家构建共识预测。 指定一名协调人以实施和管理该过程。  Delphi 方法通常包括以下阶段： 

1. 组建专家小组。
2. 设置预测任务/挑战并分发给专家。
3. 专家返回最初的预测和理由。 这些被编译和总结以提供反馈。
4. 向专家提供反馈，他们现在根据反馈审查他们的预测。 可以重复此步骤，直到达到令人满意的共识水平。
5. 最终预测是通过汇总专家的预测来构建的。

##### 类比预测

在实践中经常采用的一种有用的判断方法是类比预测。 一个常见的例子是通过评估过程为房屋定价。 估价师通过将房屋与该地区已售出的类似房产进行比较来估计房屋的市场价值。 相似度取决于所考虑的属性。 在房屋评估中，通常会考虑土地面积、住宅面积、卧室和浴室数量以及车库空间等属性。

结构化类比:

可以实施由专家小组组成的结构化方法，如 Green & Armstrong (2007) 所提议的那样。 这个概念类似于 Delphi 的概念； 然而，预测任务是通过考虑类比来完成的。 首先，任命一名协调人。 然后结构化方法涉及以下步骤。

1. 组建了一个可能对类似情况有经验的专家小组。
2. 任务/挑战被设置并分发给专家。
3. 专家尽可能多地识别和描述类比，并根据每个类比生成预测。
4. 专家列出每个类比与目标情况的异同，然后在一个尺度上对每个类比与目标情况的相似性进行评级。
5. 预测是由协调人使用一组规则得出的。 这可以是加权平均值，其中权重可以由专家对每个类比的排名分数来指导。

 与 Delphi 方法一样，专家的匿名性在不抑制创造力方面可能是一个优势，但可能会阻碍合作。 格林和阿姆斯特朗在他们的结果中发现专家之间的合作没有任何好处。 一个关键发现是，具有多个类比（超过两个）并且对类比有直接经验的专家生成了最准确的预测。

##### 情景预测

一种完全不同的判断性预测方法是基于场景的预测。 这种方法的目的是根据合理的场景生成预测。 与之前的两种方法（德尔福法和类比预测）相比，所得到的预测旨在成为可能的结果，每个基于情景的预测可能具有较低的发生概率。 这些情景是通过考虑所有可能的因素或驱动因素、它们的相对影响、它们之间的相互作用以及要预测的目标来生成的。

基于情景构建预测允许生成范围广泛的可能预测并识别一些极端情况。 例如，通常会呈现“最佳”、“中间”和“最差”案例场景，但也会生成许多其他场景。 考虑并记录这些截然不同的极端情况可以导致及早制定应急计划。

通过情景预测，决策者经常参与情景的生成。 虽然这可能会导致一些偏差，但它可以简化基于场景的预测的沟通，并有助于更好地了解结果。

##### 新产品预测

新产品的定义可能会有所不同。 它可能是已推出的全新产品、现有产品的变体（“新的和改进的”）、现有产品定价方案的变化，甚至是现有产品进入新市场。

由于无法获得历史数据，因此判断性预测通常是新产品预测的唯一可用方法。 我们已经概述的方法（Delphi，类比预测和情景预测）都适用于预测新产品的需求。

也可以使用其他更具体的方法。 以下三种在实践中常用的方法。 这些方法没有已经讨论过的方法结构化，因此可能会导致更多有偏差的预测。

* 销售人员综合 略

* 执行意见 略

* 客户意图 

  客户意图可用于预测对新产品或现有产品变体的需求。 问卷由客户填写，了解他们购买产品的意图。 使用结构化问卷，要求客户对他们购买产品的可能性进行评分； 例如，极有可能、可能、可能、不太可能、极不可能。

  需要解决调查设计挑战，例如收集代表性样本、应用具有时间和成本效益的方法以及处理不答复。 此外，在此调查设置中，我们必须牢记购买意愿之间和购买行为的关系 。 客户并不总是按照他们说的去做。 **许多研究发现购买意向和购买行为之间存在正相关关系； 然而，这些相关性的强度差异很大**。 推动这种变化的因素包括数据收集和产品发布的时间、产品“新”的定义以及行业类型。 行为理论告诉我们，如果在行为之前测量意图，则意图可以预测行为。意图和行为之间的时间会有所不同，这取决于它是全新的产品还是现有产品的变体。 此外，**与全新产品相比，现有产品和熟悉产品的变体的意图和行为之间的相关性更强**。

  无论使用哪种新产品预测方法，重要的是要彻底记录所做的预测及其背后的推理，以便在数据可用时能够对其进行评估。 

##### 判断调整

最后，我们考虑历史数据可用并用于生成统计预测的情况。 从业者通常会对这些预测进行判断性调整。 这些调整可以潜在地提供本章前面讨论过的判断性预测的所有优点。 **例如，它们为纳入统计模型中可能未考虑的因素提供了一种途径，例如促销、大型体育赛事、假期或尚未反映在数据中的近期事件**。 然而，这些优势只有在合适的条件下才能实现。 判断性调整，如判断性预测，带有偏见和局限性，我们必须实施有条不紊的策略以将它们最小化

谨慎使用调整:

从业者调整的频率比他们应该的要高得多，而且很多时候都是出于错误的原因。 通过调整统计预测，预测的用户会产生一种主人翁感和可信度。 用户通常不了解或不了解生成统计预测的机制（因为他们通常没有接受过这方面的培训）。 通过实施判断性调整，用户觉得他们对预测做出了贡献并完成了预测，现在他们可以将自己的直觉和解释与这些联系起来。 预测已经成为他们自己的预测。

判断性调整不应旨在纠正被认为被统计模型遗漏的数据中的系统模式。 这已被证明是无效的，因为预测人员倾向于读取嘈杂系列中不存在的模式。 统计模型在考虑数据模式方面要好得多，而判断性调整只会阻碍准确性。

当手头有重要的额外信息或强有力的证据表明需要进行调整时，判断性调整最有效。 只有当我们有重要的额外信息没有包含在统计模型中时，我们才应该进行调整。 因此，当它们的尺寸很大时，调整似乎是最准确的。 已经发现小调整（尤其是在促进乐观错觉的积极方向上）会阻碍准确性，应该避免。

应用结构化方法:

使用结构化和系统化方法将提高判断调整的准确性。 遵循上文中概述的关键原则至关重要。 特别是，必须记录和证明调整的合理性将使覆盖统计预测更具挑战性，并将防止不必要的调整。

由面板执行调整是很常见的。 使用 Delphi 设置具有很大的优势。 但是，如果在小组会议上进行调整，最好先考虑关键市场或产品的预测，因为小组成员在此过程中会感到疲倦。 随着会议的进行，往往会做出更少的调整。

#### 时间序列回归模型

TSLM()

##### 一些有用的预测变量

* 趋势

* 虚拟变量

  这种情况仍然可以在多元回归模型的框架内通过创建一个“虚拟变量”来处理，该虚拟变量取值 1 对应于“是”，取值 0 对应于“否”。 虚拟变量也称为“指标变量”。 虚拟变量也可用于解释数据中的异常值。 虚拟变量不是忽略异常值，而是消除其影响。 在这种情况下，虚拟变量为该观察值取值为 1，其他地方为 0。 一个例子是发生了特殊事件的情况。 例如，在预测到巴西的游客人数时，我们需要考虑 2016 年里约热内卢夏季奥运会的影响。

  如果有两个以上的类别，则可以使用多个虚拟变量（比类别总数少一个）对变量进行编码。 如果您将因子变量指定为预测变量，则 TSLM() 将自动处理这种情况。 通常不需要手动创建相应的虚拟变量。

* 季节性虚拟变量

  请注意，编码七个类别只需要六个虚拟变量。 这是因为第七个类别（在本例中为星期日）由截距捕获，并且在虚拟变量都设置为零时指定。


   许多初学者会尝试为第七类添加第七个虚拟变量。 这被称为“虚拟变量陷阱”，因为它会导致回归失败。 当还包括截距时，将有太多参数需要估计。 一般规则是使用比类别少一个虚拟变量。 所以对于季度数据，使用三个虚拟变量； 对于月度数据，使用 11 个虚拟变量； 对于每日数据，使用六个虚拟变量，依此类推。

   与虚拟变量相关的每个系数的解释是，它是该类别相对于省略类别的影响的度量。

* 干预变量

  通常需要对可能影响要预测的变量的干预进行建模。 例如，竞争对手的活动、广告支出、行业行动等等，都会产生影响。

  当效果仅持续一个时期时，我们使用“尖峰”变量。 这是一个虚拟变量，在干预期间取值为 1，在其他时间取值为 0。 尖峰变量相当于处理异常值的虚拟变量。

  其他干预措施具有直接和永久的效果。 如果干预导致水平移动（即从干预开始，序列的值突然且永久地改变），那么我们使用“阶跃”变量。 步长变量在干预前取值为零，从干预开始后取值为 1。

  另一种形式的永久效应是坡度的变化。 这里的干预是使用分段线性趋势处理的； 一种在干预时弯曲的趋势，因此是非线性的。 #

  1. 交易日

     一个月中的交易日数可能会有很大差异，并对销售数据产生重大影响。 为此，可以将每个月的交易天数作为预测指标。

     考虑到一周中不同天数的影响的替代方案具有以下预测因子： 

     $\begin{align*}  x_{1} &= \text{number of Mondays in month;} \\  x_{2} &= \text{number of Tuesdays in month;} \\        & \vdots \\  x_{7} &= \text{number of Sundays in month.} \end{align*}$

  2. 分布式滞后

     将广告支出作为预测因素通常很有用。 然而，由于广告的效果可以持续超出实际活动，我们需要包括广告支出的滞后值。 因此，可以使用以下预测器。

     $\begin{align*}  x_{1} &= \text{advertising for previous month;} \\  x_{2} &= \text{advertising for two months previously;} \\        & \vdots \\  x_{m} &= \text{advertising for $m$ months previously.} \end{align*}$

     通常要求系数随着滞后的增加而减小，尽管这超出了本章的范围。

  3. 复活节

     与大多数假期不同，因为它不是每年的同一天举行，其影响可持续数天。 在这种情况下，当假期在特定时间段内时，可以使用值为 1 的虚拟变量，否则为 0。

     对于月度数据，如果复活节在 3 月下降，则虚拟变量在 3 月取值为 1，如果在 4 月下降，虚拟变量在 4 月取值为 1。 当复活节从 3 月开始并在 4 月结束时，虚拟变量在月份之间按比例分配。(中国的春节类似)

  4. 傅立叶级数

     使用季节性虚拟变量的另一种方法是使用傅立叶项，尤其是对于**长季节性周期**。 让-巴蒂斯特·傅立叶 (Jean-Baptiste Fourier) 是一位出生于 1700 年代的法国数学家，他证明了一系列正确频率的正弦和余弦项可以近似于任何周期函数。 我们可以将它们用于季节性模式。

      如果 m 是季节性周期，则前几个傅立叶项由下式给出:

     $x_{1,t} = \sin\left(\textstyle\frac{2\pi t}{m}\right),  x_{2,t} = \cos\left(\textstyle\frac{2\pi t}{m}\right),  x_{3,t} = \sin\left(\textstyle\frac{4\pi t}{m}\right),$

     如果我们有每月的季节性，并且我们使用这些预测变量中的前 11 个，那么我们将得到与使用 11 个虚拟变量完全相同的预测。

     **对于傅立叶项，我们通常需要比虚拟变量更少的预测变量，尤其是当 m 很大时**。 这使得它们对于每周数据很有用，例如，其中 m ≈ 52 。 对于较短的季节性周期（例如，季度数据），与季节性虚拟变量相比，使用傅立叶项几乎没有优势。

      如果仅使用前两个傅立叶项$x_{1,t}$和$x_{2,t}$，则季节性模式将遵循简单的正弦波。 包含傅立叶项的回归模型通常称为调和回归，因为连续的傅立叶项代表前两个傅立叶项的谐波。

  ##### 选择预测变量

glance()

我们将这些值与其他模型的相应值进行比较。 对于 CV、AIC、AICc 和 BIC 度量，我们希望找到具有最低值的模型； 对于 Adjusted $R^2$ ，我们寻找具有最高值的模型。

虽然$R^{2}$被广泛使用，并且比其他度量存在的时间更长，但它倾向于选择过多的预测变量使其不太适合预测。

许多统计学家喜欢使用 BIC，因为它具有以下特性：如果存在真正的底层模型，BIC 会在给定足够数据的情况下选择该模型。 然而，在现实中，很少有真正的底层模型，即使有真正的底层模型，选择该模型也不一定会给出最好的预测（因为参数估计可能不准确）。

因此，建议使用 AICc、AIC 或 CV 统计数据之一，每个统计数据都以预测为目标。 如果 T 的值足够大，它们都会导致相同的模型。 

##### 回归预测

一些基本知识见回归章节，本节仅罗列与时序回归相关知识

事前与事后预测：

在对时间序列数据使用回归模型时，我们需要区分可以产生的不同类型的预测，这取决于计算预测时假设已知的内容。

事前预测是仅使用事先可获得的信息进行的预测。 例如，对样本结束后几个季度美国消费百分比变化的事前预测，应仅使用截至 2019 年第二季度（包括 2019 年第二季度）的可用信息。 这些是真实的预测，使用当时可用的任何信息提前做出。 因此，为了生成事前预测，该模型需要预测变量的预测。 为了获得这些，我们可以使用第 5.2 节中介绍的一种简单方法或第 8 章和第 9 章中更复杂的纯时间序列方法。或者，可以使用其他来源（例如政府机构）的预测。

事后预测是使用有关预测变量的后期信息进行的预测。 例如，消费的事后预测可以使用预测变量的实际观察，一旦这些已经被观察到。 这些不是真正的预测，但对研究预测模型的行为很有用。

事前预测和事后预测的比较评估有助于区分预测不确定性的来源。 这将显示预测错误是由于预测器的预测不佳还是由于预测模型不佳而出现的。

基于场景的预测：

在此设置中，预报员假设感兴趣的预测变量的可能场景。

 例如，美国政策制定者可能有兴趣比较当收入和储蓄分别持续增长 1% 和 0.5% 而就业率没有变化时，消费的预测变化与分别下降 1% 和 0.5% 的情况。  0.5%，对于样本结束后的四个季度中的每个季度。 结果预测计算如下，如图 7.18 所示。 我们应该注意到，基于情景的预测的预测区间不包括与预测变量的未来值相关的不确定性。 他们假设预测变量的值是预先知道的。

scenairos()

##### 多重共线性和预测

一个密切相关的问题是多重共线性，当多元回归中的两个或多个预测变量提供相似信息时，就会发生多重共线性。

当两个预测变量彼此高度相关（即它们的相关系数接近 +1 或 -1）时，就会发生这种情况。 在这种情况下，知道其中一个变量的值会告诉您很多关于另一个变量的值的信息。 因此，他们提供了类似的信息。 例如，脚的大小可用于预测身高，但在同一模型中包含左脚和右脚的大小不会使预测变得更好，尽管它也不会使预测变得更糟。

当预测变量的线性组合与预测变量的另一个线性组合高度相关时，也会出现多重共线性。 在这种情况下，了解第一组预测变量的值会告诉您很多有关第二组预测变量的值的信息。 因此，他们提供了类似的信息。

 当存在多重共线性时，与单个回归系数相关的不确定性会很大。 这是因为它们很难估计。 因此，对回归系数的统计检验（例如 t 检验）是不可靠的。  （在预测中，我们很少对此类测试感兴趣。）此外，不可能对每个单独的预测变量对预测的贡献做出准确的陈述。

注：**多重共线性**（Multicollinearity）是指[多变量](https://zh.wikipedia.org/wiki/一般线性模型)[线性回归](https://zh.wikipedia.org/wiki/線性回歸)中，[变量](https://zh.wikipedia.org/wiki/变量)之间由于存在高度相关关系而使[回归](https://zh.wikipedia.org/wiki/迴歸分析)估计不准确。在该情况下，多元回归的系数可能会因为模型或数据的微小变化发生剧烈改变。在样本数据集中，多重共线性不会影响模型整体的预测能力或[信度](https://zh.wikipedia.org/wiki/信度)，它只会影响单个预测值（predictor）的结果。**简而言之，一个包含有共线预测值的多元回归模型可以指示出模型整体的预测可靠程度，但可能无法对单个预测值给出有效结果，也可能无法判断哪些预测值是冗余的**。

如果未来预测变量的值超出预测变量的历史值范围，则预测将不可靠。 例如，假设您已经拟合了一个具有相互高度相关的预测变量 x 1 和 x 2 的回归模型，并假设训练数据中 x 1 的值介于 0 和 100 之间。然后基于 x 1 >  100 或 x 1 < 0 将不可靠。 当预测变量的未来值远远超出历史范围时，这总是有点危险，但当存在多重共线性时尤其成问题。

请注意，如果您使用的是优秀的统计软件，如果您对每个预测变量的具体贡献不感兴趣，并且如果您的预测变量的未来值在其历史范围内，则无需担心——多重共线性不是问题，除非存在完美的相关性。

#### 单位根过程

前面的AR、MA、ARMA主要应用于简单收益率和对数收益率。 对于价格序列， 一般其水平是缓慢变化的， 包括缓慢的增长趋势与一定的周期波动。 这样的序列不满足弱平稳的条件， 是非平稳时间序列。

典型的非平稳时间序列模型是**单位根(unit root)**非平稳时间序列。

##### 随机游走

考虑${p_t}$的模型:$\begin{align} p_t = p_{t-1} + \varepsilon_t, \ t=1,2,\dots \tag{7.1} \end{align}$

其中是零均值独立同分布白噪声列。 称是一个**随机游动**(random walk)。

上式表面上看是一个AR（1）模型，但是$\phi_1=1$不满足AR（1）的平稳性条件（$|\phi_1|<1$）,易得此模型不可预测

单位根过程的ACF估计是不相合的， 对单位根过程的样本作ACF图， 其衰减速度很慢很慢。

设$p_0=0$， 单位根过程${p_t}$有如下特点：

- $p_t$期望值等于0；
- 方差等于$\sigma^{2}t$，随线性增长，趋于无穷；
- 历史的扰动（新息）的影响不衰减；
- 预测只能用最后一个观测值作为预测， 预测均方误差趋于无穷。
- 样本ACF表现为基本不衰减，近似等于1。

##### 带漂移的随机游走

上面的随机游动模型的金融意义一般$p_t$是对数价格， 则$\varepsilon_t$是零均值的对数收益率。 实际的对数收益率常常是非零的，正数居多。 所以，模型可以推广为:$p_t = \mu + p_{t-1} + \varepsilon_t, \ t=1,2,\dots$,其中$\{ \varepsilon_t \}$仍为零均值独立同分布白噪声列。 常数$\mu$并不代表均值， 而是对数价格$p_t$的增长速度，称为模型的**漂移**(drift)

##### 固定趋势模型

设$\{ X_t \}$为弱平稳时间序列 令$Y_t = a + b t + X_t$

则$EY_t = (a + \mu_x) + bt$，$\text{Var}(Y_t) = \text{Var}(X_t) = \sigma_x^2$ ， 均值非常数所以$\{ Y_t \}$非平稳。 但是， 减去一个固定趋势$a + bt$后$\{ Y_t \}$就变成了平稳列， 这样的$\{ Y_t \}$与随机游动或者带漂移的随机游动有着本质的区别。

随机游动$p_t = p_{t+1} + \varepsilon_t$与固定趋势加扰动$Y_t = a + bt + X_t$都能呈现出缓慢的趋势变化。 区别在于：

- 随机游动的方差是线性增长的， 固定趋势的观测值方差不变；
- 随机游动的扰动的影响是永久的， 固定趋势的扰动的影响仅在一个时刻（如果扰动是白噪声） 或者很短时间（如果是扰动是线性时间序列）；
- 随机游动的趋势没有固定方向， 固定趋势的变化形状是固定的；
- 固定趋势模型减去一个固定的回归函数就可以变成平稳列， 随机游动减去任意的非随机函数都不能变平稳， 可以用差分运算变成平稳。

在AR和ARMA模型中， 常数项$\phi_0$与平稳均值有关。 但是在带漂移的随机游动模型中， 常数项$\mu$是每一步的平均增量，是固定线性趋势的斜率。 所以时间序列模型中的常数项可能会依模型的不同而具有迥然不同的含义。

将带漂移的随机游动模型中的白噪声替换成一个ARMA平稳列， 其主要的性质仍能保留。即$Y_t = Y_{t-1} + \mu + X_t$,详见：

##### 单位根检验

单位根非平稳列是金融中最常用的非平稳模型， 单位根非平稳列不能使用平稳列的模型来建模。 所以， 要建模的序列应该进行“单位根检验”。

对不带漂移的单位根过程， 考虑如下的基础模型：$\begin{align} p_t = \phi_1 p_{t-1} + \varepsilon_t  \end{align}$

其中$\{\varepsilon_t\}$是零均值独立同分布白噪声列。$|\phi_1| \leq 1$。 考虑如下零假设与对立假设：$H_0: \phi_1 = 1 \longleftrightarrow H_a: \phi_1 < 1$

这样的检验问题称为单位根检验问题。具体检验略 详见书

#### 指数平滑

ETS(R)

指数平滑是在 1950 年代后期提出的（Brown，1959 年；Holt，1957 年；Winters，1960 年），并推动了一些最成功的预测方法。 使用指数平滑方法生成的预测是过去观测值的加权平均值，随着观测值变老，权重呈指数衰减。 换句话说，观察越近，相关的权重就越高。 该框架可以快速生成可靠的预测，适用于广泛的时间序列，这是一个巨大的优势，对工业应用非常重要。

##### 简单指数平滑

最简单的指数平滑方法自然称为简单指数平滑 (SES)13。 这种方法适用于没有明显趋势或季节性模式的预测数据。

我们经常想要介于朴素和平均两个极端之间的东西。 例如，将更大的权重附加到最近的观察而不是来自遥远过去的观察可能是明智的。 这正是简单指数平滑背后的概念。 预测是使用加权平均值计算的，其中权重随着观测值来自更远的过去而呈指数下降——最小的权重与最旧的观测值相关联

$\begin{equation}
  \hat{y}_{T+1|T} = \alpha y_T + \alpha(1-\alpha) y_{T-1} + \alpha(1-\alpha)^2 y_{T-2}+ \cdots,   \tag{8.1}
\end{equation}$

其中 0 ≤ α ≤ 1 是平滑参数。 时间 T + 1 的提前一步预测是 y 1 , … , y T 序列中所有观测值的加权平均值。 权重降低的速率由参数 α 控制。

对于介于 0 和 1 之间的任何 α，随着时间的推移，附加到观测值的权重会呈指数下降，因此得名“指数平滑”。 如果 α 很小（即接近于 0），则对来自更远过去的观测值给予更大的权重。 如果 α 很大（即接近于 1），则对最近的观察给予更多的权重。 对于 α = 1 的极端情况，$\hat{y}_{T+1|T}=y_T$ ，并且预测等于朴素预测。

平坦预测 

简单指数平滑具有“平坦”预测函数：$\hat{y}_{T+h|T} = \hat{y}_{T+1|T}=\ell_T, \qquad h=2,3,\dots.$

也就是说，所有预测都采用相同的值，等于最后一个级别的组件。 请记住，这些预测仅适用于时间序列没有趋势或季节性成分的情况。

可以通过最小化 SSE 来估计任何指数平滑方法的未知参数和初始值,其中SSE:$\begin{equation} \text{SSE}=\sum_{t=1}^T(y_t - \hat{y}_{t|t-1})^2=\sum_{t=1}^Te_t^2. \tag{8.2} \end{equation}$

##### 有趋势方法

霍尔特线性趋势法：

Holt (1957) 扩展了简单指数平滑法以允许预测具有趋势的数据。 该方法涉及一个预测方程和两个平滑方程（一个用于水平，一个用于趋势）：

$\begin{align*}  \text{Forecast equation}&& \hat{y}_{t+h|t} &= \ell_{t} + hb_{t} \\  \text{Level equation}   && \ell_{t} &= \alpha y_{t} + (1 - \alpha)(\ell_{t-1} + b_{t-1})\\  \text{Trend equation}   && b_{t}    &= \beta^*(\ell_{t} - \ell_{t-1}) + (1 -\beta^*)b_{t-1}, \end{align*}$

预测函数不再是平坦的而是趋势的。  h 提前预测等于最后估计的水平加上最后估计的趋势值的 h 倍。 因此，预测是 h 的线性函数。

阻尼趋势法:

Holt 的线性方法生成的预测显示未来无限期的恒定趋势（增加或减少）。 经验证据表明，这些方法往往会过度预测，尤其是对于较长的预测范围。 受这一观察的启发，Gardner & McKenzie (1985) 引入了一个参数，该参数在未来的某个时间将趋势“抑制”为平坦线。 包括阻尼趋势的方法已被证明是非常成功的，并且可以说是当许多系列都需要自动预测时最流行的单个方法。算法：

$$\begin{align*}  \hat{y}_{t+h|t} &= \ell_{t} + (\phi+\phi^2 + \dots + \phi^{h})b_{t} \\  \ell_{t} &= \alpha y_{t} + (1 - \alpha)(\ell_{t-1} + \phi b_{t-1})\\  b_{t} &= \beta^*(\ell_{t} - \ell_{t-1}) + (1 -\beta^*)\phi b_{t-1}. \end{align*}$$

实际上， ϕ 很少小于 0.8，因为阻尼对较小的值有很强的影响。 接近 1 的 ϕ 值意味着无法将阻尼模型与非阻尼模型区分开来。 由于这些原因，我们通常将 ϕ 限制为最小值 0.8 和最大值 0.98。

```R
model(
    SES = ETS(value ~ error("A") + trend("N") + season("N")),
    Holt = ETS(value ~ error("A") + trend("A") + season("N")),
    Damped = ETS(value ~ error("A") + trend("Ad") +
                   season("N"))
  )
```

##### 季节性方法

Holt 和 Winters  扩展了 Holt 的方法来捕捉季节性。  Holt-Winters 季节性方法包括预测方程和三个平滑方程——一个用于水平$\ell_t$，一个用于趋势$b_t$，另一个用于季节性分量$s_t$ ，以及相应的平滑参数 α 、 β ∗ 和 γ 。

这种方法有两种变体，它们在季节性成分的性质上有所不同。 **当季节变化在整个系列中大致恒定时，加法方法是首选，而当季节变化与系列的水平成正比时，乘法方法是首选**。 在加法方法中，季节性分量以观测序列的尺度绝对值表示，而在水平方程中，通过减去季节性分量对序列进行季节性调整。 在每一年中，季节性成分加起来大约为零。 使用乘法方法时，季节性成分以相对项（百分比）表示，并通过除以季节性成分对序列进行季节性调整。 在每一年中，季节性分量的总和约为 m 。

加法公式：

$$\begin{align*}  \hat{y}_{t+h|t} &= \ell_{t} + hb_{t} + s_{t+h-m(k+1)} \\  \ell_{t} &= \alpha(y_{t} - s_{t-m}) + (1 - \alpha)(\ell_{t-1} + b_{t-1})\\  b_{t} &= \beta^*(\ell_{t} - \ell_{t-1}) + (1 - \beta^*)b_{t-1}\\  s_{t} &= \gamma (y_{t}-\ell_{t-1}-b_{t-1}) + (1-\gamma)s_{t-m}, \end{align*}$$

乘法公式：

$$\begin{align*}  \hat{y}_{t+h|t} &= (\ell_{t} + hb_{t})s_{t+h-m(k+1)} \\  \ell_{t} &= \alpha \frac{y_{t}}{s_{t-m}} + (1 - \alpha)(\ell_{t-1} + b_{t-1})\\  b_{t} &= \beta^*(\ell_{t}-\ell_{t-1}) + (1 - \beta^*)b_{t-1}                \\  s_{t} &= \gamma \frac{y_{t}}{(\ell_{t-1} + b_{t-1})} + (1 - \gamma)s_{t-m} \end{align*}$$

```R
model(
    additive = ETS(Trips ~ error("A") + trend("A") +
                                                season("A")),
    multiplicative = ETS(Trips ~ error("M") + trend("A") +
                                                season("M"))
  )
```

##### 指数平滑方法分类

指数平滑方法不限于我们目前介绍的那些。 通过考虑趋势和季节性成分组合的变化，可以使用九种指数平滑方法，如表 8.5 所示。 每种方法都由一对字母 (T,S) 标记，定义了“趋势”和“季节性”组件的类型。 例如，(A,M) 是具有加性趋势和乘性季节性的方法；  (Ad ,N) 是有阻尼趋势且无季节性的方法； 等等。

我们不考虑本书中的乘法趋势方法，因为它们往往会产生较差的预测。

表8.5

| Trend Component       | Seasonal Component |            |                  |
| :-------------------- | :----------------- | :--------- | :--------------- |
|                       | N                  | A          | M                |
|                       | (None)             | (Additive) | (Multiplicative) |
| N (None)              | (N,N)              | (N,A)      | (N,M)            |
| A (Additive)          | (A,N)              | (A,A)      | (A,M)            |
| Add (Additive damped) | (Add,N)            | (Add,A)    | (Add,M)          |

##### 不同状态空间

 每个模型都包含一个描述观测数据的测量方程，以及一些描述未观测到的成分或状态（水平、趋势、季节性）如何随时间变化的状态方程。 因此，这些被称为状态空间模型。

对于每种方法，存在两种模型：一种具有加性误差，另一种具有乘性误差。 如果模型使用相同的平滑参数值，则它们生成的点预测是相同的。 然而，它们会产生不同的预测区间。

 我们将每个状态空间模型标记为 ETS( ⋅ , ⋅ , ⋅ ) for (Error, Trend, Seasonal)。 这个标签也可以被认为是指数平滑。 使用与表 8.5 中相同的符号，每个分量的可能性是：Error = { A,M } ，Trend = { N,A,Ad } 和 Seasonal = { N,A,M } 

![img](https://otexts.com/fpp3/figs/statespacemodels-1.png)

##### 估计和模型选择

估计略

ETS 统计框架的一大优势是信息标准可用于模型选择。 前文中介绍的 AIC、AICc 和 BIC 可用于确定哪个 ETS 模型最适合给定的时间序列。

对于 ETS 模型，Akaike 的信息准则 (AIC) 定义为 ：$\text{AIC} = -2\log(L) + 2k$

修正小样本偏差的 AIC (AICc )定义为$$\text{AIC}_{\text{c}} = \text{AIC} + \frac{2k(k+1)}{T-k-1}$$

贝叶斯信息准则 (BIC) 是:$\text{BIC} = \text{AIC} + k[\log(T)-2].$

可能导致数值不稳定性的模型是 ETS(A,N,M)ETS(A,A,M)和ETS(A,Ad ,M)，由于除以状态方程中可能接近零的值。在选择模型时，我们通常不会考虑这些特定的组合。

 当数据严格为正时，具有乘法误差的模型很有用，但当数据包含零或负值时，模型在数值上不稳定。 因此，如果时间序列不是严格为正的，则不会考虑乘法误差模型。 在这种情况下，将仅应用六个完全可加模型。

 ETS() 函数可通过最小化 AICc 来选择模型

#### ARIMA 模型

ARIMA 模型提供了另一种时间序列预测方法。 指数平滑和 ARIMA 模型是时间序列预测中使用最广泛的两种方法，并为该问题提供了补充方法。 指数平滑模型基于对数据趋势和季节性的描述，而 ARIMA 模型旨在描述数据中的自相关。

在介绍 ARIMA 模型之前，我们必须首先讨论平稳性的概念和差分时间序列的技术。

##### 平稳性和差分

平稳时间序列是其统计属性不依赖于观察序列的时间的序列。 因此，具有趋势或季节性的时间序列不是平稳的——趋势和季节性会影响时间序列的价值 在不同的时间。 另一方面，白噪声序列是静止的——你观察它的时间并不重要，它在任何时间点看起来都应该是一样的。

有些情况可能会令人困惑——具有周期性行为（但没有趋势或季节性）的时间序列是平稳的。 这是因为循环的长度不是固定的，所以在我们观察序列之前，我们无法确定循环的波峰和波谷在哪里。

 **一般来说，一个平稳的时间序列在长期没有可预测的模式。 时间图将显示该系列大致水平（尽管可能存在某些循环行为），并具有恒定方差。**

![Which of these series are stationary? (a) Google closing stock price in 2015; (b) Daily change in the Google stock price in 2015; (c) Annual number of strikes in the US; (d) Monthly sales of new one-family houses sold in the US; (e) Annual price of a dozen eggs in the US (constant dollars); (f) Monthly total of pigs slaughtered in Victoria, Australia; (g) Annual total of Canadian Lynx furs traded by the Hudson Bay Company; (h) Quarterly Australian beer production; (i) Monthly Australian gas production.](https://otexts.com/fpp3/fpp_files/figure-html/stationary-1.png) (b) 和 (g) 作为固定序列。

差分：

在图 9.1 中，请注意（a）中 Google 股票价格是非平稳的，但（b）中每日变化是平稳的。 这显示了使非平稳时间序列平稳的一种方法 - 计算连续观察之间的差异。 这称为差分。

对数等变换有助于稳定时间序列的方差。 差分可以通过消除时间序列水平的变化来帮助稳定时间序列的平均值，从而消除（或减少）趋势和季节性。

除了数据的时间图外，ACF 图对于识别非平稳时间序列也很有用。 对于平稳时间序列，ACF 会相对较快地下降到零，而非平稳数据的 ACF 下降缓慢。 此外，对于非平稳数据，$r_1$的值通常很大且为正。

随机游走模型：

差分序列是原始序列中连续观测值之间的变化，可以写成$y'_t = y_t - y_{t-1}.$。

 差分序列将只有 T − 1 个值，因为不可能为第一次观测计算差异$y_1'$。

 当差分序列是白噪声时，原始序列的模型可以写成$y_t - y_{t-1} = \varepsilon_t,$，其中$\varepsilon_t$表示白噪声。 重新排列这会导致“随机游走”模型$y_t = y_{t-1} + \varepsilon_t.$ 。

随机游走模型广泛用于非平稳数据，尤其是金融和经济数据。 随机游走通常具有： 

* 长期明显的上升或下降趋势 
* 突然且不可预测的方向变化。

随机游走模型的预测与上次观察结果相同，因为未来的运动是不可预测的，并且上升或下降的可能性相同。 因此，随机游走模型支持在前文中提到的的朴素预测。

密切相关的模型允许差异具有非零均值。 然后$y_t - y_{t-1} = c + \varepsilon_t\quad\text{or}\quad {y_t = c + y_{t-1} + \varepsilon_t}\: .$

c 的值是连续观察之间变化的平均值。 如果 c 为正，则平均变化是$y_t$值的增加。 因此，$y_t$将趋于向上漂移。 但是，如果 c 为负，则$y_t$将趋于向下漂移。

这是漂移方法背后的模型，也在[简单预测模型](#简单预测模型)中讨论过。

二阶差分：

有时差分数据看起来不是平稳的，可能需要对数据进行第二次差分以获得平稳序列：$\begin{align*}  y''_{t}  &=  y'_{t}  - y'_{t - 1} \\           &= (y_t - y_{t-1}) - (y_{t-1}-y_{t-2})\\           &= y_t - 2y_{t-1} +y_{t-2}. \end{align*}$。
    

 在这种情况下，y ′′ t 将具有 T − 2 个值。 然后，我们将对原始数据的“变化中的变化”进行建模。 **在实践中，几乎没有必要超越二阶差分**。

季节性差异:

季节性差异是观测值与同一季节的前一个观测值之间的差异。 所以 $y'_t = y_t - y_{t-m},$，其中 m = 季节数。 这些也称为“滞后 m 差”，因为我们在 m 个周期滞后后减去观测值。

如果季节性差异数据似乎是白噪声，那么原始数据的合适模型是

 $y_t = y_{t-m}+\varepsilon_t.$

该模型的预测等于相关季节的最后一次观测。 也就是说，该模型给出了前文中介绍的季节性朴素预测。

在选择应用哪些差异时存在一定程度的主观性。 图 9.3 中的季节性差异数据与图 9.4 中的季节性差异数据没有表现出明显不同的行为。 在后一种情况下，我们本可以决定停止使用季节性差异数据，而不是进行额外的一轮差异化。 在前一种情况下，我们本可以认为数据不够平稳并进行额外一轮的差分。 下面讨论了一些正式的差分测试，但在建模过程中总会有一些选择，不同的分析师可能会做出不同的选择。

如果$y'_t = y_t - y_{t-m}$表示季节性差分序列，则两次差分序列为

$$\begin{align*} y''_t &= y'_t - y'_{t-1} \\      &= (y_t - y_{t-m}) - (y_{t-1} - y_{t-m-1}) \\      &= y_t -y_{t-1} - y_{t-m} + y_{t-m-1}\: \end{align*}$$

当应用季节性差分和一阶差分时，先做没有区别——结果是一样的。 但是，如果数据具有很强的季节性模式，我们建议先进行季节性差分，因为结果序列有时是平稳的，不需要进一步的一阶差分。 如果先进行一阶差分，仍然会存在季节性。

请注意，**应用比所需更多的差异会导致时间序列中并不真正存在的虚假动态或自相关。 因此，尽可能少地进行差异以获得平稳序列**。

重要的是，如果使用差分，差异是可解释的。 第一个差异是一次观察和下一次观察之间的变化。 季节性差异是一年与下一年之间的变化。 其他滞后不太可能有太多可解释的意义，应该避免。  

单位根检验 

更客观地确定是否需要差分的一种方法是使用单位根检验。 这些是平稳性的统计假设检验，旨在确定是否需要差分。

详细理论等见[单位根过程](#单位根过程)

有许多单位根检验可用，它们基于不同的假设，可能会导致相互矛盾的答案。 在我们的分析中，我们使用 Kwiatkowski-Phillips-Schmidt-Shin (KPSS) 测试（Kwiatkowski 等，1992）。 在这个测试中，原假设是数据是平稳的，我们寻找原假设为假的证据。 因此，小的 p 值（例如，小于 0.05）表明需要进行差分。 可以使用 unitroot_kpss() 函数计算测试。


##### 自回归模型

在前文介绍的多元回归模型中，我们使用预测变量的线性组合来预测感兴趣的变量。 在自回归模型中，我们使用变量过去值的线性组合来预测感兴趣的变量。 术语自回归表示它是变量对自身的回归。

因此，一个 p 阶自回归模型可以写成$y_{t} = c + \phi_{1}y_{t-1} + \phi_{2}y_{t-2} + \dots + \phi_{p}y_{t-p} + \varepsilon_{t},$ ，其中$\varepsilon_t$是白噪声。 这类似于多元回归，但使用$y_t$的滞后值作为预测变量。 我们将其称为 AR(p) 模型，即 p 阶自回归模型。

自回归模型在处理各种不同的时间序列模式方面非常灵活。  改变参数 ϕ 1 , … , ϕ p 会产生不同的时间序列模式。 误差项 $\varepsilon_t$的方差只会改变序列的尺度，而不是模式。

对于 AR(1) 模型：

* 当 ϕ 1 = 0 且 c = 0 时，y t 等价于白噪声； 
* 当 ϕ 1 = 1 且 c = 0 时，y t 等价于随机游走； 
* 当 ϕ 1 = 1 且 c ≠ 0 时，y t 等价于有漂移的随机游走； 
* 当 ϕ 1 < 0 时，y t 倾向于围绕均值振荡。

我们通常将自回归模型限制为固定数据，在这种情况下，需要对参数值进行一些限制。

* 对于 AR(1) 模型： − 1 < ϕ 1 < 1 。
* 对于 AR(2) 模型： − 1 < ϕ 2 < 1 , ϕ 1 + ϕ 2 < 1 , ϕ 2 − ϕ 1 < 1 。

当 p ≥ 3 时，限制要复杂得多。 在估计模型时，fable 包会处理这些限制。

##### 移动平均模型

移动平均模型不是在回归中使用预测变量的过去值，而是在类似回归的模型中使用过去的预测误差，$y_{t} = c + \varepsilon_t + \theta_{1}\varepsilon_{t-1} + \theta_{2}\varepsilon_{t-2} + \dots + \theta_{q}\varepsilon_{t-q},$

其中$\varepsilon_t$是白噪声。 我们将其称为 MA( q ) 模型，即 q 阶移动平均模型。 当然，我们没有观察到$\varepsilon_t的值，所以它并不是通常意义上的回归。

请注意，可以将$y_t$的每个值视为过去几个预测误差的加权移动平均值（尽管系数之和通常不会为 1）。 但是，不应将移动平均模型与我们在时序分解中讨论的移动平均平滑混淆。**移动平均模型用于预测未来值，而移动平均平滑用于估计过去值的趋势周期**。

MA模型的可逆性约束类似于平稳性约束。

   * 对于 MA(1) 模型：$-1<\theta_1<1$ 。
   * 对于 MA(2) 模型： $-1<\theta_2,1,~\theta_2+\theta_1 >-1,~\theta_1 -\theta_2 < 1$ 。

更复杂的条件适用于 q ≥ 3。 同样，在估计模型时，fable 包将处理这些约束。

##### 非季节性 ARIMA 模型

如果我们将差分与自回归和移动平均模型结合起来，我们就会得到一个非季节性的 ARIMA 模型。  ARIMA 是自回归积分移动平均线的首字母缩写词（在这种情况下，“积分”是差分的反义词）。 完整的模型可以写成:

$\begin{equation}  y'_{t} = c + \phi_{1}y'_{t-1} + \cdots + \phi_{p}y'_{t-p}     + \theta_{1}\varepsilon_{t-1} + \cdots + \theta_{q}\varepsilon_{t-q} + \varepsilon_{t},  \tag{9.1} \end{equation}$

其中$y_t'$是差分序列（它可能已经被差分多次）。 右侧的“预测器”包括 y t 的滞后值和滞后误差。 我们称其为 ARIMA( p , d , q ) 模型，其中

| p=   | order of the autoregressive part;      |
| ---- | -------------------------------------- |
| d=   | degree of first differencing involved; |
| q=   | order of the moving average part.      |

用于自回归和移动平均模型的相同平稳性和可逆性条件也适用于 ARIMA 模型。我们已经讨论过的许多模型都是 ARIMA 模型的特例，如图所示:

| White noise            | ARIMA(0,0,0) with no constant |
| ---------------------- | ----------------------------- |
| Random walk            | ARIMA(0,1,0) with no constant |
| Random walk with drift | ARIMA(0,1,0) with a constant  |
| Autoregression         | ARIMA(p,0,0)                  |
| Moving average         | ARIMA(0,0,q)                  |

$\begin{equation}   \begin{array}{c c c c}    (1-\phi_1B - \cdots - \phi_p B^p) & (1-B)^d y_{t} &= &c + (1 + \theta_1 B + \cdots + \theta_q B^q)\varepsilon_t\\    {\uparrow} & {\uparrow} & &{\uparrow}\\    \text{AR($p$)} & \text{$d$ differences} & & \text{MA($q$)}\\  \end{array} \end{equation}$

例子：

```R
fit <- global_economy %>%
  filter(Code == "EGY") %>%
  model(ARIMA(Exports))
report(fit)
```

了解 ARIMA 模型:

 ARIMA() 函数很有用，但任何自动化的东西都可能有点危险，即使您依赖自动程序为您选择模型，了解模型的行为也是值得的。

常数 c 对从这些模型获得的长期预测有重要影响。

* 如果 c = 0 和 d = 0 ，长期预测将为零。
* 如果 c = 0 和 d = 1 ，长期预测将变为非零常数。
* 如果 c = 0 和 d = 2 ，长期预测将遵循一条直线。
* 如果 c ≠ 0 且 d = 0 ，则长期预测将趋向于数据的均值。
* 如果 c ≠ 0 且 d = 1 ，则长期预测将遵循一条直线。
* 如果 c ≠ 0 且 d = 2 ，长期预测将遵循二次趋势。  （不推荐这样做，fable也不允许。）

d 的值也对预测区间有影响——d 的值越高，预测区间的大小增加得越快。 对于 d = 0 ，长期预测的标准差会趋向于历史数据的标准差，因此预测区间将基本相同。

如果数据显示循环，p 的值很重要。 要获得循环预测，必须使 p ≥ 2 以及参数的一些附加条件。 对于 AR(2) 模型，如果$\phi_1^2+4\phi_2<0$，就会出现循环行为。 在这种情况下，周期的平均周期为$\dfrac{2\pi}{\text{arc cos}(-\phi_1(1-\phi_2)/(4\phi_2))}.$

ACF 和 PACF 图:

通常无法仅从时间图中判断 p 和 q 的哪些值适合数据。 但是，有时可以使用 ACF 图和密切相关的 PACF 图来确定 p 和 q 的适当值。

回想一下，ACF 图显示了测量 y t 和 y t − k 之间关系的自相关性，其中 k 的不同值。 现在如果 y t 和 y t − 1 是相关的，那么 y t − 1 和 y t − 2 也一定是相关的。 然而，那么y t 和y t − 2 可能是相关的，仅仅因为它们都与y t − 1 相关，而不是因为y t − 2 中包含可用于预测y t 的任何新信息。

为了克服这个问题，我们可以使用偏自相关。 在去除滞后 1、2、3、…、k − 1 的影响后，它们测量 y t 和 y t − k 之间的关系。 所以第一个偏自相关与第一个自相关相同，因为它们之间没有任何东西可以去除。 每个偏自相关都可以估计为自回归模型中的最后一个系数。 具体而言，第 k 个偏自相关系数$\alpha_k$等于 AR( k ) 模型中$\phi k$的估计值。 在实践中，有比拟合所有这些自回归更有效的计算$\alpha_k$的算法，但它们给出相同的结果。偏自相关具有与普通自相关相同的 ± 1.96 / √ T 临界值

在一个命令中生成时间图、ACF 图和 PACF 图的一种便捷方法是使用 gg_tsdisplay()函数和 plot_type = "partial"。

如果数据来自 ARIMA( p , d ,0) 或 ARIMA(0, d , q ) 模型，则 ACF 和 PACF 图有助于确定 p 或 q 的值。 如果 p 和 q 均为正值，则绘图无助于找到合适的 p 和 q 值。

如果差分数据的 ACF 和 PACF 图显示以下模式，则数据可能遵循 ARIMA( p , d ,0) 模型：

* ACF 呈指数衰减或正弦曲线； 
* 在 PACF 的滞后 p 处有一个显着的尖峰，但没有超过滞后 p 。

如果差分数据的 ACF 和 PACF 图显示以下模式，则数据可能遵循 ARIMA(0, d , q ) 模型：

* PACF 呈指数衰减或正弦； 
* 在 ACF 中的滞后 q 处有一个显着的尖峰，但没有超出滞后 q 。

![ACF of Egyptian exports.](https://otexts.com/fpp3/fpp_files/figure-html/egyptacf-1.png)

![PACF of Egyptian exports.](https://otexts.com/fpp3/fpp_files/figure-html/egyptpacf-1.png)

在图 9.9 中，我们看到 ACF 中有一个衰减的正弦模式，在图 9.10 中，PACF 显示了滞后 4 处的最后一个显着峰值。这就是您对 ARIMA(4,0,0) 模型的期望。

我们还可以指定 ARIMA() 可以搜索的 pdq() 的特定值。 例如，要找到具有 p ∈ { 1 , 2 , 3 } , q ∈ { 0 , 1 , 2 } 和 d = 1 的最佳 ARIMA 模型，您可以使用 ARIMA(y ~ pdq(p=1:3, d  =1, q=0:2))。

##### 估计和顺序选择

最大似然估计:

一旦确定了模型阶数（即 p 、 d 和 q 的值），我们需要估计参数 c 、 ϕ 1 、... 、 ϕ p 、 θ 1 、... 、 θ q 。 当fable估计 ARIMA 模型时，它使用最大似然估计 (MLE)。 该技术找到使获得我们观察到的数据的概率最大化的参数值。 对于 ARIMA 模型，MLE 类似于通过最小化$\sum_{t=1}^T\varepsilon_t^2.$获得的最小二乘估计。
     

（对于第 7 章中考虑的回归模型，MLE 给出与最小二乘估计完全相同的参数估计。）请注意，ARIMA 模型的估计比回归模型复杂得多，并且不同的软件会因为使用不同的方法而给出略有不同的答案、估计和不同的优化算法。

在实践中，fable 包会报告数据的对数似然值； 即观测数据来自估计模型的概率的对数。 对于给定的 p 、 d 和 q 值，ARIMA() 将在寻找参数估计值时尝试最大化对数似然。

信息标准：

Akaike 的信息准则 (AIC) 可用于选择回归预测变量，也可用于确定 ARIMA 模型的阶数。 它可以写成 $\text{AIC} = -2 \log(L) + 2(p+q+k+1),$，其中 L 是数据的似然性，如果 c ≠ 0，则 k = 1，如果 c = 0，则 k = 0。 请注意，括号中的最后一项是模型中的参数数量（包括 $\sigma^2$ ，残差的方差）。

对于 ARIMA 模型，修正后的 AIC 可以写为:$\text{AICc} = \text{AIC} + \frac{2(p+q+k+1)(p+q+k+2)}{T-p-q-k-2},$

贝叶斯信息准则可以写成$\text{BIC} = \text{AIC} + [\log(T)-2](p+q+k+1).$

通过最小化 AIC、AICc 或 BIC 可以获得好的模型。 我们更喜欢使用 AICc。

重要的是要注意，这些信息标准往往不是选择模型的适当差分顺序 (d) 的良好指南，而仅适用于选择 p 和 q 的值。 **这是因为差分改变了计算似然的数据，使得具有不同差分阶数的模型之间的 AIC 值不具有可比性**。 所以我们需要使用一些其他的方法来选择 d ，然后我们可以使用 AICc 来选择 p 和 q 。

##### ARIMA建模

将 ARIMA 模型拟合到一组（非季节性）时间序列数据时，以下过程提供了一种有用的通用方法。

1. 绘制数据并识别任何不寻常的观察结果。
2. 如有必要，转换数据（使用 Box-Cox 转换）以稳定方差。
3. 如果数据是非平稳的，则取数据的一阶差分，直到数据平稳。
4. 检查 ACF/PACF：ARIMA( p , d , 0 ) 或 ARIMA( 0 , d , q ) 模型是否合适？
5. 尝试您选择的模型，并使用 AICc 搜索更好的模型。
6. 通过绘制残差的 ACF 并对残差进行组合检验来检查所选模型的残差。 如果它们看起来不像白噪声，请尝试修改模型。
7. 一旦残差看起来像白噪声，计算预测。
     Hyndman-Khandakar 算法（自动程序）只处理步骤 3-5。 因此，即使您使用它，您仍然需要自己处理其他步骤。

下图总结了该过程：

![General process for forecasting using an ARIMA model.](https://otexts.com/fpp3/figs/arimaflowchart.png)

注：

在非平稳 ARIMA 模型中包含一个常数等效于在预测中引入 d 阶多项式趋势。  （如果省略常数，则预测包括阶数为 d − 1 的多项式趋势。）当 d = 0 时，我们有一个特殊情况，即 μ 是 y t 的平均值。


 默认情况下，ARIMA() 函数将自动确定是否应包含常量。 对于 d = 0 或 d = 1 ，如果它提高了 AICc 值，将包括一个常数。 如果 d > 1，则始终忽略常数，因为在预测时二次或更高阶趋势特别危险。


 可以通过在模型公式中包含 0 或 1 来指定常量（如 lm() 中的截距）。 例如，要自动选择具有常量的 ARIMA 模型，您可以使用 ARIMA(y ~ 1 + ...)。 类似地，可以使用 ARIMA(y ~ 0 + ...) 排除常数。

##### 预测

ARIMA 模型的预测区间基于残差不相关且正态分布的假设。 如果这些假设中的任何一个不成立，则预测区间可能不正确。 因此，在生成预测区间之前，始终绘制残差的 ACF 和直方图以检查假设。

如果残差不相关但不是正态分布，则可以获得自举区间，如第 5.5 节所述。 这可以通过简单地在 forecast() 函数中添加 bootstrap=TRUE 来轻松实现。

 一般来说，ARIMA 模型的预测区间随着预测范围的增加而增加。 对于平稳模型（即 d = 0 ），它们会收敛，因此长期范围的预测区间基本上是相同的。 对于 d ≥ 1 ，预测区间将继续增长到未来。

与大多数预测区间计算一样，基于 ARIMA 的区间往往太窄。 发生这种情况是因为只考虑了误差的变化。 参数估计值和模型顺序也存在变化，这些变化未包括在计算中。 此外，计算假设已建模的历史模式将持续到预测期。

##### 季节性 ARIMA 模型

到目前为止，我们已经将注意力限制在非季节性数据和非季节性 ARIMA 模型上。 但是，ARIMA 模型还能够对范围广泛的季节性数据进行建模。

季节性 ARIMA 模型是通过在我们目前看到的 ARIMA 模型中包含额外的季节性项而形成的。 它是这样写的：



其中 m = 季节性周期（例如，每年的观测次数）。 我们对模型的季节性部分使用大写表示法，对模型的非季节性部分使用小写表示法。

 模型的季节性部分由与模型的非季节性组件相似的项组成，但涉及季节性周期的回移。 例如，ARIMA(1,1,1)(1,1,1)4 模型（没有常数）用于季度数据（ m = 4 ），可以写成$(1 - \phi_{1}B)~(1 - \Phi_{1}B^{4}) (1 - B) (1 - B^{4})y_{t} =  (1 + \theta_{1}B)~ (1 + \Theta_{1}B^{4})\varepsilon_{t}.$

ACF/PACF:

AR 或 MA 模型的季节性部分将在 PACF 和 ACF 的季节性滞后中看到。 例如，ARIMA(0,0,0)(0,0,1) 12 模型将显示： ACF 在滞后 12 处出现尖峰，但没有其他显着尖峰；  PACF 的季节性滞后呈指数衰减（即滞后 12、24、36……）。

类似地，ARIMA(0,0,0)(1,0,0) 12 模型将显示： ACF 季节性滞后的指数衰减；  PACF 中滞后 12 的单个显着峰值。

在考虑季节性 ARIMA 模型的适当季节性orders时，应将**注意力限制在季节性滞后上**。

建模过程与非季节性数据几乎相同，只是我们需要选择季节性 AR 和 MA 项以及模型的非季节性组件。 这个过程最好通过例子来说明。

例子：

我们将使用 2000 年 1 月至 2019 年 9 月的美国休闲和酒店业月度就业数据来描述季节性 ARIMA 建模，

```R
leisure <- us_employment %>%
  filter(Title == "Leisure and Hospitality",
         year(Month) > 2000) %>%
  mutate(Employed = Employed/1000) %>%
  select(Month, Employed)
autoplot(leisure, Employed) +
  labs(title = "US employment: leisure and hospitality",
       y="Number of people (millions)")
```

![Monthly US leisure and hospitality employment, 2000-2019.](https://otexts.com/fpp3/fpp_files/figure-html/usemployment1-1.png)

数据显然是非平稳的，具有很强的季节性和非线性趋势，所以我们首先取季节性差异。 

```R
leisure %>%
  gg_tsdisplay(difference(Employed, 12),
               plot_type='partial', lag=36) +
  labs(title="Seasonally differenced", y="")
```

这些显然也是非平稳的，因此我们在图 9.20 中进一步进行第一个差异。

```R
leisure %>%
  gg_tsdisplay(difference(Employed, 12) %>% difference(),
               plot_type='partial', lag=36) +
  labs(title = "Double differenced", y="")
```

![Double differenced Monthly US leisure and hospitality employment.](https://otexts.com/fpp3/fpp_files/figure-html/usemployment3-1.png)

我们现在的目标是根据图 9.20 所示的 ACF 和 PACF 找到合适的 ARIMA 模型。  ACF 滞后 2 处的显着峰值表明存在非季节性 MA(2) 分量。  ACF 滞后 12 处的显着峰值表明存在季节性 MA(1) 分量。 因此，我们从 ARIMA(0,1,2)(0,1,1) 12 模型开始，指示一阶差分、季节性差异以及非季节性 MA(2) 和季节性 MA(1) 分量。 如果我们从 PACF 开始，我们可能已经选择了 ARIMA(2,1,0)(0,1,1) 12 模型——使用 PACF 选择模型的非季节性部分，使用 ACF 选择 模型的季节性部分。 

我们还将包括一个自动选择的模型。 通过设置 stepwise=FALSE 和 approximation=FALSE，我们让 R 更加努力地找到一个好的模型。 这需要更长的时间，但只有一个系列要建模，因此花费的额外时间不是问题。

```R
fit <- leisure %>%
  model(
    arima012011 = ARIMA(Employed ~ pdq(0,1,2) + PDQ(0,1,1)),
    arima210011 = ARIMA(Employed ~ pdq(2,1,0) + PDQ(0,1,1)),
    auto = ARIMA(Employed, stepwise = FALSE, approx = FALSE)
  )
fit %>% pivot_longer(everything(), names_to = "Model name",
                     values_to = "Orders")
glance(fit) %>% arrange(AICc) %>% select(.model:BIC)
```

可以肯定的是，我们使用了 Ljung-Box 测试，它具有很大的 p 值，确认残差类似于白噪声。 请注意，**替代模型也通过了此测试**。

```R
augment(fit) %>% features(.innov, ljung_box, lag=24, dof=4)
forecast(fit, h=36) %>%
  filter(.model=='auto') %>%
  autoplot(leisure) +
  labs(title = "US employment: leisure and hospitality",
       y="Number of people (millions)")
```

注意：

当使用 AICc 值比较模型时，重要的是所有模型都具有相同的差分阶数。 然而，当使用测试集比较模型时，预测是如何产生的并不重要——比较总是有效的。 因此，在上表中，我们可以包括一些仅具有季节性差异的模型和一些具有一阶差分和季节性差分的模型，而在包含 AICc 值的较早表中，我们仅比较了具有季节性差异但没有一阶差分的模型。

 这里考虑的模型都没有通过所有的残差测试。 在实践中，我们通常会使用我们能找到的最好的模型，即使它没有通过所有的测试。

##### ARIMA vs ETS

普遍认为 ARIMA 模型比指数平滑更通用。 虽然线性指数平滑模型都是 ARIMA 模型的特例，但非线性指数平滑模型没有等效的 ARIMA 模型。 另一方面，也有许多没有指数平滑对应项的 ARIMA 模型。 特别是，所有 ETS 模型都是非平稳的，而一些 ARIMA 模型是平稳的。 图 9.27 显示了两个模型类之间的重叠。
![The ETS and ARIMA model classes overlap with the additive ETS models having equivalent ARIMA forms.](https://otexts.com/fpp3/fpp_files/figure-html/venn-1.png)

具有季节性或非阻尼趋势或两者兼有的 ETS 模型有两个单位根（即，它们需要两个差分水平才能使其平稳）。 所有其他 ETS 模型都有一个单位根（它们需要一级差分才能使其平稳）。

**AICc 可用于在同一类中的模型之间进行选择**。 例如，我们可以使用它在候选 ARIMA 模型之间选择 ARIMA 模型或在候选 ETS 模型之间选择 ETS 模型。 但是，它不能用于比较 ETS 和 ARIMA 模型，因为它们属于不同的模型类，并且可能性的计算方式不同。 下面的示例演示了在这些模型类之间进行选择。

