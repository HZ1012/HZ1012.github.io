---
layout:     post                    # 使用的布局（不需要改）
title:      时间序列（1）            # 标题 
# subtitle:   《Forecasting: Principles and Practice》中文整理 #副标题
date:       2022-02-24              # 时间
author:     HZ                      # 作者
header-img: img/time series.jpg    #这篇文章标题背景图片
catalog: true                       # 是否归档
tags:                               #标签
    - 统计学习
    - R应用
---

### 前言
时间序列分析是统计学习中的重要分支，在商业分析、数据挖掘中具有重要作用。R语言作为强大的数据分析工具在时间序列方面也具有其过人之处。但现有中文教材在R实践时间序列方面仍过于老旧。
《Forecasting: Principles and Practice》（Rob J Hyndman and George Athanasopoulos）是讲解时间序列并基于R实现的强大有用书籍，现已更新到第三版，但是中文版仍只有第二版，笔者于2020年暑期阅览该书第三版，提炼并总结了该书中的重要知识翻译出来。
另一方面，在金融时间序列分析问题中需要掌握到一些更深的知识，笔者适度补充《金融时间序列分析》（李东风）中部分章节知识，希望为各位同仁提供更方便的学习途径。

### 时间序列

#### tssibble 简短使用指南

tsibble 包将 tidyverse 扩展到时间数据。 建立在 tibble 之上的 tsibble（或 tbl_ts）是一个面向数据和模型的对象。 与 R 中传统的时间序列对象（例如 ts、zoo 和 xts）相比，tsibble 保留了时间索引作为基本数据列，并使异构数据结构成为可能。 除了类似 tibble 的表示之外，还引入了由单个或多个变量组成的键，以随着时间的推移唯一地标识观察单位（索引）。  tsibble 包旨在管理时态数据并在流畅的工作流程中完成分析。

上下文语义：索引和键

tsibble() 创建一个 tsibble 对象，而 as_tsibble() 是一种 S3 方法，用于将其他对象强制转换为 tsibble。 向量/矩阵作为基础的对象，例如 ts 和 mts，可以使用 as_tsibble() 自动转换为 tsibble，无需任何规范。 如果它是一个 tibble 或数据帧， as_tsibble() 需要更多的设置来声明索引和关键变量。

nycflights13 包中包含的天气数据包含 2013 年纽约市三个站点（即 JFK、LGA 和 EWR）的每小时气象记录（如温度、湿度和降水）。 由于 time_hour 是唯一涉及时间戳的列，因此 as_tsibble() 将其默认为索引变量； 或者，可以通过参数 index = time_hour 指定索引以禁用详细消息。

除了索引，tsibble 需要“key”，它定义了随时间测量的主题或个人。 在这个例子中，原始变量是标识符，它被传递给 as_tsibble() 中的参数键。 每个观察都应由有效 tsibble 中的索引和键唯一标识。 其他——温度、湿度和降水——被称为测量变量。 创建 tsibble 时，将首先对键进行排序，然后是从过去到最近排列时间。

根据相应的时间表示自动获得一个间隔：

- `integer`/`numeric`/`ordered`: either “unit” or “year” (`Y`)
- `yearquarter`/`yearqtr`: “quarter” (`Q`)
- `yearmonth`/`yearmon`: “month” (`M`)
- `yearweek`: “week” (`W`)
- `Date`: “day” (`D`)
- `difftime`: “week” (`W`), “day” (D), “hour” (`h`), “minute” (`m`), “second” (`s`)
- `POSIXct`/`hms`: “hour” (`h`), “minute” (`m`), “second” (`s`), “millisecond” (`us`), “microsecond” (`ms`)
- `nanotime`: “nanosecond” (`ns`)

也就是说，每月间隔的 tsibble 期望索引列中的 `yearmonth`/`yearmon` 类。  `Date` 和 `POSIXct` 都不提供每月的 tsibble。

 打印显示以数据为中心并提供上下文信息，例如数据维度、时间间隔和基于时间的单位数。 上面显示了 `weather_tsbl` 的一小时间隔（`[1h]`）和作为键的 `origin [3]` 以及表中的三个时间序列。

数据管道

这种整洁的数据表示最自然地支持将数据操作视为构建块，形成基于时间的上下文中“数据管道”的一部分。 熟悉 tidyverse 的用户会发现执行常见的时间分析任务更容易。 例如， index_by() 在时间上下文中是 group_by() 的对应物，但它只对时间索引进行分组。  index_by() + summarise() 用于总结每个站点的每日高点和低点。 结果，索引从索引 time_hour 更新为间隔一天的日期； 为每日最高和最低温度创建和计算两个新变量。

不规则的时间间隔

请注意，tsibble 可以根据其时间表示（参见 ?tsibble）很好地处理从几秒到几年的规则间隔时间数据。 默认情况下，选项常规在 as_tsibble() 中设置为 TRUE。 将regular 指定为FALSE 可为以不规则时间间隔收集的数据创建tsibble。 下面显示了纽约航班的预定日期时间：

#### 基础知识

时间序列模式：

##### 趋势：

当数据长期增加或减少时，存在趋势。它不必是线性的。有时我们会将趋势称为“改变方向”，当它可能从增加趋势变为减少趋势时。图2.2显示了抗糖尿病药物销售数据的趋势。

季节性：

当时间序列受到季节性因素（如一年中的时间或一周中的某一天）的影响时，就会出现季节性模式。季节性总是一个固定且已知的周期。抗糖尿病药物的月销售额（图2.2）显示了季节性，部分原因是日历年末药物成本的变化。

周期性：当数据呈现出非固定频率的上升和下降时，发生周期性。这些波动通常是由经济状况引起的，通常与“商业周期”有关。这些波动的持续时间通常至少为2年。

许多人把周期性行为和季节性行为混淆起来，但它们实际上是完全不同的。如果波动不是固定频率的，那么它们是周期性的；如果频率是不变的，并且与日历的某些方面相关，那么模式是季节性的。一般来说，周期的平均长度比季节性模式的长度长，周期的大小往往比季节性模式的大小变化更大。

许多时间序列包括趋势、周期和季节性。在选择预测方法时，我们首先需要识别数据中的时间序列模式，然后选择能够正确捕获模式的方法。

##### 自相关：

ACF()

正如相关性衡量两个变量之间线性关系的程度一样，自相关衡量时间序列滞后值之间的线性关系。

有几个自相关系数，对应于滞后图中的每个面板。 例如，$r_{1}$ 测量$y_{t}$和$y_{t-1}$ 之间的关系，$r_{2}$ 测量$y_{t}$和$y_{t-2}$ 之间的关系，依此类推,$r_{k}$的值可以写为

​                                              $$r_{k} = \frac{\sum\limits_{t=k+1}^T (y_{t}-\bar{y})(y_{t-k}-\bar{y})} {\sum\limits_{t=1}^T (y_{t}-\bar{y})^2}$$

当数据具有趋势时，小滞后的自相关往往较大且为正，因为时间上邻近的观测值的值也邻近。 因此，趋势时间序列的 ACF 往往具有正值，随着滞后的增加而缓慢减小

当数据是季节性的时，季节性滞后（季节性周期的倍数）的自相关将大于其他滞后

当数据既是趋势数据又是季节性数据时，您会看到这些影响的组合。 图 中绘制的 a10 数据显示了趋势和季节性。 其 ACF 如图 2.21 所示。 随着滞后时间的增加，ACF 的缓慢下降是由于趋势，而“扇贝”形状是由于季节性。

![ACF of monthly Australian antidiabetic drug sales.](https://otexts.com/fpp3/fpp_files/figure-html/acfa10-1.png)

##### 白噪声：

不显示自相关的时间序列称为白噪声

![Autocorrelation function for the white noise series.](https://otexts.com/fpp3/fpp_files/figure-html/wnoiseacf-1.png)

对于白噪声序列，我们期望每个自相关接近于零。 当然，它们不会完全等于零，因为存在一些随机变化。 对于白噪声序列，我们预计 ACF 中 95% 的尖峰位于 $\pm 2/\sqrt{T}$内，其中 T 是时间序列的长度。 通常将这些边界绘制在 ACF 的图形上（上面的蓝色虚线）。 如果一个或多个大尖峰在这些范围之外，或者超过 5% 的尖峰在这些范围之外，则该系列可能不是白噪声



#### 时序分解

时间序列数据可以表现出多种模式，将时间序列分成几个部分通常很有帮助，每个部分代表一个基础模式类别。

前文我们讨论了三种类型的时间序列模式：趋势、季节性和周期。 当我们将时间序列分解为组件时，我们通常将趋势和周期合并为一个趋势周期组件（为简单起见，通常简称为趋势）。 因此，我们可以将时间序列视为由三个部分组成：**趋势周期部分、季节性部分和剩余部分**（包含时间序列中的任何其他部分）。 对于某些时间序列（例如，那些至少每天观察到的时间序列），对应于不同的季节周期，可能有不止一个季节成分。

##### 调整和转换

调整历史数据通常可以得到更简单的时间序列。 在这里，我们处理四种调整：日历调整、人口调整、通货膨胀调整和数学变换。 这些调整和转换的目的是**通过移除已知的变异源或使整个数据集的模式更加一致来简化历史数据中的模式**。 更简单的模式通常更容易建模并导致更准确的预测。

日历调整:

在季节性数据中看到的一些变化可能是由于简单的日历效应。 在这种情况下，在进行任何进一步分析之前去除变异通常要容易得多。

 例如:如果您正在研究零售店的每月总销售额，那么除了一年中的季节性变化之外，由于每个月的交易日数不同，月份之间也会存在差异。 通过计算每个月每个交易日的平均销售额，而不是当月的总销售额，很容易消除这种变化。 然后我们有效地消除了日历变化。

人口调整:

任何受人口变化影响的数据都可以调整为人均数据。 也就是说，考虑每人（或每千人，或每百万人）的数据而不是总数。 

例如，如果您正在研究一段时间内特定区域的医院床位数量，如果您通过考虑每千人的床位数量来消除人口变化的影响，则结果会更容易解释。 然后您可以查看床位数量是否真正增加，或者增加是否完全是由于人口增加。 床位总数可能增加，但每千人床位数量减少。 当人口增长快于病床数量时，就会发生这种情况。**对于大多数受人口变化影响的数据，最好使用人均数据而不是总数**。

通货膨胀调整:

受货币价值影响的数据最好在建模前进行调整。 例如，由于通货膨胀，新房的平均成本在过去几十年中会增加。 今年 20 万美元的房子和 20 年前 20 万美元的房子不一样。 出于这个原因，通常会调整金融时间序列，以便所有价值都以特定年份的美元价值表示。 例如，房价数据可能以 2000 美元表示。

为了进行这些调整，使用了价格指数。 如果$z_{t}$表示价格指数，$y_{t}$表示$t$年的原始房价，则$x_{t} = y_{t}/z_{t} * z_{2000}$给出了 2000 年美元价值的调整后的房价。 价格指数通常由政府机构构建。 对于消费品，常见的价格指数是消费者价格指数（CPI）。

数学变换：

如果数据显示随序列水平增加或减少的变化，则转换可能很有用。 例如，对数变换通常很有用。 如果我们将原始观测值表示为$y_{1},\dots,y_{T}$，将变换后的观测值表示为$w_{1}, \dots, w_{T}$，那么$ w_ {t} = log ( y _{t} ) $。 对数很有用，因为它们是可解释的：对数值的变化是原始尺度上的相对（或百分比）变化。 因此，如果使用对数基数10，那么对数刻度上的增加1对应于原始刻度上的 10 乘法。 如果原始系列的任何值为零或负数，则对数是不可能的。

有时也使用其他转换（尽管它们不太容易解释）。 例如，可以使用平方根和立方根。 这些被称为幂变换，因为它们可以写成$w_{t} = y_{t}^p$的形式。

一个有用的变换族，包括对数和幂变换，是 Box-Cox 变换族 (Box & Cox, 1964)，它依赖于参数 λ，定义如下：

​                           $$\begin{equation}  w_t  =    \begin{cases}      \log(y_t) & \text{if $\lambda=0$};  \\      (\text{sign}(y_t)|y_t|^\lambda-1)/\lambda & \text{otherwise}.    \end{cases}    \end{equation}$$

一个好的 λ 值可以使整个系列的季节性变化的大小大致相同，guerrero 特征（Guerrero，1993）可用于为您选择 lambda 值 下图选择 λ = 0.12

![image-20210820204858624](数模整理.assets/image-20210820204858624.png)

features()

##### 时间序列组件

如果我们假设一个加法分解，那么我们可以写：$y_{t} = S_{t} + T_{t} + R_t$

其中 y t 是数据，S t 是季节性分量，T t 是趋势周期分量，R t 是剩余分量，均在 t 期间。 或者，乘法分解将写为：$y_{t} = S_{t} \times T_{t} \times R_t.$

如果季节性波动的幅度或趋势周期周围的变化不随时间序列的水平而变化，则加法分解是最合适的。 当季节性模式的变化或趋势周期周围的变化似乎与时间序列的水平成正比时，乘法分解更合适。 乘法分解在经济时间序列中很常见。

使用乘法分解的替代方法是首先转换数据，直到序列中的变化随着时间的推移看起来稳定，然后使用加法分解。 当使用对数变换时，这等效于使用乘法分解，因为:

$y_{t} = S_{t} \times T_{t} \times R_t \quad\text{is equivalent to}\quad  \log y_{t} = \log S_{t} + \log T_{t} + \log R_t.$

季节性调整数据：

如果从原始数据中去除季节性成分，则结果值就是“季节性调整”数据。

 对于加法分解，季节性调整数据由$y_{t}-S_{t}$给出，对于乘法数据，使用$ y _{t} / S_{t} $获得季节性调整值。

如果季节性变化不是主要关注点，则季节性调整序列可能有用。 例如，月度失业数据通常会进行季节性调整，以突出由于经济基本状态而不是季节性变化引起的变化。 离校生找工作造成的失业增加是季节性变化的，而经济衰退造成的失业增加是非季节性的。 大多数研究失业数据的经济分析师对非季节性变化更感兴趣。 **因此，就业数据（以及许多其他经济系列）通常会进行季节性调整**。

注：季节性调整的系列包含剩余部分以及趋势周期。 因此，它们并不“平稳”，“衰退”或“上涨”可能会产生误导。 **如果目的是寻找系列中的转折点，并解释方向的任何变化，那么最好使用趋势周期组件而不是季节性调整数据**。

##### 经典分解

经典的分解方法起源于 1920 年代。 这是一个相对简单的过程，是大多数其他时间序列分解方法的起点。 有两种形式的经典分解：加法分解和乘法分解。 下面描述了具有季节性周期 m 的时间序列（例如，对于季度数据，m = 4，对于每月数据，m = 12，对于具有每周模式的每日数据，m = 7）。

在经典分解中，**假设季节性成分每年都是恒定的**。 对于乘性季节性，构成季节性分量的 m 值有时称为“季节性指数”。

加法分解:

步骤 1 如果 m 是偶数，则使用 2 × m -MA 计算趋势周期分量 $\hat{T}_t$。 如果 m 是奇数，则使用 m -MA 计算趋势周期分量$\hat{T}_t$。

步骤 2 计算去趋势序列：$y_t - \hat{T}_t$。

步骤 3 要估计每个季节的季节性成分，只需平均该季节的去趋势值。 

例如，对于月度数据，3 月份的季节性成分是数据中所有去趋势的 3 月份值的平均值。 然后调整这些季节性分量值以确保它们加起来为零。 季节性成分是通过将这些月度值串在一起获得的，然后为每一年的数据复制序列。 这给出了$\hat{S}_t$。

步骤 4 通过减去估计的季节性和趋势周期分量来计算剩余分量：$\hat{R}_t = y_t - \hat{T}_t - \hat{S}_t$

乘法分解：

经典的乘法分解与此类似，只是减法被除法代替。

评论：

虽然经典分解仍然被广泛使用，但不推荐使用，因为现在有几种更好的方法。 下面总结了经典分解的一些问题：

* 对于前几个和最后几个观察，趋势周期的估计是不可用的。 例如，如果 m = 12 ，则没有前六个或最后六个观测值的趋势周期估计。 因此，也没有对相同时间段的剩余部分进行估计。
* 趋势周期估计倾向于过度平滑数据中的快速上升和下降。
* 经典分解方法假设季节性成分年复一年地重复。 对于许多系列，这是一个合理的假设，但对于一些较长的系列则不然。 例如，随着空调变得更加普及，电力需求模式随着时间的推移而发生了变化。 在许多地方，几十年前的季节性使用模式在冬季（由于供暖）需求最大，而当前的季节性模式在夏季（由于空调）需求最大。 经典分解方法无法捕捉这些随时间的季节性变化。
* 有时，少数时期的时间序列值可能特别不寻常。 例如，每月的航空客运量可能受到劳资纠纷的影响，使纠纷期间的客流量与平时不同。 经典方法对这些异常值并不稳健。

##### 官方统计机构方法

官方统计机构（如美国人口普查局和澳大利亚统计局）负责大量官方经济和社会时间序列。 这些机构制定了自己的分解程序，用于季节性调整。 他们中的大多数使用 X-11 方法的变体，或 SEATS 方法，或两者的组合。

**这些方法专门设计用于处理季度和月度数据**，这是官方统计机构处理的最常见的系列。 他们不会处理其他类型的季节性，例如每日数据、每小时数据或每周数据。 我们将使用这组方法的最新实现，称为“X-13ARIMA-SEATS”。

X-11:

X-11 方法起源于美国人口普查局，并由加拿大统计局进一步发展。 它基于经典分解，但包括许多额外的步骤和功能，以克服上一节中讨论的经典分解的缺点。 特别是，趋势周期估计可用于包括终点在内的所有观察，并且允许季节性成分随时间缓慢变化。

  X-11 还处理交易日变化、假期影响和已知预测因素的影响。 有加法和乘法分解的方法。 该过程是完全自动的，并且往往对时间序列中的异常值和水平变化具有高度鲁棒性。  X-11 方法的详细信息在 Dagum & Bianconcini (2016) 中有描述。

SEATS：

“SEATS”代表“ARIMA 时间序列中的季节性提取”。 这个程序是在西班牙银行开发的，现在被世界各地的政府机构广泛使用。 Dagum & Bianconcini (2016) 中提供了对该方法的完整讨论。

`seasonal` package 

##### STL分解

STL 是一种用于分解时间序列的通用且稳健的方法。  STL 是“使用 Loess 进行季节和趋势分解”的首字母缩写，而 loess 是一种估计非线性关系的方法。  STL 方法是由 R. B. Cleveland 等人开发的(1990)。

STL 与经典分解以及 SEATS 和 X-11 方法相比有几个优点： 

* 与 SEATS 和 X-11 不同，STL 将处理任何类型的季节性，而不仅仅是月度和季度数据。
* 季节性分量可以随时间变化，变化的速度可以由用户控制。
* 用户也可以控制趋势周期的平滑度。
* 它可以对异常值具有鲁棒性（即，用户可以指定鲁棒分解），以便偶尔出现的异常观察不会影响趋势周期和季节性分量的估计。 然而，它们会影响剩余部分。

另一方面，STL 也有一些缺点。 特别是它不会自动处理交易日或日历变化，它只提供用于附加分解的工具。

乘法分解可以通过首先记录数据，然后反向转换组件来获得。 可以使用 0 < λ < 1 的数据的 Box-Cox 变换获得加法和乘法之间的分解。  λ = 0 值给出乘法分解，而 λ = 1 给出加法分解。

STL()

#### 时序特征

我们已经看到了一些时间序列特征。 例如，前文讨论的自相关可以被视为时间序列的特征——它们是从该序列计算的数值汇总。 我们在上一章中看到的另一个特征是 Box-Cox 变换参数的 Guerrero 估计——同样，这是一个从时间序列计算的数字。

`feasts` package

##### ACF特征

自相关上文中讨论过。 一个系列的所有自相关都可以被认为是该系列的特征。 我们还可以总结自相关以产生新特征； 例如，前十个平方自相关系数的总和是一个有用的总结，无论滞后如何，序列中有多少自相关。

我们还可以计算不同时期之间序列变化的自相关。 也就是说，我们“区分”数据并创建一个由连续观察之间的差异组成的新时间序列。 然后我们可以计算这个新的差分序列的自相关。 有时再次应用相同的差分操作很有用，因此我们计算差异的差异。 这个双差分序列的自相关可以提供有用的信息。

另一种相关方法是计算系列的季节性差异。 例如，如果我们有月度数据，我们将计算连续的 1 月、连续的 2 月等之间的差异。 这使我们能够查看该系列如何在几年之间而不是几个月之间发生变化。 同样，季节性差异序列的自相关可能会提供有用的信息。

##### STL特征

时间序列分解可用于衡量时间序列中趋势和季节性的强度。 回想一下，分解写为$y_t = T_t + S_{t} + R_t,$其中 T t 是平滑趋势分量，S t 是季节性分量，R t 是余数分量。 

对于强趋势数据，经季节性调整的数据应该比剩余部分具有更多的变化。 因此 Var ( R t ) /Var ( T t + R t ) 应该相对较小。 但是对于趋势很小或没有趋势的数据，两个方差应该大致相同。 因此，我们将趋势强度定义为：

​                                    $$F_T = \max\left(0, 1 - \frac{\text{Var}(R_t)}{\text{Var}(T_t+R_t)}\right).$$

这将给出 0 和 1 之间趋势强度的度量。因为余数的方差有时可能甚至大于季节性调整数据的方差，将 F T 的最小可能值设置为零。

季节性强度的定义类似，但针对去趋势数据而不是季节性调整数据： 

​                                   $$F_S = \max\left(0, 1 - \frac{\text{Var}(R_t)}{\text{Var}(S_{t}+R_t)}\right).$$

季节性强度$F_S$接近 0 的系列几乎没有季节性，而季节性强的系列将具有接近 1 的$ F_S$，因为 Var ( R t ) 将远小于 Var ( S t + R t )。

这些度量可能很有用，例如，当您拥有大量时间序列，并且您需要找到最具趋势或最具季节性的序列时。 

feat_stl() 

##### 其他特征

features()

- `coef_hurst` 将计算时间序列的 Hurst 系数，这是“长记忆”的度量。 具有长记忆力的序列对于许多滞后将具有显着的自相关性。

- `feat_spectral` 将计算时间序列的（香农）谱熵，这是对序列预测难易程度的度量。 具有强烈趋势和季节性（因此易于预测）的序列的熵接近于 0。噪声非常大（因此难以预测）的序列的熵接近于 1。

- `box_pierce` 给出用于测试时间序列是否为白噪声的 Box-Pierce 统计量，以及相应的 p 值。 该测试在[残差诊断](#残差诊断)中讨论。

- `ljung_box`给出用于测试时间序列是否为白噪声的 Ljung-Box 统计量，以及相应的 p 值。 该测试在[残差诊断](#残差诊断)中讨论。

- 第 k 个偏自相关测量在去除观测值之间的影响后相隔 k 周期的观测值之间的关系。 所以第一个偏自相关 (k=1) 与第一个自相关相同，因为在连续观测之间没有要删除的内容。 部分自相关在[非季节性 ARIMA 模型](#非季节性 ARIMA 模型)中讨论。

  The `feat_pacf` 函数包含几个涉及偏自相关的特征，包括原始序列、一阶差分序列和二阶差分序列的前五个偏自相关的平方和。 对于季节性数据，它还包括第一个季节性滞后的偏自相关。.

- `unitroot_kpss` 给出用于检验序列是否平稳的 Kwiatkowski-Phillips-Schmidt-Shin (KPSS) 统计量，以及相应的 p 值。 该测试在[平稳性和差分](#平稳性和差分)讨论。

- `unitroot_pp`给出用于检验序列是否非平稳的 Phillips-Perron 统计量，以及相应的 p 值。

- `unitroot_ndiffs` - 根据 KPSS 测试给出导致平稳序列所需的差异数量。 

- `unitroot_nsdiffs` 给出使序列平稳所需的季节性差异数。 这在[平稳性和差分](#平稳性和差分)讨论。

- `var_tiled_mean` 给出“平铺均值”的方差（即连续非重叠观测块的均值）。 默认图块长度为 10（对于非季节性数据）或季节性周期的长度。 这有时称为“稳定性”功能。

- `var_tiled_var` 给出“平铺方差”的方差（即连续非重叠观测块的方差）。 这有时被称为“块状”特征。

- `shift_level_max` 找到时间序列的两个连续滑动窗口之间的最大均值偏移。 这对于查找时间序列中的突然跳跃或下降很有用。

- `shift_level_index` 给出发生最大均值偏移的索引。

- `shift_var_max` 找到时间序列的两个连续滑动窗口之间的最大方差偏移。 这对于**发现时间序列波动性的突然变化很有用**。

- `shift_var_index` - 给出发生最大均值偏移的索引 -`shift_kl_max` 找到时间序列的两个连续滑动窗口之间的最大分布偏移（基于 Kulback-Leibler 散度）。 这对于查找时间序列分布的突然变化很有用。

- `shift_kl_index` 给出最大 KL 偏移发生处的索引。

- `n_crossing_points` 计算时间序列穿过中位数的次数。

- `longest_flat_spot` 计算序列相对不变的数据部分的数量。

- `stat_arch_lm` 返回基于 Engle (1982) 的拉格朗日乘数 (LM) 检验的自回归条件异方差性 (ARCH) 的统计量。

- `guerrero` 使用 Guerrero 方法计算 Box-Cox 变换的最佳 λ 值（在[调整和转换](#调整和转换)中讨论）。

#### 时序预测知识

##### 简单预测方法

一些预测方法极其简单且非常有效。使用四种简单的预测方法作为基准。

平均法：

MEAN()

在这里，所有未来值的预测等于历史数据的平均值（或“平均值”）。 如果我们让历史数据用 y 1 , … , y T 表示，那么我们可以把预测写成：

​                                       $\hat{y}_{T+h|T} = \bar{y} = (y_{1}+\dots+y_{T})/T.$

朴素法：

对于朴素预测，我们只需将所有预测设置为最后一次观察的值。 即 $\hat{y}_{T+h|T} = y_{T}.$

这种方法对于许多经济和金融时间序列非常有效。

因为当数据遵循随机游走时，朴素预测是最佳的，所以这些也称为随机游走预测，可以使用 RW() 函数代替 NAIVE。

季节性朴素方法:

类似的方法对于高度季节性的数据很有用。 在这种情况下，我们将每个预测设置为等于一年中同一季节（例如，上一年的同一个月）的最后一个观测值。 形式上，时间 T + h 的预测写为 

​                                        $\hat{y}_{T+h|T} = y_{T+h-m(k+1)},$

其中 m = 季节性周期，k 是 ( h − 1 ) / m 的整数部分（即时间T + h之前预测期的完整年数 )。 这看起来比实际更复杂。 例如，对于月度数据，所有未来 2 月值的预测等于最后观察到的 2 月值。 对于季度数据，所有未来 Q2 值的预测等于最后观察到的 Q2 值（其中 Q2 表示第二季度）。 类似的规则适用于其他月份和季度以及其他季节性时期。

漂移法:

Naïve 方法的一个变体是允许预测随时间增加或减少，其中随时间的变化量（称为漂移）设置为历史数据中看到的平均变化。 因此，时间 $T + h$ 的预测由 

​              $$\hat{y}_{T+h|T} = y_{T} + \frac{h}{T-1}\sum_{t=2}^T (y_{t}-y_{t-1}) = y_{T} + h \left( \frac{y_{T} -y_{1}}{T-1}\right).$$

这相当于在第一次和最后一次观察之间画一条线，并将其外推到未来。

有时，这些简单方法之一将是可用的最佳预测方法； 但在许多情况下，这些方法将作为基准而不是选择的方法。 也就是说，我们开发的任何预测方法都会与这些简单的方法进行比较，以确保新方法优于这些简单的替代方法。 如果不是，则新方法不值得考虑。

##### 拟合值和残差

时间序列中的每个观察都可以使用所有先前的观察进行预测。 我们将这些拟合值称为 $\hat{y}_{t|t-1}$，表示基于观测值 y 1 , … , y t − 1 的 y t 预测。 我们经常使用这些，有时我们会去掉部分下标，只写  $\hat{y}_{t}$而不是 $\hat{y}_{t|t-1}$ 。

时间序列模型中的“残差”是拟合模型后剩下的。 残差等于观测值与相应拟合值之间的差值： $e_{t} = y_{t}-\hat{y}_{t}.$

如果模型中使用了变换，那么查看变换尺度上的残差通常很有用。 我们称这些为“创新残余”。 例如，假设我们对数据的对数进行建模， w t = log ( y t ) 。 然后创新残差由$w_t - \hat{w}_t$ 给出，而常规残差由 $y_{t}-\hat{y}_{t}$给出。  如果未使用转换，则创新残差与常规残差相同，在这种情况下，我们将简单地称其为“残差”。

augment()

##### 残差诊断

一个好的预测方法将产生具有以下特性的创新残差： 

1. 创新残差是不相关的。 如果创新残差之间存在相关性，那么残差中就有信息可用于计算
2. 创新残差的均值为零。 如果它们的均值不为零，则预测有偏差。

任何不满足这些性质的预测方法都可以改进。 但是，这并不意味着不能改进满足这些属性的预测方法。 对于同一个数据集，可能有几种不同的预测方法，所有这些方法都满足这些属性。 检查这些属性对于查看方法是否使用所有可用信息很重要，但这不是选择预测方法的好方法。

如果不满足这些属性中的任何一个，则可以修改预测方法以提供更好的预测。 调整偏差很容易：如果残差的均值为 m，那么只需从所有预测中减去 m，偏差问题就解决了。 解决相关性问题比较困难，我们要到#才会解决它

 除了这些基本属性之外，残差还具有以下两个属性是有用的（但不是必需的)。

1. 创新残差具有恒定的方差。 这被称为“同方差性”。
2. 创新残差呈正态分布。

这两个属性使预测区间的计算更容易。 然而，不满足这些性质的预测方法不一定能得到改进。 有时应用 Box-Cox 变换可能对这些属性有所帮助，但除此之外，您通常无法确保您的创新残差具有恒定方差和正态分布。 相反，需要另一种获得预测区间的方法。 我们将在后文展示如何处理非正态创新残差。

自相关的 Portmanteau 检验：

除了查看 ACF 图之外，我们还可以通过将一整套 r k 值视为一个组来对自相关进行更正式的测试，而不是单独处理每个值

回想一下，r k 是滞后 k 的自相关。 当我们查看 ACF 图以查看每个尖峰是否在要求的范围内时，我们隐含地进行了多个假设检验，每个假设检验都有很小的概率给出误报。 当完成足够多的这些测试时，很可能至少有一个会给出误报，因此我们可以得出结论，残差具有一些剩余的自相关性，而实际上它们没有。

 为了克服这个问题，我们测试第一个 ℓ 自相关是否与白噪声过程的预期显著不同。 对一组自相关的测试称为 portmanteau 测试，来自法语单词，描述了携带多件衣服的手提箱或衣架。

 一种这样的测试是 Box-Pierce 测试，它基于以下统计量 

​                                                   $$Q = T \sum_{k=1}^\ell r_k^2,$$

其中 ℓ 是所考虑的最大滞后，T 是观察次数。 如果每个 r k 接近于零，那么 Q 就会很小。 如果某些 r k 值很大（正或负），则 Q 会很大。 我们建议对非季节性数据使用 ℓ = 10，对季节性数据使用 ℓ = 2 m，其中 m 是季节性周期。 但是，当 ℓ 较大时测试效果不佳，因此如果这些值大于 T / 5 ，则使用 ℓ = T / 5

一个相关的（更准确的）测试是 Ljung-Box 测试，它基于:

​                                     $$Q^* = T(T+2) \sum_{k=1}^\ell (T-k)^{-1}r_k^2.$$

同样，Q ∗ 的大值表明自相关不是来自白噪声序列。

多大是太大？ 如果自相关确实来自白噪声序列，那么 Q 和 Q ∗ 都将具有 ( ℓ − K ) 自由度的 $\chi^2$分布，其中 K 是模型中的参数数量。 如果它们是根据原始数据（而不是模型的残差）计算的，则设置 K = 0 。
    

对于 Google 股票价格示例，Naïve 方法没有参数，因此在这种情况下 K = 0。 在代码中，lag = ℓ 和 dof = K。

##### 分布预测和预测区间

预测分布：

我们使用概率分布表示预测中的不确定性。 它描述了使用拟合模型观察可能的未来值的概率。 点预测是该分布的均值。 大多数时间序列模型产生正态分布的预测——也就是说，我们假设未来可能值的分布遵循正态分布。 我们将在本节后面介绍正态分布的几种替代方案。

预测区间：$\hat{y}_{T+h|T} \pm c \hat\sigma_h$

预测区间的价值在于它们表达了预测中的不确定性。 如果我们只生成点预测，则无法判断预测的准确程度。 然而，如果我们也产生预测区间，那么很明显每个预测有多少不确定性。 因此，如果没有伴随的预测区间，点预测几乎没有价值。

一步预测区间:

当提前一步预测时，预测分布的标准差可以用下式给出的残差的标准差来估计$\begin{equation}  \hat{\sigma} = \sqrt{\frac{1}{T-K}\sum_{t=1}^T e_t^2} \end{equation}$,其中 K 是预测方法中估计的参数数量。

多步预测区间:

预测区间的一个共同特征是它们的长度通常随着预测范围的增加而增加。 我们预测得越远，与预测相关的不确定性就越大，因此预测区间越宽。 也就是说，σ h 通常随 h 增加（尽管有一些非线性预测方法不具有此属性）。

为了产生一个预测区间，有必要估计 σ h 。 如前所述，对于一步预测 (h = 1)，上式 提供了对预测标准偏差 σ 1 的良好估计。 对于多步预测，需要更复杂的计算方法。 这些计算假设残差不相关。

基准方法：对于四种基准方法，可以在不相关残差的假设下从数学上推导出预测标准差。 hilo()

来自bootstrapped残差的预测区间：

当残差的正态分布是不合理的假设时，一种替代方法是使用bootstrapped法，它仅假设残差与恒定方差不相关。

该方法基于对过去残差的采样预测未来残差，进而预测未来数值反复这样做，我们获得了许多可能的未来。 要查看其中一些，我们可以使用 generate() 函数。

注意，预测分布现在表示为样本路径的模拟。 因为没有正态性假设，所以预测区间不是对称的。

##### 分解预测

时间序列分解可能是生成预测的有用步骤。

假设加法分解，分解后的时间序列可以写成$y_t = \hat{S}_t + \hat{A}_t,$其中 $\hat{A}_t = \hat{T}_t+\hat{R}_{t}$ 是季节性调整的分量。 或者，如果使用乘法分解，我们可以写成 $y_t = \hat{S}_t  \hat{A}_t,$其中 $\hat{A}_t = \hat{T}_t+\hat{R}_{t}$。

为了预测分解的时间序列，我们分别预测季节性分量$\hat{S}_t$和季节性调整分量 $\hat{A}_t$。 **通常假设季节性分量是不变的，或者变化极其缓慢**，因此只需取估计分量的最后一年就可以进行预测。 换句话说，季节性朴素方法用于季节性成分。

为了预测经季节性调整的成分，可以使用任何非季节性预测方法。 例如，可以使用 Drift 方法或 Holt# 方法或非季节性 ARIMA #模型。

decomposition_model()允许通过任何加法分解计算预测，使用其他模型函数来预测分解的每个组件

##### 评估点预测准确性

使用真实预测来评估预测准确性非常重要。 因此，残差的大小并不是真实预测误差可能有多大的可靠指标。 预测的准确性只能通过考虑模型在拟合模型时未使用的新数据上的表现来确定。

测试集的大小通常约为总样本的 20%，尽管此值取决于样本的长度以及您想要预测的提前程度。 理想情况下，测试集应至少与所需的最大预测范围一样大。 应注意以下几点:

* 一个很好地拟合训练数据的模型不一定能很好地预测。
* 使用具有足够参数的模型总是可以获得完美的拟合。
* 模型过度拟合数据与无法识别数据中的系统模式一样糟糕。

filter()用于提取时序数据中的一部分，slice()允许使用索引从每个组中选择一个子集

尺度相关误差：

预测误差与数据的尺度相同。 因此，仅基于 e t 的准确度度量取决于尺度，不能用于在涉及不同单位的系列之间进行比较。

两种最常用的尺度相关度量基于绝对误差或平方误差：

​         $$\begin{align*}
  \text{Mean absolute error: MAE} & = \text{mean}(|e_{t}|),\\
  \text{Root mean squared error: RMSE} & = \sqrt{\text{mean}(e_{t}^2)}.
\end{align*}$$

在比较应用于单个时间序列或具有相同单位的多个时间序列的预测方法时，MAE 很受欢迎，因为它易于理解和计算。 最小化 MAE 的预测方法将导致对中位数的预测，而最小化 RMSE 将导致对均值的预测。 因此，RMSE 也被广泛使用，尽管更难以解释。

百分比误差:

百分比误差由$p_{t} = 100 e_{t}/y_{t}$给出。 百分比误差具有无单位的优点，因此**经常用于比较数据集之间的预测性能**。 最常用的度量是：平均绝对百分比误差：$\text{Mean absolute percentage error: MAPE} = \text{mean}(|p_{t}|).$

如果$y_{t}=0$对于感兴趣期间的任何 t，则基于百分比误差的度量具有无限或未定义的缺点，并且如果任何 接$y_{t}$近于零，则具有极值。 另一个经常被忽视的百分比误差问题是他们假设测量单位有一个有意义的零.例如，在测量华氏或摄氏温度预测的准确性时，百分比误差没有意义，因为温度有一个任意的零点。

它们还有一个缺点，那就是它们对负错误的惩罚比对正错误的惩罚更重。 这一观察导致使用 Armstrong (1978, p. 348) 提出的所谓的“对称”MAPE (sMAPE)，该方法用于 M3 预测竞赛。 它由$\text{sMAPE} = \text{mean}\left(200|y_{t} - \hat{y}_{t}|/(y_{t}+\hat{y}_{t})\right).$定义。

但是，如果 y t 接近于零，则$\hat{y}_{t}$也可能接近于零。 因此，该度量仍然涉及除以接近于零的数字，从而使计算不稳定。 此外，sMAPE 的值可能为负，因此它根本不是“绝对百分比误差”的衡量标准。

Hyndman & Koehler (2006) 建议不要使用 sMAPE。 将它包含在这里只是因为它被广泛使用，尽管我们不会在本书中使用它。

比例误差:

比例误差由 Hyndman & Koehler (2006) 提出，作为比较不同单位的系列预测准确度时使用百分比误差的替代方法。 他们建议根据简单预测方法的训练 MAE 来缩放误差。

对于非季节性时间序列，定义比例误差的一种有用方法是使用朴素预测： 

​                                       $q_{j} = \frac{\displaystyle e_{j}}    {\displaystyle\frac{1}{T-1}\sum_{t=2}^T |y_{t}-y_{t-1}|}.$

因为分子和分母都涉及原始数据尺度上的值，所以 q j 与数据尺度无关。 如果缩放误差来自比在训练数据上计算的平均一步朴素预测更好的预测，则缩放误差小于 1。 相反，如果预测比在训练数据上计算的平均一步朴素预测差，则它大于 1。

对于季节性时间序列，可以使用季节性朴素预测定义缩放误差：

​                                     $$q_{j} = \frac{\displaystyle e_{j}}    {\displaystyle\frac{1}{T-m}\sum_{t=m+1}^T |y_{t}-y_{t-m}|}.$$

自然的有：$\text{MASE} = \text{mean}(|q_{j}|).$ $\text{RMSSE} = \sqrt{\text{mean}(q_{j}^2)},$

accuracy() 自动从数据中提取相关时期以匹配预测

##### 评估分布预测准确性

前面测量了所有测量点预测的准确性。 在评估分布预测时，我们需要使用其他一些度量。

分位数分数：

假设我们对未来时间 t 的概率为 p 的分位数预测感兴趣，并用$f_{p,t}$表示。 也就是说，我们期望观测值 y t 小于$f_{p,t}$的概率为 p 。 例如，第 10 个百分位数将是$f_{0.10,t}$。 如果 y t 表示在时间 t 的观察，那么分位数分数是:

​                      $$Q_{p,t} = \begin{cases}  2(1 - p) \big(f_{p,t} - y_{t}\big), & \text{if $y_{t} < f_{p,t}$}\\  2p \big(y_{t} - f_{p,t}\big), & \text{if $y_{t} \ge f_{p,t}$} \end{cases}$$

这有时被称为“pinball loss function”，因为它的图形类似于弹球桌上球的轨迹。 乘数 2 经常被省略，但包括它会使解释更容易一些。 $Q_{p,t}$的低值表示对分位数的更好估计。

分位数分数可以解释为绝对误差。 实际上，当 p = 0.5 时，分位数得分$Q_{0.5,t}$与绝对误差相同。 对于 p 的其他值，“误差”$(y_t - f_{p,t})$被加权以考虑它是正数还是负数的可能性。 如果 p > 0.5 ,$Q_{p,t}$在观测值大于估计分位数时比在观测值小于估计分位数时给出更重的惩罚。 当 p < 0.5 时，情况正好相反。

这可以使用带有 quantile_score() 函数的 precision() 轻松计算

Winkler Score:

**评估预测区间**（而不是几个分位数）通常是令人感兴趣的，Winkler（1972）提出的Winkler分数就是为了这个目的而设计的。如果100（1− α）%时间t的预测区间是$[\ell_{\alpha,t}, u_{\alpha,t}]$，则Winkler分数定义为间隔长度加上惩罚（如果观察值在间隔之外）：

$$W_{\alpha,t} = \begin{cases}  (u_{\alpha,t} - \ell_{\alpha,t}) + \frac{2}{\alpha} (\ell_{\alpha,t} - y_t) & \text{if } y_t < \ell_{\alpha,t} \\  (u_{\alpha,t} - \ell_{\alpha,t})   & \text{if }  \ell_{\alpha,t} \le y_t \le u_{\alpha,t} \\  (u_{\alpha,t} - \ell_{\alpha,t}) + \frac{2}{\alpha} (y_t - u_{\alpha,t}) & \text{if } y_t > u_{\alpha,t}.  \end{cases}$$

对于区间内的观察，Winkler分数只是区间的长度。因此，低分数与狭窄的时间间隔有关。但是，如果观察值落在间隔之外，则应用惩罚，惩罚与观察值在间隔之外的距离成比例。

通常构造预测区间通过设置$\ell_{\alpha,t} = f_{\alpha/2,t}$和$u_{\alpha,t} = f_{1-\alpha/2,t}$。如果我们加上相应的分位数分数并除以α，我们得到Winkler分数：

​                                $$W_{\alpha,t} = (Q_{\alpha/2,t} + Q_{1-\alpha/2,t})/\alpha.$$

这可以使用带有 quantile_score() 函数的winkler_score()轻松计算

连续排序概率得分：

我们通常对整个预测分布感兴趣，而不是特定的分位数或预测区间。在这种情况下，我们可以对p的所有值的分位数分数进行平均，以获得连续排名的概率分数或CRPS（Gneiting&Katzfuss，2014）。

在Google股票价格示例中，我们可以计算测试集中所有天的平均CRPS值。CRPS值有点像从整个预测分布计算的加权绝对误差，其中加权考虑了概率。

使用技能分数的无尺度比较：

与点预测一样，能够在不同尺度的系列中比较几种方法的分布预测准确性是很有用的。 对于点预测，我们为此使用了比例误差。 另一种方法是使用技能分数。 这些可用于点预测精度和分布预测精度。

使用技能分数，我们计算相对于某些基准方法的预测准确性度量。 例如，如果我们使用 Naïve 方法作为基准，并使用 Drift 方法计算预测，我们可以计算 Drift 方法相对于 Naïve 方法的 CRPS 技能分数为：

​                                             $$\frac{\text{CRPS}_{\text{Naïve}} - \text{CRPS}_{\text{Drift}}}{\text{CRPS}_{\text{Naïve}}}.$$

这给出了漂移方法优于基于 CRPS 的朴素方法的比例。 使用accuracy()函数中的Skill_score() 。

 Skill_score() 函数可用于任何准确度度量。 例如，skill_score(MSE) 提供了一种跨不同系列比较 MSE 值的方法。 然而，重要的是测试集足够大以允许可靠地计算误差度量，尤其是在分母中。 出于这个原因，MASE 或 RMSSE 通常是点预测准确性的首选无标度度量

##### 时间序列交叉验证

一个更复杂的训练/测试集版本是时间序列交叉验证。**在这个过程中，有一系列测试集，每个测试集由一个单一的观察组成**。 相应的训练集仅包含在形成测试集的观察之前发生的观察。 因此，未来的观测不能用于构建预测。 由于不可能基于较小的训练集获得可靠的预测，因此不将最早的观察结果视为测试集。

下图说明了一系列训练和测试集，其中蓝色观测值构成训练集，橙色观测值构成测试集。

![img](https://otexts.com/fpp3/fpp_files/figure-html/cv1-1.svg)

预测准确度是通过对测试集求平均值来计算的。 这个过程有时被称为“对滚动预测原点的评估”，因为预测所基于的“原点”在时间上向前滚动。

对于时间序列预测，一步预测可能不如多步预测那么相关。 在这种情况下，可以修改基于滚动预测原点的交叉验证程序，以允许使用多步错误。 假设我们对产生良好的 4 步提前预测的模型感兴趣。 那么对应的图如下所示。

![img](https://otexts.com/fpp3/fpp_files/figure-html/cv4-1.svg)

stretch_tsibble()

选择最佳预测模型的一个好方法是找到使用时间序列交叉验证计算的具有最小 RMSE 的模型。
