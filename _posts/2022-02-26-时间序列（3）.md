---
layout:     post                    # 使用的布局（不需要改）
title:      时间序列（3）            # 标题 
# subtitle:   《Forecasting: Principles and Practice》中文整理 #副标题
date:       2022-02-24              # 时间
author:     HZ                      # 作者
header-img: img/time series.jpg    #这篇文章标题背景图片
catalog: true                       # 是否归档
tags:                               #标签
    - 统计学习
    - R应用
---

> 本篇主要介绍动态回归、分层分组时间序列、先进时序预测方法、多元时间序列知识点和一些实际问题

#### 动态回归模型

##### 带有 ARIMA 误差的回归

如果公式中包含外生回归量，则函数 ARIMA() 将拟合具有 ARIMA 误差的回归模型。 正如前文中介绍的那样，特殊的 pdq() 指定了 ARIMA 误差模型的顺序。 如果指定了差分，则在估计模型之前将差分应用于回归模型中的所有变量。

ARIMA() 函数还可用于为误差选择最佳 ARIMA 模型。 这是通过不指定 pdq() 特殊来完成的。 是否需要差分是通过对使用普通最小二乘法估计的回归模型的残差应用 KPSS 检验来确定的。 如果需要差分，则对所有变量进行差分，并使用最大似然估计重新估计模型。 最终模型将根据原始变量表示，即使它已使用差分变量进行估计。

AICc 是为最终模型计算的，该值可用于确定最佳预测变量。 也就是说，应对所有要考虑的预测变量子集重复该过程，并选择具有最低 AICc 值的模型。

##### 预测

要使用具有 ARIMA 误差的回归模型进行预测，我们需要对模型的回归部分和模型的 ARIMA 部分进行预测，并将结果结合起来。 与普通回归模型一样，为了获得预测，我们首先需要预测预测变量。 当预测变量在未来已知时（例如，与日历相关的变量，如时间、星期几等），这很简单。 但是当预测变量本身未知时，我们必须对它们分别建模，或者为每个预测变量使用假设的未来值。

##### 随机和确定性趋势

有两种不同的方法可以对线性趋势进行建模。 

使用回归模型 $y_t = \beta_0 + \beta_1 t + \eta_t,$获得确定性趋势，其中 η t 是 ARMA 过程。 

使用模型$y_t = \beta_0 + \beta_1 t + \eta_t,$ 获得随机趋势，其中 η t 是 d = 1 的 ARIMA 过程。 在后一种情况下，我们可以对两边进行差分，使得 $y_t' = \beta_1 + \eta_t'$，其中 η ′ t 是一个 ARMA 过程。 换言之，$y_t = y_{t-1} + \beta_1 + \eta_t'$。

这类似于带有漂移的随机游走，但这里的误差项是一个 ARMA 过程，而不是简单的白噪声。

尽管这些模型看起来非常相似（它们仅在需要应用于 η t 的差异数量上有所不同），但它们的预测特征却大不相同。

有一个具有确定性趋势的隐含假设，即趋势的斜率不会随时间变化。 另一方面，随机趋势可能会发生变化，估计的增长率仅假设为历史时期的平均增长率，不一定是未来观察到的增长率。 因此，使用随机趋势进行预测更安全，尤其是对于较长的预测范围，因为预测区间允许未来增长的更大不确定性。

##### 动态谐波回归

当存在较长的季节性周期时，傅立叶项的动态回归通常比我们在本书中考虑的其他模型更好。例如，每日数据的年度季节性长度为 365，每周数据的季节性周期约为 52，而 半小时数据可以有多个季节性时段，其中最短的是时段 48 的每日模式。

ARIMA 和 ETS 模型的季节性版本设计用于较短的时间段，例如 12 为月度数据或 4 为季度数据。  ETS() 模型将季节性限制为最多 24 个周期，以允许每小时数据，但不允许数据具有更大的季节性周期。 问题是对于初始季节性状态有 m - 1 个参数需要估计，其中 m 是季节性周期。 所以对于大 m ，估计变得几乎不可能。

ARIMA() 函数将允许最多 m = 350 的季节性周期，但在实践中通常会在季节性周期超过 200 时耗尽内存。无论如何，高阶的季节性差分不会产生很多 意义——对于日常数据，它涉及将今天发生的事情与一年前发生的事情进行比较，并且没有限制季节性模式是平滑的。

 因此，对于此类时间序列，我们更喜欢调和回归方法，其中使用傅立叶项对季节性模式进行建模，并使用由 ARMA 误差处理的短期时间序列动态。

这种方法的优点是：

1. 它允许任何长度的季节性； 对于多于一个季节的数据，可以包含不同频率的傅里叶项；
2. 季节性模式的平滑度可以通过 K 控制，即傅立叶正弦和余弦对的数量——对于较小的 K 值，季节性模式更平滑； 
3. 短期动态很容易通过一个简单的 ARMA 误差处理。

 唯一真正的缺点（与季节性 ARIMA 模型相比）是**假设季节性是固定的——季节性模式不允许随时间变化**。 但在实践中，季节性通常非常恒定，因此除了长时间序列外，这不是一个大缺点。

#### 预测分层和分组的时间序列

时间序列通常可以通过各种感兴趣的属性自然地分解。 例如，自行车制造商销售的自行车总数可以按产品类型分类，如公路自行车、山地自行车和混合动力车。 这些中的每一个都可以分解为更细的类别。 例如混合动力自行车可以分为城市自行车、通勤自行车、舒适自行车和徒步自行车； 等等。 这些类别嵌套在较大的组类别中，因此时间序列的集合遵循分层聚合结构。 因此，我们将这些称为“分层时间序列”。 由于地理划分，经常会出现分层时间序列。 例如，自行车总销量可以按国家分类，然后在每个国家按州分类，在每个州按地区分类，依此类推，直到销售点级别。

当感兴趣的属性交叉而不是嵌套时，会出现替代聚合结构。 例如，自行车制造商可能对诸如车架尺寸、性别、价格范围等属性感兴趣。这些属性不会以独特的分层方式自然分解，因为这些属性没有嵌套。 我们将交叉属性的结果时间序列称为“分组时间序列”。 当感兴趣的属性既嵌套又交叉时，会出现更复杂的结构。 例如，自行车制造商自然会对按产品类型和地域划分的销售额感兴趣。 然后将产品分组和地理层次结构混合在一起。 我们在 11.1 节介绍了替代聚合结构。

所有分解和聚合系列通常都需要预测，并且很自然地希望预测以与数据相同的方式累加。 例如，区域销售的预测加起来应该与州销售的预测相加，而州销售的预测加起来又可以给出全国销售的预测。

在本节中，我们讨论预测以某种方式聚合的大量时间序列。 挑战在于我们需要在整个聚合结构中进行一致的预测。 也就是说，我们要求预测以与定义时间序列集合的层次结构或组的聚合结构一致的方式相加。

##### 分层和分组的时间序列

下图显示了一个简单的层次结构。 层次结构的顶部是“总计”，即数据的最聚合级别。  Total 系列的第 t 个观测值由 y t 表示，因为 t = 1 , … , T 。 总计被分解为两个系列，在层次结构的最底层又分别分为三个和两个系列。 在顶层之下，我们使用$y_{j,t}$表示与节点 j 对应的系列的第 t 个观测值。 例如，$y{A}{t}$表示节点 A 对应的序列的第 t 个观测值，$y{AB}{t}$表示节点 AB 对应的序列的第 t 个观测值，依此类推。

<img src="https://otexts.com/fpp3/figs/hts.png" alt="A two level hierarchical tree diagram." style="zoom:50%;" />

对于任何时间 t ，层次结构底层的观测值将与上述系列的观测值相加。

 例如，$\begin{equation}  y_{t}=y{AA}{t}+y{AB}{t}+y{AC}{t}+y{BA}{t}+y{BB}{t},  \tag{11.1} \end{equation}$

$\begin{equation}  y{A}{t}=y{AA}{t}+y{AB}{t}+y{AC}{t}\qquad \text{and} \qquad  y{B}{t}=y{BA}{t}+y{BB}{t}.  \tag{11.2} \end{equation}$

​     将(11.2)代入(11.1)，我们也得到$y_{t}=y{A}{t}+y{B}{t}$。

使用aggregate_key() 函数，我们可以创建层次结构时间序列，其中包含层次结构底部区域的过夜旅行，聚合到州，再聚合到全国总数。 使用父/子规范创建对应于嵌套结构的分层时间序列。

```R
tourism_hts <- tourism %>%
  aggregate_key(State / Region, Trips = sum(Trips))
```

分组时间序列

对于分组时间序列，数据结构不会以独特的分层方式自然分解。 下图显示了一个简单的分组结构。 分组结构的顶部是 Total，即数据的最聚合级别，同样由 y t 表示。  Total 可以按属性 (A, B) 分解，形成系列 y A , t 和 y B , t ，或按属性 (X, Y) 分解，形成系列 y X , t 和 y Y , t 。 在底层，数据按这两个属性进行分解。

<img src="https://otexts.com/fpp3/fpp_files/figure-html/GroupTree-1.png" alt="Alternative representations of a two level grouped structure." style="zoom:50%;" />



此示例显示分组结构存在替代聚合路径。 对于任何时间 t ，与层次结构一样，$\begin{equation*} y_{t}=y{AX}{t}+y{AY}{t}+y{BX}{t}+y{BY}{t}. \end{equation*}$

但是，对于分组结构的第一级，$\begin{equation} y{A}{t}=y{AX}{t}+y{AY}{t}\quad \quad y{B}{t}=y{BX}{t}+y{BY}{t} \tag{11.3} \end{equation}$,

但还有，

$\begin{equation} y{X}{t}=y{AX}{t}+y{BX}{t}\quad \quad y{Y}{t}=y{AY}{t}+y{BY}{t} \tag{11.4}. \end{equation}$

分组时间序列有时可以被认为是不强加唯一层次结构的层次时间序列，因为序列可以分组的顺序不是唯一的。

使用aggregate_key() 创建一个分组时间序列，现在使用语法attribute1*attribute2 交叉感兴趣的属性或分组（与用于分层时间序列的父/子语法相反）。 以下代码为具有交叉属性的监狱数据构建了一个分组的 tsibble：性别、法律地位和状态。

```
prison_gts <- prison %>%
  aggregate_key(Gender * Legal * State, Count = sum(Count)/1e3)
```

在 filter() 中使用 is_aggregated() 有助于探索或绘制图 11.7 底部面板中显示的主要组。 

混合分层和分组结构:

分解因素通常是嵌套的和交叉的。 例如，澳大利亚的旅游数据也可以按照旅游的四个目的进行分类：度假、商务、探亲访友和其他。 此分组变量不嵌套在任何地理变量中。 事实上，我们可以考虑按旅行目的为整个澳大利亚、每个州和每个地区划分过夜旅行。 我们将这种结构描述为与旅行目的“交叉”的“嵌套”地理层次结构。 使用aggregate_key() 可以通过简单地组合因素来指定。

```R
tourism_full <- tourism %>%
  aggregate_key((State/Region) * Purpose, Trips = sum(Trips))
```

##### 单层方法

传统上，分层或分组时间序列的预测涉及选择一个聚合级别并为该级别生成预测。 然后将它们汇总到更高级别，或分解为较低级别，以获得结构其余部分的一组连贯预测。

自下而上的方法:

生成连贯预测的一种简单方法是“自下而上”的方法。 这种方法涉及首先在底层为每个序列生成预测，然后将它们相加以生成结构中所有序列的预测。

 这种方法的一个优点是我们在结构的底层进行预测，因此不会因聚合而丢失信息。 另一方面，底层数据可能非常嘈杂，并且对建模和预测更具挑战性。

我们将使用 reconcile() 函数来指定我们要如何计算相干预测。

```R
data %>% aggregate_key() %>% model() %>%
  reconcile() %>% forecast()
```

从包含各个底层系列的 tsibble 对象（此处标记为数据）开始。

1. 在aggregate_key() 中定义聚合结构并构建一个包含聚合系列的tsibble 对象。
2. 在所有聚合级别为每个系列确定一个模型（）。
3. 在 reconcile() 中指定如何从所选模型生成一致预测。
4. 使用 forecast() 函数为整个聚合结构生成预测。

自上而下的方法:

自上而下的方法涉及首先生成对 Total 系列 y t 的预测，然后在层次结构中向下分解这些预测。

让 p 1 , … , p m 表示一组分解比例，这些比例决定如何分布 Total 系列的预测以获得结构底层每个系列的预测。

一旦生成了底层 h-step-ahead 预测，这些预测就会被聚合起来，为系列的其余部分生成连贯的预测。

可以使用 reconcile() 函数中的 top_down() 生成自上而下的预测。

可以指定几种可能的自顶向下方法。 两种最常见的自上而下方法根据数据的历史比例指定分解比例。 这些在 Gross & Sohl (1990) 的研究中表现良好:

1. 平均历史比例$p_j=\frac{1}{T}\sum_{t=1}^{T}\frac{y_{j,t}}{{y_t}}$
2. 历史平均值的比例$p_j={\sum_{t=1}^{T}\frac{y_{j,t}}{T}}\Big/{\sum_{t=1}^{T}\frac{y_t}{T}}$

这种自上而下的方法的一个便利属性是它们的简单性。 人们只需要为最聚合的顶级系列建模和生成预测。 一般来说，这些方法似乎对总体水平产生了相当可靠的预测，并且它们对于低计数数据很有用。

 另一方面，一个缺点是由于聚合导致信息丢失。 使用这种自上而下的方法，我们无法捕捉和利用各个系列的特征，例如时间动态、特殊事件、不同的季节性模式等。

预测比例:

因为用于分解的历史比例没有考虑这些比例如何随时间变化，基于历史比例的自上而下的方法往往比自下而上的方法在层次结构的较低级别产生更不准确的预测。 为了解决这个问题，可以使用基于预测而不是历史数据的比例（G. Athanasopoulos 等，2009）。

 考虑一个一级层次结构。 我们首先为所有系列生成 h-step-ahead 预测。 我们不直接使用这些预测，而且它们不连贯（它们加起来不正确）。 让我们称这些为“初始”预测。 我们计算每个在底层的提前 h 步初始预测与该级别所有提前 h 步初始预测的总和的比例。 我们将这些称为预测比例，我们使用它们来分解顶级 h 步提前初始预测，以便为整个层次结构生成连贯的预测。

 对于 K 级层次结构，对每个节点重复此过程，从顶层到底层。 应用此过程可得出以下获取预测比例的一般规则：$p_j=\prod^{K-1}_{\ell=0}\frac{\hat{y}_{j,h}^{(\ell)}}{\hat{S}_{j,h}^{(\ell+1)}}$

其中$j=1,2,\dots,m$, $\hat{y}_{j,h}^{(\ell)}$ 是对应于j以上$\ell$级节点的系列的 h 超前初始预测，以及$\hat{S}_{j,h}^{(\ell)}$是在节点 j 上ℓ 层且直接连接到该节点的节点下的 h 步提前初始预测的总和。这些预测比例分解了总序列的 h 步超前初始预测，以获得底层序列的 h 步超前连贯预测。

这种方法是通过设置 method = "forecast_proportions" 在 top_down() 函数中实现的。 因为这种方法往往比其他自顶向下方法更有效，所以当没有指定方法参数时，它是 top_down() 函数中的默认选择。

所有自上而下的方法的一个缺点是，即使基础预测是无偏的，它们也不会产生无偏的连贯预测（Hyndman 等，2011）。

中出方法:

中出方法结合了自下而上和自上而下的方法。 同样，它只能用于严格的分层聚合结构。

首先，选择“中间”级别并为该级别的所有系列生成预测。 对于中层以上的序列，使用自下而上的方法通过向上聚合“中层”预测来生成连贯的预测。 对于“中层”以下的系列，通过向下分解“中层”预测，使用自上而下的方法生成连贯的预测。

这种方法在 middle_out() 函数中通过 level 参数指定适当的中间层并使用 method 参数选择自上而下的方法来实现。

##### 预测协调 

假设我们预测所有序列而忽略任何聚合约束。 我们称这些为基础预测，并用$\hat y_{h}$表示，其中 h 是预测范围。 它们以与数据$y_t$相同的顺序堆叠。

那么对于分层结构或分组结构的所有连贯预测方法都可以表示为:

$\begin{equation}  \tilde{{y}}_h={S}{G}\hat{{y}}_h,   \end{equation}$

迄今为止所考虑的传统方法的局限性在于，它们仅使用来自单一聚合级别的基础预测，这些基础预测已被聚合或分解以获得所有其他级别的预测。 因此，他们使用有限的信息。 然而，一般来说，我们可以使用其他 G 矩阵，然后 S G 组合和协调所有基础预测以产生一致的预测。

 事实上，我们可以找到最优的 G 矩阵来给出最准确的协调预测。

MinT 最优对账方法：

我们需要找出预测中的错误。 维克拉马苏里亚等人 (2019) 表明 h-step-ahead 相干预测误差的方差-协方差矩阵由下式给出:

$\begin{equation*} {V}_h = \text{Var}[{y}_{T+h}-\tilde{{y}}_h]={S}{G}{W}_h{G}'{S}' \end{equation*}$

详细公式略，最佳协调预测：

 MinT 由 reconcile() 函数中的 min_trace() 实现。

 为了在实践中使用它，我们需要估计 W h ，即提前 h 步基础预测的预测误差方差。 这可能很困难，因此提供了四种简化的近似值，这些近似值在模拟和实践中都表现良好。

1. 为所有 h 设置 ${W}_h=k_h{I}$，其中 k h > 0 . 这是最简单的假设，意味着 G 独立于数据，提供了大量的计算节省。 然而，缺点是该规范没有考虑结构级别之间的规模差异，或系列之间的关系。

2. 为所有 h 设置 ${W}_h = k_h {W}_1$ ，其中 k h > 0 。 这里我们只假设误差协方差矩阵彼此成比例，我们直接估计完整的一步协方差矩阵 W 1 。 最明显和最简单的方法是使用样本协方差。 这是通过设置 method = "mint_cov" 在 min_trace() 中实现的。

   但是，对于底层序列 m 的数量与序列 T 的长度比较大的情况，这不是一个好的估计器。 相反，我们使用收缩估计器将样本协方差收缩为对角矩阵。 这是通过设置 method = "mint_shrink" 

method = "ols" method = "wls_var" method = "wls_struct" method = "mint_shrink"

总之，与任何其他现有方法不同，最佳调节预测是使用分层或分组结构中的所有可用信息生成的。 这很重要，因为特定的聚合级别或分组可能会揭示用户感兴趣且对建模很重要的数据特征。 这些特征在其他层次上可能完全隐藏或不易识别。

 例如，考虑第 11.1 节中介绍的澳大利亚旅游数据，其中层次结构遵循一个国家的地理划分，将其划分为州和地区。 一些地区将主要是夏季目的地，而其他地区可能是冬季目的地。 我们在图 11.4 中看到了北部和南部各州之间对比鲜明的季节性模式。 由于汇总，这些差异将在国家层面得到平滑。

与自下而上的方法相比，使用 OLS 和 MinT 协调基础预测会产生更准确的预测。 这种结果在应用中很常见，因为协调方法使用来自结构各个层次的信息，与使用有限信息的旧传统方法相比，可以产生更准确的连贯预测。 此外，调节通常可以改善几乎所有级别的不连贯的基本预测。

##### 一个例子

```R
tourism_full <- tourism %>%
  aggregate_key((State/Region) * Purpose, Trips = sum(Trips))

fit <- tourism_full %>%
  filter(year(Quarter) <= 2015) %>%
  model(base = ETS(Trips)) %>%
  reconcile(
    bu = bottom_up(base),
    ols = min_trace(base, method = "ols"),
    mint = min_trace(base, method = "mint_shrink"),
  )
fc <- fit %>% forecast(h = "2 years")
fc %>%
  filter(is_aggregated(Region), is_aggregated(Purpose)) %>%
  autoplot(
    tourism_full %>% filter(year(Quarter) >= 2011),
    level = NULL
  ) +
  labs(y = "Trips ('000)") +
  facet_wrap(vars(State), scales = "free_y")
fc %>%
  filter(is_aggregated(State), !is_aggregated(Purpose)) %>%
  autoplot(
    tourism_full %>% filter(year(Quarter) >= 2011),
    level = NULL
  ) +
  labs(y = "Trips ('000)") +
  facet_wrap(vars(Purpose), scales = "free_y")
#准确度度量
fc %>%
  filter(is_aggregated(State), is_aggregated(Purpose)) %>%
  accuracy(
    data = tourism_full,
    measures = list(rmse = RMSE, mase = MASE)
  ) %>%
  group_by(.model) %>%
  summarise(rmse = mean(rmse), mase = mean(mase))
```

注：要以这种方式生成自举预测区间，我们只需在 predict() 函数中设置 bootstrap = TRUE。

#### 先进预测方法

##### 复杂季节性

到目前为止，我们主要考虑了相对简单的季节性模式，例如季度和月度数据。 然而，更高频率的时间序列通常表现出更复杂的季节性模式。 例如，每日数据可能具有每周模式和年度模式。 每小时数据通常具有三种类型的季节性：每日模式、每周模式和年度模式。 即使是每周数据也很难预测，因为一年中没有完整的周数，因此年度模式的季节性周期平均为 365.25 / 7 ≈ 52.179。 到目前为止，我们考虑的大多数方法都无法处理这些季节性的复杂性。

我们不一定要在我们的模型中包括所有可能的季节性时期——只是那些可能出现在数据中的时期。 例如，如果我们只有 180 天的数据，我们可能会忽略年度季节性。 如果数据是对自然现象（例如温度）的测量，我们可能可以安全地忽略任何每周季节性。

具有多个季节性周期的 STL：

STL() 函数旨在处理多个季节性。 它将返回多个季节性成分，以及趋势和剩余成分。 在这种情况下，我们需要重新索引 tsibble 以避免缺失值，然后明确给出季节性周期。

具有多个季节性周期的动态谐波回归：

对于多个季节性，我们可以像在前面的章节中那样使用傅立叶项。 因为有多个季节性，我们需要为每个季节性周期添加傅立叶项。 在这种情况下，季节性周期为 169 和 845，因此傅立叶项的形式为

$\sin\left(\frac{2\pi kt}{169}\right), \quad  \cos\left(\frac{2\pi kt}{169}\right), \quad  \sin\left(\frac{2\pi kt}{845}\right), \quad  \text{and} \quad  \cos\left(\frac{2\pi kt}{845}\right),$

我们将拟合具有 ARIMA 误差结构的动态谐波回归模型。 可以选择每个季节期间的傅立叶项总数以最小化 AICc。 但是，对于高季节性时期，这往往会高估所需的术语数量，因此我们将使用更主观的选择，其中 10 个术语用于每日季节性，5 个用于每周季节性。 

例子：电力的预测

##### Prophet model

最近的一个提议是 Prophet 模型，可通过 [fable.prophet] 包获得。 该模型由 Facebook（S. J. Taylor & Letham，2018 年）引入，最初用于预测具有每周和每年季节性以及假日效应的每日数据。 后来扩展到涵盖更多类型的季节性数据。 **它最适用于具有强烈季节性和多个季节历史数据的时间序列**。

Prophet 可以被认为是一个非线性回归模型，形式为$y_t = g(t) + s(t) + h(t) + \varepsilon_t,$

其中 g ( t ) 描述分段线性趋势（或“增长项”）， s ( t ) 描述各种季节性模式， h ( t ) 捕捉假期效应，而 ε t 是白噪声误差项。

* 如果未明确指定，将自动选择分段线性趋势的节点（或变化点）。 或者，可以使用逻辑函数来设置趋势的上限。
* 季节性成分由相关时期的傅立叶项组成。 默认情况下，order 10 用于年度季节性，order 3 用于每周季节性。
* 假日效应被添加为简单的虚拟变量。
* 该模型使用贝叶斯方法进行估计，以允许自动选择变化点和其他模型特征。

Prophet 具有比我们之前考虑的 DHR 模型更快估计的优势，并且它是完全自动化的。 但是，正如这两个示例所说明的那样，它很少能提供比替代方法更好的预测准确性。

##### 向量自回归

到目前为止，我们考虑的模型的一个限制是它们强加了一种单向关系——预测变量受预测变量的影响，但反之则不然。 然而，在很多情况下也应该允许相反的情况——所有变量都会相互影响。 在前文中，根据个人可支配收入 (I t ) 的变化预测了个人消费支出 ( C t ) 的变化。 然而，在这种情况下，双向关系可能更合适：$I_t$的增加将导致$C_t$的增加，反之亦然。

在向量自回归 (VAR) 框架中允许这种反馈关系。 在这个框架中，所有变量都被对称对待。 它们都被建模，就好像它们都平等地相互影响。 在更正式的术语中，所有变量现在都被视为“内生的”。 为了表示这一点，我们现在改变符号并将所有变量写为 y s： $y_{1,t}$表示变量$y_1$的第 t 次观察.$y_{2,t}$表示变量 y 2 的第 t 次观察，依此类推。

VAR 模型是用于预测时间序列向量的单变量自回归模型的推广。 它包括系统中的每个变量一个方程。 每个方程的右侧包括一个常数和系统中所有变量的滞后。 为简单起见，我们将考虑一个滞后的两变量 VAR。 我们将二维 VAR(1) 模型写为

$\begin{align}  y_{1,t} &= c_1+\phi _{11,1}y_{1,t-1}+\phi _{12,1}y_{2,t-1}+\varepsilon_{1,t} \\  y_{2,t} &= c_2+\phi _{21,1}y_{1,t-1}+\phi _{22,1}y_{2,t-1}+\varepsilon_{2,t},  \end{align}$

其中ε 1 , t 和ε 2 , t 是可能同时相关的白噪声过程。 系数 $\phi_{ii,\ell}$捕捉变量 y i 的第 $\ell$个滞后对其自身的影响，而系数 ϕ i j , ℓ 捕捉变量 y j 的第 ℓ 个滞后对 y i 的影响。

如果序列是平稳的，我们通过直接将 VAR 拟合到数据（称为“水平 VAR”）来预测它们。 如果序列是非平稳的，我们取数据的差异以使它们平稳，然后拟合 VAR 模型（称为“差异中的 VAR”）。 在这两种情况下，模型都是使用最小二乘原理逐个方程估计的。 对于每个方程，通过最小化$e_{i,t}$值的平方和来估计参数。

另一种可能性超出了本节的范围，因此我们不在这里探讨，是该系列可能是非平稳但协整的，这意味着它们存在平稳的线性组合。 在这种情况下，应包括包含误差校正机制（通常称为向量误差校正模型）的 VAR 规范，(见下文协整分析)并应使用最小二乘估计的替代估计方法

预测是从 VAR 以递归方式生成的。  VAR 为系统中包含的每个变量生成预测。 为了说明这个过程，假设我们已经拟合了方程 中描述的二维 VAR(1) 模型，适用于时间 T 之前的所有观测值。 然后通过以下方式生成一步预测：

$\begin{align*}  \hat y_{1,T+1|T} &=\hat{c}_1+\hat\phi_{11,1}y_{1,T}+\hat\phi_{12,1}y_{2,T} \\  \hat y_{2,T+1|T} &=\hat{c}_2+\hat\phi _{21,1}y_{1,T}+\hat\phi_{22,1}y_{2,T}. \end{align*}$

使用 VAR 进行预测时，必须做出两个决定，即系统中应包含多少变量（由 K 表示）和多少滞后（由 p 表示）。 要在 VAR 中估计的系数数量等于$K+pK^2$（或每个方程 1 + p K）。 例如，对于 K = 5 个变量和 p = 3 个滞后的 VAR，每个方程有 16 个系数，总共需要估计 80 个系数。 需要估计的系数越多，进入预测的估计误差就越大。

在实践中，通常保持 K 较小并且仅包含彼此相关的变量，因此可用于相互预测。 信息标准通常用于选择要包括的滞后数。 使用 AICc 时应该小心，因为它倾向于选择大量的滞后； 相反，**对于 VAR 模型，我们经常使用 BIC 代替**。 该模型的更复杂版本是“稀疏 VAR”（其中许多系数设置为零）； 另一种方法是使用“收缩估计”（其中系数较小）。

 VAR 面临的一个批评是它们是无理论的； 也就是说，它们不是建立在对方程施加理论结构的经济理论之上。 假设每个变量都会影响系统中的每个其他变量，这使得对估计系数的直接解释变得困难。 尽管如此，VAR 在多种情况下还是很有用的：

1. 预测不需要明确解释的相关变量的集合； 
2. 测试一个变量是否对预测另一个变量有用（格兰杰因果检验的基础）； 
3. 脉冲响应分析，分析一个变量对另一个变量的突然但暂时的变化的响应； 
4. 预测误差方差分解，其中每个变量的预测方差的比例归因于其他变量的影响。

##### Bootstrapping and bagging

Bootstrapping time series：

在前文节中，我们引导时间序列的残差，以便使用模型模拟序列的未来值。

更一般地说，我们可以使用另一种类型的引导程序生成与我们观察到的序列相似的新时间序列。

首先，必要时对时间序列进行转换，然后使用 STL 将其分解为趋势、季节性和剩余部分。 然后我们获得剩余部分的混洗版本以获得引导的剩余系列。 因为 STL 余数序列中可能存在自相关，所以我们不能简单地使用 5.5 节中描述的重绘过程。 相反，我们使用“blocked bootstrap”，其中时间序列的连续部分被随机选择并连接在一起。 这些自举剩余序列被添加到趋势和季节性分量中，并反转转换以给出原始时间序列的变化。

袋装预测：

这些自举时间序列的一种用途是提高预测准确性。 如果我们从每个额外的时间序列中生成预测，并对结果预测进行平均，我们会得到比直接直接预测原始时间序列更好的预测。 这称为“装袋”，代表“引导程序聚合”。 

#### 多元时间序列

多元时间序列的一些计算使用蔡瑞胸(R.S. Tsay)教授的MTS扩展包

经济的全球一体化和信息传播的发展使得各国的金融市场相互关联， 一个市场的价格变动可以很快地扩散到另一个市场。 持有多个资产的投资者也希望了解多个资产的收益率之间的关系。 这些问题属于多元时间序列分析的范畴。

多元时间序列包含多个一元时间序列作为分量， 各个一元时间序列的采样时间点相同， 所以数据可以用矩阵形式表示， 每行为一个时间点， 每列为一个一元时间序列。 在R中可以保存为矩阵、数据框、ts或者xts时间序列对象。 设$\boldsymbol r_t = (r_{1t}, \dots, r_{kt})^T$表示$k$个资产在$t$时刻的对数收益率。

一元时间序列的某些方法可以推广到多元情形， 但是有些问题需要注意。 某些情况下需要提出新的模型和方法。

##### 基础知识

多元时间序列分析中一个重要概念是引导与滞后关系。 为此， 用互相关阵来衡量时间序列之间的线性关系的强度。 元弱平稳列的滞后的互协方差阵定义为

$\begin{aligned} \Gamma_l = (\Gamma_{ij}(l))_{k \times k} = E[ (\boldsymbol r_t - \boldsymbol\mu) (\boldsymbol r_{t-l} - \boldsymbol\mu)^T ] \end{aligned}$

这是一元时间序列的自协方差函数$\gamma_l$的推广. $\Gamma_l$仅依赖于滞后$l$而与时刻$t$无关。

$k$元弱平稳列的滞后的互相关阵 (Cross Correlation Matrix, CCM)定义为:

$\begin{aligned} \boldsymbol\rho_l = (\rho_{ij}(l))_{k\times k} = D^{-1} \Gamma_l D^{-1} \end{aligned}$

其中:$\begin{aligned} \rho_{ij}(l) = \text{corr}(r_{it}, r_{j, t-l}) = \frac{\Gamma_{ij}(l)}{\sqrt{\Gamma_{ii}(0) \Gamma_{jj}(0)}} \end{aligned}$是$r_{it}$和$r_{j,t-1}$的相关系数。

不同于一元时间序列的自协方差满足$\gamma_l = \gamma_{-l}$， 对$k$元时间序列有

$\begin{aligned} \Gamma_{ij}(l) =& \text{Cov}(r_{it}, r_{j,t-l})  = \text{Cov}(r_{j,t-l}, r_{i,t}) = \text{Cov}(r_{j,t}, r_{i,t+l}) \\ =& \text{Cov}(r_{j,t}, r_{i,t-(-l)}) = \Gamma_{ji}(-l) \end{aligned}$

即：$\begin{aligned} \Gamma_{-l} = \Gamma_l^T \end{aligned}$,对互相关阵$\boldsymbol\rho_l$也有$\begin{aligned}
\boldsymbol\rho_{-l} = \boldsymbol\rho_l^T
\end{aligned}$,所以只需要考虑:$\boldsymbol\rho_l, l \geq 0$

##### 时间序列之间线性依存性分类

![image-20210905224019529](数模整理.assets/image-20210905224019529.png)

##### 多元混成检验

Hosking(1980,1981), Li和McLeod(1981) 已经把一元的Ljung-Box白噪声检验推广到了多元的情形。 对一个多元序列，检验零假设：$\begin{aligned} H_0: \boldsymbol\rho_1 = \dots = \boldsymbol\rho_m = \boldsymbol 0 \end{aligned}$

对立假设是不全为零矩阵。 这可以检验多元时间序列$\boldsymbol r_t$为宽白噪声的零假设， 即$\boldsymbol r_t$为弱平稳列且无序列自相关， 可以有同步的分量间相关。

使用检验统计量:$\begin{aligned} Q_k(m) = T^2 \sum_{l=1}^m \frac{1}{T-l} \text{tr}( \hat\Gamma_l^T \hat\Gamma_0^{-1} \hat\Gamma_l \hat\Gamma_0^{-1}) \end{aligned}$

`MTS::mq()`计算多元混成检验：

$Q_k(m)$统计量是对$\boldsymbol {r_t}$的前$m$个互相关阵的一个联合检验， 如果结果显著， 就应该建立多元的均值模型描述序列分量之间的领先–滞后关系。 **最常用的是向量自回归(VAR)模型**

#### 协整分析和向量误差修正模型

线性回归分析是统计学的最常用的模型之一， 但是， 如果回归的自变量和因变量都是时间序列， 回归就不满足回归分析的基本假定： 模型误差项独立同分布。

比如，一元线性回归模型

$y_t = a + b x_t + e_t, \ t=1,2,\dots,n,$

需要假定$e_1, e_2, \dots, e_t$不相关， 零均值，方差同为$\sigma^2$，$x_1, x_2, \dots, x_n$非随机， 这时最小二乘估计是无偏估计。当极限存在， 有正极限时估计相合。

如果$e_t,x_t,y_t$之中有时间序列， 则回归可能不相合， 或者估计相合但是回归结果中的标准误差估计和假设检验有错误。

##### 协整分析概念

对于二元时间序列$\boldsymbol x_{t} = (x_{1t}, x_{2t})^T$， 如果$x_{1t}$和$x_{2t}$都是一元单位根过程， 但存在非零线性组合$\boldsymbol\beta = (\beta_1, \beta_2)$使得$z_t = \beta_1 x_{1t} + \beta_2 x_{2t}$弱平稳， 则称两个分量$x_{1t}$和$x_{2t}$存在**协整**关系（cointegration）， $(\beta_1, \beta_2)^T$称为$\boldsymbol x_t$的**协整向量**。 多个分量的多元时间序列可以类似地定义协整关系， 多元时可以有多个协整向量。

##### Engle和Granger两阶段法

考虑两个分量的多元时间序列$\boldsymbol r_t$。 为了检验协整性， 首先要用一元的单位根检验（如ADF检验）确认两个分量都是单位根过程， 并且差分之后就没有单位根，这样的单位根过程称为“单整”的， 或I(1)序列。

其次，将$x_{1t}$当作因变量，$x_{2t}$当作自变量， 作一元线性回归，得到残差$e_t$序列， 和回归系数$\beta 1$，方程为$x_{1t} = \beta_0 + \beta_1 x_{2t} + e_t$

根据([R. R. Engle and Granger 1987](https://www.math.pku.edu.cn/teachers/lidf/course/fts/ftsnotes/html/_ftsnotes/References.html#ref-EngleGranger1987:cointegration))的研究， 回归在协整关系成立时参数估计相合， 但是系数的估计非正态， 所以用线性最小二乘估计得到的点估计可用， 但是结果中的t检验和F检验结果无效。

为了验证协整关系是否成立， 只要对序列进行一元的单位根检验， 但是因为是回归残差， 其自由度有变化， 所以统计量p值的计算需要进行调整， ([Phillips and Ouliaris 1990](https://www.math.pku.edu.cn/teachers/lidf/course/fts/ftsnotes/html/_ftsnotes/References.html#ref-Phillips1990:coint))给出了利用回归残差进行协整检验的方法， 称为Phillips-Ouliaris协整检验。 如果经检验不存在单位根， 则称两个分量是协整的。

这样的检验方法称为Engle和Granger两阶段法， 利用([Phillips and Ouliaris 1990](https://www.math.pku.edu.cn/teachers/lidf/course/fts/ftsnotes/html/_ftsnotes/References.html#ref-Phillips1990:coint))方法计算这个检验称为Phillips-Ouliaris协整检验。 但是，这里的两阶段， 其实第二阶段指的是在多元情况下需要找出所有的协整向量， 这需要利用向量误差修正模型(VECM)。

R扩展包tseries中`po.test()`可以执行基于EG两阶段法步骤的Phillips-Ouliaris协整检验， 零假设是非协整， 对立假设是存在协整关系。 参见([Phillips and Ouliaris 1990](https://www.math.pku.edu.cn/teachers/lidf/course/fts/ftsnotes/html/_ftsnotes/References.html#ref-Phillips1990:coint))。

##### 误差修正模型

因为在协整系统中， 单位根非平稳分量的个数多于单位根的个数 （通过线性组合可以使得单位根非平稳的分量减少）， 所以如果对每个单位根非平稳分量计算差分， 虽然使得分量都平稳了， 但是会造成过度差分， 使得部分分量的ARMA模型的MA部分有单位根， 这样的模型平稳但不可逆， 不可逆的模型在估计和预测上比较困难。

([R. R. Engle and Granger 1987](https://www.math.pku.edu.cn/teachers/lidf/course/fts/ftsnotes/html/_ftsnotes/References.html#ref-EngleGranger1987:cointegration))讨论了协整系统的误差修正表示， 称为向量误差修正模型(VECM, vector error correction model)。

#### 格兰格因果性

##### 介绍

考虑两个时间序列之间的因果性。 这里的因果性指的是时间顺序上的关系， 如果$X_{t-1}, X_{t-2}, \dots$对有作用， 而$Y_{t-1}, Y_{t-2}, \dots$对$X_t$没有作用， 则称是的格兰格原因， 而不是的格兰格原因。 如果对有作用， 对也有作用， 则在没有进一步信息的情况下无法确定两个时间序列的因果性关系。

注意这种因果性与采样频率有关系， 在日数据或者月度数据中能发现的领先——滞后性质的因果关系， 到年度数据可能就以及混杂在以前变成同步的关系了。

([C. W. J. Granger 1969](https://www.math.pku.edu.cn/teachers/lidf/course/fts/ftsnotes/html/_ftsnotes/References.html#ref-Granger1969:causal))首先提出了时间序列之间因果关系的概念。 时间序列因果关系可以是假设没有因果关系， 然后检验能否否定， 这是([C. W. J. Granger 1969](https://www.math.pku.edu.cn/teachers/lidf/course/fts/ftsnotes/html/_ftsnotes/References.html#ref-Granger1969:causal))的方法； 也可以是首先建立有因果关系的模型， 然后检验其中表示因果关系的参数是否不显著， 这是利用VAR和VECM的方法。 后一种方法首先提出于([Sims 1972](https://www.math.pku.edu.cn/teachers/lidf/course/fts/ftsnotes/html/_ftsnotes/References.html#ref-Sims1972:cause))。

在具有因果性的情况下， 可以用来改善预测。 比如， 如果是的格兰格原因， 则可以利用的现在与过去值、 的现在与过去值去预测的将来值， 会比仅利用的值预测要好， 这是认为的已有值中包含了的已有值中缺少的信息， 而这些信息对预测的将来值是有作用的。 ([C. W. J. Granger 1969](https://www.math.pku.edu.cn/teachers/lidf/course/fts/ftsnotes/html/_ftsnotes/References.html#ref-Granger1969:causal))的检验方法就是针对这一点进行检验。

在经济与金融时间序列建模中考虑对影响的另一个原因是， 许多时间序列具有较强的正自相关性， 比如单位根过程或者特征根接近于单位圆的ARMA模型， 对于这样的两个时间序列， 如果以为因变量， 为自变量作线性回归， 可能发生虚假的回归， 即使两个序列之间独立， 但是回归结果可以是显著的。 这是因为，与之间的强序列相关性。 如果在回归中引入滞后项， 这样的虚假回归就可以被消除。 参见([Clive W. J. Granger and Newbold 1974](https://www.math.pku.edu.cn/teachers/lidf/course/fts/ftsnotes/html/_ftsnotes/References.html#ref-Granger1974:spurious-reg))。

从因果性的角度讲， 只有两个序列的新息（innovation）对另一个序列的影响才是有意义的。 参见([Schwert 1979](https://www.math.pku.edu.cn/teachers/lidf/course/fts/ftsnotes/html/_ftsnotes/References.html#ref-Schwert1979:causality))。

#### 一些实际的预测问题

##### 每周、每日和次日数据

尽管出于不同的原因，每周、每日和次日数据对于预测来说可能具有挑战性。

每周数据 

每周数据很难处理，因为季节性周期（一年中的周数）既大又非整数。 一年中的平均周数为 52.18。 我们考虑过的大多数方法都要求季节性周期为整数。 即使我们将其近似为 52，大多数方法也无法有效地处理如此大的季节性周期。

 最简单的方法是使用 STL 分解以及应用于季节性调整数据的非季节性方法（如第 3 章所述）。 最简单的方法是使用 STL 分解以及应用于季节性调整数据的非季节性方法（如第 3 章所述）。 以下是一个示例，使用了 1991 年 2 月至 2005 年 5 月期间供应的美国成品车用汽油产品（以每天百万桶计）的每周数据。

```R
my_dcmp_spec <- decomposition_model(
  STL(Barrels),
  ETS(season_adjust ~ season("N"))
)
us_gasoline %>%
  model(stl_ets = my_dcmp_spec) %>%
  forecast(h = "2 years") %>%
  autoplot(us_gasoline) +
  labs(y = "Millions of barrels per day",
       title = "Weekly US gasoline production")
```

另一种方法是使用[动态谐波回归模型](#动态谐波回归)。 在以下示例中，通过最小化 AICc 来选择傅立叶项的数量。  ARIMA 模型的阶次也是通过最小化 AICc 来选择的，尽管这是在 ARIMA() 函数中完成的。 **我们使用 PDQ(0,0,0) 来防止 ARIMA() 尝试使用季节性 ARIMA 组件处理季节性**。

```R
gas_dhr <- us_gasoline %>%
  model(dhr = ARIMA(Barrels ~ PDQ(0, 0, 0) + fourier(K = 6)))
  
gas_dhr %>%
  forecast(h = "2 years") %>%
  autoplot(us_gasoline) +
  labs(y = "Millions of barrels per day",
       title = "Weekly US gasoline production")
```

拟合模型有 6 对傅立叶项，可以写成:$y_t = bt + \sum_{j=1}^{6}    \left[      \alpha_j\sin\left(\frac{2\pi j t}{52.18}\right) +      \beta_j\cos\left(\frac{2\pi j t}{52.18}\right)    \right] +    \eta_t$

其中$\eta_t$是 ARIMA(0,1,1) 过程。 因为$\eta_t$是非平稳的，所以模型实际上是根据这个方程两边变量的差异来估计的。 有 12 个参数来捕捉季节性，而总自由度数为 14（另外两个来自 MA 参数和漂移参数）。

选择方法：

当季节性随时间变化时，STL 方法更可取。 

如果存在作为有用预测变量的协变量，则动态谐波回归方法更可取，因为这些变量可以作为额外的回归变量添加。

每日和次日数据：
每日和次日（例如每小时）数据由于不同的原因而具有挑战性——它们通常涉及多种季节性模式，因此我们需要使用一种方法来处理如此复杂的季节性。

当然，如果时间序列相对较短，以至于只存在一种季节性，那么可以使用我们在前几章中讨论过的单季节性方法之一（例如，ETS 或季节性 ARIMA 模型）  . 但是当时间序列足够长以至于某些较长的季节性周期变得明显时，就需要使用 STL、动态谐波回归或 Prophet，如上文所述。

然而，这些方法只允许有规律的季节性。 捕捉与复活节、身份证或农历新年等活动事件相关的季节性更加困难。 即使使用月度数据，这也可能很棘手，因为节日可能在 3 月或 4 月（复活节）、1 月或 2 月（农历新年）或一年中的任何时间（Id）。

处理移动假期效应的最佳方法是在模型中包含虚拟变量。 例如，**这可以在 ARIMA() 或 prophet() 函数中完成，但不能在 ETS() 中完成**。 事实上，prophet() 有一个特殊的holiday() 可以很容易地结合假日效果。

##### 计数的时间序列

本书中讨论的所有方法都假设数据具有连续的样本空间。 但数据通常以计数的形式出现。 例如，我们可能希望预测每天进入商店的顾客数量。 我们可以有 0 , 1 , 2 , ... 客户，但我们不能有 3.45693 个客户。

在实践中，只要我们的计数足够大，这很少有问题。 如果最小客户数至少为 100，那么连续样本空间 [ 100 , ∞ ) 和离散样本空间 { 100 , 101 , 102 , ... } 之间的差异对我们的预测没有明显影响。 但是，如果我们的数据包含小计数（ 0 , 1 , 2 , … ），那么我们需要使用更适合非负整数样本空间的预测方法。

 此类模型超出了本章的范围。 但是，有一种简单的方法可以在这种情况下使用，我们想提一下。 它是“克罗斯顿方法”，以其英国发明者约翰克罗斯顿的名字命名，并在克罗斯顿 (1972) 中首次描述。 其实这个方法也没有很好地处理数据的计数性质，但是它使用的太频繁了，值得了解一下。

使用 Croston 的方法，我们通过注意哪些时间段包含零值以及哪些时间段包含非零值，从原始时间序列构建两个新序列。 令$q_i$为第$i$个非零量，令$a_i$为$q_{i-1}$和 $q_i$之间的时间。  Croston 的方法涉及对两个新序列 a 和 q 进行单独的简单指数平滑预测。 因为该方法通常应用于物品需求的时间序列，所以 q 通常被称为“需求”和“到达间隔时间”。

如果$\hat{q}_{i+1|i}$和$\hat{a}_{i+1|i}$分别是第 (i + 1 ) 次需求和到达间隔时间的一步预测，基于直到需求 i 的数据，那么 Croston 的方法给出:

$\begin{align}  \hat{q}_{i+1|i} & = (1-\alpha_q)\hat{q}_{i|i-1} + \alpha_q q_i\\  \hat{a}_{i+1|i} & = (1-\alpha_a)\hat{a}_{i|i-1} + \alpha_a a_i.  \end{align}$

平滑参数$\alpha_a$和$\alpha_q$取值介于 0 和 1 之间。让 j 是最后观察到的正观察的时间。 那么在时间 T + h 时对需求的 h 步提前预测，由比率$\begin{equation}  \hat{y}_{T+h|T} = \hat{q}_{j+1|j}/\hat{a}_{j+1|j}. \end{equation}$给出

没有代数结果允许我们计算该方法的预测区间，因为该方法不对应于任何统计模型 (Shenstone & Hyndman, 2005)。

CROSTON() 函数使用 Croston 的方法生成预测。 两个平滑参数$\alpha_a$和$\alpha_q$是从数据中估计出来的。 这与克罗斯顿设想的方法不同。

##### 确保预测保持在限制范围内

通常希望预测为正值，或要求它们在某个指定范围 [a , b ] 内。 使用转换处理这两种情况都相对容易。

正向预测：

为了施加正面约束，我们可以简单地在对数尺度上工作。 例如，考虑一打鸡蛋的实际价格（1900-1993 年；以美分计）。 由于对数变换，预测分布被限制为保持正数，因此随着均值的降低，它们将逐渐变得更加偏斜。

```R
egg_prices <- prices %>% filter(!is.na(eggs))
egg_prices %>%
  model(ETS(log(eggs) ~ trend("A"))) %>%
  forecast(h = 50) %>%
  autoplot(egg_prices) +
  labs(title = "Annual egg prices",
       y = "$US (in cents adjusted for inflation) ")
```

预测受限于一个区间:

要了解如何处理受限于区间的数据，假设鸡蛋价格被限制在 a = 50 和 b = 400 之内。 然后我们可以使用缩放 logit 变换来变换数据，该变换将 ( a , b ) 映射到整条实线：$y = \log\left(\frac{x-a}{b-x}\right),$，其中 x 在原始尺度上，y 是变换后的数据。 为了反转变换，我们将使用$x  = \frac{(b-a)e^y}{1+e^y} + a.$。

这不是内置转换，因此我们需要首先设置转换函数。

```R
scaled_logit <- function(x, lower = 0, upper = 1) {
  log((x - lower) / (upper - x))
}
inv_scaled_logit <- function(x, lower = 0, upper = 1) {
  (upper - lower) * exp(x) / (1 + exp(x)) + lower
}
my_scaled_logit <- new_transformation(
                    scaled_logit, inv_scaled_logit)
egg_prices %>%
  model(
    ETS(my_scaled_logit(eggs, lower = 50, upper = 400)
          ~ trend("A"))
  ) %>%
  forecast(h = 50) %>%
  autoplot(egg_prices) +
  labs(title = "Annual egg prices",
       y = "$US (in cents adjusted for inflation) ")
```

此处会自动应用偏差调整，并且这些变换的预测区间具有与变换尺度上相同的覆盖概率，因为分位数在单调递增变换下得以保留。

由于转换，预测区间高于 50。 由于这种人为（且不切实际）的约束，预测分布变得极度偏斜。

##### 预测组合

提高预测准确性的一种简单方法是对同一时间序列使用几种不同的方法，并对结果预测进行平均。  50 多年前，John Bates 和 Clive Granger 撰写了一篇著名的论文（Bates & Granger，1969 年），表明组合预测通常会带来更好的预测准确性。 二十年后，Clemen (1989) 写道，结果几乎是一致的：结合多种预测可以提高预测准确性。 在许多情况下，只需对预测进行平均，就可以显着提高性能。

虽然已经有大量关于使用加权平均或其他一些更复杂的组合方法的研究，但使用简单的平均已经证明很难被击败。

例子：

```R
auscafe <- aus_retail %>%
  filter(stringr::str_detect(Industry, "Takeaway")) %>%
  summarise(Turnover = sum(Turnover))
train <- auscafe %>%
  filter(year(Month) <= 2013)
STLF <- decomposition_model(
  STL(log(Turnover) ~ season(window = Inf)),
  ETS(season_adjust ~ season("N"))
)
cafe_models <- train %>%
  model(
    ets = ETS(Turnover),
    stlf = STLF,
    arima = ARIMA(log(Turnover))
  ) %>%
  mutate(combination = (ets + stlf + arima) / 3)
cafe_fc <- cafe_models %>%
  forecast(h = "5 years")
```

请注意，我们通过简单地采用估计模型的线性函数在 mutate() 函数中形成了一个组合。 这种非常简单的语法将通过考虑所包含模型的预测误差之间的相关性自动适当地处理预测分布。

对区间的预测省略

##### 聚合的预测区间

一个常见的问题是使用适合分解数据的模型来预测多个时间段数据的聚合。 例如，我们可能有月度数据，但希望预测下一年的总数。 或者我们可能有每周数据，并希望预测接下来四个星期的总数。

如果点预测是均值，那么将它们相加可以很好地估计总数。 但是由于预测误差之间的相关性，预测区间更加棘手。

 一般的解决方案是使用模拟。 （例子见原书）

##### 倒推

有时“回溯”时间序列是有用的——即逆时预测。 尽管没有内置的 R 函数来执行此操作，但通过创建新的时间索引很容易实现。

##### 很长很短的时间序列

预测非常短的时间序列：

我们经常被问到可以使用多少数据点来拟合时间序列模型。 与几乎所有样本量问题一样，没有简单的答案。 它取决于要估计的模型参数的数量和数据中的随机性数量。 所需的样本大小随着要估计的参数数量和数据中的噪声量而增加。

 一些教科书提供了经验法则，给出了各种时间序列模型的最小样本量。 这些在理论或实践中具有误导性且未经证实。 此外，他们忽略了数据的潜在可变性，并且经常忽略要估计的参数数量。 例如，对于 ARIMA 建模通常给出的最小值 30 的幻数没有任何理由。 唯一的理论限制是我们需要比预测模型中的参数更多的观察。 然而，在实践中，我们通常需要比这更多的观察。

理想情况下，我们会测试我们选择的模型与一些更简单的方法相比是否在样本外表现良好。 然而，对于短序列，没有足够的数据允许为了测试目的而保留一些观察结果，甚至时间序列交叉验证也很难应用。  AICc 在这里特别有用，因为它是一步预测样本外 MSE 的代理。 选择具有最小 AICc 值的模型可以同时考虑参数数量和噪声量。

短序列往往发生的情况是 AICc 建议使用简单的模型，因为任何具有超过一两个参数的参数都会由于估计错误而产生较差的预测。 

预测很长的时间序列：

大多数时间序列模型不适用于很长的时间序列。 问题是真实数据并非来自我们使用的模型。 当观察的数量不是很大（比如大约 200）时，模型通常可以很好地作为生成数据的任何过程的近似值。 但最终我们将有足够的数据，真实过程和模型之间的差异开始变得更加明显。 另一个问题是参数的优化变得更加耗时，因为所涉及的观察次数较多。

如何处理这些问题取决于模型的目的。 可以使用更灵活和更复杂的模型，但这仍然假设模型结构将在整个数据周期内工作。 更好的方法通常是允许模型本身随时间变化。  **ETS 模型旨在通过允许趋势和季节性术语随时间演变来处理这种情况。 具有差分的 ARIMA 模型具有相似的属性。 但是动态回归模型不允许模型组件的任何演变**。

如果我们只对预测接下来的几次观察感兴趣，一种简单的方法是丢弃最早的观察结果，只对最近的观察结果拟合模型。 然后一个不灵活的模型可以很好地工作，因为没有足够的时间让关系发生实质性变化。

例如，我们将动态谐波回归模型拟合到 26 年的每周汽油产量。 假设季节性模式在近三年内保持不变可能是不现实的。 所以我们可以简单地将模型拟合到最近几年。

##### 预测训练集和测试集

通常，我们计算训练数据（“拟合值”）的一步预测和测试数据的多步预测。 然而，有时我们可能希望计算训练数据的多步预测，或测试数据的一步预测。

对训练数据的多步预测：

我们**通常将拟合值定义为对训练集的一步预测**，但类似的想法也可用于多步预测。 我们将说明使用 ARIMA 模型计算澳大利亚外卖食品支出的方法。 过去五年用于测试集，预测如图 13.9 所示。

```R
training <- auscafe %>% filter(year(Month) <= 2013)
test <- auscafe %>% filter(year(Month) > 2013)
cafe_fit <- training %>%
  model(ARIMA(log(Turnover)))
cafe_fit %>%
  forecast(h = 60) %>%
  autoplot(auscafe) +
  labs(title = "Australian food expenditure",
       y = "$ (billions)")
```

fitted() 函数有一个 h 参数，以允许在训练集上使用 h 步“拟合值”。 图 13.10 是对训练集的 12 步（一年）预测图。 由于该模型同时涉及季节性（滞后 12）和第一（滞后 1）差分，因此无法计算前几个观测值的这些预测。

```R
fits12 <- fitted(cafe_fit, h = 12)
training %>%
  autoplot(Turnover) +
  autolayer(fits12, .fitted, col = "#D55E00") +
  labs(title = "Australian food expenditure",
       y = "$ (billions)")
```

对测试数据的一步预测：

通常的做法是使用训练数据拟合模型，然后在测试数据集上评估其性能。 通常这样做的方式意味着对测试数据的比较使用不同的预测范围。 在上面的例子中，我们使用了测试数据的最后六十个观测值，并在训练数据上估计了我们的预测模型。 那么预测误差将是提前 1 步、2 步、……、60 步。 预测方差通常随着预测范围的增加而增加，因此**如果我们只是对测试集的绝对误差或平方误差进行平均，我们就是在将结果与不同的方差相结合**。

此问题的一种解决方案是在测试数据上获得 1 步错误。 也就是说，我们仍然使用训练数据来估计任何参数，但是当我们计算测试数据的预测时，我们使用每个观测之前的所有数据（训练和测试数据）。 所以我们的训练数据是时间 1, 2, … , T − 60 。 我们在这些数据上估计模型，然后计算$\hat{y}_{T-60+h|T-61+h}$，对于$h=1,\dots,T-1$。 因为没有使用测试数据来估计参数，所以这仍然给了我们一个“公平”的预测。

```R
cafe_fit %>%
  refit(test) %>%
  accuracy()
```

请注意，在这种情况下不会重新估计模型。 相反，先前获得的模型（并存储为 cafe_fit）将应用于测试数据。 因为模型没有重新估计，所以这里得到的“残差”实际上是一步预测误差。 因此，accuracy() 命令产生的结果实际上是在测试集上（尽管输出是“训练集”）。 **这种方法可用于比较来自不同模型的一步预测**。  

##### 处理异常值和缺失值

真实数据通常包含缺失值、异常观测值和其他杂乱的特征。 与他们打交道有时会很麻烦。

异常值:

异常值是与时间序列中的大多数观察结果非常不同的观察结果。 它们可能是错误，也可能只是不寻常。  （有关回归上下文中异常值的讨论，请参见第 7.3 节。）如果数据中存在极端异常值，我们在本书中考虑的任何方法都不会奏效。 在这种情况下，我们可能希望用缺失值或与大多数数据更一致的估计值来替换它们。

简单地替换异常值而不考虑它们发生的原因是一种危险的做法。 它们可能提供有关产生数据的过程的有用信息，在预测时应予以考虑。 但是，如果我们愿意假设异常值确实是错误，或者它们不会在预测期内发生，那么替换它们可以使预测任务更容易。

图 13.11 显示了南澳大利亚阿德莱德山地区的游客人数。  2002 年第四季度似乎有一个不寻常的观察结果。

```R
tourism %>%
  filter(
    Region == "Adelaide Hills", Purpose == "Visiting"
  ) %>%
  autoplot(Trips) +
  labs(title = "Quarterly overnight trips to Adelaide Hills",
       y = "Number of trips")
```

查找异常值的一种有用方法是将 STL() 应用于参数为robust=TRUE 的系列。 然后任何异常值都应该出现在剩余系列中。 图 13.11 中的数据几乎没有明显的季节性，因此我们将通过设置 period=1 来应用没有季节性成分的 STL。

```R
ah_decomp <- tourism %>%
  filter(
    Region == "Adelaide Hills", Purpose == "Visiting"
  ) %>%
  # Fit a non-seasonal STL decomposition
  model(
    stl = STL(Trips ~ season(period = 1), robust = TRUE)
  ) %>%
  components()
ah_decomp %>% autoplot()
```

在上面的例子中，异常值很容易识别。 在更具挑战性的情况下，使用剩余系列的箱线图会很有用。 我们可以从数据的中心 50% 中识别出大于 1.5 四分位距 (IQR) 的异常值。 如果余数呈正态分布，则每 1000 个观测值中将显示 7 个为“异常值”。 **更严格的规则是将离群值定义为距离中心 50% 的数据大于 3 个四分位距 (IQR) 的离群值**，这将使 500,000 个正态分布观测值中只有 1 个为离群值。 这是我们更喜欢使用的规则。

```R
outliers <- ah_decomp %>%
  filter(
    remainder < quantile(remainder, 0.25) - 3*IQR(remainder) |
    remainder > quantile(remainder, 0.75) + 3*IQR(remainder)
  )
outliers
```

这找到了我们从图 13.11 中怀疑的一个异常值。 类似的东西可以应用于完整数据集，以识别其他系列中的异常观察。

缺失值:

数据缺失的原因有很多，值得考虑的是，缺失是否会导致预测模型出现偏差。 例如，假设我们正在研究一家商店的销售数据，当商店关门时，公共假期会出现缺失值。 结果，第二天的销售额可能会增加。 如果我们的预测模型没有考虑到这一点，我们很可能会低估公众假期后第一天的销售额，但高估之后几天的销售额。 处理这种情况的一种方法是使用动态回归模型，其中虚拟变量指示当天是公共假期还是公共假期后的第二天。 没有自动化方法可以处理这种影响，因为它们取决于特定的预测环境。

在其他情况下，缺失可能本质上是随机的。 例如，有人可能忘记记录销售数字，或者数据记录设备可能出现故障。 如果缺失数据的时间不能为预测问题提供信息，则可以更轻松地处理缺失值。

最后，我们可能会删除一些不寻常的观察结果，从而在系列中创建缺失值。

有些方法允许缺失值没有任何问题。 例如，朴素预测方法继续有效，最近的非缺失值提供对未来时间段的预测。 同样，当历史数据中存在缺失值时，第 5.2 节中介绍的其他基准方法都会产生预测。  **ARIMA 模型、动态回归模型和 NNAR 模型等fable函数也将正常工作而不会导致错误**。 但是，其他建模函数不处理缺失值，包括 ETS() 和 STL()。

 当缺失值导致错误时，至少有两种方法可以处理该问题。 首先，**假设有足够长的观察序列来产生有意义的预测，我们可以只取最后一个缺失值之后的数据部分。 或者，我们可以通过首先拟合 ARIMA 模型，然后使用该模型对缺失的观测值进行插值来用估计值替换缺失值**。

我们将用 ARIMA 模型的估计替换图 13.12 中识别的异常值。

```R
ah_miss <- tourism %>%
  filter(
    Region == "Adelaide Hills",
    Purpose == "Visiting"
  ) %>%
  # Remove outlying observations
  anti_join(outliers) %>%
  # Replace with missing values
  fill_gaps()
ah_fill <- ah_miss %>%
  # Fit ARIMA model to the data containing missing values
  model(ARIMA(Trips)) %>%
  # Estimate Trips for all periods
  interpolate(ah_miss)
ah_fill %>%
  # Only show outlying periods
  right_join(outliers %>% select(-Trips))
```

interpolate() 函数使用 ARIMA 模型来估计序列中的任何缺失值。 现在可以使用不允许缺失值的函数对 ah_fill 数据进行建模。

```R
ah_fill %>%
  autoplot(Trips) +
  autolayer(ah_fill %>% filter_index("2002 Q3"~"2003 Q1"),
    Trips, colour="#D55E00") +
  labs(title = "Quarterly overnight trips to Adelaide Hills",
       y = "Number of trips")
```
