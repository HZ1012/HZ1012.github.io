---
layout:     post                    # 使用的布局（不需要改）
title:      数模整理              # 标题 
subtitle:   beauty of math #副标题
date:       2022-02-27              # 时间
author:     HZ                      # 作者
header-img: img/a beautiful mind.jpg    #这篇文章标题背景图片
catalog: true                       # 是否归档
tags:                               #标签
    - 学习
---
# 从虚拟变量创建一个因子数模整理

[TOC]



## 前言

本文作于2021年暑期，目的是为了准备21年国赛，分为心得和模型两部分，由于准备以C题为主.

## 心得

### [研究问题和相应的统计测试](http://www.sthda.com/english/articles/31-principal-component-methods-in-r-practical-guide/117-hcpc-hierarchical-clustering-on-principal-components-essentials/)

1. 是否**两个变量**（N = 2）的**相关性**（即，相关联）
2. 是否**多个变量**（N> 2）的**相关**
3. 是否**两组**样本（N = 2）彼此**不同**
4. 是否**多组**（N> = 2）样本彼此**不同**
5. 两个样本的**变异性**是否不同

使用以下统计测试来回答：

1. 两个变量之间的**相关性检验**

2. 多个变量之间的**相关矩阵**

3. 比较两组的均值

   ：

   - **学生 t 检验**（参数）
   - **Wilcoxon 秩检验**（非参数）

4. 比较两组以上的均值

   - **ANOVA 检验**（方差分析，参数）：t 检验的扩展以比较两个以上的组。
   - **Kruskal-Wallis 秩和检验**（非参数）：Wilcoxon 秩检验的扩展以比较两个以上的组

5. 比较方差

   ：

   - 比较两组的方差：**F-test**（参数）
   - 两组以上方差的比较：**Bartlett's test**（参数）、**Levene's test**（参数）和**Fligner-Killeen test**（非参数）

注：参数方法需满足统计假设：

- 数据呈**正态分布**
- 并且要比较的组的**方差齐次**（相等）

正态性：（n>30）中心极限/**Shapiro-Wilk** 显著性检验

方差齐次：例如**学生 t 检验**（比较两个独立样本）和方差分析检验（比较多个样本）还假设要比较的样本具有相等的方差，在已知样本遵循正态分布的情况下

- 比较两个样本方差的 **F 检验**
- **Bartlett 检验**或**Levene 检验**来比较多个样本的方差

### [聚类标准差](https://datascience.blog.wzb.eu/2021/05/18/clustered-standard-errors-with-r/#refs)

在许多情况下，数据是按组或集群结构化的，例如 班级内（学校内）的学生、国家内的调查受访者，或者对于纵向调查，每个主题的调查答案。 简单地忽略这种结构可能会导致虚假的低标准误差，即对我们系数的误导性精确估计。 这反过来又会导致置信区间过窄、p 值过低以及可能得出错误的结论。

聚类标准错误(*Clustered standard errors* )是处理此问题的常用方法。 与 Stata 不同，R 没有内置功能来估计聚类标准误差。 尽管有几个包添加了此功能，本文将介绍其中的三个，解释如何使用它们以及它们的优缺点。

### [相关分析](http://www.sthda.com/english/wiki/correlation-analyses-in-r)

1. [R中两个变量之间的相关性测试](http://www.sthda.com/english/wiki/correlation-test-between-two-variables-in-r)
   - 使用函数**cor.test** (x,y) 分析两个变量之间的相关系数并获得相关性的显着性水平。
   - 使用函数**cor.test** (x,y) 的三种可能的相关方法：pearson、kendall、spearman
2. [相关矩阵：分析、格式化和可视化](http://www.sthda.com/english/wiki/correlation-matrix-a-quick-start-guide-to-analyze-format-and-visualize-a-correlation-matrix-using-r-software)
   - 使用**cor** ()函数进行简单的**相关分析**
   - 使用**rcorr**从（）函数**Hmisc**包来计算**相关系数的矩阵**和**p值的矩阵**在单个步骤。
   - 使用**symnum** ()、**corrplot** ()[来自**corrplot**包]、**chart.Correlation** () [来自**PerformanceAnalytics**包]、ggpairs[来自GGally],或**heatmap** () 函数来可视化**相关矩阵**。

3. [使用相关图可视化相关矩阵](http://www.sthda.com/english/wiki/visualize-correlation-matrix-using-correlogram)
   - 使用**cor()**函数计算**相关矩阵**。
   - 使用**lower.tri()**和**upper.tri()**函数获取**相关矩阵**的下半部分或上半部分
   - 使用**xtable** R 函数以**Latex**或 html 格式显示一个很好的相关矩阵

4. [使用 xtable R 包的优雅相关表](http://www.sthda.com/english/wiki/elegant-correlation-table-using-xtable-r-package)

5. [相关矩阵：一个 R 函数来完成你需要的一切](http://www.sthda.com/english/wiki/correlation-matrix-an-r-function-to-do-all-you-need)

### **比较均值**

- 将单样本均值与标准已知均值进行比较：

  - [单样本 T 检验（参数）](http://www.sthda.com/english/wiki/one-sample-t-test-in-r)

    **单样本 t 检验**用于将一个样本的**平均值**与已知标准（或**理论/假设**）**平均值**比较

  - [单样本 Wilcoxon 检验（非参数）](http://www.sthda.com/english/wiki/one-sample-wilcoxon-signed-rank-test-in-r)

    数据不是正态分布时使用（中位数）

- 比较两个独立组的均值：

  - [未配对的两个样本 T 检验（参数）](http://www.sthda.com/english/wiki/unpaired-two-samples-t-test-in-r)

    用于比较两个独立组的均值

  - [未配对的两样本 Wilcoxon 检验（非参数）](http://www.sthda.com/english/wiki/unpaired-two-samples-wilcoxon-test-in-r)

    数据不是正态分布时使用（中位数）

- 比较配对样本的均值：

  - [配对样本 T 检验（参数）](http://www.sthda.com/english/wiki/paired-samples-t-test-in-r)

    用于比较两个相关组的均值，例如治疗前和治疗后小鼠的平均体重

  - [配对样本 Wilcoxon 检验（非参数）](http://www.sthda.com/english/wiki/paired-samples-wilcoxon-test-in-r)

    数据不是正态分布时使用（中位数）

- 比较两组以上的均值

  - 方差分析（ANOVA，参数）：

    - [R 中的单向方差分析测试](http://www.sthda.com/english/wiki/one-way-anova-test-in-r)

      未配对T检验的多组延申，

      前提：各因子水平数据正态分布、同方差

      以及tukey多重配对比较

      同方差可放宽**oneway.test** ()

    - [R 中的双向 ANOVA 检验](http://www.sthda.com/english/wiki/two-way-anova-test-in-r)

      同时评估两个分组变量（A 和 B）对响应变量的影响，

      前提：正态分布、同方差，

      分为平衡设计和不平衡设计**Anova** () 

    - [R 中的 MANOVA 检验：方差的多变量分析](http://www.sthda.com/english/wiki/manova-test-in-r-multivariate-analysis-of-variance)

      在多个响应变量的情况下，使用**多元方差分析**( **MANOVA** )同时测试它们，例如：进行一个实验，对两组小鼠进行两种处理（A 和 B），对小鼠的体重和身高感兴趣。在这种情况下，小鼠的体重和身高是两个因变量。

      前提：因变量应在组内正态分布**mshapiro.test** ( )，预测变量同方差，线性关系

  - [R 中的 Kruskal-Wallis 检验（单向方差分析的非参数替代方案）](http://www.sthda.com/english/wiki/kruskal-wallis-test-in-r)

    不满足单向方差分析时使用

    使用**pairwise.wilcox.test** () 计算组级别之间的成对比较，并进行多次测试的校正



#### 比较差异

- [F 检验：比较 R 中的两个方差](http://www.sthda.com/english/wiki/f-test-compare-two-variances-in-r)

  用于检验方差是否相等，或者新方法是否减少旧方法的可变性

  前提：正态分布

- [比较 R 中的多个样本方差](http://www.sthda.com/english/wiki/compare-multiple-sample-variances-in-r)

  - **Bartlett's test**：比较k个样本的方差，其中k可以是两个以上的样本。数据必须是正态分布的。
  - **Levene's test**：比较k组样本的方差，其中k可以是两组以上的样本。它是 Bartlett 检验的一种替代方法，它对偏离正态性不太敏感。
  - **Fligner-Killeen 检验**：一种非参数检验，对于偏离正态性非常稳健。

#### 比较比例

- [R 中的比例 Z 检验：将观察到的比例与预期的比例进行比较](http://www.sthda.com/english/wiki/one-proportion-z-test-in-r)

  用途：将观察到的比例与理论比例进行比较

  例：我们有一群老鼠，其中一半是雄性，一半是雌性（p = 0.5 = 50%）。其中一些小鼠 (n = 160) 发生了自发性癌症，包括 95 只雄性和 65 只雌性，问癌症对男性的影响是否大于对女性的影响？

  注意：np>.5时有效

- [R 中的两个比例 Z 检验：比较两个观察到的比例](http://www.sthda.com/english/wiki/two-proportions-z-test-in-r)

  用途：比较两个观测的比例

  例：A组肺癌个体，B组健康个体，统计吸烟比例，两组个体中吸烟者的比例是否相同？

  注意：np>.5时有效

  附：对于2×2表，标准卡方检验**chisq.test**（）完全等同于**prop.test**（）

- [R 中的卡方拟合优度检验：将多个观察到的比例与预期概率进行比较](http://www.sthda.com/english/wiki/chi-square-goodness-of-fit-test-in-r)

  用途：将多个观察到的比例与预期概率进行比较

  例：采集了野生郁金香，发现81朵是红色的，50朵是黄色的，27朵是白色的，收集数据的地区，红色、黄色和白色郁金香的比例为 3:2:1，观察到的比例和预期的比例之间是否存在显着差异？

- [R 中独立性的卡方检验：评估两个分类变量之间的关联](http://www.sthda.com/english/wiki/chi-square-test-of-independence-in-r)

  用途：分析列联表的关联性

  可视化：**balloonplot()** [gplots],mosaicplot（）[*garphics*],assoc[vcd]

  注意：频数>5

  附：可以可视化Pearson残差，用于解释行和列的关联；且能计算给定类别对总卡方分数的贡献，并可视化

### 生存

##### [生存分析基础：曲线和对数检验](http://www.sthda.com/english/wiki/survival-analysis-basics)

生存分析是一组用于数据分析的统计方法，其中感兴趣的结果变量是事件发生前的时间。

生存数据通常根据两个相关函数进行描述和建模：

- 幸存者函数表示个体从起源时间到时间 t 之后的某个时间存活的概率。它通常由 Kaplan-Meier 方法估计。对数秩检验可用于检验组（例如治疗组）的生存曲线之间的差异。
- 危险函数给出了一次发生事件的瞬时潜力，并给出了到那个时间的生存者。它主要用作诊断工具或用于指定生存分析的数学模型

需要了解：

- 危险和生存函数的定义，
- 不同患者组Kaplan-Meier生存曲线的构建
- 用于比较两条或更多条生存曲线的对数秩检验

局限性：用于单变量分析，忽略了任何其他因素的影响，Kaplan-Meier 曲线和对数秩检验仅在预测变量是分类变量时才有用，对于基因表达、体重或年龄等定量预测因素，它们并不容易发挥作用。

##### [考克斯比例风险模型](http://www.sthda.com/english/wiki/cox-proportional-hazards-model)

目的：同时评估几个因素对生存的影响。换句话说，它使我们能够检查特定因素如何影响特定事件（例如感染、死亡）在特定时间点的发生率。这个比率通常被称为危险率。在生存分析文献中，预测变量（或因子）通常称为*协变量*

假设：1. 观察组（或患者）的风险曲线应该成比例且不能交叉，换句话说，如果一个人在某个初始时间点的死亡风险是另一个人的两倍，那么在以后的所有时间里，死亡风险仍然是另一个人的两倍

2. 连续协变量具有线性形式

##### [考克斯模型假设](http://www.sthda.com/english/wiki/cox-model-assumptions)

- 测试比例风险假设。
- 检查有影响的观察结果（或异常值）。
- 检测对数风险和协变量之间关系的非线性。

### 主成分方法

1. 基本

-  R 简介

#### [ 主成分方法的 R 包](http://www.sthda.com/english/articles/31-principal-component-methods-in-r-practical-guide/123-required-r-packages-for-principal-component-methods/)

#### 经典方法

##### [PCA - 主成分分析](http://www.sthda.com/english/articles/31-principal-component-methods-in-r-practical-guide/112-pca-principal-component-analysis-essentials/)，用于分析包含连续变量的数据集

主成分分析 (PCA) 使我们能够总结和可视化数据集中的信息，该数据集中包含由多个相互关联的定量变量描述的个人/观察结果。 每个变量都可以被视为不同的维度。 如果您的数据集中有 3 个以上的变量，则可能很难可视化多维超空间。

主成分分析用于从多元数据表中提取重要信息，并将此信息表示为一组称为主成分的少数新变量。 这些新变量对应于原始变量的线性组合。 主成分数小于或等于原始变量数。

给定数据集中的信息对应于它包含的总变异。  PCA 的目标是确定数据变化最大的方向（或主成分）。

换句话说，PCA 将多变量数据的维数减少到两个或三个主成分，这些主成分可以用图形方式可视化，信息损失最小。

如图 3.1 所示，此处使用的数据描述了运动员在两项体育赛事（Desctar 和 OlympicG）中的表现。 它包含由 13 个变量描述的 27 个人（运动员）。

![NeatReader-1631176091158](数模整理.assets/NeatReader-1631176091158.png)

请注意，只有其中一些个体和变量将用于执行主成分分析。 因子图上剩余个体和变量的坐标将在 PCA 之后进行预测。

##### [CA - 对应分析](http://www.sthda.com/english/articles/31-principal-component-methods-in-r-practical-guide/113-ca-correspondence-analysis-in-r-essentials/)，用于分析两个分类变量之间的关联。

对应分析 (CA) 是主成分分析的扩展，适用于探索定性变量（或分类数据）之间的关系。 与主成分分析一样，它提供了一种在二维图中汇总和可视化数据集的解决方案。

在这里，我们描述简单对应分析，它用于分析由两个分类数据形成的频率，一个数据表称为列联表。 它为列联表的行和列点提供因子分数（坐标）。 这些坐标用于以图形方式可视化列联表中行和列元素之间的关联。

 在分析双向列联表时，一个典型的问题是某些行元素是否与列元素的某些元素相关联。 对应分析是一种将双向列联表的行列可视化为低维空间中的点的几何方法，使得行列点的位置与其在表中的关联一致。 目的是对有助于解释的数据有一个全局视图。

在当前章节中，我们将展示如何使用两个 R 包计算和解释对应分析：i）用于分析的 FactoMineR 和 ii）用于数据可视化的 factoextra。 此外，我们将展示如何揭示解释数据集中变化的最重要变量。 我们继续解释如何使用补充行和列应用对应分析。 如果您想使用 CA 进行预测，这很重要。 本指南的最后部分还描述了如何过滤 CA 结果以仅保留最重要的变量。 最后，我们将看到如何处理异常值。

代码示例见补充模型

数据是一个列联表，其中包含 13 个家庭任务及其在夫妻中的重新分配：行是不同的任务，值是完成任务的频率：由妻子或仅由丈夫或共同完成

![NeatReader-1631175936390](数模整理.assets/NeatReader-1631175936390.png)



##### [MCA - 多重对应分析](http://www.sthda.com/english/articles/31-principal-component-methods-in-r-practical-guide/114-mca-multiple-correspondence-analysis-in-r-essentials/)，用于分析包含 2 个以上分类变量的数据集。

多重对应分析 (MCA) 是简单对应分析（CA）的扩展，用于汇总和可视化包含两个以上分类变量的数据表。 当要分析的变量是分类变量而不是定量变量时，它也可以看作是主成分分析的概括（Abdi 和 Williams 2010）。

 MCA 通常用于分析调查中的数据集。 目标是确定：

*  一组在回答问题时具有相似特征的个体 
* 变量类别之间的关联 

之前，我们描述了如何计算和解释简单对应分析（第 5 章）。 在当前章节中，我们将演示如何使用 FactoMineR（用于分析）和 factoextra（用于数据可视化）在 R 软件中计算和可视化多重对应分析。 此外，我们将展示如何揭示对解释数据集中的变化贡献最大的最重要变量。 我们继续解释如何预测补充个体和变量的结果。 最后，我们将演示如何过滤 MCA 结果以仅保留贡献最大的变量。

示例代码见补充模型

数据包含 55 行（个人）和 15 列（变量）。 我们将仅使用其中一些个体（儿童）和变量来执行多重对应分析。 因子图上剩余个体和变量的坐标将根据之前的 MCA 结果进行预测。

#### 高级方法

##### [FAMD - 混合数据的因子分析](http://www.sthda.com/english/articles/31-principal-component-methods-in-r-practical-guide/115-famd-factor-analysis-of-mixed-data-in-r-essentials/)，用于分析包含定量和定性变量的数据集。

混合数据的因子分析 (FAMD) 是一种主成分方法，专门用于分析包含定量和定性变量的数据集 (J. Pages 2004)。 通过考虑混合类型的变量，可以分析个体之间的相似性。 此外，人们可以探索所有变量之间的关联，包括定量和定性变量。

粗略地说，FAMD 算法可以看作是主成分分析（PCA）和多重对应分析（MCA）的混合体。 换句话说，它充当 PCA 定量变量和定性变量的 MCA。
    

定量和定性变量在分析过程中被标准化，以平衡每组变量的影响。

代码示例见补充模型：分析葡萄酒的特征。（取子集）

前两列是因子（分类变量）：标签（Saumur、Bourgueil 或 Chinon）和土壤（reference、Env1、Env2 或 Env4）。其余列是数字（连续变量）。

##### [MFA - 多因素分析](http://www.sthda.com/english/articles/31-principal-component-methods-in-r-practical-guide/116-mfa-multiple-factor-analysis-in-r-essentials/)

（J.Pagès 2002）是一种多变量数据分析方法，用于总结和可视化复杂数据表，其中个体由多组变量（定量和/或定性）组成。它考虑了所有活跃的变量组的贡献来定义个体之间的距离。

MFA 可被视为一般因素分析。 粗略地说，MFA 的核心基于：当变量为定量时，主成分分析，当变量为定性时，多重对应分析。

这种**同时考虑多组变量的全局分析需要平衡每组变量的影响**。 因此，在 MFA 中，变量在分析过程中被加权。 同一组中的变量使用相同的权重值进行标准化，这些权重值可能因一组而异。 从技术上讲，MFA 为组 j 的每个变量分配一个权重，该权重等于组 j 的分析（PCA 或 MCA，根据变量类型）的第一个特征值的倒数。

多因素分析可用于各种领域（J. Pages 2002），其中变量被组织成组： 

1. 调查分析，其中一个人是一个人； 变量是一个问题。 问题按主题（问题组）进行组织。

2. 感官分析，其中个人是食品。 第一组变量包括感官变量（甜味、苦味等）； 第二组包括化学变量（pH、葡萄糖率等）。

3. 生态学，其中一个人是一个观察场所。 第一组变量描述了土壤特征； 第二组描述植物群。

4. 时间序列，在不同的日期观察到几个人。 在这种情况下，通常有两种定义变量组的方法：

   通常，将同时（日期）观察到的变量聚集在一起。

   当变量从一个日期到其他日期都相同时，每个集合都可以为一个变量收集不同的日期。

  在当前章节中，我们将展示如何使用 FactoMineR（用于分析）和 factoextra（用于数据可视化）在 R 软件中计算和可视化多因素分析。 此外，我们将展示如何揭示对解释数据集中的变化贡献最大的最重要变量。

代码见R补充模型：**分析葡萄酒的特征**。

4. 聚类

- [ HCPC - 主成分的分层聚类](http://www.sthda.com/english/articles/31-principal-component-methods-in-r-practical-guide/117-hcpc-hierarchical-clustering-on-principal-components-essentials/)

  目的：

  - 有一个包含连续变量的大型数据集时，可以在层次聚类分析之前使用主成分分析来降低数据的维数。
  - 有一个包含分类变量的数据集时，可以使用（多个）对应分析将分类变量转换为几个连续的主成分，这些主成分可以用作聚类分析的输入

  进一步进行数据挖掘，识别出相似对象的组

  一般执行PCA、CA、MCA、FAMD、MFA后再用

  算法：

  1. `Compute principal component methods`：PCA、(M)CA 或 MFA 取决于数据集中变量的类型和数据集的结构。在这一步，通过指定参数*ncp*来选择要在输出中保留的维数。默认值为 5。
  2. `Compute hierarchical clustering`：使用 Ward 标准对选定的主成分执行分层聚类。Ward 准则用于层次聚类，因为它基于多维方差，如主成分分析。
  3. `Choose the number of clusters based on the hierarchical tree`：通过切割分层树来执行初始分区。
  4. `Perform K-means clustering`改进从层次聚类获得的初始分区。

### 聚类

#### [ 聚类分析基础](https://www.datanovia.com/?p=7641)：

- 用于聚类分析的数据准备和基本 R 包

- 聚类距离度量要点

  思考：选择什么类型的距离度量，欧几里得、相关性或者混合数据类型？

  是否要对数据标准化？

 

#### [分区聚类方法](https://www.datanovia.com/?p=7673)：

**分区聚类**是一种聚类方法，用于根据数据集中的观察结果的相似性将其分为多个组。算法要求分析师指定要生成的聚类数

- **K-means clustering** (MacQueen 1967)，其中，每个集群由属于该集群的数据点的中心或均值表示。K-means 方法对异常数据点和异常值很敏感。
  - 它假设数据的先验知识，并要求分析师提前选择适当数量的集群（k）
  - 获得的最终结果对聚类中心的初始随机选择很敏感。为什么会出现问题？因为，对于同一数据集上算法的每次不同运行，您可以选择不同的初始中心集。这可能会导致算法的不同运行产生不同的聚类结果。
  - 它对异常值很敏感。
  - 如果重新排列数据，很可能每次更改数据的顺序时都会得到不同的解决方案。
- **K-medoids 聚类**或**PAM**（*Partitioning Around* Medoids，Kaufman & Rousseeuw，1990），其中每个簇由簇中的一个对象表示。与 k 均值相比，PAM 对异常值不太敏感。
  - K-medoid 是 k-means 聚类的强大替代方案。这意味着，与 k-means 相比，该算法对噪声和异常值不太敏感，因为它使用 medoids 作为聚类中心而不是均值
  - 在 k-medoids 方法中，每个簇由簇内的选定对象表示。选定的对象被命名为中心点，并对应于集群中位于最中心的点。
  - PAM 算法要求用户了解数据并指明要生成的适当簇数。这可以使用函数*fviz_nbclust*进行估计。R函数*pam* ()[ *cluster* package]可用于计算PAM算法。简化格式为 pam(x, k)，其中“x”是数据，k 是要生成的簇数。
  - 之后，执行 PAM 聚类，可以使用 R 函数*fviz_cluster* () [ **factoextra**包] 来可视化结果
  - 注意，对于大数据集，*pam* ()可能需要太多的内存或太多的计算时间。在这种情况下，函数*clara* () 更可取。这对于现代计算机来说应该不是问题
- **CLARA 算法**（*Clustering Large Applications*），它是 PAM 的扩展，适用于大型数据集。
  - CLARA 不是为整个数据集寻找中心点，而是考虑具有固定大小 ( *sampsize* )的小数据样本，并应用 PAM 算法为样本生成最佳中心点集。生成的中心点的质量通过整个数据集中每个对象与其集群的中心点之间的平均差异来衡量，定义为成本函数
  - 格式：clara(x, k, metric = "euclidean", stand = FALSE,       samples = 5, pamLike = TRUE)

#### [层次聚类](https://www.datanovia.com/?p=7685)：

简介：层次聚类不需要预先指定要产生的聚类数量。层次聚类可以细分为两种类型：

1. *凝聚聚类*，其中每个观察最初都被认为是它自己的一个集群（叶子）。然后，依次合并最相似的集群，直到只有一个大集群（根）。

2. *划分聚类*，是凝聚聚类的逆向，从根开始，所有对象都包含在一个聚类中。然后依次划分最异构的簇，直到所有观察都在它们自己的簇中

凝聚聚类擅长识别小聚类。分裂聚类擅长识别大聚类。

R 包 cluster 使在 R 中执行聚类分析变得容易。它提供了函数 agnes() 和 diana() 用于计算凝聚和分裂聚类，

- 凝聚聚类

  - 算法和步骤

    聚聚类以“自下而上”的方式工作。也就是说，每个对象最初都被认为是一个单元素簇（叶子）。在算法的每一步，最相似的两个集群被组合成一个新的更大的集群（节点）。重复此过程，直到所有点都只是一个大集群（根）的成员

    注意：聚类方式选择时，ward和complete是首选

    只能根据首先融合包含这两个对象的分支的高度来得出关于两个对象的接近度的结论。我们不能使用两个对象沿水平轴的接近度作为它们相似性的标准

  - 验证簇树

    目的：评估树中的距离（即高度）是否准确反映了原始距离

    方法：计算*cophenetic*距离与*dist* () 函数生成的原始距离数据之间的相关性

  - 将树状图切割成不同的组

- 分裂聚类

- 比较树状图

  - 两个树状图的视觉比较
  - 树状图列表之间的相关矩阵

- 可视化树状图

  - 小数据集的案例
  - 具有大数据集的树状图案例：缩放、子树、PDF
  - 使用 dendexend 自定义树状图

- 热图：静态和交互式

  **热图**是另一种方式来可视化分级聚类。它也称为假彩色图像，其中数据值转换为色标。

  - R基础热图
  - 漂亮的热图
  - 交互式热图
  - 复杂的热图
  - 实际应用：基因表达数据

 

##### [聚类验证和评估策略](https://www.datanovia.com/?p=8058)：

- 评估聚类趋势

  简介：在对数据应用任何聚类方法之前，重要的是评估数据集是否包含有意义的聚类（即：非随机结构）。 如果是，那么有多少个集群。 这个过程被定义为聚类趋势的评估或聚类分析的可行性

  方法：霍普金斯统计hopkins() [clustertend package]：

  （测试数据的空间随机概率）原假设：数据集 D 是均匀分布的（即没有有意义的集群） •替代假设：数据集 D 不是均匀分布的 H值大约为.5表示均匀分布

  视觉评估(VAT 方法)：对聚类趋势进行视觉评估，VAT通过计算VAT图像中沿对角线的方形暗块的数量以视觉形式检测聚类趋势。

  

- 确定最佳簇数

  这些方法包括直接方法和统计检验方法： 

  1. 直接方法：包括优化标准，例如聚类内平方和或平均轮廓。 相应的方法分别命名为肘部方法和轮廓方法。

     肘部和平均轮廓方法的缺点是，它们仅测量全局聚类特征。 一种更复杂的方法是使用间隙统计，它提供了一种统计程序来形式化肘部/轮廓启发式，以估计最佳的聚类数。

     2. 统计检验方法：包括将证据与零假设进行比较。 一个例子是差距统计。

- 集群验证统计

  聚类验证统计可以分为 3 类：

  1. 内部聚类验证，它使用聚类过程的内部信息，在不参考外部信息的情况下评估聚类结构的优劣。 它还可以用于在没有任何外部数据的情况下**估计聚类数量和适当的聚类算法**。

     内部验证措施通常反映集群分区的紧凑性、连通性和分离性。

     两个常用指标：轮廓宽度（具有大 Si（几乎 1）的观测值非常好地聚集在一起）和邓恩指数（邓恩指数应该最大化）。 这些内部度量也可用于确定数据中的最佳聚类数。连通性的值介于 0 和无穷大之间，应将其最小化。


  2. 外部聚类验证，包括将聚类分析的结果与外部已知结果（例如外部提供的类标签）进行比较。 它测量集群标签与外部提供的类标签匹配的程度。 由于我们预先知道“真实”的聚类数，因此该方法主要用于**为特定数据集选择正确的聚类算法**。

     有两个指标来评估两个聚类的相似度，分别是修正后的Rand指标和Meila’s VI


  3. 相对聚类验证，通过改变相同算法的不同参数值来评估聚类结构（例如：改变聚类的数量 k）。 它通常用于**确定最佳聚类数**。

- 选择最佳聚类算法

  clValid package

  1. 内部度量，它使用数据中的内在信息来评估聚类的质量。 内部测量包括连通性、轮廓系数和 Dunn 指数，如上文（集群验证统计）中所述。

  2. 稳定性度量，一种特殊版本的内部度量，它通过将聚类结果与删除每一列后获得的聚类进行比较来评估聚类结果的一致性，一次一个。

     集群稳定性度量包括： • 非重叠的平均比例 (APN) • 平均距离 (AD) • 均值之间的平均距离 (ADM) • 品质因数 (FOM)

     APN、ADM 和 FOM 的取值范围为 0 到 1，较小的值对应于高度一致的聚类结果。  AD 的值介于 0 和无穷大之间，也优选较小的值。

- 计算分层聚类的 p 值

  pvclust package

  由于聚类噪声或采样错误，可以在数据集中偶然发现聚类。
    AU >= 95% 的集群被认为得到了数据的强烈支持。

 

##### [高级聚类](https://www.datanovia.com/?p=8077)：

- 分层 K 均值聚类

  K-means（上文）代表了最流行的聚类算法之一。 但是，它有一些局限性：它需要用户预先指定簇的数量并随机选择初始质心。 最终的 k-means 聚类解决方案对聚类中心的这种初始随机选择非常敏感。 每次计算 k 均值时，结果可能（略有）不同。

- 模糊聚类

  funny()

  模糊聚类被认为是软聚类，其中每个元素都有属于每个聚类的概率。 换句话说，每个元素都有一组对应于在给定集群中的程度的隶属系数。
  这与 k-means 和 k-medoid 聚类不同，其中每个对象都精确地作用于一个聚类。  K-means 和 k-medoids 聚类被称为硬聚类或非模糊聚类。
  在模糊聚类中，靠近簇中心的点可能比位于簇边缘的点在簇中的程度更高。 元素属于给定簇的程度是一个从 0 到 1 变化的数值。
   fuzzy c-means (FCM) 算法是应用最广泛的模糊聚类算法之一。 聚类的质心计算为所有点的平均值，由它们属于聚类的程度加权：

- 基于模型的聚类

  传统的聚类方法，如层次聚类（第 7 章）和 k-均值聚类（第 4 章），是启发式的，不基于形式模型。
  此外，k-means 算法通常是随机初始化的，因此不同的 k-means 运行通常会产生不同的结果。 此外，k-means 要求用户指定最佳聚类数。
  另一种方法是基于模型的聚类，它认为数据来自两个或多个聚类的混合分布与 k-means 不同，基于模型的聚类使用软分配，其中每个数据点都有属于每个聚类的概率。

  Mclust 包使用最大似然来拟合所有这些模型，具有不同的协方差矩阵参数化，适用于一系列 k 分量。
    使用贝叶斯信息准则或 BIC 选择最佳模型。 较大的 BIC 分数表明相应模型的有力证据。

- DBSCAN：基于密度的聚类

  划分方法（K-means，PAM聚类）和层次聚类适合于寻找球形或凸形聚类。换句话说，它们只适用于紧凑且分离良好的簇。此外，数据中存在的噪声和异常值也严重影响了它们。

  DBSCAN是Ester等人1996年提出的一种基于密度的聚类算法，可用于识别包含噪声和离群点的数据集中任何形状的聚类。
  基于密度的聚类方法的基本思想来源于人类直观的聚类方法
  聚类是数据空间中的密集区域，由点密度较低的区域隔开。DBSCAN算法基于“簇”和“噪声”这一直观概念。关键思想是，对于簇中的每个点，给定半径的邻域必须至少包含最少数量的点。优点：

  1.与K-means不同，DBSCAN不需要用户指定要生成的簇的数量

  2.DBSCAN可以找到任何形状的簇。集群不一定是圆形的。
  3.DBSCAN可以识别异常值

### 异常点检测

#### 适用情形：

一是在做特征工程的时候需要对异常的数据做过滤，防止对归一化等处理的结果产生影响。二是对没有标记输出的特征数据做筛选，找出异常的数据。三是对有标记输出的特征数据做二分类时，由于某些类别的训练样本非常少，**类别严重不平衡**，此时也可以考虑用非监督的异常点检测算法来做

#### 类别：

常用的异常点检测算法一般分为三类

第一类是基于统计学的方法来处理异常数据，这种方法一般会构建一个概率分布模型，并计算对象符合该模型的概率，把具有低概率的对象视为异常点。比如特征工程中的[RobustScaler](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.RobustScaler.html#sklearn.preprocessing.RobustScaler)方法，在做数据特征值缩放的时候，它会利用数据特征的分位数分布，将数据根据分位数划分为多段，只取中间段来做缩放，比如只取25%分位数到75%分位数的数据做缩放。这样减小了异常数据的影响。

第二类是基于聚类的方法来做异常点检测。这个很好理解，由于大部分聚类算法是基于数据特征的分布来做的，通常如果我们聚类后发现某些聚类簇的数据样本量比其他簇少很多，而且这个簇里数据的特征均值分布之类的值和其他簇也差异很大，这些簇里的样本点大部分时候都是异常点。比如[BIRCH聚类算法原理](https://www.cnblogs.com/pinard/p/6179132.html)和[DBSCAN密度聚类算法](http://www.cnblogs.com/pinard/p/6208966.html)都可以在聚类的同时做异常点的检测。

第三类是基于专门的异常点检测算法来做。这些算法不像聚类算法，检测异常点只是一个赠品，它们的目的就是专门检测异常点的，这类算法的代表是LOF,One Class SVM和[Isolation Forest](#随机森林 (Random forest))

LOF: 局部异常因子是一种尝试利用最近邻的思想进行异常值检测的技术。每个示例都根据其本地邻域的大小分配了一个关于其孤立程度或成为异常值的可能性的评分。那些得分最高的例子更有可能是异常值

这对于低维（特征很少）的特征空间很有效，尽管随着特征数量的增加它可能变得不那么可靠，称为维数灾难

One Class SVM：对于SVDD来说，我们期望所有不是异常的样本都是正类别，同时它采用一个超球体而不是一个超平面来做划分，该算法在特征空间中获得数据周围的球形边界，期望最小化这个超球体的体积，从而最小化异常点数据的影响

​                                            $$\underbrace{min}_{r,o}V(r) + C\sum\limits_{i=1}^m\xi_i$$

​                            $$||x_i-o||_2 \leq r + \xi_i,\;\; i=1,2,...m$$​

#### 小结：

IForest目前是异常点检测最常用的算法之一，它的优点非常突出，它具有线性时间复杂度。因为是随机森林的方法，所以可以用在含有海量数据的数据集上面。通常树的数量越多，算法越稳定。由于每棵树都是互相独立生成的，因此可以部署在大规模分布式系统上来加速运算。对于目前大数据分析的趋势来说，它的好用是有原因的。

但是IForest也有一些缺点，比如不适用于特别高维的数据。由于每次切数据空间都是随机选取一个维度和该维度的随机一个特征，建完树后仍然有大量的维度没有被使用，导致算法可靠性降低。此时推荐降维后使用，或者考虑使用One Class SVM。

另外iForest仅对即全局稀疏点敏感，不擅长处理局部的相对稀疏点 ，这样在某些局部的异常点较多的时候检测可能不是很准。

而One Class SVM对于中小型的数据分析，尤其是训练样本不是特别海量的时候用起来经常会比iForest顺手，因此比较适合做原型分析。

### 数据降维

过多输入变量的问题：

机器学习算法的性能会因输入变量过多而降低

我们可以将表示 n 维特征空间维度的数据列和数据行视为该空间中的点。 这是对数据集的有用几何解释。

在特征空间中拥有大量维度可能意味着该空间的体积非常大，反过来，我们在该空间中的点（数据行）通常代表一个小且不具代表性的样本。

这会极大地影响适合具有许多输入特征的数据的机器学习算法的性能，通常称为“维度灾难”。 因此，通常需要减少输入特征的数量。

降维：

高维可能意味着数百、数千甚至数百万个输入变量。

更少的输入维度通常意味着机器学习模型中相应的参数更少或更简单的结构，称为自由度。 具有太多自由度的模型可能会过度拟合训练数据集，因此可能无法在新数据上表现良好。

希望有简单的模型可以很好地泛化，反过来，输入数据的输入变量很少。 对于输入数量和模型的自由度通常密切相关的线性模型尤其如此。

降维是一种在建模之前对数据执行的数据准备技术。 它可以在数据清理和数据缩放之后以及训练预测模型之前执行。

#### 降维方法 

[特征选择：](#特征选择)

也许最常见的是所谓的特征选择技术，它使用评分或统计方法来选择保留哪些特征和删除哪些特征。

矩阵分解：

来自线性代数的技术可用于降维。

具体来说，矩阵分解方法可用于将数据集矩阵缩减为其组成部分。示例包括特征分解和奇异值分解。然后可以对这些部分进行排序，并且可以选择这些部分的一个子集，以最好地捕获可用于表示数据集的矩阵的显着结构。

对成分进行排序的最常用方法是主成分分析，简称 PCA。

流形学习：

来自高维统计的技术也可用于降维。

这些技术有时被称为“流形学习”，用于创建高维数据的低维投影，通常用于数据可视化。该投影旨在创建数据集的低维表示，同时最好地保留数据中的显着结构或关系。流形学习技术的例子包括：

- [Kohonen Self-Organizing Map (SOM)](https://en.wikipedia.org/wiki/Self-organizing_map).
- [Sammons Mapping](https://en.wikipedia.org/wiki/Sammon_mapping)
- Multidimensional Scaling (MDS)
- t-distributed Stochastic Neighbor Embedding (t-SNE).

投影中的特征通常与原始列几乎没有关系，例如 它们没有列名，这会让初学者感到困惑。

自编码器方法：

可以构建深度学习神经网络来执行降维。

一种流行的方法称为自动编码器。 这涉及构建一个自监督学习问题，其中模型必须正确再现输入。

使用网络模型试图将数据流压缩到维度比原始输入数据少得多的瓶颈层。 在瓶颈之前并包括瓶颈的模型部分称为编码器，读取瓶颈输出并重建输入的模型部分称为解码器。训练后，解码器被丢弃，瓶颈的输出直接用作输入的降维。 由该编码器转换的输入然后可以输入另一个模型，不一定是神经网络模型。

编码器的输出是一种投影，与其他投影方法一样，瓶颈输出与原始输入变量没有直接关系，这使得它们难以解释。

![img](https://pic1.zhimg.com/80/v2-1499966759ac2e9b7cf07e473bda7e14_720w.jpg)

- **缺失值比率（Missing Value Ratio）**：如果数据集的缺失值太多，我们可以用这种方法减少变量数。
- **低方差滤波（Low Variance Filter）**：这个方法可以从数据集中识别和删除常量变量，方差小的变量对目标变量影响不大，所以可以放心删去。
- **高相关滤波（High Correlation filter）**：具有高相关性的一对变量会增加数据集中的多重共线性，所以用这种方法删去其中一个是有必要的。
- **随机森林**：这是最常用的降维方法之一，它会明确算出数据集中每个特征的重要性。
- **前向特征选择**和**反向特征消除**：这两种方法耗时较久，计算成本也都很高，所以只适用于输入变量较少的数据集。
- **因子分析**：这种方法适合数据集中存在高度相关的变量集的情况。
- **PCA**：这是处理线性数据最广泛使用的技术之一。
- **ICA**：我们可以用ICA将数据转换为独立的分量，使用更少的分量来描述数据。
- **ISOMAP**：适合非线性数据处理。
- **t-SNE**：也适合非线性数据处理，相较上一种方法，这种方法的可视化更直接。
- **UMAP**：适用于高维数据，与t-SNE相比，这种方法速度更快

建议：

没有最好的降维技术，也没有技术到问题的映射。相反，最好的方法是使用系统控制的实验来发现哪些降维技术与您选择的模型搭配使用时，会在您的数据集上产生最佳性能。

通常，线性代数和流形学习方法假设所有输入特征具有相同的尺度或分布。 这表明，如果输入变量具有不同的尺度或单位，则在使用这些方法之前对数据进行归一化或标准化是一种很好的做法。

### 数据不平衡

为什么不平衡数据是机器学习中的一个问题？

大多数机器学习分类算法对预测类中的不平衡非常敏感。让我们考虑一个比我们的乳腺癌数据更极端的例子：假设我们有10个恶性和90个良性样本。在这样的数据集上经过训练和测试的机器学习模型现在可以预测所有样本的“良性”，并且仍然获得非常高的精度。不平衡的数据集将使预测模型偏向更常见的类！

面对这种情况，可以采取哪些措施来解决？

#### 重新采样数据集

过采样和欠采样背后的基本理论概念非常简单：

通过欠采样，我们从具有更多实例的类中随机选择一个样本子集，以匹配来自每个类的样本数量。 在我们的示例中，我们将从 458 个良性案例中随机挑选 241 个。 欠采样的主要缺点是我们从遗漏的样本中丢失了潜在的相关信息。

通过过采样，我们从具有较少实例的类中随机复制样本，或者根据我们拥有的数据生成额外的实例，以匹配每个类中的样本数量。 虽然我们避免使用这种方法丢失信息，但我们也冒着过度拟合模型的风险，因为我们更有可能在训练和测试数据中获得相同的样本，即测试数据不再独立于训练数据。 这会导致高估我们模型的性能和普遍性。

 允许这样做的一些算法包括变分自动编码器 (VAE)、SMOTE（合成少数过采样技术）或 MSMOTE（修改后的合成少数过采样技术）。

 但实际上，我们不应该简单地对训练数据进行过采样或欠采样，然后再运行模型。 **我们需要考虑交叉验证并独立对每个折叠进行过采样或欠采样，以获得对模型性能的诚实估计！**

ROSE:“ROSE 包提供了处理存在不平衡类的二元分类问题的功能。 人工平衡样本是根据平滑自举方法生成的，并允许在存在稀有类别的情况下帮助二元分类器的估计和准确性评估阶段。 还提供了对类别不平衡实施更传统补救措施的函数和评估准确性的不同指标。 这些是通过坚持、引导或交叉验证方法估计的。”

SMOTE:“这篇论文表明，我们对少数（异常）类进行过采样和对多数（正常）类进行欠采样的方法相结合，可以比仅对多数类进行欠采样获得更好的分类器性能（在 ROC 空间中）。 本文还表明，与改变 Ripper 中的损失率或朴素贝叶斯中的类先验相比，我们对少数类进行过采样和对多数类进行欠采样的方法相结合，可以获得更好的分类器性能（在 ROC 空间中）。 我们对少数类进行过采样的方法涉及创建合成的少数类示例。”

#### 从少数类收集更多数据

这个选项看起来微不足道，但它在适用时解决了问题。

#### 使用“足够”的正确算法

一些算法比其他算法更健壮。 掌握每种算法背后的理论将有助于您了解它们在各种情况下的优缺点。 请记住，机器学习算法是根据输入数据和手头的学习任务选择的。

#### 改变你的方法

与构建分类器不同，有时改变方法和范围是有益的； 一种选择是从“异常检测”的角度分析您的数据。 然后，您可以将“one class SVM”应用于“局部异常因子 (LOF)”算法。

#### 使用惩罚模型

许多算法都有自己的惩罚版本。 通常，算法对所有错误分类都一视同仁，因此其想法是惩罚少数类的错误分类多于多数类。 训练期间犯的错误会带来额外的成本（这就是为什么它们被称为成本敏感分类器），但理论上，这些惩罚有助于模型提高对少数类的关注。 有时，惩罚被称为权重。 实现正确的惩罚矩阵可能很困难，有时对改善结果没有太大作用，因此请尝试多种模式，直到找到最适合您情况的模式。

### 关联算法

#### Apriori

　Apriori算法是常用的用于挖掘出数据关联规则的算法，它用来找出数据值中频繁出现的数据集合，找出这些集合的模式有助于我们做一些决策。比如在常见的超市购物数据集，或者电商的网购数据集中，如果我们找到了频繁出现的数据集，那么对于超市，我们可以优化产品的位置摆放，对于电商，我们可以优化商品所在的仓库位置，达到节约成本，增加经济效益的目的。

Apriori算法采用了迭代的方法，先搜索出候选1项集及对应的支持度，剪枝去掉低于支持度的1项集，得到频繁1项集。然后对剩下的频繁1项集进行连接，得到候选的频繁2项集，筛选去掉低于支持度的候选频繁2项集，得到真正的频繁二项集，以此类推，迭代下去，直到无法找到频繁k+1项集为止，对应的频繁k项集的集合即为算法的输出结果。

![img](https://images2015.cnblogs.com/blog/1042406/201701/1042406-20170117161036255-1753157633.png)

Aprior算法是一个非常经典的频繁项集的挖掘算法，很多算法都是基于Aprior算法而产生的，包括FP-Tree,GSP, CBA等。这些算法利用了Aprior算法的思想，但是对算法做了改进，数据挖掘效率更好一些，因此现在一般很少直接用Aprior算法来挖掘数据了，但是理解Aprior算法是理解其它Aprior类算法的前提，同时算法本身也不复杂，因此值得好好研究一番。

#### FP Tree

在[Apriori算法原理总结](http://www.cnblogs.com/pinard/p/6293298.html)中，我们对Apriori算法的原理做了总结。作为一个挖掘频繁项集的算法，Apriori算法需要多次扫描数据，I/O是很大的瓶颈。为了解决这个问题，FP Tree算法（也称FP Growth算法）采用了一些技巧，无论多少数据，只需要扫描两次数据集，因此提高了算法运行的效率。

#### PrefixSpan

前面我们讲到频繁项集挖掘的关联算法Apriori和FP Tree。这两个算法都是挖掘频繁项集的。而今天我们要介绍的PrefixSpan算法也是关联算法，但是它是挖掘频繁序列模式的，因此要解决的问题目标稍有不同。

![img](https://images2015.cnblogs.com/blog/1042406/201701/1042406-20170120160812015-470353744.png)

PrefixSpan算法由于不用产生候选序列，且投影数据库缩小的很快，内存消耗比较稳定，作频繁序列模式挖掘的时候效果很高。比起其他的序列挖掘算法比如GSP,FreeSpan有较大优势，因此是在生产环境常用的算法。

### 特征工程

#### 特征选择

1. 过滤法

   第一个最简单的方法就是方差筛选。方差越大的特征，那么我们可以认为它是比较有用的。如果方差较小，比如小于1，那么这个特征可能对我们的算法作用没有那么大。最极端的，如果某个特征方差为0，即所有的样本该特征的取值都是一样的，那么它对我们的模型训练没有任何作用，可以直接舍弃。在实际应用中，我们会指定一个方差的阈值，当方差小于这个阈值的特征会被我们筛掉

   第二个可以使用的是相关系数。这个主要用于输出连续值的监督学习算法中。我们分别计算所有训练集中各个特征与输出值之间的相关系数，设定一个阈值，选择相关系数较大的部分特征。

   第三个可以使用的是假设检验，比如卡方检验。卡方检验可以检验某个特征分布和输出值分布之间的相关性。个人觉得它比比粗暴的方差法好用。如果大家对卡方检验不熟悉，可以参看这篇[卡方检验原理及应用](https://segmentfault.com/a/1190000003719712)，这里就不展开了。在sklearn中，可以使用chi2这个类来做卡方检验得到所有特征的卡方值与显著性水平P临界值，我们可以给定卡方值阈值， 选择卡方值较大的部分特征。

   除了卡方检验，我们还可以使用F检验和t检验，它们都是使用假设检验的方法，只是使用的统计分布不是卡方分布，而是F分布和t分布而已。在sklearn中，有F检验的函数f_classif和f_regression，分别在分类和回归特征选择时使用。

   第四个是互信息，即从信息熵的角度分析各个特征和输出值之间的关系评分。在[决策树](http://www.cnblogs.com/pinard/p/6050306.html)算法中我们讲到过互信息（信息增益）。互信息值越大，说明该特征和输出值之间的相关性越大，越需要保留。在sklearn中，可以使用mutual_info_classif(分类)和mutual_info_regression(回归)来计算各个输入特征和输出值之间的互信息。

   以上就是过滤法的主要方法，个人经验是，在没有什么思路的 时候，可以优先使用**卡方检验和互信息来做特征选择**

2. 包装法

   包装法的解决思路没有过滤法这么直接，它会选择一个目标函数来一步步的筛选特征。

   最常用的包装法是递归消除特征法(recursive feature elimination,以下简称RFE)。递归消除特征法使用一个机器学习模型来进行多轮训练，每轮训练后，消除若干权值系数的对应的特征，再基于新的特征集进行下一轮训练。在sklearn中，可以使用RFE函数来选择特征。

   我们下面以经典的SVM-RFE算法来讨论这个特征选择的思路。这个算法以支持向量机来做RFE的机器学习模型选择特征。它在第一轮训练的时候，会选择所有的特征来训练，得到了分类的超平面wx˙+b=0后，如果有n个特征，那么RFE-SVM会选择出w中分量的平方值$w_i^2$最小的那个序号i对应的特征，将其排除，在第二类的时候，特征数就剩下n-1个了，我们继续用这n-1个特征和输出值来训练SVM，同样的，去掉$w_i^2$​​最小的那个序号i对应的特征。以此类推，直到剩下的特征数满足我们的需求为止。

3. 嵌入法

   嵌入法也是用机器学习的方法来选择特征，但是它和RFE的区别是它不是通过不停的筛掉特征来进行训练，而是使用的都是特征全集。在sklearn中，使用SelectFromModel函数来选择特征。

   最常用的是使用L1正则化和L2正则化来选择特征。正则化惩罚项越大，那么模型的系数就会越小。当正则化惩罚项大到一定的程度的时候，部分特征系数会变成0，当正则化惩罚项继续增大到一定程度时，所有的特征系数都会趋于0. 但是我们会发现一部分特征系数会更容易先变成0，这部分系数就是可以筛掉的。也就是说，我们选择特征系数较大的特征。常用的L1正则化和L2正则化来选择特征的基学习器是逻辑回归。

   此外也可以使用决策树或者GBDT。那么是不是所有的机器学习方法都可以作为嵌入法的基学习器呢？也不是，一般来说，可以得到特征系数coef或者可以得到特征重要度(feature importances)的算法才可以做为嵌入法的基学习器。

4. ### **寻找高级特征**

   在我们拿到已有的特征后，我们还可以根据需要寻找到更多的高级特征。比如有车的路程特征和时间间隔特征，我们就可以得到车的平均速度这个二级特征。根据车的速度特征，我们就可以得到车的加速度这个三级特征，根据车的加速度特征，我们就可以得到车的加加速度这个四级特征。。。也就是说，高级特征可以一直寻找下去

   在Kaggle之类的算法竞赛中，高分团队主要使用的方法除了集成学习算法，剩下的主要就是在高级特征上面做文章。所以寻找高级特征是模型优化的必要步骤之一。当然，**在第一次建立模型的时候，我们可以先不寻找高级特征，得到以后基准模型后，再寻找高级特征进行优化**。

   若干项特征加和： 我们假设你希望根据每日销售额得到一周销售额的特征。你可以将最近的7天的销售额相加得到。
   若干项特征之差： 假设你已经拥有每周销售额以及每月销售额两项特征，可以求一周前一月内的销售额。
   若干项特征乘积： 假设你有商品价格和商品销量的特征，那么就可以得到销售额的特征。
   若干项特征除商： 假设你有每个用户的销售额和购买的商品件数，那么就是得到该用户平均每件商品的销售额。

　#### 特征表达

   1. 缺失值处理

      特征有缺失值是非常常见的，大部分机器学习模型在拟合前需要所有的特征都有值，不能是空或者NULL。那么如果有缺失值我们需要怎么处理呢？

      首先我们会看是该特征是连续值还是离散值。如果是连续值，那么一般有两种选择，一是选择所有有该特征值的样本，然后取平均值，来填充缺失值，另一种是取中位数来填充缺失值。如果是离散值，则一般会选择所有有该特征值的样本中最频繁出现的类别值，来填充缺失值。

2. 特殊的特征处理

   有些特征的默认取值比较特殊，一般需要做了处理后才能用于算法。比如日期时间，比如显示20180519，这样的值一般没办法直接使用。那么一般需要如何变换呢？

   对于时间原始特征，处理方法有很多，这里只举例几种有代表性的方法。　第一种是使用连续的时间差值法，即计算出所有样本的时间到某一个未来时间之间的数值差距，这样这个差距是UTC的时间差，从而将时间特征转化为连续值。第二种方法是根据时间所在的年，月，日，星期几，小时数，将一个时间特征转化为若干个离散特征，这种方法在分析具有明显时间趋势的问题比较好用。第三种是权重法，即根据时间的新旧得到一个权重值。比如对于商品，三个月前购买的设置一个较低的权重，最近三天购买的设置一个中等的权重，在三个月内但是三天前的设置一个较大的权重。当然，还有其他的设置权重的方法，这个要根据要解决的问题来灵活确定。

   对于地理特征，比如“广州市天河区XX街道XX号”，这样的特征我们应该如何使用呢？处理成离散值和连续值都是可以的。如果是处理成离散值，则需要转化为多个离散特征，比如城市名特征，区县特征，街道特征等。但是如果我们需要判断用户分布区域，则一般处理成连续值会比较好，这时可以将地址处理成经度和纬度的连续特征。

3. 离散特征的连续化处理

   最常见的离散特征连续化的处理方法是独热编码one-hot encoding。处理方法其实比较简单，比如某特征的取值是高，中和低，那么我们就可以创建三个取值为0或者1的特征，将高编码为1,0,0这样三个特征，中编码为0,1,0这样三个特征，低编码为0,0,1这样三个特征。也就是说，之前的一个特征被我们转化为了三个特征。sklearn的OneHotEncoder可以帮我们做这个处理。

   第二个方法是特征嵌入embedding。这个一般用于深度学习中。比如对于用户的ID这个特征，如果要使用独热编码，则维度会爆炸，如果使用特征嵌入就维度低很多了。对于每个要嵌入的特征，我们会有一个特征嵌入矩阵，这个矩阵的行很大，对应我们该特征的数目。比如用户ID，如果有100万个，那么嵌入的特征矩阵的行就是100万。但是列一般比较小，比如可以取20。这样每个用户ID就转化为了一个20维的特征向量。进而参与深度学习模型。

4. 离散特征的离散化处理

   离散特征有时候也不能直接使用，需要先进行转化。比如最常见的，如果特征的取值是高，中和低，那么就算你需要的是离散值，也是没法直接使用的。

   对于原始的离散值特征，最常用的方法也是独热编码，方法在第三节已经讲到。

   第二种方法是虚拟编码dummy coding，它和独热编码类似，但是它的特点是，如果我们的特征有N个取值，它只需要N-1个新的0,1特征来代替，而独热编码会用N个新特征代替。比如一个特征的取值是高，中和低，那么我们只需要两位编码，比如只编码中和低，如果是1，0则是中，0,1则是低。0,0则是高了。目前虚拟编码使用的没有独热编码广，因此一般有需要的话还是使用独热编码比较好。

   此外，有时候我们可以对特征进行研究后做一个更好的处理。比如，我们研究商品的销量对应的特征。里面有一个原始特征是季节春夏秋冬。我们可以将其转化为淡季和旺季这样的二值特征，方便建模。当然有时候转化为三值特征或者四值特征也是可以的。

5. 连续特征的离散化处理

   对于连续特征，有时候我们也可以将其做离散化处理。这样特征变得高维稀疏，方便一些算法的处理。

   对常用的方法是根据阈值进行分组，比如我们根据连续值特征的分位数，将该特征分为高，中和低三个特征。将分位数从0-0.3的设置为高，0.3-0.7的设置为中，0.7-1的设置为高。

   当然还有高级一些的方法。比如使用GBDT。在LR+GBDT的经典模型中，就是使用GDBT来先将连续值转化为离散值。那么如何转化呢？比如我们用训练集的所有连续值和标签输出来训练GBDT，最后得到的GBDT模型有两颗决策树，第一颗决策树有三个叶子节点，第二颗决策树有4个叶子节点。如果某一个样本在第一颗决策树会落在第二个叶子节点，在第二颗决策树落在第4颗叶子节点，那么它的编码就是0,1,0,0,0,0,1，一共七个离散特征，其中会有两个取值为1的位置，分别对应每颗决策树中样本落点的位置。

#### 特征预处理

1. 标准化和归一化

2. z-score标准化：这是最常见的特征预处理方式，基本所有的线性模型在拟合的时候都会做 z-score标准化。具体的方法是求出样本特征x的均值mean和标准差std，然后用（x-mean)/std来代替原特征。这样特征就变成了均值为0，方差为1了。在sklearn中，我们可以用StandardScaler来做z-score标准化。当然，如果我们是用pandas做数据预处理，可以自己在数据框里面减去均值，再除以方差，自己做z-score标准化。  

   max-min标准化：也称为离差标准化，预处理后使特征值映射到[0,1]之间。具体的方法是求出样本特征x的最大值max和最小值min，然后用(x-min)/(max-min)来代替原特征。如果我们希望将数据映射到任意一个区间[a,b]，而不是[0,1]，那么也很简单。用(x-min)(b-a)/(max-min)+a来代替原特征即可。在sklearn中，我们可以用MinMaxScaler来做max-min标准化。这种方法的问题就是如果测试集或者预测数据里的特征有小于min，或者大于max的数据，会导致max和min发生变化，需要重新计算。所以实际算法中， 除非你对特征的取值区间有需求，否则max-min标准化没有 z-score标准化好用。

   L1/L2范数标准化：如果我们只是为了统一量纲，那么通过L2范数整体标准化也是可以的，具体方法是求出每个样本特征向量$\vec{x}$的L2范数$||\vec{x}||_2$,然后用$\vec{x}/||\vec{x}||_2$代替原样本特征即可。当然L1范数标准化也是可以的，即用$\vec{x}/||\vec{x}||_1$代替原样本特征。通常情况下，范数标准化首选L2范数标准化。在sklearn中，我们可以用Normalizer来做L1/L2范数标准化。

   此外，经常我们还会用到中心化，主要是在PCA降维的时候，此时我们求出特征x的平均值mean后，用x-mean代替原特征，也就是特征的均值变成了0, 但是方差并不改变。这个很好理解，因为PCA就是依赖方差来降维的。

   虽然大部分机器学习模型都需要做标准化和归一化，也有不少模型可以不做做标准化和归一化，主要是基于概率分布的模型，比如决策树大家族的CART，随机森林等。当然此时使用标准化也是可以的，大多数情况下对模型的泛化能力也有改进

3. 异常特征样本清洗 见前文

4. 处理不平衡数据 见前文

### [深度学习](file:///D:/pdf%20library/AI%E7%AE%97%E6%B3%95%E5%B7%A5%E7%A8%8B%E5%B8%88%E6%89%8B%E5%86%8C.pdf)

详见《AI算法工程师手册》

### 自然语言处理

#### 文本挖掘的分词原理

在做文本挖掘的时候，首先要做的预处理就是分词。英文单词天然有空格隔开容易按照空格分词，但是也有时候需要把多个单词做为一个分词，比如一些名词如“New York”，需要做为一个词看待。而中文由于没有空格，分词就是一个需要专门去解决的问题了。

1. 基本原理

   现代分词都是基于统计的分词，而统计的样本内容来自于一些标准的语料库。假如有一个句子：“小明来到荔湾区”，我们期望语料库统计后分词的结果是："小明/来到/荔湾/区"，而不是“小明/来到/荔/湾区”。那么如何做到这一点呢？在NLP中，为了简化计算，我们通常使用马尔科夫假设，即每一个分词出现的概率仅仅和前一个分词有关，即：

   $P(A_{ij}|A_{i1},A_{i2},...,A_{i(j-1)}) = P(A_{ij}|A_{i(j-1)})$

   利用语料库建立的统计概率，对于一个新的句子，我们就可以通过计算各种分词方法对应的联合分布概率，找到最大概率对应的分词方法，即为最优分词。

2. N元模型

   我们一般称只依赖于前一个词的模型为二元模型(Bi-Gram model)，而依赖于前两个词的模型为三元模型。以此类推，我们可以建立四元模型，五元模型,...一直到通用的NN元模型。越往后，概率分布的计算复杂度越高。当然算法的原理是类似的。

   在实际应用中，N一般都较小，一般都小于4，主要原因是N元模型概率分布的空间复杂度为$O(|V|^N)$，其中|V|为语料库大小，而N为模型的元数，当N增大时，复杂度呈指数级的增长。

3. 维特比算法与分词

   对于一个有很多分词可能的长句子，我们当然可以用暴力方法去计算出所有的分词可能的概率，再找出最优分词方法。但是用维特比算法可以大大简化求出最优分词的时间。维特比算法采用的是动态规划来解决这个最优分词问题的，动态规划要求局部路径也是最优路径的一部分，很显然我们的问题是成立的。

4. 常用分词工具

   对于文本挖掘中需要的分词功能，一般我们会用现有的工具。简单的英文分词不需要任何工具，通过空格和标点符号就可以分词了，而进一步的英文分词推荐使用[nltk](http://www.nltk.org/)。对于中文分词，则推荐用[结巴分词](https://github.com/fxsjy/jieba/)（jieba）。这些工具使用都很简单。你的分词没有特别的需求直接使用这些分词工具就可以了。

#### 词袋模型

词袋模型假设我们不考虑文本中词与词之间的上下文关系，仅仅只考虑所有词的权重。而权重与词在文本中出现的频率有关。

词袋模型首先会进行分词，在分词之后，通过统计每个词在文本中出现的次数，我们就可以得到该文本基于词的特征，如果将各个文本样本的这些词与对应的词频放在一起，就是我们常说的向量化。向量化完毕后一般也会使用TF-IDF进行特征的权重修正，再将特征进行标准化。 再进行一些其他的特征工程后，就可以将数据带入机器学习算法进行分类聚类了。

总结下词袋模型的三部曲：分词（tokenizing），统计修订词特征值（counting）与标准化（normalizing）。

当然，词袋模型有很大的局限性，因为它仅仅考虑了词频，没有考虑上下文的关系，因此会丢失一部分文本的语义。但是大多数时候，如果我们的目的是分类聚类，则词袋模型表现的很好。

##### 向量化

在词袋模型的统计词频这一步，我们会得到该文本中所有词的词频，有了词频，我们就可以用词向量表示这个文本。

由于大部分的文本都只会使用词汇表中的很少一部分的词，因此我们的词向量中会有大量的0。也就是说词向量是稀疏的。在实际应用中一般使用稀疏矩阵来存储。

将文本做了词频统计后，我们一般会通过TF-IDF进行词特征值修订，这部分我们后面再讲。

向量化的方法很好用，也很直接，但是在有些场景下很难使用，比如分词后的词汇表非常大，达到100万+，此时如果我们直接使用向量化的方法，将对应的样本对应特征矩阵载入内存，有可能将内存撑爆，在这种情况下我们怎么办呢？第一反应是我们要进行特征的降维，说的没错！而Hash Trick就是非常常用的文本特征降维方法。

##### Hash Trick

在Hash Trick里，我们会定义一个特征Hash后对应的哈希表的大小，这个哈希表的维度会远远小于我们的词汇表的特征维度，因此可以看成是降维。具体的方法是，对应任意一个特征名，我们会用Hash函数找到对应哈希表的位置，然后将该特征名对应的词频统计值累加到该哈希表位置。如果用数学语言表示,假如哈希函数h使第i个特征哈希到位置jj,即h(i)=j,则第ii个原始特征的词频数值$\phi(i)$将累加到哈希后的第j个特征的词频数值$\bar{\phi}$上，即： $\bar{\phi}(j) = \sum_{i\in \mathcal{J}; h(i) = j}\phi(i)$

从实际应用中说，由于文本特征的高稀疏性，这么做是可行的。

和PCA类似，Hash Trick降维后的特征我们已经不知道它代表的特征名字和意义。此时我们不能像上一节向量化时候可以知道每一列的意义，所以Hash Trick的解释性不强。

一般来说，只要词汇表的特征不至于太大，大到内存不够用，肯定是使用一般意义的向量化比较好。因为向量化的方法解释性很强，我们知道每一维特征对应哪一个词，进而我们还可以使用TF-IDF对各个词特征的权重修改，进一步完善特征的表示。

而Hash Trick用大规模机器学习上，此时我们的词汇量极大，使用向量化方法内存不够用，而使用Hash Trick降维速度很快，降维后的特征仍然可以帮我们完成后续的分类和聚类工作。当然由于分布式计算框架的存在，其实一般我们不会出现内存不够的情况。因此，实际工作中大多数使用的都是特征向量化。

#### TF-IDF

如果我们直接将统计词频后的19维特征做为文本分类的输入，会发现有一些问题。比如第一个文本，我们发现"come","China"和“Travel”各出现1次，而“to“出现了两次。似乎看起来这个文本与”to“这个特征更关系紧密。但是实际上”to“是一个非常普遍的词，几乎所有的文本都会用到，因此虽然它的词频为2，但是重要性却比词频为1的"China"和“Travel”要低的多。如果我们的向量化特征仅仅用词频表示就无法反应这一点。因此我们需要进一步的预处理来反应文本的这个特征，而这个预处理就是TF-IDF。

##### 概述

TF-IDF是Term Frequency -  Inverse Document Frequency的缩写，即“词频-逆文本频率”。它由两部分组成，TF和IDF。

前面的TF也就是我们前面说到的词频，我们之前做的向量化也就是做了文本中各个词的出现频率统计，并作为文本特征，这个很好理解。关键是后面的这个IDF，即“逆文本频率”如何理解。在上一节中，我们讲到几乎所有文本都会出现的"to"其词频虽然高，但是重要性却应该比词频低的"China"和“Travel”要低。我们的IDF就是来帮助我们来反应这个词的重要性的，进而修正仅仅用词频表示的词特征值。

概括来讲， IDF反应了一个词在所有文本中出现的频率，如果一个词在很多的文本中出现，那么它的IDF值应该低，比如上文中的“to”。而反过来如果一个词在比较少的文本中出现，那么它的IDF值应该高。比如一些专业的名词如“Machine Learning”。这样的词IDF值应该高。一个极端的情况，如果一个词在所有的文本中都出现，那么它的IDF值应该为0。

上面是从定性上说明的IDF的作用，那么如何对一个词的IDF进行定量分析呢？这里直接给出一个词x的IDF的基本公式如下：

$IDF(x) = log\frac{N}{N(x)}$ 平滑化处理后的公式如下：$IDF(x) = log\frac{N+1}{N(x)+1} + 1$

即有：$TF-IDF(x) = TF(x) * IDF(x)$

##### 总结

TF-IDF是非常常用的文本挖掘预处理基本步骤，但是如果预处理中使用了Hash Trick，则一般就无法使用TF-IDF了，因为Hash Trick后我们已经无法得到哈希后的各特征的IDF的值。使用了IF-IDF并标准化以后，我们就可以使用各个文本的词特征向量作为文本的特征，进行分类或者聚类分析。

#### 中文文本挖掘预处理

1. 特点

   首先，中文文本是没有像英文的单词空格那样隔开的，因此不能直接像英文一样可以直接用最简单的空格和标点符号完成分词。所以一般我们需要用分词算法来完成分词，在[文本挖掘的分词原理](http://www.cnblogs.com/pinard/p/6677078.html)中，我们已经讲到了中文的分词原理，这里就不多说。

   　　　　第二，中文的编码不是utf8，而是unicode。这样会导致在分词的时候，和英文相比，我们要处理编码的问题。

   　　　　这两点构成了中文分词相比英文分词的一些不同点，后面我们也会重点讲述这部分的处理。

2. 数据收集

   文本数据的获取方法一般有两种：使用别人做好的语料库和自己用爬虫去在网上去爬自己的语料数据。

   对于第一种方法，常用的文本语料库在网上有很多，如果大家只是学习，则可以直接下载下来使用，但如果是某些特殊主题的语料库，比如“机器学习”相关的语料库，则这种方法行不通，需要我们自己用第二种方法去获取。

   对于第二种使用爬虫的方法，开源工具有很多，通用的爬虫可以使用[beautifulsoup](http://link.zhihu.com/?target=http%3A//www.crummy.com/software/BeautifulSoup/)。但是我们我们需要某些特殊的语料数据，比如上面提到的“机器学习”相关的语料库，则需要用主题爬虫（也叫聚焦爬虫）来完成。这个可以使用[ache](https://github.com/ViDA-NYU/ache)。 ache允许我们用关键字或者一个分类算法来过滤出我们需要的主题语料，比较强大

3. 除去数据中非文本部分

   这一步主要是针对我们用爬虫收集的语料数据，由于爬下来的内容中有很多html的一些标签，需要去掉。少量的非文本内容的可以直接用Python的正则表达式(re)删除, 复杂的则可以用[beautifulsoup](http://link.zhihu.com/?target=http%3A//www.crummy.com/software/BeautifulSoup/)来去除。去除掉这些非文本的内容后，我们就可以进行真正的文本预处理了。

4. 处理中文编码

   由于Python2不支持unicode的处理，因此我们使用Python2做中文文本预处理时需要遵循的原则是，存储数据都用utf8，读出来进行中文相关处理时，使用GBK之类的中文编码

5. 常用的中文分词软件有很多，个人比较推荐结巴分词。安装也很简单，比如基于Python的，用"pip install jieba"就可以完成。

6. 引入停用词

7. 特征处理

   在[文本挖掘预处理之向量化与Hash Trick](http://www.cnblogs.com/pinard/p/6688348.html)中，有两种特征处理的方法，向量化与Hash Trick。而向量化是最常用的方法，因为它可以接着进行TF-IDF的特征处理。在[文本挖掘预处理之TF-IDF](http://www.cnblogs.com/pinard/p/6693230.html)中，也有TF-IDF特征处理的方法。这里我们就用scikit-learn的TfidfVectorizer类来进行TF-IDF特征处理

8. 建立分析模型

#### 英文文本挖掘预处理

英文文本的预处理方法和中文的有部分区别。首先，英文文本挖掘预处理一般可以不做分词（特殊需求除外），而中文预处理分词是必不可少的一步。第二点，大部分英文文本都是uft-8的编码，这样在大多数时候处理的时候不用考虑编码转换的问题，而中文文本处理必须要处理unicode的编码问题。这两部分我们在中文文本挖掘预处理里已经讲了。

而英文文本的预处理也有自己特殊的地方，第三点就是拼写问题，很多时候，我们的预处理要包括拼写检查，比如“Helo World”这样的错误，我们不能在分析的时候讲错纠错。所以需要在预处理前加以纠正。第四点就是词干提取(stemming)和词形还原(lemmatization)。这个东西主要是英文有单数，复数和各种时态，导致一个词会有不同的形式。比如“countries”和"country"，"wolf"和"wolves"，我们期望是有一个词。

1. 数据收集

   这部分英文和中文类似。获取方法一般有两种：使用别人做好的语料库和自己用爬虫去在网上去爬自己的语料数据。

2. 除去数据中非文本部分

   略

3. 拼写检查更正

   由于英文文本中可能有拼写错误，因此一般需要进行拼写检查。如果确信我们分析的文本没有拼写问题，可以略去此步。

   拼写检查，我们一般用[pyenchant](http://pythonhosted.org/pyenchant/)类库完成。[pyenchant](http://pythonhosted.org/pyenchant/)的安装很简单："pip install pyenchant"即可。

4. 拼写检查更正

   由于英文文本中可能有拼写错误，因此一般需要进行拼写检查。如果确信我们分析的文本没有拼写问题，可以略去此步。

   拼写检查，我们一般用[pyenchant](http://pythonhosted.org/pyenchant/)类库完成。

5. 词干提取(stemming)和词形还原(lemmatization)

   词干提取(stemming)和词型还原(lemmatization)是英文文本预处理的特色。两者其实有共同点，即都是要找到词的原始形式。只不过词干提取(stemming)会更加激进一点，它在寻找词干的时候可以会得到不是词的词干。比如"imaging"的词干可能得到的是"imag", 并不是一个词。而词形还原则保守一些，它一般只对能够还原成一个正确的词的词进行处理。个人比较喜欢使用词型还原而不是词干提取。

   在实际应用中，一般使用nltk来进行词干提取和词型还原。

6. 转化为小写

   由于英文单词有大小写之分，我们期望统计时像“Home”和“home”是一个词。因此一般需要将所有的词都转化为小写。这个直接用python的API就可以搞定

7. 引入停用词

   在英文文本中有很多无效的词，比如“a”，“to”，一些短词，还有一些标点符号，这些我们不想在文本分析的时候引入，因此需要去掉，这些词就是停用词。个人常用的英文停用词表[下载地址在这](http://www.matthewjockers.net/wp-content/uploads/2013/04/uwm-workshop.zip)。

8. 特征处理

   现在我们就可以用scikit-learn来对我们的文本特征进行处理了，在[文本挖掘预处理之向量化与Hash Trick](#词袋模型)中，我们讲到了两种特征处理的方法，向量化与Hash Trick。而向量化是最常用的方法，因为它可以接着进行TF-IDF的特征处理。在[文本挖掘预处理之TF-IDF](#TF-IDF)中，我们也讲到了TF-IDF特征处理的方法。

   TfidfVectorizer类可以帮助我们完成向量化，TF-IDF和标准化三步。当然，还可以帮我们处理停用词。这部分工作和中文的特征处理也是完全相同的，大家参考前文即可。

#### 文本主题模型

在数据分析中，我们经常会进行非监督学习的聚类算法，它可以对我们的特征数据进行非监督的聚类。而主题模型也是非监督的算法，目的是得到文本按照主题的概率分布。从这个方面来说，主题模型和普通的聚类算法非常的类似。但是两者其实还是有区别的。

聚类算法关注于从样本特征的相似度方面将数据聚类。比如通过数据样本之间的欧式距离，曼哈顿距离的大小聚类等。而主题模型，顾名思义，就是对文字中隐含主题的一种建模方法。比如从“人民的名义”和“达康书记”这两个词我们很容易发现对应的文本有很大的主题相关度，但是如果通过词特征来聚类的话则很难找出，因为聚类方法不能考虑到到隐含的主题这一块。

那么如何找到隐含的主题呢？这个一个大问题。常用的方法一般都是基于统计学的生成方法。即假设以一定的概率选择了一个主题，然后以一定的概率选择当前主题的词。最后这些词组成了我们当前的文本。所有词的统计概率分布可以从语料库获得，具体如何以“一定的概率选择”，这就是各种具体的主题模型算法的任务了。

##### 潜在语义索引（LSI）

潜在语义索引(Latent Semantic Indexing,以下简称LSI)，有的文章也叫Latent Semantic  Analysis（LSA）。其实是一个东西，后面我们统称LSI，它是一种简单实用的主题模型。LSI是基于奇异值分解（SVD）的方法来得到文本的主题的。

我们输入的有m个文本，每个文本有n个词。而$A_{ij}$则对应第i个文本的第j个词的特征值，这里最常用的是基于预处理后的标准化TF-IDF值。k是我们假设的主题数，一般要比文本数少。SVD分解后，$U_{il}$对应第i个文本和第l个主题的相关度。$V_{jm}$对应第j个词和第m个词义的相关度。$Σ_{lm}$对应第l个主题和第m个词义的相关度。

LSI得到的文本主题矩阵可以用于文本相似度计算.

LSI是最早出现的主题模型了，它的算法原理很简单，一次奇异值分解就可以得到主题模型，同时解决词义的问题，非常漂亮。但是LSI有很多不足，导致它在当前实际的主题模型中已基本不再使用。

主要的问题有：

　　　　1） SVD计算非常的耗时，尤其是我们的文本处理，词和文本数都是非常大的，对于这样的高维度矩阵做奇异值分解是非常难的。

　　　　2） 主题值的选取对结果的影响非常大，很难选择合适的k值。

　　　　3） LSI得到的不是一个概率模型，缺乏统计基础，结果难以直观的解释。

　　　　对于问题1），主题模型非负矩阵分解（NMF）可以解决矩阵分解的速度问题。对于问题2），这是老大难了，大部分主题模型的主题的个数选取一般都是凭经验的，较新的层次狄利克雷过程（HDP）可以自动选择主题个数。对于问题3），牛人们整出了pLSI(也叫pLSA)和隐含狄利克雷分布(LDA)这类基于概率分布的主题模型来替代基于矩阵分解的主题模型。

　　　　回到LSI本身，对于一些规模较小的问题，如果想快速粗略度的找出一些主题分布的关系，则LSI是比较好的一个选择，其他时候，如果需要使用主题模型，推荐使用LDA和HDP。

##### 非负矩阵分解(NMF)

非负矩阵分解(non-negative matrix factorization，以下简称NMF)是一种非常常用的矩阵分解方法，它可以适用于很多领域，比如图像特征识别，语音识别等，这里我们会主要关注于它在文本主题模型里的运用。

NMF虽然也是矩阵分解，它却使用了不同的思路，它的目标是期望将矩阵分解为两个矩阵:$A_{m \times n} \approx W_{m \times k}H_{k \times n}$,即优化如下式子：

$\underbrace{arg\;min}_{W,H}\frac{1}{2}||A-WH||_{Fro}^2 +\alpha\rho|| W||_1+\alpha\rho|| H||_1+\frac{\alpha(1-\rho)}{2}|| W||_{Fro}^2 + \frac{\alpha(1-\rho)}{2}|| H||_{Fro}^2$

注意：如果我们决定加上了L1正则化的话就不能用梯度下降和拟牛顿法了。此时可以用坐标轴下降法或者最小角回归法来求解。

回到我们本文的主题，NMF矩阵分解如何运用到我们的主题模型呢？

此时NMF可以这样解释：我们输入的有m个文本，n个词，而$A_{ij}$j对应第i个文本的第j个词的特征值，这里最常用的是基于预处理后的标准化TF-IDF值。k是我们假设的主题数，一般要比文本数少。NMF分解后，$W_{ik}$对应第i个文本的和第k个主题的概率相关度，而$H_{kj}$对应第j个词和第k个主题的概率相关度。

其他应用：

虽然我们是在主题模型里介绍的NMF，但实际上NMF的适用领域很广，除了我们上面说的图像处理，语音处理，还包括信号处理与医药工程等，是一个普适的方法。在这些领域使用NMF的关键在于将NMF套入一个合适的模型，使得W,HW,H矩阵都可以有明确的意义。这里给一个图展示NMF在做语音处理时的情形：

![img](https://images2015.cnblogs.com/blog/1042406/201705/1042406-20170505140318101-63195225.png)

小结：

NMF作为一个漂亮的矩阵分解方法，它可以很好的用于主题模型，并且使主题的结果有基于概率分布的解释性。但是NMF以及它的变种pLSA虽然可以从概率的角度解释了主题模型，却都只能对训练样本中的文本进行主题识别，而对不在样本中的文本识别不一定很准确。根本原因在于NMF与pLSA这类主题模型方法没有考虑主题概率分布的先验知识，比如文本中出现体育主题的概率肯定比哲学主题的概率要高，这点来源于我们的先验知识，但是无法告诉NMF主题模型。而LDA主题模型则考虑到了这一问题，目前来说，绝大多数的文本主题模型都是使用LDA以及其变体。

#### LDA

##### 基础

一般意义上的K维Dirichlet 分布表达式为：$Dirichlet(\vec p| \vec \alpha) = \frac{\Gamma(\sum\limits_{k=1}^K\alpha_k)}{\prod_{k=1}^K\Gamma(\alpha_k)}\prod_{k=1}^Kp_k^{\alpha_k-1}$

注意到多项分布和Dirichlet 分布满足共轭关系，这样我们可以得到结论：

$Dirichlet(\vec p|\vec \alpha) + MultiCount(\vec m) = Dirichlet(\vec p|\vec \alpha + \vec m)$

对于Dirichlet 分布的期望，也有和Beta分布类似的性质：

$E(Dirichlet(\vec p|\vec \alpha)) = (\frac{\alpha_1}{\sum\limits_{k=1}^K\alpha_k}, \frac{\alpha_2}{\sum\limits_{k=1}^K\alpha_k},...,\frac{\alpha_K}{\sum\limits_{k=1}^K\alpha_k})$

我们的目标是找到每一篇文档的主题分布和每一个主题中词的分布。在LDA模型中，我们需要先假定一个主题数目KK，这样所有的分布就都基于KK个主题展开。那么具体LDA模型是怎么样的呢？具体如下图：

![img](https://images2015.cnblogs.com/blog/1042406/201705/1042406-20170517134339588-825441177.png)

这个模型里，我们有M个文档主题的Dirichlet分布，而对应的数据有M个主题编号的多项分布，这样$\alpha \to \theta_d \to \vec z_{d}$就组成了Dirichlet-multi共轭，可以使用前面提到的贝叶斯推断的方法得到基于Dirichlet分布的文档主题后验分布。

如果在第d个文档中，第k个主题的词的个数为：$n_d^{(k)}$, 则对应的多项分布的计数可以表示为:

$\vec n_d = (n_d^{(1)}, n_d^{(2)},...n_d^{(K)})$

利用Dirichlet-multi共轭，得到$\theta_d$的后验分布为：$Dirichlet(\theta_d | \vec \alpha + \vec n_d)$

同样的道理，对于主题与词的分布，我们有K个主题与词的Dirichlet分布，而对应的数据有K个主题编号的多项分布，这样$\vec n_k = (n_k^{(1)}, n_k^{(2)},...n_k^{(V)})$就组成了Dirichlet-multi共轭，可以使用前面提到的贝叶斯推断的方法得到基于Dirichlet分布的主题词的后验分布。

如果在第k个主题中，第v个词的个数为：$n_k^{(v)}$, 则对应的多项分布的计数可以表示为:

$\vec n_k = (n_k^{(1)}, n_k^{(2)},...n_k^{(V)})$

利用Dirichlet-multi共轭，得到$\beta_k$的后验分布为：$Dirichlet(\beta_k | \vec \eta+ \vec n_k)$

##### 求解

Gibbs采样

流程：

​                1） 选择合适的主题数K, 选择合适的超参数向量$\vec \alpha,\vec \eta$

　　　　2） 对应语料库中每一篇文档的每一个词，随机的赋予一个主题编号zz

　　　　3) 重新扫描语料库，对于每一个词，利用Gibbs采样公式更新它的topic编号，并更新语料中该词的编号。

　　　　4） 重复第3步的基于坐标轴轮换的Gibbs采样，直到Gibbs采样收敛。

　　　　5） 统计语料库中的各个文档各个词的主题，得到文档主题分布$\theta_d$，统计语料库中各个主题词的分布，得到LDA的主题与词的分布$\beta_k$。

小结：

使用Gibbs采样算法训练LDA模型，我们需要先确定三个超参数$K, \vec \alpha,\vec \eta$。其中选择一个合适的K尤其关键,这个值一般和我们解决问题的目的有关。如果只是简单的语义区分，则较小的K即可，如果是复杂的语义区分，则K需要较大，而且还需要足够的语料。

由于Gibbs采样可以很容易的并行化，因此也可以很方便的使用大数据平台来分布式的训练海量文档的LDA模型。以上就是LDA Gibbs采样算法。

变分推断EM

LDA的变分推断EM算法求解，应用于Spark MLlib和Scikit-learn的LDA算法实现，因此值得好好理解。

问题：

问题是在EM算法的E步，由于θ,β,z的耦合，我们难以求出隐藏变量θ,β,z的条件概率分布，也难以求出对应的期望，需要“变分推断“来帮忙，这里所谓的变分推断，也就是在隐藏变量存在耦合的情况下，我们通过变分假设，即假设所有的隐藏变量都是通过各自的独立分布形成的，这样就去掉了隐藏变量之间的耦合关系。我们用各个独立分布形成的变分分布来模拟近似隐藏变量的条件分布，这样就可以顺利的使用EM算法了。

流程：

输入：主题数KK,M个文档与对应的词。

　　　　1） 初始化α,ηα,η向量。

　　　　2）开始EM算法迭代循环直到收敛。

　　　　　　a) 初始化所有的ϕ,γ,λ，进行LDA的E步迭代循环,直到λ,ϕ,γ收敛。

　　　　　　　　(i) for d from 1 to M:

　　　　　　　　　  　for n from 1 to NdNd:

　　　　　　　　　　　  　for k from 1 to K:

　　　　　　　　　　　　　　　　按照(23)式更新$\phi_{dnk}$

　　　　　　　　　　　  标准化$\phi_{nk}$使该向量各项的和为1.

　　　　　　　　　　按照(24) 式更新$\gamma_{dk}$。

　　　　　　　　(ii) for k from 1 to K:

　　　　　　　　　　　　for i from 1 to V:

　　　　　　　　　　按照(26) 式更新$\lambda_{ki}$。

　　　　　　　　(iii)如果ϕ,γ,λ均已收敛，则跳出a)步，否则回到(i)步。

　　　　　　b) 进行LDA的M步迭代循环， 直到α,η收敛

　　　　　　　　(i) 按照(27)(28)式用牛顿法迭代更新α,η直到收敛

　　　　　　c) 如果所有的参数均收敛，则算法结束，否则回到第2)步。

#### 隐马尔可夫模型HMM

[hmmlearn(python)]([用hmmlearn学习隐马尔科夫模型HMM - 刘建平Pinard - 博客园 (cnblogs.com)](https://www.cnblogs.com/pinard/p/7001397.html))

隐马尔科夫模型（Hidden Markov Model，以下简称HMM）是比较经典的机器学习模型了，它在语言识别，自然语言处理，模式识别等领域得到广泛的应用。当然，随着目前深度学习的崛起，尤其是[RNN](http://www.cnblogs.com/pinard/p/6509630.html)，[LSTM](http://www.cnblogs.com/pinard/p/6519110.html)等神经网络序列模型的火热，HMM的地位有所下降。但是作为一个经典的模型，学习HMM的模型和对应算法，对我们解决问题建模的能力提高以及算法思路的拓展还是很好的。

##### 适用范围：

用HMM模型时我们的问题一般有这两个特征：１）我们的问题是基于序列的，比如时间序列，或者状态序列。２）我们的问题中有两类数据，一类序列数据是可以观测到的，即观测序列；而另一类数据是不能观察到的，即隐藏状态序列，简称状态序列。

有了这两个特征，那么这个问题一般可以用HMM模型来尝试解决。这样的问题在实际生活中是很多的。比如：我现在在打字写博客，我在键盘上敲出来的一系列字符就是观测序列，而我实际想写的一段话就是隐藏序列，输入法的任务就是从敲入的一系列字符尽可能的猜测我要写的一段话，并把最可能的词语放在最前面让我选择，这就可以看做一个HMM模型了。再举一个，我在和你说话，我发出的一串连续的声音就是观测序列，而我实际要表达的一段话就是状态序列，你大脑的任务，就是从这一串连续的声音中判断出我最可能要表达的话的内容。

##### 定义：

HMM模型做了两个很重要的假设如下：

1） 齐次马尔科夫链假设。如果在时刻t的隐藏状态是$i_t= q_i$在时刻t+1隐藏状态是$i_{t+1} = q_j$, 则从时刻t到时刻t+1的HMM状态转移概率$a_{ij}$可以表示为：$a_{ij} = P(i_{t+1} = q_j | i_t= q_i)$,这样$a_{ij}$可以组成马尔科夫链的状态转移矩阵A:$A=[a_{ij}]N×N$

2） 观测独立性假设。即任意时刻的观察状态只仅仅依赖于当前时刻的隐藏状态，这也是一个为了简化模型的假设。如果在时刻t的隐藏状态是$i_t= q_j$, 而对应的观察状态为$o_t = v_k$, 则该时刻观察状态$v_k$在隐藏状态$q_j$下生成的概率为$b_j(k)$,满足：$b_j(k) = P(o_t = v_k | i_t= q_j)$

这样$b_j^{k}$可以组成观测状态生成的概率矩阵B: $B = \Big [b_j(k) \Big ]_{N \times M}$

除此之外，我们需要一组在时刻t=1的隐藏状态概率分布$\Pi$:

$\Pi = \Big [ \pi(i)\Big ]_N \; 其中 \;\pi(i) = P(i_1 = q_i)$

一个HMM模型，可以由隐藏状态初始概率分布Π, 状态转移概率矩阵A和观测状态概率矩阵B决定。Π,A决定状态序列，B决定观测序列。因此，HMM模型可以由一个三元组λ表示如下：λ=(A,B,Π)

##### 基本问题：HMM模型一共有三个经典的问题需要解决：

　　　　1） 评估观察序列概率。即给定模型λ=(A,B,Π)和观测序列O={o1,o2,...oT}，计算在模型λ下观测序列O出现的概率P(O|λ)。这个问题的求解需要用到前向后向算法，我们在这个系列的第二篇会详细讲解。这个问题是HMM模型三个问题中最简单的。

　　　　2）模型参数学习问题。即给定观测序列O={o1,o2,...oT}，估计模型λ=(A,B,Π)的参数，使该模型下观测序列的条件概率P(O|λ)P(O|λ)最大。这个问题的求解需要用到基于EM算法的鲍姆-韦尔奇算法， 这个问题是HMM模型三个问题中最复杂的。

　　　　3）预测问题，也称为解码问题。即给定模型λ=(A,B,Π)和观测序列O={o1,o2,...oT}，求给定观测序列条件下，最可能出现的对应的状态序列，这个问题的求解需要用到基于动态规划的维特比算法，这个问题是HMM模型三个问题中复杂度居中的算法。

#### 条件随机场CRF

条件随机场(Conditional Random Fields, 以下简称CRF)是给定一组输入序列条件下另一组输出序列的条件概率分布模型，在自然语言处理中得到了广泛应用。本系列主要关注于CRF的特殊形式：线性链(Linear chain) CRF。本文关注与CRF的模型基础。

##### 适用范围：

和HMM类似，在讨论CRF之前，我们来看看什么样的问题需要CRF模型。这里举一个简单的例子：

　　　　假设我们有Bob一天从早到晚的一系列照片，Bob想考考我们，要我们猜这一系列的每张照片对应的活动，比如: 工作的照片，吃饭的照片，唱歌的照片等等。一个比较直观的办法就是，我们找到Bob之前的日常生活的一系列照片，然后找Bob问清楚这些照片代表的活动标记，这样我们就可以用监督学习的方法来训练一个分类模型，比如逻辑回归，接着用模型去预测这一天的每张照片最可能的活动标记。

这种办法虽然是可行的，但是却忽略了一个重要的问题，就是这些照片之间的顺序其实是有很大的时间顺序关系的，而用上面的方法则会忽略这种关系。比如我们现在看到了一张Bob闭着嘴的照片，那么这张照片我们怎么标记Bob的活动呢？比较难去打标记。但是如果我们有Bob在这一张照片前一点点时间的照片的话，那么这张照片就好标记了。如果在时间序列上前一张的照片里Bob在吃饭，那么这张闭嘴的照片很有可能是在吃饭咀嚼。而如果在时间序列上前一张的照片里Bob在唱歌，那么这张闭嘴的照片很有可能是在唱歌。

**为了让我们的分类器表现的更好，可以在标记数据的时候，可以考虑相邻数据的标记信息**。这一点，是普通的分类器难以做到的。而这一块，也是CRF比较擅长的地方。

在实际应用中，自然语言处理中的词性标注(POS Tagging)就是非常适合CRF使用的地方。词性标注的目标是给出一个句子中每个词的词性（名词，动词，形容词等）。而这些词的词性往往和上下文的词的词性有关，因此，使用CRF来处理是很适合的，当然CRF不是唯一的选择，也有很多其他的词性标注方法。

##### 理论：

1. 从随机场到马尔科夫随机场

   首先，我们来看看什么是随机场。随机场是由若干个位置组成的整体，当给每一个位置中按照某种分布随机赋予一个值之后，其全体就叫做随机场。还是举词性标注的例子：假如我们有一个十个词形成的句子需要做词性标注。这十个词每个词的词性可以在我们已知的词性集合（名词，动词...)中去选择。当我们为每个词初始化一个词性后，这就形成了一个随机场。

   了解了随机场，我们再来看看马尔科夫随机场。马尔科夫随机场是随机场的特例，**它假设随机场中某一个位置的赋值仅仅与和它相邻的位置的赋值有关，和与其不相邻的位置的赋值无关**。继续举十个词的句子词性标注的例子：　如果我们假设所有词的词性只和它相邻的词的词性有关时，这个随机场就特化成一个马尔科夫随机场。比如第三个词的词性除了与自己本身的位置有关外，只与第二个词和第四个词的词性有关。

2. 从马尔科夫随机场到条件随机场

   理解了马尔科夫随机场，再理解CRF就容易了。CRF是马尔科夫随机场的特例，它假设马尔科夫随机场中只有X和Y两种变量，X一般是给定的，而Y一般是在给定X的条件下我们的输出。这样马尔科夫随机场就特化成了条件随机场。在我们十个词的句子词性标注的例子中，X是词，Y是词性。因此，如果我们假设它是一个马尔科夫随机场，那么它也就是一个CRF。

   对于CRF，我们给出准确的数学语言描述：

   设X与Y是随机变量，P(Y|X)是给定X时Y的条件概率分布，若随机变量Y构成的是一个马尔科夫随机场，则称条件概率分布P(Y|X)是条件随机场。

3. 从条件随机场到线性链条件随机场

   注意在CRF的定义中，我们并没有要求X和Y有相同的结构。而实现中，我们一般都假设X和Y有相同的结构，即:

   $X =(X_1,X_2,...X_n),\;\;Y=(Y_1,Y_2,...Y_n)$

   我们一般考虑如下图所示的结构：X和Y有相同的结构的CRF就构成了线性链条件随机场(Linear chain Conditional Random Fields,以下简称 linear-CRF)。

   在我们的十个词的句子的词性标记中，词有十个，词性也是十个，因此，如果我们假设它是一个马尔科夫随机场，那么它也就是一个linear-CRF。

##### 基本问题：

和HMM不同，在linear-CRF中，我们对于给出的观测序列x是一直作为一个整体看待的，也就是不会拆开看(x1,x2,...)，因此linear-CRF的问题模型要比HMM简单一些，如果你很熟悉HMM，那么CRF的这三个问题的求解就不难了。

linear-CRF第一个问题是评估，即给定 linear-CRF的条件概率分布P(y|x), 在给定输入序列x和输出序列y时，计算条件概率P(yi|x)和P(yi−1，yi|x)以及对应的期望. 

linear-CRF第二个问题是学习，即给定训练数据集X和Y，学习linear-CRF的模型参数$w_k$和条件概率$P_w(y|x)$，这个问题的求解比HMM的学习算法简单的多，普通的梯度下降法，拟牛顿法都可以解决。

linear-CRF第三个问题是解码，即给定 linear-CRF的条件概率分布P(y|x),和输入序列x, 计算使条件概率最大的输出序列y。类似于HMM，使用维特比算法可以很方便的解决这个问题。　

##### linear-CRF vs HMM

linear-CRF模型和HMM模型有很多相似之处，尤其是其三个典型问题非常类似，除了模型参数学习的问题求解方法不同以外，概率估计问题和解码问题使用的算法思想基本也是相同的。同时，两者都可以用于序列模型，因此都广泛用于自然语言处理的各个方面。

现在来看看两者的不同点。最大的不同点是linear-CRF模型是判别模型，而HMM是生成模型，即linear-CRF模型要优化求解的是条件概率P(y|x)P(y|x),则HMM要求解的是联合分布P(x,y)P(x,y)。第二，linear-CRF是利用最大熵模型的思路去建立条件概率模型，对于观测序列并没有做马尔科夫假设。而HMM是在对观测序列做了马尔科夫假设的前提下建立联合分布的模型。

最后想说的是，只有linear-CRF模型和HMM模型才是可以比较讨论的。但是linear-CRF是CRF的一个特例，CRF本身是一个可以适用于很复杂条件概率的模型，因此理论上CRF的使用范围要比HMM广泛的多。

#### word2vec

[gensim(python)]([用gensim学习word2vec - 刘建平Pinard - 博客园 (cnblogs.com)](https://www.cnblogs.com/pinard/p/7278324.html))

word2vec是google在2013年推出的一个NLP工具，它的特点是将所有的词向量化，这样词与词之间就可以定量的去度量他们之间的关系，挖掘词之间的联系。

##### 基础

One hot representation用来表示词向量非常简单，但是却有很多问题。最大的问题是我们的词汇表一般都非常大，比如达到百万级别，这样每个词都用百万维的向量来表示简直是内存的灾难。这样的向量其实除了一个位置是1，其余的位置全部都是0，表达的效率不高，能不能把词向量的维度变小呢？

Distributed representation可以解决One hot representation的问题，它的思路是通过训练，将每个词都映射到一个较短的词向量上来。所有的这些词向量就构成了向量空间，进而可以用普通的统计学的方法来研究词与词之间的关系。这个较短的词向量维度是多大呢？这个一般需要我们在训练时自己来指定。

比如下图我们将词汇表里的词用"Royalty","Masculinity", "Femininity"和"Age"4个维度来表示，King这个词对应的词向量可能是(0.99,0.99,0.05,0.7)(0.99,0.99,0.05,0.7)。当然在实际情况中，我们并不能对词向量的每个维度做一个很好的解释。

![img](https://images2015.cnblogs.com/blog/1042406/201707/1042406-20170713150625759-1047275185.png)

有了用Distributed Representation表示的较短的词向量，我们就可以较容易的分析词之间的关系了，比如我们将词的维度降维到2维，有一个有趣的研究表明，用下图的词向量表示我们的词时，我们可以发现：

$\vec {King} - \vec {Man} + \vec {Woman} = \vec {Queen}$

![img](https://images2015.cnblogs.com/blog/1042406/201707/1042406-20170713151608181-1336632086.png)

可见我们只要得到了词汇表里所有词对应的词向量，那么我们就可以做很多有趣的事情了。不过，怎么训练得到合适的词向量呢？一个很常见的方法是使用神经网络语言模型。

##### 神经网络语言模型

在word2vec出现之前，已经有用神经网络DNN来用训练词向量进而处理词与词之间的关系了。采用的方法一般是一个三层的神经网络结构（当然也可以多层），分为输入层，隐藏层和输出层(softmax层)。

这个模型是如何定义数据的输入和输出呢？一般分为CBOW(Continuous Bag-of-Words 与Skip-Gram两种模型。

CBOW模型的训练输入是某一个特征词的上下文相关的词对应的词向量，而输出就是这特定的一个词的词向量。比如下面这段话，我们的上下文大小取值为4，特定的这个词是"Learning"，也就是我们需要的输出词向量,上下文对应的词有8个，前后各4个，这8个词是我们模型的输入。由于CBOW使用的是词袋模型，因此这8个词都是平等的，也就是不考虑他们和我们关注的词之间的距离大小，只要在我们上下文之内即可。

这样我们这个CBOW的例子里，我们的输入是8个词向量，输出是所有词的softmax概率（训练的目标是期望训练样本特定词对应的softmax概率最大），对应的CBOW神经网络模型输入层有8个神经元，输出层有词汇表大小个神经元。隐藏层的神经元个数我们可以自己指定。通过DNN的反向传播算法，我们可以求出DNN模型的参数，同时得到所有的词对应的词向量。这样当我们有新的需求，要求出某8个词对应的最可能的输出中心词时，我们可以通过一次DNN前向传播算法并通过softmax激活函数找到概率最大的词对应的神经元即可。

Skip-Gram模型和CBOW的思路是反着来的，即输入是特定的一个词的词向量，而输出是特定词对应的上下文词向量。还是上面的例子，我们的上下文大小取值为4， 特定的这个词"Learning"是我们的输入，而这8个上下文词是我们的输出。

这样我们这个Skip-Gram的例子里，我们的输入是特定词， 输出是softmax概率排前8的8个词，对应的Skip-Gram神经网络模型输入层有1个神经元，输出层有词汇表大小个神经元。隐藏层的神经元个数我们可以自己指定。通过DNN的反向传播算法，我们可以求出DNN模型的参数，同时得到所有的词对应的词向量。这样当我们有新的需求，要求出某1个词对应的最可能的8个上下文词时，我们可以通过一次DNN前向传播算法得到概率大小排前8的softmax概率对应的神经元所对应的词即可。

以上就是神经网络语言模型中如何用CBOW与Skip-Gram来训练模型与得到词向量的大概过程。但是这和word2vec中用CBOW与Skip-Gram来训练模型与得到词向量的过程有很多的不同。

word2vec优化使用的数据结构是用**霍夫曼树来代替隐藏层和输出层的神经元**，霍夫曼树的叶子节点起到输出层神经元的作用，叶子节点的个数即为词汇表的小大。 而内部节点则起到隐藏层神经元的作用。

##### 改进

word2vec有两种改进方法，一种是基于Hierarchical Softmax的，另一种是基于Negative Sampling的。详细算法解释略

## 模型

### 结构因果模型SCM

图论包：dagitty  SEM包：lavaan

定义：$X$​ 是 $Y$​ 的直接原因，它通过函数 $f()$​ 影响 $Y$​，并且假设噪声变量 $\epsilon_X$​ 和 $\epsilon_Y$​ 是独立的。 在 SCM 中，我们将每个方程视为一个因果陈述，并通过使用赋值符号 $:=$​ 而不是等号 $=$​ 来强调这一点。 请注意，这与标准回归模型形成鲜明对比； 在这里，我们明确地陈述了我们的因果假设。

SCM充分利用贝叶斯网络的结论， 在因果阶梯的最底层——关联——我们已经看到有向无环图如何帮助我们可视化条件独立性，以及 d-separation 如何为我们提供一种算法工具来检查这种独立性。

上升到第二个层次——干预——我们已经看到了 do-operator 如何对干预下的人群进行建模。 这帮助我们定义混杂——观察数据分析的祸根——发生在 $p(Y \mid X = x) \neq p(Y \mid do(X = x))$ 时。 这伴随着重要的观察结果，即将所有变量输入回归以“控制”它们是错误的； 相反，**我们需要仔细考虑潜在的因果关系**，以免我们想通过例如对碰撞器进行调节来引入偏见。 **后门标准**为我们提供了一种图形化的方式来评估效果是否受到混淆。

最后，我们已经看到结构因果模型 (SCM) 提供了观察和干预分布遵循的构建块。  SCM 进一步暗示反事实陈述，它位于因果层次结构的顶部。 这些使我们能够超越 do-operator 和平均因果效应：它们使我们能够回答关于如果事情有所不同会怎样的问题。



### 探索性因子分析EFA

假设您正在进行一项调查，并且想知道调查中的项目是否具有相似的响应模式，这些项目是否“挂在一起”以创建构造？ 因子分析的基本假设是，**对于一组观测变量，存在一组称为因子（小于观测变量）的潜在变量，可以解释这些变量之间的相互关系**

在因子分析中划分方差 由于因子分析的目标是对项目之间的相互关系进行建模，因此我们主要关注方差和协方差而不是均值。 因子分析假设方差可以划分为两种类型的方差，共同的和独特的：

![img](https://stats.idre.ucla.edu/wp-content/uploads/2018/05/fig02d.png)

提取因子 因子提取有两种方法，它们源于不同的方差划分方法：

a) 主成分分析和 b) 公因子分析

### [验证性因子分析CFA](https://stats.idre.ucla.edu/r/seminars/rcfa/)

验证性因子分析借鉴了探索性因子分析中的许多相同概念，不同之处在于我们不是让数据告诉我们因子结构，而是预先确定因子结构并验证先前开发的量表的心理测量结构

路径图可以帮助我们理解我们的 CFA 模型，因为它是测量模型和模型隐含协方差的象征性一对一可视化。 在我们展示实际路径图之前，下表定义了我们将使用的符号。 圆圈代表潜在变量，正方形代表观察到的指标，三角形代表截距或均值，单向箭头代表路径，双向箭头代表方差或协方差：

![img](https://stats.idre.ucla.edu/wp-content/uploads/2020/02/pathlegend2.png)

$\mbox{number of known values }=p(p+1)/2$

$\mbox{df} = \mbox{number of known values } – \mbox{ number of free parameters}$​

在 CFA 中，我们真正想要的是一个过度识别模型，其中已知值的数量大于自由参数的数量。 过度识别的模型允许我们评估模型拟合:

- df negative, known < free (*under-identified*, bad)
- df = 0, known = free (*just identified or saturated*, neither bad nor good)
- df positive, known > free (*over-identified*, good)

CFA 中最基本的模型是单因子模型，它会假设项目之间的协方差是由于单个公因子造成的,为了在具有三个或更多项目的 CFA 模型中识别一个因子，有两个选项分别称为**标记法和方差标准化法**

1. **marker method** fixes the *first* loading of each factor to 1,
2. **variance standardization method** fixes the variance of each factor to 1 but freely estimates all loadings.

将 CFA 与三个以上的项目拟合并评估模型的拟合总是更好，除非成本或理论限制阻止您这样做。执行包含三个以上项目的单因素 CFA 的好处是 a) 您的模型会自动识别，因为将有 6 个以上的自由参数，并且 b) 您的模型不会饱和，这意味着您将有自由度 来评估模型拟合。

对于超过三个项目的 CFA 模型，有一种方法可以评估模型对数据的拟合程度，即（总体）模型隐含的协方差矩阵与（总体）观察到的协方差矩阵匹配的接近程度。  CFA 模型中的原假设和替代假设是：

$H_0: \Sigma{(\theta)}=\Sigma$

$H_1: \Sigma{(\theta)} \ne \Sigma$

默认情况下，lavaan 输出模型卡方又名模型测试用户模型。 要请求额外的拟合统计数据，您将 fit.measures=TRUE 选项添加到 summary 中:

1. **Model chi-square** is the chi-square statistic we obtain from the maximum likelihood statistic (in lavaan, this is known as the Test Statistic for the Model Test User Model)
2. **CFI** is the *Comparative Fit Index* – values can range between 0 and 1 (values greater than 0.90, conservatively 0.95 indicate good fit)
3. **TLI** *Tucker Lewis Index* which also ranges between 0 and 1 (if it’s greater than 1 it should be rounded to 1) with values greater than 0.90 indicating good fit. If the CFI and TLI are less than one, the CFI is always greater than the TLI.
4. RMSEA is the root mean square error of approximation 
   - 在 lavaan 中，您还可以获得一个接近拟合的 p 值，即 RMSEA < 0.05。 如果您拒绝该模型，则表示您的模型不是紧密拟合模型

![img](https://stats.idre.ucla.edu/wp-content/uploads/2020/02/fit.png)

注：卡方值越大，样本隐含协方差矩阵与样本观测协方差矩阵之间的差异越大，您拒绝模型的可能性就越大。在 CFA 和 SEM 文献中有充分记载，卡方在模型测试中通常过于敏感，尤其是对于大样本。  David Kenny 指出，对于包含 75 到 200 个案例的模型，卡方是一个合理的拟合度量，但对于 400 个或更多案例，它几乎总是显着的

CFA 和结构方程模型的一般类别实际上是大样本技术，并且大部分理论都基于您的样本量尽可能大的前提。Kline (2016) 注意到了规则N:q，其中指出样本大小应由模型中的参数数量q决定，建议的比率为20:1

双因素CFA分为相关和不相关

总结：

CFA 与 EFA 不同，它是一种评估先前定义的假设可信度的方法，即模型隐含的协方差矩阵由测量模型定义，可以忠实地再现观察到的协方差矩阵。 注意：如果卡方显著，拒绝可能是由于卡方对大样本的敏感性，而不是模型的真实拒绝。 因此，研究人员经常使用拟合指数标准（例如 CFI > 0.95、TLI > 0.90 和 RMSEA < 0.10）来支持他们的主张。 由于其目标是重现观察到的协方差矩阵，其自由参数完全由$\Sigma$的维度决定。

 因此，识别是通过灌输固定参数来确保自由参数数量小于或等于参数总数的关键方法。 观察到的指标用作未观察到的构造或因素的量度。 一个刚刚确定的单因素模型的模型正好有三个指标，但由于资源限制，一些研究人员只需要每个因素两个指标； 然而，每个因素有超过三个项目是理想的，因为它允许导致拟合度量的自由度。 

最后，如果拟合表明单因素模型的拟合效果不佳，则双因素模型可能更合适，即项目测量的不仅仅是一个构造，并且两个构造函数或因子之间可能存在潜在的相关性。 然而，如果理论认为这两个结构之间的相关性是由第三个因素引起的，那么这两个一阶因素可以作为**潜在的二阶因素的潜在指标**。 然而，如果因素之间的相关性表示为回归路径，那么我们就超出了本次研讨会的范围，进入了所谓的结构方程建模(SEM)

### [结构方程模型SEM](https://stats.idre.ucla.edu/r/seminars/rsem/)

结构方程建模是一个线性模型框架，它用潜在变量对两个联立回归方程进行建模。 线性回归、多元回归、路径分析、验证性因素分析和结构回归等模型可以被认为是 SEM 的特例。  SEM 中可能存在以下关系：

- observed to observed variables (γ, e.g., regression)
- latent to observed variables (λ, e.g., confirmatory factor analysis)
- latent to latent variables (γ,β e.g., structural regression)

定义：

- **观测变量:** a variable that exists in the data, a.k.a **item** or manifest variable
- **潜在变量:** a variable that is constructed and does not exist in the data
- **外生变量:** an independent variable either observed (x) or latent (ξ) that explains an endogenous variable
- **内生变量:** a dependent variable, either observed (y) or latent (η) that has a causal path leading to it
- **测量模型:** a model that links observed variables with latent variables
- **指标:** an observed variable in a measurement model (can be exogenous or endogenous)
- **因子**: a latent variable defined by its indicators (can be exogenous or endogenous)
- **载荷:** a path between an indicator and a factor
- **结构模型:** a model that specifies casual relationships among exogenous variables to endogenous variables (can be observed or latent)
- **回归路径:** a path between exogenous and endogenous variables (can be observed or latent)

- `~` **predict**, used for regression of observed outcome to observed predictors (e.g., `y ~ x`)
- `=~` **indicator**, used for latent variable to observed indicator in factor analysis measurement models (e.g., `f =~ q + r + s`)
- `~~` **covariance** (e.g., `x ~~ x`)
- `~1` **intercept** or mean (e.g., `x ~ 1` estimates the mean of variable `x`)
- `1*` **fixes** **parameter** or loading to one (e.g., `f =~ 1*q`)
- `NA*` **frees** **parameter** or loading (useful to override default marker method, (e.g., `f =~ NA*q`)
- `a*` **labels** the **parameter** ‘a’, used for model constraints (e.g., `f =~ a*q`)

注：R 中的 lm() 函数使用最小二乘估计，而 lavaan 使用最大似然。

简单线性回归：

![img](https://stats.idre.ucla.edu/wp-content/uploads/2021/02/m1a-1.png)

多重线性回归：

![img](https://stats.idre.ucla.edu/wp-content/uploads/2021/02/m2.png)

多元线性回归：

![img](https://stats.idre.ucla.edu/wp-content/uploads/2021/02/m3a.png)

注：lm与lavaan在估计系数方面存在差异：默认情况下，lavaan 会协变内生变量 .read ~~ .arith 的残差方差$\psi_{12}$​​。 去除默认的残差协方差，则估计结果相同

完全饱和的多元回归：

![img](https://stats.idre.ucla.edu/wp-content/uploads/2021/02/m3e.png)

路径分析：

![img](https://stats.idre.ucla.edu/wp-content/uploads/2021/02/m4a.png)

假设：

- E(ζ)=0 the mean of the residuals is zero
- ζ is uncorrelated with x
- (I−B) is invertible (for example B≠I)

过度识别的模型允许灵活地对剩余的自由度进行建模。 例如在模型 4A 中，我们可以在 ppsych 和 read 之间添加一个额外的路径，但我们也可以在 .read 和 .arith 之间添加一个协方差。 添加这些参数中的任何一个都会产生一个完全饱和的模型。 如果没有强大的先验假设，可能很难确定要估计的最佳参数。 一种解决方案是使用**修正指数**，这是一种单自由度卡方检验，用于评估模型卡方将如何因将参数包含在模型中而发生变化。 卡方变化越大，添加附加参数的影响就越大

注意：并非对模型的所有修改都有意义。 例如，残差的协方差通常被视为一种在不改变模型的情况下改进拟合的“简单”方法。 但是，通过添加残差协方差，您正在对根据定义未由假设模型建模的变量之间无法解释的协方差进行建模。 尽管对这些协方差建模人为地提高了拟合度，但它们并没有说明您的模型假设的偶然机制。

测量模型

测量模型本质上是一个多元回归模型，其中预测变量是外生或内生**潜在变量**（又名因子）

外生测量模型：

![img](https://stats.idre.ucla.edu/wp-content/uploads/2021/02/m5a.png)

内生测量模型：

![img](https://stats.idre.ucla.edu/wp-content/uploads/2021/02/m5b.png)

结构回归模型 

到目前为止，我们已经讨论了构成结构回归模型的所有单个组件。 回想一下，多元回归涉及同时存在内生变量的回归，而路径分析允许解释性内生变量。 验证性因子分析是一种将潜在变量与指标联系起来的测量模型。 最后，结构回归统一了测量和结构模型，以允许解释潜在变量，无论是内生的还是外生的。

$$\mathbf{x= \tau_x + \Lambda_x \xi+ \delta}$$

$$\mathbf{y= \tau_y + \Lambda_y \eta + \epsilon}$$

$$\mathbf{\eta = \alpha + \Gamma \xi + B \eta + \zeta}$$

假设：

- η and ξ are not observed
- ϵ and δ are errors of measurement for y and x respectively
- ϵ is uncorrelated with 

具有一个内生变量的结构回归：

![img](https://stats.idre.ucla.edu/wp-content/uploads/2021/02/m6a.png)

具有两个内生变量的结构回归

![img](https://stats.idre.ucla.edu/wp-content/uploads/2021/02/m6b.png)

结论：

正如我们所见，结构方程建模是一个广泛的框架，它包含大量线性模型，即线性回归、多元回归、路径分析、验证性因素分析和结构回归。 了解矩阵参数化对于实际实施而言并不重要，而是让数据分析师能够充分了解每个 SEM 模型的细微差别和亚型。 

例如，潜在模型必须通过其相应的观察指标来识别，在观察所有变量的路径分析模型中不需要这种限制。 此外，一个明显地将潜在变量预测为观察到的内生变量的模型实际上是一个潜在的结构回归，其中观察到的内生变量被迫成为具有约束的单一指标测量模型。这些微妙之处对于临时分析师来说并不明显，直到他或她明白结构回归中的$\Gamma$和$B$矩阵仅指定潜在变量之间的关系。 

例如，在路径分析模型中，设置$B=0$等效于多元回归，其中唯一的预测是在观察到的外生变量和观察到的内生变量之间。 知道路径分析模型不包含$\eta$或$\xi$变量意味着理解路径分析仅适用于观察到的变量。 一旦分析师能够区分这些参数，他或她将开始理解结构方程模型的理论基础。 然而，区分$\Gamma$和$B$不足以理解所有的SEM，例如多组 SEM、潜在增长模型和测量不变性测试。 还有大量关于 SEM 的文献和书籍。

![img](https://stats.idre.ucla.edu/wp-content/uploads/2021/02/semflow.png)

$P=(identity*.062+satisfy)*0.730+identity$

附：[lavaan包官方网站](https://lavaan.ugent.be/tutorial/index.html)

### 回归

#### 线性回归

##### 岭回归

##### lasso回归

##### 弹性网

##### PCR和PLS

**偏最小二乘回归（英语：Partial least squares regression， PLS回归）**是一种[统计学](https://zh.wikipedia.org/wiki/统计学)方法，与[主成分回归](https://zh.wikipedia.org/w/index.php?title=主成分回归&action=edit&redlink=1)有关系，但不是寻找响应和独立变量之间最小[方差](https://zh.wikipedia.org/wiki/方差)的[超平面](https://zh.wikipedia.org/wiki/超平面)，而是通过投影[预测变量](https://zh.wikipedia.org/w/index.php?title=预测变量&action=edit&redlink=1)和[观测变量](https://zh.wikipedia.org/w/index.php?title=观测变量&action=edit&redlink=1)到一个新空间来寻找一个[线性回归](https://zh.wikipedia.org/wiki/線性回歸)模型。因为数据*X*和*Y*都会投影到新空间，PLS系列的方法都被称为双线性因子模型。当Y是分类数据时有“偏最小二乘判别分析（英语：Partial least squares Discriminant Analysis， PLS-DA）”，是PLS的一个变形。

偏最小二乘用于查找两个[矩阵](https://zh.wikipedia.org/wiki/矩阵)（*X*和*Y*）的基本关系，即一个在这两个空间对[协方差](https://zh.wikipedia.org/wiki/协方差)结构建模的[隐变量](https://zh.wikipedia.org/wiki/隐变量)方法。偏最小二乘模型将试图找到*X*空间的多维方向来解释*Y*空间方差最大的多维方向。偏最小二乘回归特别适合当预测矩阵比观测的有更多变量，以及*X*的值中有[多重共线性](https://zh.wikipedia.org/wiki/多重共线性)的时候。相比之下，标准的回归在这些情况下不见效（除非它是[吉洪诺夫正则化](https://zh.wikipedia.org/wiki/吉洪诺夫正则化)）。

PLS在化学计量学应用广泛，许多变量是数字化的光谱数据。在实践中，它的表现通常没有岭回归或主成分分析好。作为有监督的降维技术，PLS虽然可以降低方差，但它可能同时增大方差，所以总体来说PLS和PCA各有优劣

#### KNN回归

#### 正则化回归

#### 非线性模型

##### 多项式回归

##### 阶梯函数

##### 样条

##### 广义可加模型

#### 树回归

#### 支持向量机



### 分类

#### 近邻 (Nearest Neighbor)

典型的例子是KNN，它的思路就是——对于待判断的点，找到离它最近的几个数据点，根据它们的类型决定待判断点的类型。

它的特点是完全跟着数据走，没有数学模型可言。

适用情景：

需要一个特别容易解释的模型的时候。

比如需要向用户解释原因的推荐算法。

#### 贝叶斯 (Bayesian)

典型的例子是Naive Bayes，核心思路是根据条件概率计算待判断点的类型。

是相对容易理解的一个模型，至今依然被垃圾邮件过滤器使用。

适用情景：

需要一个比较容易解释，而且不同维度之间相关性较小的模型的时候。

可以高效处理高维数据，虽然结果可能不尽如人意。

#### 决策树 (Decision tree)

决策树的特点是它总是在沿着特征做切分。随着层层递进，这个划分会越来越细。

虽然生成的树不容易给用户看，但是数据分析的时候，通过观察树的上层结构，能够对分类器的核心思路有一个直观的感受。

适用情景：

因为它能够生成清晰的基于特征(feature)选择不同预测结果的树状结构，数据分析师希望更好的理解手上的数据的时候往往可以使用决策树。

同时它也是相对容易被攻击的分类器[3]。这里的攻击是指人为的改变一些特征，使得分类器判断错误。常见于垃圾邮件躲避检测中。因为决策树最终在底层判断是基于单个条件的，攻击者往往只需要改变很少的特征就可以逃过监测。

受限于它的简单性，决策树更大的用处是作为一些更有用的算法的基石。

#### 随机森林 (Random forest)

提到决策树就不得不提随机森林。顾名思义，森林就是很多树。

严格来说，随机森林其实算是一种集成算法。它首先随机选取不同的特征(feature)和训练样本(training sample)，生成大量的决策树，然后综合这些决策树的结果来进行最终的分类。

随机森林在现实分析中被大量使用，它相对于决策树，在准确性上有了很大的提升，同时一定程度上改善了决策树容易被攻击的特点。

适用情景：

数据维度相对低（几十维），同时对准确性有较高要求时。

因为不需要很多参数调整就可以达到不错的效果，基本上不知道用什么方法的时候都可以先试一下随机森林。

RF的推广：

1) ## extra trees

   随机选择了特征值的划分点位，而不是最优点位，这样会导致生成的决策树的规模一般会大于RF所生成的决策树。也就是说，模型的方差相对于RF进一步减少，但是偏倚相对于RF进一步增大。在某些时候，extra trees的泛化能力比RF更好

2) ## Totally Random Trees Embedding

   Totally Random Trees Embedding(以下简称 TRTE)是一种非监督学习的数据转化方法。它将低维的数据集映射到高维，从而让映射到高维的数据更好的运用于分类回归模型。我们知道，在支持向量机中运用了核方法来将低维的数据集映射到高维，此处TRTE提供了另外一种方法

3) ## Isolation Forest

   Isolation Forest（以下简称IForest）是一种异常点检测的方法。它也使用了类似于RF的方法来检测异常点

RF的主要优点有：

　　　　1） 训练可以高度并行化，对于大数据时代的大样本训练速度有优势。个人觉得这是的最主要的优点。

　　　　2） 由于可以随机选择决策树节点划分特征，这样在样本特征维度很高的时候，仍然能高效的训练模型。

　　　　3） 在训练后，可以给出各个特征对于输出的重要性

　　　　4） 由于采用了随机采样，训练出的模型的方差小，泛化能力强。

　　　　5） 相对于Boosting系列的Adaboost和GBDT， RF实现比较简单。

　　　　6） 对部分特征缺失不敏感。

　　　　RF的主要缺点有：

　　　　1）在某些噪音比较大的样本集上，RF模型容易陷入过拟合。

　　　　2) 取值划分比较多的特征容易对RF的决策产生更大的影响，从而影响拟合的模型的效果。

#### SVM (Support vector machine)

SVM的核心思想就是找到不同类别之间的分界面，使得两类样本尽量落在面的两边，而且离分界面尽量远。

最早的SVM是平面的，局限很大。但是利用核函数(kernel function)，我们可以把平面投射(mapping)成曲面，进而大大提高SVM的适用范围。

提高之后的SVM同样被大量使用，在实际分类中展现了很优秀的正确率。

<img src="数模整理.assets/image-20210818001005377.png" alt="image-20210818001005377" style="zoom:80%;" />

<img src="数模整理.assets/image-20210818000945060.png" alt="image-20210818000945060" style="zoom:80%;" />

因此SVM算法有相当多的超参数要调整，但最重要的是要考虑:

- the kernel (shown in figure 4)
- the *degree* hyperparameter, which controls how “bendy” the decision boundary will be for the polynomial kernel (shown in figure 4)
- the *cost* or *C* hyperparameter, which controls how “hard” or “soft” the margin is (shown in figure 5)
- the *gamma* hyperparameter, which controls how much influence individual cases have on the position of the decision boundary (shown in figure 5)

注：多项式阶数越高，可以学习到的决策边界越弯曲和复杂，但这有可能过度拟合训练集。

cost hyperparameter为边际内的案例分配成本或惩罚，或者换句话说，告诉算法边际内的案例有多糟糕。低成本告诉算法，在边界内有更多的案例是可以接受的，并且会导致更宽的边界，而不受类边界附近的局部差异的影响。高成本对边界内的案例施加了更严厉的惩罚，并将导致更窄的利润空间，更受阶级边界附近的局部差异的影响。

边界内的案例也是支持向量，因为移动它们会改变超平面的位置。
gamma超参数控制每种情况对超平面位置的影响，并由除线性核外的所有核函数使用。gamma值越大，每种情况下寻求关注的程度越高，决策边界的粒度越细（可能导致过度拟合）。gamma值越小，每种情况下寻求关注的程度越低，决策边界的粒度越小（可能导致拟合不足）。图5底部显示了高斯径向基核的伽马效应。

适用情景：

SVM在很多数据集上都有优秀的表现。

相对来说，SVM尽量保持与样本间距离的性质导致它抗攻击的能力更强。

和随机森林一样，这也是一个拿到数据就可以先尝试一下的算法。

#### 逻辑斯蒂回归 (Logistic regression)

回归方法的核心就是为函数找到最合适的参数，使得函数的值和样本的值最接近。例如线性回归(Linear regression)就是对于函数f(x)=ax+b，找到最合适的a,b。

LR拟合的就不是线性函数了，它拟合的是一个概率学中的函数，f(x)的值这时候就反映了样本属于这个类的概率。

适用情景：

LR同样是很多分类算法的基础组件，它的好处是输出值自然地落在0到1之间，并且有概率意义。

因为它本质上是一个线性的分类器，所以处理不好特征之间相关的情况。

虽然效果一般，却胜在模型清晰，背后的概率学经得住推敲。它拟合出来的参数就代表了每一个特征(feature)对结果的影响。也是一个理解数据的好工具。

#### 判别分析 (Discriminant analysis)

判别分析的典型例子是线性判别分析(Linear discriminant analysis)，简称LDA。

LDA的核心思想是把高维的样本投射(project)到低维上，如果要分成两类，就投射到一维。要分三类就投射到二维平面上。这样的投射当然有很多种不同的方式，LDA投射的标准就是让同类的样本尽量靠近，而不同类的尽量分开。对于未来要预测的样本，用同样的方式投射之后就可以轻易地分辨类别了。

使用情景：

判别分析适用于高维数据需要降维的情况，自带降维功能使得我们能方便地观察样本分布。它的正确性有数学公式可以证明，所以同样是很经得住推敲的方式。

但是它的分类准确率往往不是很高，所以不是统计系的人就把它作为降维工具用吧。

同时注意它是假定样本成正态分布的，所以那种同心圆形的数据就不要尝试了。

LDA算法既可以用来降维，又可以用来分类，但是目前来说，主要还是用于降维。在我们进行图像识别图像识别相关的数据分析时，LDA是一个有力的工具。下面总结下LDA算法的优缺点。

　　　　LDA算法的主要优点有：

　　　　1）在降维过程中可以使用类别的先验知识经验，而像PCA这样的无监督学习则无法使用类别先验知识。

　　　　2）LDA在样本分类信息依赖均值而不是方差的时候，比PCA之类的算法较优。

　　　　LDA算法的主要缺点有：

　　　　1）LDA不适合对非高斯分布样本进行降维，PCA也有这个问题。

　　　　2）LDA降维最多降到类别数k-1的维数，如果我们降维的维度大于k-1，则不能使用LDA。当然目前有一些LDA的进化版算法可以绕过这个问题。

　　　　3）LDA在样本分类信息依赖方差而不是均值的时候，降维效果不好。

　　　　4）LDA可能过度拟合数据。

#### 神经网络 (Neural network)

它的核心思路是利用训练样本(training sample)来逐渐地完善参数。还是举个例子预测身高的例子，如果输入的特征中有一个是性别（1:男；0:女），而输出的特征是身高（1:高；0:矮）。那么当训练样本是一个个子高的男生的时候，在神经网络中，从“男”到“高”的路线就会被强化。同理，如果来了一个个子高的女生，那从“女”到“高”的路线就会被强化。

最终神经网络的哪些路线比较强，就由我们的样本所决定。

神经网络的优势在于，它可以有很多很多层。如果输入输出是直接连接的，那它和LR就没有什么区别。但是通过大量中间层的引入，它就能够捕捉很多输入特征之间的关系。

使用情景：

数据量庞大，参数之间存在内在联系的时候。

当然现在神经网络不只是一个分类器，它还可以用来生成数据，用来做降维，这些就不在这里讨论了。

#### 提升算法（Boosting）

接下来讲的一系列模型，都属于集成学习算法(Ensemble Learning)，基于一个核心理念：三个臭皮匠，顶个诸葛亮。

翻译过来就是：当我们把多个较弱的分类器结合起来的时候，它的结果会比一个强的分类器更

典型的例子是AdaBoost,GBDT。

AdaBoost的实现是一个渐进的过程，从一个最基础的分类器开始，每次寻找一个最能解决当前错误样本的分类器。用加权取和(weighted sum)的方式把这个新分类器结合进已有的分类器中。

它的好处是自带了特征选择（feature selection），只使用在训练集中发现有效的特征(feature)。这样就降低了分类时需要计算的特征数量，也在一定程度上解决了高维数据难以理解的问题。

最经典的AdaBoost实现中，它的每一个弱分类器其实就是一个决策树。这就是之前为什么说决策树是各种算法的基石。

Adaboost的主要优点有：

　　　　1）Adaboost作为分类器时，分类精度很高

　　　　2）在Adaboost的框架下，可以使用各种回归分类模型来构建弱学习器，非常灵活。

　　　　3）作为简单的二元分类器时，构造简单，结果可理解。

　　　　4）不容易发生过拟合

　　　　Adaboost的主要缺点有：

　　　　1）对异常样本敏感，异常样本在迭代中可能会获得较高的权重，影响最终的强学习器的预测准确性。

GBDT利用加法模型和前向分步算法实现学习的优化过程。当损失函数时平方损失和指数损失函数时，每一步的优化很简单，如平方损失函数学习残差回归树。

对于一般的损失函数，往往每一步优化没那么容易，如上图中的绝对值损失函数和Huber损失函数。针对这一问题,Freidman提出了梯度提升算法：利用最速下降的近似方法，即利用损失函数的负梯度在当前模型的值，作为回归问题中提升树算法的残差的近似值，拟合一个回归树。

GBDT主要的优点有：

　　　　1) 可以灵活处理各种类型的数据，包括连续值和离散值。

　　　　2) 在相对少的调参时间情况下，预测的准确率也可以比较高。这个是相对SVM来说的。

　　　　3）使用一些健壮的损失函数，对异常值的鲁棒性非常强。比如 Huber损失函数和Quantile损失函数。

　　　　GBDT的主要缺点有：

　　　　1)由于弱学习器之间存在依赖关系，难以并行训练数据。不过可以通过自采样的SGBT来达到部分并行。

使用情景：

好的Boosting算法，它的准确性不逊于随机森林。虽然在[1]的实验中只有一个挤进前十，但是实际使用中它还是很强的。因为自带特征选择（feature selection）所以对新手很友好，是一个“不知道用什么就试一下它吧”的算法。

#### 装袋算法（Bagging）

同样是弱分类器组合的思路，相对于Boosting，其实Bagging更好理解。它首先随机地抽取训练集（training set），以之为基础训练多个弱分类器。然后通过取平均，或者投票(voting)的方式决定最终的分类结果。

因为它随机选取训练集的特点，Bagging可以一定程度上避免过渡拟合(overfit)。

在[1]中，最强的Bagging算法是基于SVM的。如果用定义不那么严格的话，随机森林也算是Bagging的一种。

附：Boosting和Bagging的区别：

Boosting主要关注降低偏差，因此Boosting能基于泛化性能相当弱的学习器构建出很强的集成；Bagging主要关注降低方差，因此它在不剪枝的决策树、神经网络等学习器上效用更为明显

Bagging算法是这样做的：每个分类器都随机**从原样本中做有放回的采样**，然后分别在这些采样后的样本上训练分类器，然后再把这些分类器组合起来。简单的多数投票一般就可以。其代表算法是随机森林。Boosting的意思是这样，他通过迭代地训练一系列的分类器，每个分类器采用的样本分布都**和上一轮的学习结果有关**。其代表算法是AdaBoost, GBDT

对于Bagging算法来说，由于我们会并行地训练很多不同的分类器的目的就是降低这个方差(variance) ,因为采用了相互独立的基分类器多了以后，h的值自然就会靠近.所以对于每个基分类器来说，目标就是如何降低这个偏差（bias),所以我们会采用深度很深甚至不剪枝的决策树。

 对于Boosting来说，每一步我们都会在上一轮的基础上更加拟合原数据，所以可以保证偏差（bias）,所以对于每个基分类器来说，问题就在于如何选择variance更小的分类器，即更简单的分类器，所以我们选择了深度很浅的决策树。

#### XGBOOST

作为GBDT的高效实现，XGBoost是一个上限特别高的算法，因此在算法竞赛中比较受欢迎。简单来说，对比原算法GBDT，XGBoost主要从下面三个方面做了优化：

一是算法本身的优化：在算法的弱学习器模型选择上，对比GBDT只支持决策树，还可以直接很多其他的弱学习器。在算法的损失函数上，除了本身的损失，还加上了正则化部分。在算法的优化方式上，GBDT的损失函数只对误差部分做负梯度（一阶泰勒）展开，而XGBoost损失函数对误差部分做二阶泰勒展开，更加准确。

二是算法运行效率的优化：对每个弱学习器，比如决策树建立的过程做并行选择，找到合适的子树分裂特征和特征值。在并行选择之前，先对所有的特征的值进行排序分组，方便前面说的并行选择。对分组的特征，选择合适的分组大小，使用CPU缓存进行读取加速。将各个分组保存到多个硬盘以提高IO速度。

三是算法健壮性的优化：对于缺失值的特征，通过枚举所有缺失值在当前节点是进入左子树还是右子树来决定缺失值的处理方式。算法本身加入了L1和L2正则化项，可以防止过拟合，泛化能力更强。

#### LightGBM

XGBoost的缺点：

空间消耗大。这样的算法需要保存数据的特征值，还保存了特征排序的结果（例如，为了后续快速的计算分割点，保存了排序后的索引），这就需要消耗训练数据两倍的内存。其次，时间上也有较大的开销，在遍历每一个分割点的时候，都需要进行分裂增益的计算，消耗的代价大。最后，对cache优化不友好。在预排序后，特征对梯度的访问是一种随机访问，并且不同的特征访问的顺序不一样，无法对cache进行优化。同时，在每一层长树的时候，需要随机访问一个行索引到叶子索引的数组，并且不同特征访问的顺序也不一样，也会造成较大的cache miss

LightGBM的优化：

为了避免上述XGBoost的缺陷，并且能够在不损害准确率的条件下加快GBDT模型的训练速度，lightGBM在传统的GBDT算法上进行了如下优化：

- 基于Histogram的决策树算法。
- 单边梯度采样 Gradient-based One-Side Sampling(GOSS)：使用GOSS可以减少大量只具有小梯度的数据实例，这样在计算信息增益的时候只利用剩下的具有高梯度的数据就可以了，相比XGBoost遍历所有特征值节省了不少时间和空间上的开销。
- 互斥特征捆绑 Exclusive Feature Bundling(EFB)：使用EFB可以将许多互斥的特征绑定为一个特征，这样达到了降维的目的。
- 带深度限制的Leaf-wise的叶子生长策略：大多数GBDT工具使用低效的按层生长 (level-wise) 的决策树生长策略，因为它不加区分的对待同一层的叶子，带来了很多没必要的开销。实际上很多叶子的分裂增益较低，没必要进行搜索和分裂。LightGBM使用了带有深度限制的按叶子生长 (leaf-wise) 算法。
- 直接支持类别特征(Categorical Feature)
- 支持高效并行
- Cache命中率优化

优点：

这部分主要总结下 LightGBM 相对于 XGBoost 的优点，从内存和速度两方面进行介绍。

**（1）速度更快**

- LightGBM 采用了直方图算法将遍历样本转变为遍历直方图，极大的降低了时间复杂度；
- LightGBM 在训练过程中采用单边梯度算法过滤掉梯度小的样本，减少了大量的计算；
- LightGBM 采用了基于 Leaf-wise 算法的增长策略构建树，减少了很多不必要的计算量；
- LightGBM 采用优化后的特征并行、数据并行方法加速计算，当数据量非常大的时候还可以采用投票并行的策略；
- LightGBM 对缓存也进行了优化，增加了缓存命中率；

**（2）内存更小**

- XGBoost使用预排序后需要记录特征值及其对应样本的统计值的索引，而 LightGBM 使用了直方图算法将特征值转变为 bin 值，且不需要记录特征到样本的索引，将空间复杂度从 ![[公式]](https://www.zhihu.com/equation?tex=O%282%2A%5C%23data%29) 降低为 ![[公式]](https://www.zhihu.com/equation?tex=O%28%5C%23bin%29) ，极大的减少了内存消耗；
- LightGBM 采用了直方图算法将存储特征值转变为存储 bin 值，降低了内存消耗；
- LightGBM 在训练过程中采用互斥特征捆绑算法减少了特征数量，降低了内存消耗。

缺点：

- 可能会长出比较深的决策树，产生过拟合。因此LightGBM在Leaf-wise之上增加了一个最大深度限制，在保证高效率的同时防止过拟合；
- Boosting族是迭代算法，每一次迭代都根据上一次迭代的预测结果对样本进行权重调整，所以随着迭代不断进行，误差会越来越小，模型的偏差（bias）会不断降低。由于LightGBM是基于偏差的算法，所以会对噪点较为敏感；
- 在寻找最优解时，依据的是最优切分变量，没有将最优解是全部特征的综合这一理念考虑进去；

### 精确率与召回率，ROC与PR曲线



1. 　　True Positives,TP：预测为正样本，实际也为正样本的特征数

2. 　　False Positives,FP：预测为正样本，实际为负样本的特征数

3. 　　True Negatives,TN：预测为负样本，实际也为负样本的特征数

4. 　　False Negatives,FN：预测为负样本，实际为正样本的特征数

![img](https://images2015.cnblogs.com/blog/1042406/201610/1042406-20161024154443875-2037260202.jpg)

精确率（Precision）的定义在上图可以看出，是绿色半圆除以红色绿色组成的圆。严格的数学定义如下：

​                 $$P = \frac{TP}{TP + FP }$$

召回率(Recall)的定义也在图上能看出，是绿色半圆除以左边的长方形。严格的数学定义如下：

　　　　$$R = \frac{TP}{TP + FN }$$

特异性(specificity)的定义图上没有直接写明，这里给出，是右边长方形去掉红色半圆部分后除以右边的长方形。严格的数学定义如下：

​                 $$ S = \frac{TN}{FP + TN }$$

有时也用一个F1值来综合评估精确率和召回率，它是精确率和召回率的调和均值。当精确率和召回率都高时,F1值也会高。严格的数学定义如下：

​                 $$\frac{2}{F_1} = \frac{1}{P} + \frac{1}{R}$$​

有时候我们对精确率和召回率并不是一视同仁，比如有时候我们更加重视精确率。我们用一个参数ββ来度量两者之间的关系。如果β>1, 召回率有更大影响，如果β<1,精确率有更大影响。自然，当β=1的时候，精确率和召回率影响力相同，和F1形式一样。含有度量参数β的F1我们记为$F_\beta$, 严格的数学定义如下：

　　　　$$F_\beta = \frac{(1+\beta^2)*P*R}{\beta^2*P + R}$$

此外还有灵敏度(true positive rate ,TPR)，它是所有实际正例中，正确识别的正例比例，它和召回率的表达式没有区别。严格的数学定义如下：

​                 $$TPR = \frac{TP}{TP + FN }$$

另一个是1-特异度(false positive rate, FPR)，它是实际负例中，错误的识别为正例的负例比例。严格的数学定义如下：

　　　　$$FPR = \frac{FP}{FP + TN }$$ 

我们熟悉了精确率， 召回率和特异性，以及TPR和FPR，后面的ROC曲线和PR曲线就好了解了。

以TPR为y轴，以FPR为x轴，我们就直接得到了RoC曲线。从FPR和TPR的定义可以理解，TPR越高，FPR越小，我们的模型和算法就越高效。也就是画出来的RoC曲线越靠近左上越好。如下图左图所示。从几何的角度讲，RoC曲线下方的面积越大越大，则模型越优。所以有时候我们用RoC曲线下的面积，即AUC（Area Under Curve）值来作为算法和模型好坏的标准

![img](https://images2015.cnblogs.com/blog/1042406/201610/1042406-20161024164359046-1869944207.png)

以精确率为y轴，以召回率为x轴，我们就得到了PR曲线。仍然从精确率和召回率的定义可以理解，精确率越高，召回率越高，我们的模型和算法就越高效。也就是画出来的PR曲线越靠近右上越好。如上图右图所示

使用ROC曲线和PR曲线，我们就能很方便的评估我们的模型的分类能力的优劣了

补充：J指数（又称尤登的J统计）为敏感性+特异性-1。接近1的值成为最佳值。（往往用在类别不平衡数据集的判别）

### 典型关联分析CCA

典型关联分析(Canonical Correlation Analysis，以下简称CCA)是最常用的挖掘数据关联关系的算法之一。比如我们拿到两组数据，第一组是人身高和体重的数据，第二组是对应的跑步能力和跳远能力的数据。那么我们能不能说这两组数据是相关的呢？CCA可以帮助我们分析这个问题

CCA使用的方法是将多维的X和Y都用线性变换为1维的X'和Y'，然后再使用相关系数来看X'和Y'的相关性。将数据从多维变到1位，也可以理解为CCA是在进行降维，将高维数据降到1维，然后再用相关系数进行相关性的分析

回想下主成分分析PCA，降维的原则是投影方差最大；再回想下线性判别分析LDA，降维的原则是同类的投影方差小，异类间的投影方差大。对于我们的CCA，它选择的投影标准是降维到1维后，两组数据的相关系数最大

![Canonical Correlation Analysis CCA Example in R](https://i2.wp.com/cmdlinetips.com/wp-content/uploads/2020/12/Canonical_Correlation_Analysis_CCA.png?resize=413%2C371&ssl=1)

CCA算法广泛的应用于数据相关度的分析，同时还是偏最小二乘法的基础。但是由于它依赖于数据的线性表示，当我们的数据无法线性表示时，CCA就无法使用，此时我们可以利用核函数的思想，将数据映射到高维后，再利用CCA的思想降维到1维，求对应的相关系数和线性关系，这个算法一般称为KCCA。

此外，我们在算法里只找了相关度最大的奇异值或者特征值，作为数据的相关系数，实际上我们也可以像PCA一样找出第二大奇异值，第三大奇异值...得到第二相关系数和第三相关系数。然后对数据做进一步的相关性分析。但是一般的应用来说，找出第一相关系数就可以了。

有时候我们的矩阵$S_{XX},S_{YY}$不可逆，此时我们得不到对应的逆矩阵，一般遇到这种情况可以对$S_{XX},S_{YY}$进行正则化，将$S_{XX},S_{YY}$变化为$S_{XX}+\gamma I,S_{YY}+\gamma I$​,然后继续求逆。其中γ为正则化系数

### [集成学习]([Stacking Ensemble Machine Learning With Python (machinelearningmastery.com)](https://machinelearningmastery.com/stacking-ensemble-machine-learning-with-python/))

#### [生长和修剪集成]([Growing and Pruning Ensembles in Python (machinelearningmastery.com)](https://machinelearningmastery.com/growing-and-pruning-ensembles-in-python/))

尽管 ensemble 可能有大量的 ensemble 成员，但很难知道 ensemble 正在使用最好的成员组合。 例如，不是简单地使用所有成员，而是可以通过添加更多不同的模型类型或删除一个或多个模型来获得更好的结果。

这可以通过使用加权平均集成和使用优化算法为每个成员找到合适的权重来解决，允许某些成员具有零权重，从而有效地将他们从集成中移除。 加权平均集成的问题在于所有模型仍然是集成的一部分，可能需要比开发和维护更复杂的集成。

另一种方法是优化集成本身的组成。 自动选择或优化集成成员的一般方法称为集成选择。

两种常见的方法包括集成增长和集成修剪:

- **Ensemble Growing**: 将成员添加到集合中，直到观察不到进一步的改进。
- **Ensemble Pruning**: 从整体中移除成员，直到观察不到进一步的改进。

优点:

它可能导致一个具有更小规模（较低复杂性）的集成和/或一个具有更好预测性能的集成。 有时，如果可以在模型复杂性和由此产生的维护负担大幅下降的情况下实现性能的小幅下降是可取的。 或者，在某些项目中，预测技能比所有其他问题都更重要，并且集成选择提供了另一种策略来尝试从贡献模型中获得最大收益

使用说明：

在预期少量集成成员表现更好的情况下，出于计算效率原因，集成增长可能是首选，而在预期大量集成成员表现更好的情况下，集成修剪将更有效。

简单的贪婪集成增长和剪枝与逐步特征选择技术有很多共同点，例如在回归中使用的那些技术（例如所谓的逐步回归）。

可以使用更复杂的技术，例如根据他们在数据集上的独立表现来选择要添加到集合中或从集合中删除的成员，或者甚至通过使用全局搜索过程，试图找到能够获得最佳总体性能的集合成员组合。

#### [投票集成]([How to Develop Voting Ensembles With Python (machinelearningmastery.com)](https://machinelearningmastery.com/voting-ensembles-with-python/))

投票是一种集成机器学习算法。 对于回归，投票集成涉及进行预测，该预测是多个其他回归模型的平均值。 在分类中：

**硬投票**：直接用类别值，少数服从多数。
**软投票**：各自分类器的概率值进行加权平均

一个投票集合可以被认为是一个元模型，一个模型的模型。
作为元模型，它可以与任何现有训练机器学习模型的集合一起使用，并且现有模型不需要知道它们正在集成中使用。 这意味着您可以探索在任何拟合模型集或子集上使用投票集成来完成您的预测建模任务。 当您有两个或多个模型在预测建模任务上表现良好时，投票集成是合适的。 集成中使用的模型必须大多与他们的预测一致。

在以下情况下使用投票集成：

1. 集成中的所有模型通常具有相同的良好性能 
2. 整体中的所有模型大多已经同意。
3. 它比集成中使用的任何模型产生更好的性能。
4. 它导致比集成中使用的任何模型更低的方差。

当投票集成中使用的模型预测清晰的类标签时，硬投票是合适的。 当投票集成中使用的模型预测类成员的概率时，软投票是合适的。 软投票可用于本身不预测类成员概率的模型，尽管在用于集成之前可能需要校准它们的类概率分数（例如支持向量机、k-最近邻和决策树）。

投票集成不能保证提供比集成中使用的任何单个模型更好的性能。 如果集成中使用的任何给定模型的性能优于投票集成，则可能应该使用该模型而不是投票集成。 这并非总是如此。 投票集成可以在对单个模型的预测中提供较低的方差。 这可以从回归任务的预测误差的较低方差中看出。 这也可以从分类任务准确性的较低差异中看出。 **这种较低的方差可能会导致集成的平均性能较低，鉴于模型的稳定性或置信度较高，这可能是可取的。**

投票集成对于使用随机学习算法并在每次在同一数据集上训练时产生不同最终模型的机器学习模型特别有用。 一个例子是使用随机梯度下降拟合的神经网络。

投票集成的另一个特别有用的情况是将同一机器学习算法的多个拟合与略有不同的超参数组合在一起。
投票集成在以下情况下最有效： 

1. 结合使用随机学习算法训练的模型的多个拟合
2. 将模型的多个拟合与不同的超参数相结合。

投票集成的一个限制是它对所有模型都一视同仁，这意味着所有模型对预测的贡献相同。 如果某些模型在某些情况下很好，而在其他情况下很差，这就是一个问题。

投票集合的扩展：

1. 加权平均集成（混合）。
2. 堆叠泛化（stacking）。

#### [加权投票集成]([How to Develop a Weighted Average Ensemble With Python (machinelearningmastery.com)](https://machinelearningmastery.com/weighted-average-ensemble-with-python/))

加权平均或加权和集成是一种集成机器学习方法，它结合了来自多个模型的预测，其中每个模型的贡献与其能力或技能成比例地加权。

加权平均集成与投票集成相关。投票集成技术的一个限制是它假设集成中的所有模型都同样有效。 情况可能并非如此，因为某些模型可能比其他模型更好，尤其是当使用不同的机器学习算法来训练每个模型集成成员时。

 投票的另一种选择是假设集合成员的能力并不完全相同，相反，某些模型比其他模型更好，并且在进行预测时应该获得更多选票或更多席位。 这为加权总和或加权平均集成方法提供了动机。

加权平均预测涉及首先为每个集合成员分配一个固定的权重系数。 这可能是一个介于 0 和 1 之间的浮点值，表示权重的百分比。 它也可以是一个从 1 开始的整数，代表给每个模型的投票数。

我们可以看到，只要分数具有相同的尺度，并且权重具有相同的尺度并且正在最大化（意味着更大的权重更好），加权和会产生一个合理的值，反过来，加权平均值是也是明智的，这意味着结果的规模与分数的规模相匹配。

同样的方法可用于计算每个清晰类别标签的加权投票总和或每个类别标签在分类问题上的加权概率总和。

使用加权平均集成的挑战在于**如何为每个集成成员选择相对权重。**

有很多方法可以使用。 例如，可以根据每个模型的技能选择权重，例如分类准确率或负误差，其中权重大意味着模型性能更好。 可以在用于训练的数据集或保持数据集上计算性能，后者可能更相关。

每个模型的分数可以直接使用，也可以转换成不同的值，比如每个模型的相对排名。 另一种方法可能是使用搜索算法来测试不同的权重组合。


#### [超级学习器]([How to Develop Super Learner Ensembles in Python (machinelearningmastery.com)](https://machinelearningmastery.com/super-learner-ensemble-in-python/))

什么是超级学习器？

考虑到您已经在数据集上拟合了许多不同的算法，并且某些算法已经使用不同的配置进行了多次评估。 您的问题可能有数十或数百种不同的模型。 为什么不使用所有这些模型代替组中最好的模型？

这就是所谓的“超级学习器”集成算法背后的直觉。

超级学习器算法首先要预先定义数据的 k 折分割，然后在相同的数据分割上评估所有不同的算法和算法配置。 然后保留所有未折叠的预测并用于训练学习如何最好地组合预测的 。

超级学习器技术是称为“堆叠泛化”或简称“堆叠”的通用方法的一个示例，在应用机器学习中称为混合，因为通常使用线性模型作为元模型。

The procedure can be summarized as follows:

- Select a k-fold split of the training dataset.
- Select m base-models or model configurations.
-  For each basemodel:
  - a. Evaluate using k-fold cross-validation.
  - b. Store all out-of-fold predictions.
  - c. Fit the model on the full training dataset and store.
-  Fit a meta-model on the out-of-fold predictions.
-  Evaluate the model on a holdout dataset or use model to make predictions.

![Diagram Showing the Data Flow of the Super Learner Algorithm](https://machinelearningmastery.com/wp-content/uploads/2019/10/Diagram-Showing-the-Data-Flow-of-the-Super-Learner-Algorithm.png)

元模型将基础模型的预测作为输入，并预测训练数据集的目标作为输出。

优点：可以集成多个模型结果，可用于回归和分类，模型性能优于任意一个单个模型

注：

1. 元模型通常很简单，提供了对基础模型所做预测的平滑解释。 因此，线性模型通常用作元模型，例如用于回归任务（预测数值）的线性回归和用于分类任务（预测类别标签）的逻辑回归。 虽然这很常见，但不是必需的。

2. 由于算法或评估过程的随机性，或数值精度的差异，您的结果可能会有所不同。考虑运行该示例几次，并比较平均结果。

3. 当多个不同的机器学习模型在一个数据集上有技能，但在不同的方式上有技能时，堆叠是合适的。 另一种说法是模型做出的预测或模型做出的预测误差不相关或相关性较低。

   基础模型通常是复杂多样的。 因此，使用一系列对如何解决预测建模任务做出截然不同假设的模型通常是一个好主意，例如线性模型、决策树、支持向量机、神经网络等。 其他集成算法也可以用作基础模型，例如随机森林。

4. 堆叠旨在提高建模性能，但不能保证在所有情况下都能带来改进。 实现性能改进取决于问题的复杂性，以及它是否被训练数据充分代表，是否足够复杂，以至于通过组合预测可以学习更多。 它还取决于基础模型的选择以及它们的预测（或错误）是否足够熟练且足够不相关。 如果基础模型的性能与堆叠集成一样好或更好，则应改用基础模型，因为它的复杂性较低（例如，它更易于描述、训练和维护）。

5. Q:为每个基础模型制作了最佳参数，并为每个基础模型制作了默认参数。 在我看来，如果每个基础模型都能达到更好的性能，那么元模型将通过训练数据与基础模型生成的预测相结合而获得更高的准确性。 但事实上，结果要差一些

   A:这是常见的。原因是高度调整的模型对小的变化很脆弱。

6. Q：如何从 Stacking Ensemble 中获取特征重要性？
   A: 顺便说一句，我不认为堆叠提供了这种能力。



#### [随机子空间集成]([How to Develop a Random Subspace Ensemble With Python (machinelearningmastery.com)](https://machinelearningmastery.com/random-subspace-ensemble-with-python/))

预测建模问题由一个或多个输入变量和一个目标变量组成。

 变量是数据中的一列，通常也称为特征。 我们可以将所有输入特征一起视为定义一个 n 维向量空间，其中 n 是输入特征的数量，每个示例（数据的输入行）是特征空间中的一个点。

这是机器学习中的一个常见概念，随着输入特征空间变大，空间中点之间的距离增加，通常称为维数灾难。

因此，输入特征的子集可以被认为是输入特征空间或子空间的子集。

选择特征是定义输入特征空间的子空间的一种方式。 例如，特征选择是指通过选择要保留的特征子集或要删除的特征子集来减少输入特征空间的维数的尝试，通常基于它们与目标变量的关系。

或者，我们可以选择输入特征的随机子集来定义随机子空间。 这可以用作集成学习算法的基础，其中模型可以适合每个随机特征子空间。 这被称为随机子空间系综或随机子空间方法。

因此，随机子空间集成与引导程序聚合（装袋）相关，它通过在训练数据集的不同随机样本上训练每个模型（通常是决策树）并替换（例如引导程序采样方法）来引入多样性。 **随机森林集成也可以被认为是装袋和随机子集集成方法的混合体**。

随机子空间方法可用于任何机器学习算法，尽管它非常适合对输入特征的大变化敏感的模型，例如决策树和 k 最近邻。

它适用于具有大量输入特征的数据集，因为它可以带来良好的性能和良好的效率。 **如果数据集包含许多不相关的输入特征，最好使用特征选择作为数据准备技术，因为子空间中不相关特征的普遍存在可能会损害集成的性能**。

随机子空间集成超参数:

1. 探索树的数量

2. 探索特征的数量

3. 探索替代算法

   决策树是随机子空间集成中最常用的算法。这样做的原因是它们易于配置并且可以很好地解决大多数问题。

   其他算法可用于构造随机子空间，并且必须配置为具有适度的高方差。 一个例子是 k-最近邻算法，其中 k 值可以设置为一个较低的值。

   集成中使用的算法通过“base_estimator”参数指定，并且必须设置为要使用的算法和算法配置的实例。

#### [动态分类器选择(DCS)]([Dynamic Classifier Selection Ensembles in Python (machinelearningmastery.com)](https://machinelearningmastery.com/dynamic-classifier-selection-in-python/))

动态分类器选择是一种用于分类预测建模的集成学习算法。

它是从许多训练有素的模型中选择一个以根据输入的特定细节进行预测的算法。

鉴于 DCS 中使用了多个模型，它被认为是一种集成学习技术。

动态分类器选择算法通常涉及以某种方式对输入特征空间进行分区，并分配特定模型来负责对每个分区进行预测。 有多种不同的 DCS 算法，研究工作主要集中在如何评估分类器并将其分配给输入空间的特定区域。

一种早期流行的方法涉及首先在训练数据集上拟合一组小的、多样化的分类模型。 当需要进行预测时，首先使用 k-最近邻 (kNN) 算法从训练数据集中找到与该示例匹配的 k 个最相似的示例。 然后在 k 个训练样本的邻居上评估模型中每个先前拟合的分类器，并选择表现最好的分类器来对新样本进行预测。

作者描述了两种选择单个分类器模型以对给定输入示例进行预测的方法，它们是：

- **Local Accuracy**, often referred to as LA or Overall Local Accuracy (OLA).
- **Class Accuracy**, often referred to as CA or Local Class Accuracy (LCA).

局部精度 (OLA) 涉及评估每个模型在 k 个训练示例的邻域上的分类精度。 然后选择在该邻域中表现最好的模型来对新示例进行预测。

分类准确度 (LCA) 涉及使用每个模型对新示例进行预测并记录预测的类。 然后，评估每个模型在 k 个训练样例的邻居上的准确性，并选择对其在新样例上预测的类别具有最佳技能的模型并返回其预测。

#### [动态集成选择(DES)]([Dynamic Ensemble Selection (DES) for Classification in Python (machinelearningmastery.com)](https://machinelearningmastery.com/dynamic-ensemble-selection-in-python/))

DCS 的一个自然扩展是动态选择一个或多个模型以进行预测的算法。 也就是说，动态选择分类器的子集或集合。 这些技术被称为动态集成选择或 DES。

动态集成选择算法的操作与 DCS 算法非常相似，不同之处在于使用来自多个分类器模型的投票而不是单个最佳模型进行预测。 实际上，输入特征空间的每个区域都由在该区域表现最佳的模型子集拥有。

KNORA 由 Albert Ko 等人描述。 在他们 2008 年题为“从动态分类器选择到动态集成选择”的论文中。 它是 DCS-LA 的扩展，它选择在邻域上表现良好的多个模型，然后使用多数投票将其预测组合起来，以做出最终的输出预测。

集成被认为是动态的，因为成员是根据需要预测的特定输入模式及时选择的。 这与静态相反，其中集成成员被选择一次，例如对模型中所有分类器的平均预测。

作者描述了 KNORA 的两个版本，包括 KNORA-Eliminate 和 KNORA-Union。

- **KNORA-Eliminate (KNORA-E)**: 在新示例的邻域上实现完美精度的分类器集合，并减小邻域大小，直到找到至少一个完美的分类器。
- **KNORA-Union (KNORA-U)**: 所有分类器的集合，通过加权投票对邻域进行至少一个正确的预测，并且投票与邻域的准确性成正比。

KNORA 的超参数调优：

1. 用于模型局部评估的 k 最近邻模型中的 k 值

   k 值控制邻域的大小，重要的是将其设置为适合数据集的值，特别是特征空间中的样本密度。 值太小意味着训练集中的相关示例可能会被排除在邻域之外，而值太大可能意味着信号被太多示例冲掉了。

2. 如何使用自定义分类器池

   除了指定分类器池之外，还可以从 scikit-learn 库中指定单个集成算法，KNORA 算法将自动使用内部集成成员作为分类器。

### 时间序列

#### tssibble 简短使用指南

tsibble 包将 tidyverse 扩展到时间数据。 建立在 tibble 之上的 tsibble（或 tbl_ts）是一个面向数据和模型的对象。 与 R 中传统的时间序列对象（例如 ts、zoo 和 xts）相比，tsibble 保留了时间索引作为基本数据列，并使异构数据结构成为可能。 除了类似 tibble 的表示之外，还引入了由单个或多个变量组成的键，以随着时间的推移唯一地标识观察单位（索引）。  tsibble 包旨在管理时态数据并在流畅的工作流程中完成分析。

上下文语义：索引和键

tsibble() 创建一个 tsibble 对象，而 as_tsibble() 是一种 S3 方法，用于将其他对象强制转换为 tsibble。 向量/矩阵作为基础的对象，例如 ts 和 mts，可以使用 as_tsibble() 自动转换为 tsibble，无需任何规范。 如果它是一个 tibble 或数据帧， as_tsibble() 需要更多的设置来声明索引和关键变量。

nycflights13 包中包含的天气数据包含 2013 年纽约市三个站点（即 JFK、LGA 和 EWR）的每小时气象记录（如温度、湿度和降水）。 由于 time_hour 是唯一涉及时间戳的列，因此 as_tsibble() 将其默认为索引变量； 或者，可以通过参数 index = time_hour 指定索引以禁用详细消息。

除了索引，tsibble 需要“key”，它定义了随时间测量的主题或个人。 在这个例子中，原始变量是标识符，它被传递给 as_tsibble() 中的参数键。 每个观察都应由有效 tsibble 中的索引和键唯一标识。 其他——温度、湿度和降水——被称为测量变量。 创建 tsibble 时，将首先对键进行排序，然后是从过去到最近排列时间。

根据相应的时间表示自动获得一个间隔：

- `integer`/`numeric`/`ordered`: either “unit” or “year” (`Y`)
- `yearquarter`/`yearqtr`: “quarter” (`Q`)
- `yearmonth`/`yearmon`: “month” (`M`)
- `yearweek`: “week” (`W`)
- `Date`: “day” (`D`)
- `difftime`: “week” (`W`), “day” (D), “hour” (`h`), “minute” (`m`), “second” (`s`)
- `POSIXct`/`hms`: “hour” (`h`), “minute” (`m`), “second” (`s`), “millisecond” (`us`), “microsecond” (`ms`)
- `nanotime`: “nanosecond” (`ns`)

也就是说，每月间隔的 tsibble 期望索引列中的 `yearmonth`/`yearmon` 类。  `Date` 和 `POSIXct` 都不提供每月的 tsibble。

 打印显示以数据为中心并提供上下文信息，例如数据维度、时间间隔和基于时间的单位数。 上面显示了 `weather_tsbl` 的一小时间隔（`[1h]`）和作为键的 `origin [3]` 以及表中的三个时间序列。

数据管道

这种整洁的数据表示最自然地支持将数据操作视为构建块，形成基于时间的上下文中“数据管道”的一部分。 熟悉 tidyverse 的用户会发现执行常见的时间分析任务更容易。 例如， index_by() 在时间上下文中是 group_by() 的对应物，但它只对时间索引进行分组。  index_by() + summarise() 用于总结每个站点的每日高点和低点。 结果，索引从索引 time_hour 更新为间隔一天的日期； 为每日最高和最低温度创建和计算两个新变量。

不规则的时间间隔

请注意，tsibble 可以根据其时间表示（参见 ?tsibble）很好地处理从几秒到几年的规则间隔时间数据。 默认情况下，选项常规在 as_tsibble() 中设置为 TRUE。 将regular 指定为FALSE 可为以不规则时间间隔收集的数据创建tsibble。 下面显示了纽约航班的预定日期时间：

#### 基础知识

时间序列模式：

##### 趋势：

当数据长期增加或减少时，存在趋势。它不必是线性的。有时我们会将趋势称为“改变方向”，当它可能从增加趋势变为减少趋势时。图2.2显示了抗糖尿病药物销售数据的趋势。

季节性：

当时间序列受到季节性因素（如一年中的时间或一周中的某一天）的影响时，就会出现季节性模式。季节性总是一个固定且已知的周期。抗糖尿病药物的月销售额（图2.2）显示了季节性，部分原因是日历年末药物成本的变化。

周期性：当数据呈现出非固定频率的上升和下降时，发生周期性。这些波动通常是由经济状况引起的，通常与“商业周期”有关。这些波动的持续时间通常至少为2年。

许多人把周期性行为和季节性行为混淆起来，但它们实际上是完全不同的。如果波动不是固定频率的，那么它们是周期性的；如果频率是不变的，并且与日历的某些方面相关，那么模式是季节性的。一般来说，周期的平均长度比季节性模式的长度长，周期的大小往往比季节性模式的大小变化更大。

许多时间序列包括趋势、周期和季节性。在选择预测方法时，我们首先需要识别数据中的时间序列模式，然后选择能够正确捕获模式的方法。

##### 自相关：

ACF()

正如相关性衡量两个变量之间线性关系的程度一样，自相关衡量时间序列滞后值之间的线性关系。

有几个自相关系数，对应于滞后图中的每个面板。 例如，$r_{1}$ 测量$y_{t}$和$y_{t-1}$ 之间的关系，$r_{2}$ 测量$y_{t}$和$y_{t-2}$ 之间的关系，依此类推,$r_{k}$的值可以写为

​                                              $$r_{k} = \frac{\sum\limits_{t=k+1}^T (y_{t}-\bar{y})(y_{t-k}-\bar{y})} {\sum\limits_{t=1}^T (y_{t}-\bar{y})^2}$$

当数据具有趋势时，小滞后的自相关往往较大且为正，因为时间上邻近的观测值的值也邻近。 因此，趋势时间序列的 ACF 往往具有正值，随着滞后的增加而缓慢减小

当数据是季节性的时，季节性滞后（季节性周期的倍数）的自相关将大于其他滞后

当数据既是趋势数据又是季节性数据时，您会看到这些影响的组合。 图 中绘制的 a10 数据显示了趋势和季节性。 其 ACF 如图 2.21 所示。 随着滞后时间的增加，ACF 的缓慢下降是由于趋势，而“扇贝”形状是由于季节性。

![ACF of monthly Australian antidiabetic drug sales.](https://otexts.com/fpp3/fpp_files/figure-html/acfa10-1.png)

##### 白噪声：

不显示自相关的时间序列称为白噪声

![Autocorrelation function for the white noise series.](https://otexts.com/fpp3/fpp_files/figure-html/wnoiseacf-1.png)

对于白噪声序列，我们期望每个自相关接近于零。 当然，它们不会完全等于零，因为存在一些随机变化。 对于白噪声序列，我们预计 ACF 中 95% 的尖峰位于 $\pm 2/\sqrt{T}$内，其中 T 是时间序列的长度。 通常将这些边界绘制在 ACF 的图形上（上面的蓝色虚线）。 如果一个或多个大尖峰在这些范围之外，或者超过 5% 的尖峰在这些范围之外，则该系列可能不是白噪声



#### 时序分解

时间序列数据可以表现出多种模式，将时间序列分成几个部分通常很有帮助，每个部分代表一个基础模式类别。

前文我们讨论了三种类型的时间序列模式：趋势、季节性和周期。 当我们将时间序列分解为组件时，我们通常将趋势和周期合并为一个趋势周期组件（为简单起见，通常简称为趋势）。 因此，我们可以将时间序列视为由三个部分组成：**趋势周期部分、季节性部分和剩余部分**（包含时间序列中的任何其他部分）。 对于某些时间序列（例如，那些至少每天观察到的时间序列），对应于不同的季节周期，可能有不止一个季节成分。

##### 调整和转换

调整历史数据通常可以得到更简单的时间序列。 在这里，我们处理四种调整：日历调整、人口调整、通货膨胀调整和数学变换。 这些调整和转换的目的是**通过移除已知的变异源或使整个数据集的模式更加一致来简化历史数据中的模式**。 更简单的模式通常更容易建模并导致更准确的预测。

日历调整:

在季节性数据中看到的一些变化可能是由于简单的日历效应。 在这种情况下，在进行任何进一步分析之前去除变异通常要容易得多。

 例如:如果您正在研究零售店的每月总销售额，那么除了一年中的季节性变化之外，由于每个月的交易日数不同，月份之间也会存在差异。 通过计算每个月每个交易日的平均销售额，而不是当月的总销售额，很容易消除这种变化。 然后我们有效地消除了日历变化。

人口调整:

任何受人口变化影响的数据都可以调整为人均数据。 也就是说，考虑每人（或每千人，或每百万人）的数据而不是总数。 

例如，如果您正在研究一段时间内特定区域的医院床位数量，如果您通过考虑每千人的床位数量来消除人口变化的影响，则结果会更容易解释。 然后您可以查看床位数量是否真正增加，或者增加是否完全是由于人口增加。 床位总数可能增加，但每千人床位数量减少。 当人口增长快于病床数量时，就会发生这种情况。**对于大多数受人口变化影响的数据，最好使用人均数据而不是总数**。

通货膨胀调整:

受货币价值影响的数据最好在建模前进行调整。 例如，由于通货膨胀，新房的平均成本在过去几十年中会增加。 今年 20 万美元的房子和 20 年前 20 万美元的房子不一样。 出于这个原因，通常会调整金融时间序列，以便所有价值都以特定年份的美元价值表示。 例如，房价数据可能以 2000 美元表示。

为了进行这些调整，使用了价格指数。 如果$z_{t}$表示价格指数，$y_{t}$表示$t$年的原始房价，则$x_{t} = y_{t}/z_{t} * z_{2000}$给出了 2000 年美元价值的调整后的房价。 价格指数通常由政府机构构建。 对于消费品，常见的价格指数是消费者价格指数（CPI）。

数学变换：

如果数据显示随序列水平增加或减少的变化，则转换可能很有用。 例如，对数变换通常很有用。 如果我们将原始观测值表示为$y_{1},\dots,y_{T}$，将变换后的观测值表示为$w_{1}, \dots, w_{T}$，那么$ w_ {t} = log ( y _{t} ) $。 对数很有用，因为它们是可解释的：对数值的变化是原始尺度上的相对（或百分比）变化。 因此，如果使用对数基数10，那么对数刻度上的增加1对应于原始刻度上的 10 乘法。 如果原始系列的任何值为零或负数，则对数是不可能的。

有时也使用其他转换（尽管它们不太容易解释）。 例如，可以使用平方根和立方根。 这些被称为幂变换，因为它们可以写成$w_{t} = y_{t}^p$的形式。

一个有用的变换族，包括对数和幂变换，是 Box-Cox 变换族 (Box & Cox, 1964)，它依赖于参数 λ，定义如下：

​                           $$\begin{equation}  w_t  =    \begin{cases}      \log(y_t) & \text{if $\lambda=0$};  \\      (\text{sign}(y_t)|y_t|^\lambda-1)/\lambda & \text{otherwise}.    \end{cases}    \end{equation}$$

一个好的 λ 值可以使整个系列的季节性变化的大小大致相同，guerrero 特征（Guerrero，1993）可用于为您选择 lambda 值 下图选择 λ = 0.12

![image-20210820204858624](数模整理.assets/image-20210820204858624.png)

features()

##### 时间序列组件

如果我们假设一个加法分解，那么我们可以写：$y_{t} = S_{t} + T_{t} + R_t$

其中 y t 是数据，S t 是季节性分量，T t 是趋势周期分量，R t 是剩余分量，均在 t 期间。 或者，乘法分解将写为：$y_{t} = S_{t} \times T_{t} \times R_t.$

如果季节性波动的幅度或趋势周期周围的变化不随时间序列的水平而变化，则加法分解是最合适的。 当季节性模式的变化或趋势周期周围的变化似乎与时间序列的水平成正比时，乘法分解更合适。 乘法分解在经济时间序列中很常见。

使用乘法分解的替代方法是首先转换数据，直到序列中的变化随着时间的推移看起来稳定，然后使用加法分解。 当使用对数变换时，这等效于使用乘法分解，因为:

$y_{t} = S_{t} \times T_{t} \times R_t \quad\text{is equivalent to}\quad  \log y_{t} = \log S_{t} + \log T_{t} + \log R_t.$

季节性调整数据：

如果从原始数据中去除季节性成分，则结果值就是“季节性调整”数据。

 对于加法分解，季节性调整数据由$y_{t}-S_{t}$给出，对于乘法数据，使用$ y _{t} / S_{t} $获得季节性调整值。

如果季节性变化不是主要关注点，则季节性调整序列可能有用。 例如，月度失业数据通常会进行季节性调整，以突出由于经济基本状态而不是季节性变化引起的变化。 离校生找工作造成的失业增加是季节性变化的，而经济衰退造成的失业增加是非季节性的。 大多数研究失业数据的经济分析师对非季节性变化更感兴趣。 **因此，就业数据（以及许多其他经济系列）通常会进行季节性调整**。

注：季节性调整的系列包含剩余部分以及趋势周期。 因此，它们并不“平稳”，“衰退”或“上涨”可能会产生误导。 **如果目的是寻找系列中的转折点，并解释方向的任何变化，那么最好使用趋势周期组件而不是季节性调整数据**。

##### 经典分解

经典的分解方法起源于 1920 年代。 这是一个相对简单的过程，是大多数其他时间序列分解方法的起点。 有两种形式的经典分解：加法分解和乘法分解。 下面描述了具有季节性周期 m 的时间序列（例如，对于季度数据，m = 4，对于每月数据，m = 12，对于具有每周模式的每日数据，m = 7）。

在经典分解中，**假设季节性成分每年都是恒定的**。 对于乘性季节性，构成季节性分量的 m 值有时称为“季节性指数”。

加法分解:

步骤 1 如果 m 是偶数，则使用 2 × m -MA 计算趋势周期分量 $\hat{T}_t$。 如果 m 是奇数，则使用 m -MA 计算趋势周期分量$\hat{T}_t$。

步骤 2 计算去趋势序列：$y_t - \hat{T}_t$。

步骤 3 要估计每个季节的季节性成分，只需平均该季节的去趋势值。 

例如，对于月度数据，3 月份的季节性成分是数据中所有去趋势的 3 月份值的平均值。 然后调整这些季节性分量值以确保它们加起来为零。 季节性成分是通过将这些月度值串在一起获得的，然后为每一年的数据复制序列。 这给出了$\hat{S}_t$。

步骤 4 通过减去估计的季节性和趋势周期分量来计算剩余分量：$\hat{R}_t = y_t - \hat{T}_t - \hat{S}_t$

乘法分解：

经典的乘法分解与此类似，只是减法被除法代替。

评论：

虽然经典分解仍然被广泛使用，但不推荐使用，因为现在有几种更好的方法。 下面总结了经典分解的一些问题：

* 对于前几个和最后几个观察，趋势周期的估计是不可用的。 例如，如果 m = 12 ，则没有前六个或最后六个观测值的趋势周期估计。 因此，也没有对相同时间段的剩余部分进行估计。
* 趋势周期估计倾向于过度平滑数据中的快速上升和下降。
* 经典分解方法假设季节性成分年复一年地重复。 对于许多系列，这是一个合理的假设，但对于一些较长的系列则不然。 例如，随着空调变得更加普及，电力需求模式随着时间的推移而发生了变化。 在许多地方，几十年前的季节性使用模式在冬季（由于供暖）需求最大，而当前的季节性模式在夏季（由于空调）需求最大。 经典分解方法无法捕捉这些随时间的季节性变化。
* 有时，少数时期的时间序列值可能特别不寻常。 例如，每月的航空客运量可能受到劳资纠纷的影响，使纠纷期间的客流量与平时不同。 经典方法对这些异常值并不稳健。

##### 官方统计机构方法

官方统计机构（如美国人口普查局和澳大利亚统计局）负责大量官方经济和社会时间序列。 这些机构制定了自己的分解程序，用于季节性调整。 他们中的大多数使用 X-11 方法的变体，或 SEATS 方法，或两者的组合。

**这些方法专门设计用于处理季度和月度数据**，这是官方统计机构处理的最常见的系列。 他们不会处理其他类型的季节性，例如每日数据、每小时数据或每周数据。 我们将使用这组方法的最新实现，称为“X-13ARIMA-SEATS”。

X-11:

X-11 方法起源于美国人口普查局，并由加拿大统计局进一步发展。 它基于经典分解，但包括许多额外的步骤和功能，以克服上一节中讨论的经典分解的缺点。 特别是，趋势周期估计可用于包括终点在内的所有观察，并且允许季节性成分随时间缓慢变化。

  X-11 还处理交易日变化、假期影响和已知预测因素的影响。 有加法和乘法分解的方法。 该过程是完全自动的，并且往往对时间序列中的异常值和水平变化具有高度鲁棒性。  X-11 方法的详细信息在 Dagum & Bianconcini (2016) 中有描述。

SEATS：

“SEATS”代表“ARIMA 时间序列中的季节性提取”。 这个程序是在西班牙银行开发的，现在被世界各地的政府机构广泛使用。 Dagum & Bianconcini (2016) 中提供了对该方法的完整讨论。

`seasonal` package 

##### STL分解

STL 是一种用于分解时间序列的通用且稳健的方法。  STL 是“使用 Loess 进行季节和趋势分解”的首字母缩写，而 loess 是一种估计非线性关系的方法。  STL 方法是由 R. B. Cleveland 等人开发的(1990)。

STL 与经典分解以及 SEATS 和 X-11 方法相比有几个优点： 

* 与 SEATS 和 X-11 不同，STL 将处理任何类型的季节性，而不仅仅是月度和季度数据。
* 季节性分量可以随时间变化，变化的速度可以由用户控制。
* 用户也可以控制趋势周期的平滑度。
* 它可以对异常值具有鲁棒性（即，用户可以指定鲁棒分解），以便偶尔出现的异常观察不会影响趋势周期和季节性分量的估计。 然而，它们会影响剩余部分。

另一方面，STL 也有一些缺点。 特别是它不会自动处理交易日或日历变化，它只提供用于附加分解的工具。

乘法分解可以通过首先记录数据，然后反向转换组件来获得。 可以使用 0 < λ < 1 的数据的 Box-Cox 变换获得加法和乘法之间的分解。  λ = 0 值给出乘法分解，而 λ = 1 给出加法分解。

STL()

#### 时序特征

我们已经看到了一些时间序列特征。 例如，前文讨论的自相关可以被视为时间序列的特征——它们是从该序列计算的数值汇总。 我们在上一章中看到的另一个特征是 Box-Cox 变换参数的 Guerrero 估计——同样，这是一个从时间序列计算的数字。

`feasts` package

##### ACF特征

自相关上文中讨论过。 一个系列的所有自相关都可以被认为是该系列的特征。 我们还可以总结自相关以产生新特征； 例如，前十个平方自相关系数的总和是一个有用的总结，无论滞后如何，序列中有多少自相关。

我们还可以计算不同时期之间序列变化的自相关。 也就是说，我们“区分”数据并创建一个由连续观察之间的差异组成的新时间序列。 然后我们可以计算这个新的差分序列的自相关。 有时再次应用相同的差分操作很有用，因此我们计算差异的差异。 这个双差分序列的自相关可以提供有用的信息。

另一种相关方法是计算系列的季节性差异。 例如，如果我们有月度数据，我们将计算连续的 1 月、连续的 2 月等之间的差异。 这使我们能够查看该系列如何在几年之间而不是几个月之间发生变化。 同样，季节性差异序列的自相关可能会提供有用的信息。

##### STL特征

时间序列分解可用于衡量时间序列中趋势和季节性的强度。 回想一下，分解写为$y_t = T_t + S_{t} + R_t,$其中 T t 是平滑趋势分量，S t 是季节性分量，R t 是余数分量。 

对于强趋势数据，经季节性调整的数据应该比剩余部分具有更多的变化。 因此 Var ( R t ) /Var ( T t + R t ) 应该相对较小。 但是对于趋势很小或没有趋势的数据，两个方差应该大致相同。 因此，我们将趋势强度定义为：

​                                    $$F_T = \max\left(0, 1 - \frac{\text{Var}(R_t)}{\text{Var}(T_t+R_t)}\right).$$

这将给出 0 和 1 之间趋势强度的度量。因为余数的方差有时可能甚至大于季节性调整数据的方差，将 F T 的最小可能值设置为零。

季节性强度的定义类似，但针对去趋势数据而不是季节性调整数据： 

​                                   $$F_S = \max\left(0, 1 - \frac{\text{Var}(R_t)}{\text{Var}(S_{t}+R_t)}\right).$$

季节性强度$F_S$接近 0 的系列几乎没有季节性，而季节性强的系列将具有接近 1 的$ F_S$，因为 Var ( R t ) 将远小于 Var ( S t + R t )。

这些度量可能很有用，例如，当您拥有大量时间序列，并且您需要找到最具趋势或最具季节性的序列时。 

feat_stl() 

##### 其他特征

features()

- `coef_hurst` 将计算时间序列的 Hurst 系数，这是“长记忆”的度量。 具有长记忆力的序列对于许多滞后将具有显着的自相关性。
- `feat_spectral` 将计算时间序列的（香农）谱熵，这是对序列预测难易程度的度量。 具有强烈趋势和季节性（因此易于预测）的序列的熵接近于 0。噪声非常大（因此难以预测）的序列的熵接近于 1。
- `box_pierce` 给出用于测试时间序列是否为白噪声的 Box-Pierce 统计量，以及相应的 p 值。 该测试在[残差诊断](#残差诊断)中讨论。
- `ljung_box`给出用于测试时间序列是否为白噪声的 Ljung-Box 统计量，以及相应的 p 值。 该测试在[残差诊断](#残差诊断)中讨论。
- 第 k 个偏自相关测量在去除观测值之间的影响后相隔 k 周期的观测值之间的关系。 所以第一个偏自相关 (k=1) 与第一个自相关相同，因为在连续观测之间没有要删除的内容。 部分自相关在[非季节性 ARIMA 模型](#非季节性 ARIMA 模型)中讨论。

  The `feat_pacf` 函数包含几个涉及偏自相关的特征，包括原始序列、一阶差分序列和二阶差分序列的前五个偏自相关的平方和。 对于季节性数据，它还包括第一个季节性滞后的偏自相关。.
- `unitroot_kpss` 给出用于检验序列是否平稳的 Kwiatkowski-Phillips-Schmidt-Shin (KPSS) 统计量，以及相应的 p 值。 该测试在[平稳性和差分](#平稳性和差分)讨论。
- `unitroot_pp`给出用于检验序列是否非平稳的 Phillips-Perron 统计量，以及相应的 p 值。
- `unitroot_ndiffs` - 根据 KPSS 测试给出导致平稳序列所需的差异数量。 
- `unitroot_nsdiffs` 给出使序列平稳所需的季节性差异数。 这在[平稳性和差分](#平稳性和差分)讨论。
- `var_tiled_mean` 给出“平铺均值”的方差（即连续非重叠观测块的均值）。 默认图块长度为 10（对于非季节性数据）或季节性周期的长度。 这有时称为“稳定性”功能。
- `var_tiled_var` 给出“平铺方差”的方差（即连续非重叠观测块的方差）。 这有时被称为“块状”特征。
- `shift_level_max` 找到时间序列的两个连续滑动窗口之间的最大均值偏移。 这对于查找时间序列中的突然跳跃或下降很有用。
- `shift_level_index` 给出发生最大均值偏移的索引。
- `shift_var_max` 找到时间序列的两个连续滑动窗口之间的最大方差偏移。 这对于**发现时间序列波动性的突然变化很有用**。
- `shift_var_index` - 给出发生最大均值偏移的索引 -`shift_kl_max` 找到时间序列的两个连续滑动窗口之间的最大分布偏移（基于 Kulback-Leibler 散度）。 这对于查找时间序列分布的突然变化很有用。
- `shift_kl_index` 给出最大 KL 偏移发生处的索引。
- `n_crossing_points` 计算时间序列穿过中位数的次数。
- `longest_flat_spot` 计算序列相对不变的数据部分的数量。
- `stat_arch_lm` 返回基于 Engle (1982) 的拉格朗日乘数 (LM) 检验的自回归条件异方差性 (ARCH) 的统计量。
- `guerrero` 使用 Guerrero 方法计算 Box-Cox 变换的最佳 λ 值（在[调整和转换](#调整和转换)中讨论）。

#### 时序预测知识

##### 简单预测方法

一些预测方法极其简单且非常有效。使用四种简单的预测方法作为基准。

平均法：

MEAN()

在这里，所有未来值的预测等于历史数据的平均值（或“平均值”）。 如果我们让历史数据用 y 1 , … , y T 表示，那么我们可以把预测写成：

​                                       $\hat{y}_{T+h|T} = \bar{y} = (y_{1}+\dots+y_{T})/T.$

朴素法：

对于朴素预测，我们只需将所有预测设置为最后一次观察的值。 即 $\hat{y}_{T+h|T} = y_{T}.$

这种方法对于许多经济和金融时间序列非常有效。

因为当数据遵循随机游走时，朴素预测是最佳的，所以这些也称为随机游走预测，可以使用 RW() 函数代替 NAIVE。

季节性朴素方法:

类似的方法对于高度季节性的数据很有用。 在这种情况下，我们将每个预测设置为等于一年中同一季节（例如，上一年的同一个月）的最后一个观测值。 形式上，时间 T + h 的预测写为 

​                                        $\hat{y}_{T+h|T} = y_{T+h-m(k+1)},$

其中 m = 季节性周期，k 是 ( h − 1 ) / m 的整数部分（即时间T + h之前预测期的完整年数 )。 这看起来比实际更复杂。 例如，对于月度数据，所有未来 2 月值的预测等于最后观察到的 2 月值。 对于季度数据，所有未来 Q2 值的预测等于最后观察到的 Q2 值（其中 Q2 表示第二季度）。 类似的规则适用于其他月份和季度以及其他季节性时期。

漂移法:

Naïve 方法的一个变体是允许预测随时间增加或减少，其中随时间的变化量（称为漂移）设置为历史数据中看到的平均变化。 因此，时间 $T + h$ 的预测由 

​              $$\hat{y}_{T+h|T} = y_{T} + \frac{h}{T-1}\sum_{t=2}^T (y_{t}-y_{t-1}) = y_{T} + h \left( \frac{y_{T} -y_{1}}{T-1}\right).$$

这相当于在第一次和最后一次观察之间画一条线，并将其外推到未来。

有时，这些简单方法之一将是可用的最佳预测方法； 但在许多情况下，这些方法将作为基准而不是选择的方法。 也就是说，我们开发的任何预测方法都会与这些简单的方法进行比较，以确保新方法优于这些简单的替代方法。 如果不是，则新方法不值得考虑。

##### 拟合值和残差

时间序列中的每个观察都可以使用所有先前的观察进行预测。 我们将这些拟合值称为 $\hat{y}_{t|t-1}$，表示基于观测值 y 1 , … , y t − 1 的 y t 预测。 我们经常使用这些，有时我们会去掉部分下标，只写  $\hat{y}_{t}$而不是 $\hat{y}_{t|t-1}$ 。

时间序列模型中的“残差”是拟合模型后剩下的。 残差等于观测值与相应拟合值之间的差值： $e_{t} = y_{t}-\hat{y}_{t}.$

如果模型中使用了变换，那么查看变换尺度上的残差通常很有用。 我们称这些为“创新残余”。 例如，假设我们对数据的对数进行建模， w t = log ( y t ) 。 然后创新残差由$w_t - \hat{w}_t$ 给出，而常规残差由 $y_{t}-\hat{y}_{t}$给出。  如果未使用转换，则创新残差与常规残差相同，在这种情况下，我们将简单地称其为“残差”。

augment()

##### 残差诊断

一个好的预测方法将产生具有以下特性的创新残差： 

1. 创新残差是不相关的。 如果创新残差之间存在相关性，那么残差中就有信息可用于计算
2. 创新残差的均值为零。 如果它们的均值不为零，则预测有偏差。

任何不满足这些性质的预测方法都可以改进。 但是，这并不意味着不能改进满足这些属性的预测方法。 对于同一个数据集，可能有几种不同的预测方法，所有这些方法都满足这些属性。 检查这些属性对于查看方法是否使用所有可用信息很重要，但这不是选择预测方法的好方法。

如果不满足这些属性中的任何一个，则可以修改预测方法以提供更好的预测。 调整偏差很容易：如果残差的均值为 m，那么只需从所有预测中减去 m，偏差问题就解决了。 解决相关性问题比较困难，我们要到#才会解决它

 除了这些基本属性之外，残差还具有以下两个属性是有用的（但不是必需的)。

1. 创新残差具有恒定的方差。 这被称为“同方差性”。
2. 创新残差呈正态分布。

这两个属性使预测区间的计算更容易。 然而，不满足这些性质的预测方法不一定能得到改进。 有时应用 Box-Cox 变换可能对这些属性有所帮助，但除此之外，您通常无法确保您的创新残差具有恒定方差和正态分布。 相反，需要另一种获得预测区间的方法。 我们将在后文展示如何处理非正态创新残差。

自相关的 Portmanteau 检验：

除了查看 ACF 图之外，我们还可以通过将一整套 r k 值视为一个组来对自相关进行更正式的测试，而不是单独处理每个值

回想一下，r k 是滞后 k 的自相关。 当我们查看 ACF 图以查看每个尖峰是否在要求的范围内时，我们隐含地进行了多个假设检验，每个假设检验都有很小的概率给出误报。 当完成足够多的这些测试时，很可能至少有一个会给出误报，因此我们可以得出结论，残差具有一些剩余的自相关性，而实际上它们没有。

 为了克服这个问题，我们测试第一个 ℓ 自相关是否与白噪声过程的预期显著不同。 对一组自相关的测试称为 portmanteau 测试，来自法语单词，描述了携带多件衣服的手提箱或衣架。

 一种这样的测试是 Box-Pierce 测试，它基于以下统计量 

​                                                   $$Q = T \sum_{k=1}^\ell r_k^2,$$

其中 ℓ 是所考虑的最大滞后，T 是观察次数。 如果每个 r k 接近于零，那么 Q 就会很小。 如果某些 r k 值很大（正或负），则 Q 会很大。 我们建议对非季节性数据使用 ℓ = 10，对季节性数据使用 ℓ = 2 m，其中 m 是季节性周期。 但是，当 ℓ 较大时测试效果不佳，因此如果这些值大于 T / 5 ，则使用 ℓ = T / 5

一个相关的（更准确的）测试是 Ljung-Box 测试，它基于:

​                                     $$Q^* = T(T+2) \sum_{k=1}^\ell (T-k)^{-1}r_k^2.$$

同样，Q ∗ 的大值表明自相关不是来自白噪声序列。

多大是太大？ 如果自相关确实来自白噪声序列，那么 Q 和 Q ∗ 都将具有 ( ℓ − K ) 自由度的 $\chi^2$分布，其中 K 是模型中的参数数量。 如果它们是根据原始数据（而不是模型的残差）计算的，则设置 K = 0 。
    

对于 Google 股票价格示例，Naïve 方法没有参数，因此在这种情况下 K = 0。 在代码中，lag = ℓ 和 dof = K。

##### 分布预测和预测区间

预测分布：

我们使用概率分布表示预测中的不确定性。 它描述了使用拟合模型观察可能的未来值的概率。 点预测是该分布的均值。 大多数时间序列模型产生正态分布的预测——也就是说，我们假设未来可能值的分布遵循正态分布。 我们将在本节后面介绍正态分布的几种替代方案。

预测区间：$\hat{y}_{T+h|T} \pm c \hat\sigma_h$

预测区间的价值在于它们表达了预测中的不确定性。 如果我们只生成点预测，则无法判断预测的准确程度。 然而，如果我们也产生预测区间，那么很明显每个预测有多少不确定性。 因此，如果没有伴随的预测区间，点预测几乎没有价值。

一步预测区间:

当提前一步预测时，预测分布的标准差可以用下式给出的残差的标准差来估计$\begin{equation}  \hat{\sigma} = \sqrt{\frac{1}{T-K}\sum_{t=1}^T e_t^2} \end{equation}$,其中 K 是预测方法中估计的参数数量。

多步预测区间:

预测区间的一个共同特征是它们的长度通常随着预测范围的增加而增加。 我们预测得越远，与预测相关的不确定性就越大，因此预测区间越宽。 也就是说，σ h 通常随 h 增加（尽管有一些非线性预测方法不具有此属性）。

为了产生一个预测区间，有必要估计 σ h 。 如前所述，对于一步预测 (h = 1)，上式 提供了对预测标准偏差 σ 1 的良好估计。 对于多步预测，需要更复杂的计算方法。 这些计算假设残差不相关。

基准方法：对于四种基准方法，可以在不相关残差的假设下从数学上推导出预测标准差。 hilo()

来自bootstrapped残差的预测区间：

当残差的正态分布是不合理的假设时，一种替代方法是使用bootstrapped法，它仅假设残差与恒定方差不相关。

该方法基于对过去残差的采样预测未来残差，进而预测未来数值反复这样做，我们获得了许多可能的未来。 要查看其中一些，我们可以使用 generate() 函数。

注意，预测分布现在表示为样本路径的模拟。 因为没有正态性假设，所以预测区间不是对称的。

##### 分解预测

时间序列分解可能是生成预测的有用步骤。

假设加法分解，分解后的时间序列可以写成$y_t = \hat{S}_t + \hat{A}_t,$其中 $\hat{A}_t = \hat{T}_t+\hat{R}_{t}$ 是季节性调整的分量。 或者，如果使用乘法分解，我们可以写成 $y_t = \hat{S}_t  \hat{A}_t,$其中 $\hat{A}_t = \hat{T}_t+\hat{R}_{t}$。

为了预测分解的时间序列，我们分别预测季节性分量$\hat{S}_t$和季节性调整分量 $\hat{A}_t$。 **通常假设季节性分量是不变的，或者变化极其缓慢**，因此只需取估计分量的最后一年就可以进行预测。 换句话说，季节性朴素方法用于季节性成分。

为了预测经季节性调整的成分，可以使用任何非季节性预测方法。 例如，可以使用 Drift 方法或 Holt# 方法或非季节性 ARIMA #模型。

decomposition_model()允许通过任何加法分解计算预测，使用其他模型函数来预测分解的每个组件

##### 评估点预测准确性

使用真实预测来评估预测准确性非常重要。 因此，残差的大小并不是真实预测误差可能有多大的可靠指标。 预测的准确性只能通过考虑模型在拟合模型时未使用的新数据上的表现来确定。

测试集的大小通常约为总样本的 20%，尽管此值取决于样本的长度以及您想要预测的提前程度。 理想情况下，测试集应至少与所需的最大预测范围一样大。 应注意以下几点:

* 一个很好地拟合训练数据的模型不一定能很好地预测。
* 使用具有足够参数的模型总是可以获得完美的拟合。
* 模型过度拟合数据与无法识别数据中的系统模式一样糟糕。

filter()用于提取时序数据中的一部分，slice()允许使用索引从每个组中选择一个子集

尺度相关误差：

预测误差与数据的尺度相同。 因此，仅基于 e t 的准确度度量取决于尺度，不能用于在涉及不同单位的系列之间进行比较。

两种最常用的尺度相关度量基于绝对误差或平方误差：

​         $$\begin{align*}
  \text{Mean absolute error: MAE} & = \text{mean}(|e_{t}|),\\
  \text{Root mean squared error: RMSE} & = \sqrt{\text{mean}(e_{t}^2)}.
\end{align*}$$

在比较应用于单个时间序列或具有相同单位的多个时间序列的预测方法时，MAE 很受欢迎，因为它易于理解和计算。 最小化 MAE 的预测方法将导致对中位数的预测，而最小化 RMSE 将导致对均值的预测。 因此，RMSE 也被广泛使用，尽管更难以解释。

百分比误差:

百分比误差由$p_{t} = 100 e_{t}/y_{t}$给出。 百分比误差具有无单位的优点，因此**经常用于比较数据集之间的预测性能**。 最常用的度量是：平均绝对百分比误差：$\text{Mean absolute percentage error: MAPE} = \text{mean}(|p_{t}|).$

如果$y_{t}=0$对于感兴趣期间的任何 t，则基于百分比误差的度量具有无限或未定义的缺点，并且如果任何 接$y_{t}$近于零，则具有极值。 另一个经常被忽视的百分比误差问题是他们假设测量单位有一个有意义的零.例如，在测量华氏或摄氏温度预测的准确性时，百分比误差没有意义，因为温度有一个任意的零点。

它们还有一个缺点，那就是它们对负错误的惩罚比对正错误的惩罚更重。 这一观察导致使用 Armstrong (1978, p. 348) 提出的所谓的“对称”MAPE (sMAPE)，该方法用于 M3 预测竞赛。 它由$\text{sMAPE} = \text{mean}\left(200|y_{t} - \hat{y}_{t}|/(y_{t}+\hat{y}_{t})\right).$定义。

但是，如果 y t 接近于零，则$\hat{y}_{t}$也可能接近于零。 因此，该度量仍然涉及除以接近于零的数字，从而使计算不稳定。 此外，sMAPE 的值可能为负，因此它根本不是“绝对百分比误差”的衡量标准。

Hyndman & Koehler (2006) 建议不要使用 sMAPE。 将它包含在这里只是因为它被广泛使用，尽管我们不会在本书中使用它。

比例误差:

比例误差由 Hyndman & Koehler (2006) 提出，作为比较不同单位的系列预测准确度时使用百分比误差的替代方法。 他们建议根据简单预测方法的训练 MAE 来缩放误差。

对于非季节性时间序列，定义比例误差的一种有用方法是使用朴素预测： 

​                                       $q_{j} = \frac{\displaystyle e_{j}}    {\displaystyle\frac{1}{T-1}\sum_{t=2}^T |y_{t}-y_{t-1}|}.$

因为分子和分母都涉及原始数据尺度上的值，所以 q j 与数据尺度无关。 如果缩放误差来自比在训练数据上计算的平均一步朴素预测更好的预测，则缩放误差小于 1。 相反，如果预测比在训练数据上计算的平均一步朴素预测差，则它大于 1。

对于季节性时间序列，可以使用季节性朴素预测定义缩放误差：

​                                     $$q_{j} = \frac{\displaystyle e_{j}}    {\displaystyle\frac{1}{T-m}\sum_{t=m+1}^T |y_{t}-y_{t-m}|}.$$

自然的有：$\text{MASE} = \text{mean}(|q_{j}|).$ $\text{RMSSE} = \sqrt{\text{mean}(q_{j}^2)},$

accuracy() 自动从数据中提取相关时期以匹配预测

##### 评估分布预测准确性

前面测量了所有测量点预测的准确性。 在评估分布预测时，我们需要使用其他一些度量。

分位数分数：

假设我们对未来时间 t 的概率为 p 的分位数预测感兴趣，并用$f_{p,t}$表示。 也就是说，我们期望观测值 y t 小于$f_{p,t}$的概率为 p 。 例如，第 10 个百分位数将是$f_{0.10,t}$。 如果 y t 表示在时间 t 的观察，那么分位数分数是:

​                      $$Q_{p,t} = \begin{cases}  2(1 - p) \big(f_{p,t} - y_{t}\big), & \text{if $y_{t} < f_{p,t}$}\\  2p \big(y_{t} - f_{p,t}\big), & \text{if $y_{t} \ge f_{p,t}$} \end{cases}$$

这有时被称为“pinball loss function”，因为它的图形类似于弹球桌上球的轨迹。 乘数 2 经常被省略，但包括它会使解释更容易一些。 $Q_{p,t}$的低值表示对分位数的更好估计。

分位数分数可以解释为绝对误差。 实际上，当 p = 0.5 时，分位数得分$Q_{0.5,t}$与绝对误差相同。 对于 p 的其他值，“误差”$(y_t - f_{p,t})$被加权以考虑它是正数还是负数的可能性。 如果 p > 0.5 ,$Q_{p,t}$在观测值大于估计分位数时比在观测值小于估计分位数时给出更重的惩罚。 当 p < 0.5 时，情况正好相反。

这可以使用带有 quantile_score() 函数的 precision() 轻松计算

Winkler Score:

**评估预测区间**（而不是几个分位数）通常是令人感兴趣的，Winkler（1972）提出的Winkler分数就是为了这个目的而设计的。如果100（1− α）%时间t的预测区间是$[\ell_{\alpha,t}, u_{\alpha,t}]$，则Winkler分数定义为间隔长度加上惩罚（如果观察值在间隔之外）：

$$W_{\alpha,t} = \begin{cases}  (u_{\alpha,t} - \ell_{\alpha,t}) + \frac{2}{\alpha} (\ell_{\alpha,t} - y_t) & \text{if } y_t < \ell_{\alpha,t} \\  (u_{\alpha,t} - \ell_{\alpha,t})   & \text{if }  \ell_{\alpha,t} \le y_t \le u_{\alpha,t} \\  (u_{\alpha,t} - \ell_{\alpha,t}) + \frac{2}{\alpha} (y_t - u_{\alpha,t}) & \text{if } y_t > u_{\alpha,t}.  \end{cases}$$

对于区间内的观察，Winkler分数只是区间的长度。因此，低分数与狭窄的时间间隔有关。但是，如果观察值落在间隔之外，则应用惩罚，惩罚与观察值在间隔之外的距离成比例。

通常构造预测区间通过设置$\ell_{\alpha,t} = f_{\alpha/2,t}$和$u_{\alpha,t} = f_{1-\alpha/2,t}$。如果我们加上相应的分位数分数并除以α，我们得到Winkler分数：

​                                $$W_{\alpha,t} = (Q_{\alpha/2,t} + Q_{1-\alpha/2,t})/\alpha.$$

这可以使用带有 quantile_score() 函数的winkler_score()轻松计算

连续排序概率得分：

我们通常对整个预测分布感兴趣，而不是特定的分位数或预测区间。在这种情况下，我们可以对p的所有值的分位数分数进行平均，以获得连续排名的概率分数或CRPS（Gneiting&Katzfuss，2014）。

在Google股票价格示例中，我们可以计算测试集中所有天的平均CRPS值。CRPS值有点像从整个预测分布计算的加权绝对误差，其中加权考虑了概率。

使用技能分数的无尺度比较：

与点预测一样，能够在不同尺度的系列中比较几种方法的分布预测准确性是很有用的。 对于点预测，我们为此使用了比例误差。 另一种方法是使用技能分数。 这些可用于点预测精度和分布预测精度。

使用技能分数，我们计算相对于某些基准方法的预测准确性度量。 例如，如果我们使用 Naïve 方法作为基准，并使用 Drift 方法计算预测，我们可以计算 Drift 方法相对于 Naïve 方法的 CRPS 技能分数为：

​                                             $$\frac{\text{CRPS}_{\text{Naïve}} - \text{CRPS}_{\text{Drift}}}{\text{CRPS}_{\text{Naïve}}}.$$

这给出了漂移方法优于基于 CRPS 的朴素方法的比例。 使用accuracy()函数中的Skill_score() 。

 Skill_score() 函数可用于任何准确度度量。 例如，skill_score(MSE) 提供了一种跨不同系列比较 MSE 值的方法。 然而，重要的是测试集足够大以允许可靠地计算误差度量，尤其是在分母中。 出于这个原因，MASE 或 RMSSE 通常是点预测准确性的首选无标度度量

##### 时间序列交叉验证

一个更复杂的训练/测试集版本是时间序列交叉验证。**在这个过程中，有一系列测试集，每个测试集由一个单一的观察组成**。 相应的训练集仅包含在形成测试集的观察之前发生的观察。 因此，未来的观测不能用于构建预测。 由于不可能基于较小的训练集获得可靠的预测，因此不将最早的观察结果视为测试集。

下图说明了一系列训练和测试集，其中蓝色观测值构成训练集，橙色观测值构成测试集。

![img](https://otexts.com/fpp3/fpp_files/figure-html/cv1-1.svg)

预测准确度是通过对测试集求平均值来计算的。 这个过程有时被称为“对滚动预测原点的评估”，因为预测所基于的“原点”在时间上向前滚动。

对于时间序列预测，一步预测可能不如多步预测那么相关。 在这种情况下，可以修改基于滚动预测原点的交叉验证程序，以允许使用多步错误。 假设我们对产生良好的 4 步提前预测的模型感兴趣。 那么对应的图如下所示。

![img](https://otexts.com/fpp3/fpp_files/figure-html/cv4-1.svg)

stretch_tsibble()

选择最佳预测模型的一个好方法是找到使用时间序列交叉验证计算的具有最小 RMSE 的模型。

#### 判断性预测

使用判断进行预测在实践中很常见。 在许多情况下，判断性预测是唯一的选择，例如当完全缺乏历史数据时，或者当新产品正在推出时，或者当一个新的竞争对手进入市场时，或者在全新且独特的市场条件下。 例如，2012 年 12 月，澳大利亚政府在全球率先通过立法，禁止在烟盒上使用公司标志，并要求所有烟盒为深绿色。 由于没有历史先例，因此必须应用判断以预测此类政策的效果。

也有数据不完整或延迟一段时间后才可用的情况。 例如，中央银行在预测当前经济活动水平时包括判断，这一程序称为临近预报，因为 GDP 仅按季度提供。

该领域的研究表明，当预测者拥有 (i) 重要的领域知识和 (ii) 更及时、最新的信息时，判断预测的准确性会提高。 判断方法可以快速适应此类变化、信息或事件。

使用条件： 

(i) 没有可用数据，因此统计方法不适用，判断预测是唯一可行的方法；  

(ii) 可获得数据，生成统计预测，然后根据判断进行调整；  

(iii) 数据是可用的，统计和判断预测是独立生成的，然后再结合起来。 我们应该澄清，当数据可用时，应用统计方法（例如其他章节中讨论的方法）是更可取的，并且应始终作为起点。 统计预测通常优于仅使用判断来生成预测。 在本章的大部分内容中，我们将重点放在没有可用数据的第一种设置上，在最后一节中，我们将讨论统计预测的判断性调整。 我们将在#中讨论组合预测。

##### 注意限制

判断性预测是主观的，因此不能没有偏见或限制。

* 判断性预测可能不一致。 与每次都可以由相同的数学公式生成的统计预测不同，判断性预测在很大程度上依赖于人类的认知，并且容易受到其局限性的影响。 例如，有限的记忆可能会使最近发生的事件比实际情况更重要，并且可能会忽略更遥远过去的重大事件； 或有限的注意力可能会导致错过重要信息； 或者对因果关系的误解可能导致错误的推论。 此外，由于心理因素的影响，人类的判断可能会有所不同。 可以想象，某天一位处于积极心态中的经理做出可能趋于乐观的预测，而另一天处于消极心态下，则做出不太乐观的预测。
* 个人或政治议程可能会影响判断，因为目标和预测没有分开。 例如，如果销售经理知道她生成的预测将用于设置销售预期（目标），她可能倾向于将这些设置得较低以显示良好的绩效（即超出预期目标）。 即使在目标和预测完全分开的情况下，判断也可能受到乐观或一厢情愿的困扰。 例如，一个致力于推出新产品的团队极不可能预测到它的失败。 正如我们稍后将讨论的，这种乐观情绪可以在小组会议环境中得到加强。  “当心你的营销和销售同事的热情”。
* 在判断性预测中常见的另一个不良特性是锚定效应。 在这种情况下，后续预测趋于收敛或接近初始熟悉的参考点。 例如，通常以最后观察到的值作为参考点。 预测者受到先验信息的过度影响，因此在预测过程中给予更多的重视。 锚定可能导致保守主义和低估新的和更新的信息，从而产生系统性偏见。

##### 关键原则

在判断预测中使用系统和结构良好的方法有助于减少判断预测局限性的不利影响，我们在上一节中列出了其中的一些。 无论这种方法涉及一个人还是多个人，都应遵循以下原则。

1. **清晰简洁地设定预测任务** 在设定预测挑战和表达预测任务时需要小心。 每个人都清楚任务是什么很重要。 所有定义都应清晰、全面，避免含糊不清的表述。 此外，避免包含可能分散预测者注意力的情绪术语和不相关信息也很重要。 在随后的 Delphi 方法中，有时在设置预测任务之前进行初步的信息收集可能会很有用。

2. **实施系统方法** 通过使用系统方法进行判断性预测，包括与预测任务相关的信息类别清单，可以提高预测的准确性和一致性。 例如，确定哪些信息是重要的以及如何对这些信息进行加权是有帮助的。 在预测新产品的需求时，我们应该考虑哪些因素以及我们应该如何考虑这些因素？ 是否应该是价格、竞争的质量和/或数量、当时的经济环境、产品的目标人群？ 值得投入大量精力和资源来整合决策规则，从而形成最佳的系统方法。

3. **记录和证明**在系统方法中实施的决策规则和假设的形式化和记录可以促进一致性，因为相同的规则可以重复实施。 此外，要求预测者记录和证明他们的预测会导致问责，从而减少偏差。 此外，正式文件对接下来建议的系统评估过程有很大帮助。

4. **系统地评估预测** 系统地监控预测过程可以识别不可预见的违规行为。 特别是，保留预测记录，并在相应的观察结果可用时使用它们来获得反馈。 尽管作为预报员，您可能会尽力而为，但您所处的环境是动态的。 发生变化，您需要监控这些变化以评估决策规则和假设。 反馈和评估有助于预测者学习和提高他们的预测准确性。

5. **将预报员和用户分开** 如果预报任务是由预报用户执行的，例如那些负责实施与预报有关的行动计划的用户，则可能会妨碍预报的准确性。 我们应该在这里再次澄清，鉴于所有可用信息，包括历史数据和可能影响预测的任何未来事件的知识，预测就是尽可能准确地预测未来。 预报员和用户应明确分开。 一个经典案例是新产品的推出。 预测应该是对新产品销量的合理估计，这可能与管理层为实现公司财务目标而预期或希望的销量大不相同。 在这种情况下，预报员可能会向用户提供现实检查。

   预报员将预报彻底传达给潜在用户非常重要。 用户可能会感到与预测疏远和脱节，并且可能对它们没有充分的信心。 解释和澄清过程并证明导致预测的基本假设的合理性将为用户提供一些保证。

   使用和实施预测的方式显然取决于管理决策。 例如，管理层可能决定向上调整预测（过于乐观），因为预测可用于指导采购和库存水平。 在成本效益分析表明持有过剩库存的成本远低于销售损失的成本后，可以做出这样的决定。 这种类型的调整应该是设定目标或计划供应的一部分，而不是预测过程的一部分。 相比之下，如果将预测用作目标，则可以将其设置得较低，以便更容易超过。 再次重申，**设定目标与制定预测不同，两者不应混淆**。

##### The Delphi method

德尔菲法是兰德公司的奥拉夫·赫尔默和诺曼·达尔基在 1950 年代发明的，目的是解决特定的军事问题。 该方法依赖于一个关键假设，即群体的预测通常比个人的预测更准确。  Delphi 方法的目标是以结构化的迭代方式从一组专家构建共识预测。 指定一名协调人以实施和管理该过程。  Delphi 方法通常包括以下阶段： 

1. 组建专家小组。
2. 设置预测任务/挑战并分发给专家。
3. 专家返回最初的预测和理由。 这些被编译和总结以提供反馈。
4. 向专家提供反馈，他们现在根据反馈审查他们的预测。 可以重复此步骤，直到达到令人满意的共识水平。
5. 最终预测是通过汇总专家的预测来构建的。

##### 类比预测

在实践中经常采用的一种有用的判断方法是类比预测。 一个常见的例子是通过评估过程为房屋定价。 估价师通过将房屋与该地区已售出的类似房产进行比较来估计房屋的市场价值。 相似度取决于所考虑的属性。 在房屋评估中，通常会考虑土地面积、住宅面积、卧室和浴室数量以及车库空间等属性。

结构化类比:

可以实施由专家小组组成的结构化方法，如 Green & Armstrong (2007) 所提议的那样。 这个概念类似于 Delphi 的概念； 然而，预测任务是通过考虑类比来完成的。 首先，任命一名协调人。 然后结构化方法涉及以下步骤。

1. 组建了一个可能对类似情况有经验的专家小组。
2. 任务/挑战被设置并分发给专家。
3. 专家尽可能多地识别和描述类比，并根据每个类比生成预测。
4. 专家列出每个类比与目标情况的异同，然后在一个尺度上对每个类比与目标情况的相似性进行评级。
5. 预测是由协调人使用一组规则得出的。 这可以是加权平均值，其中权重可以由专家对每个类比的排名分数来指导。

 与 Delphi 方法一样，专家的匿名性在不抑制创造力方面可能是一个优势，但可能会阻碍合作。 格林和阿姆斯特朗在他们的结果中发现专家之间的合作没有任何好处。 一个关键发现是，具有多个类比（超过两个）并且对类比有直接经验的专家生成了最准确的预测。

##### 情景预测

一种完全不同的判断性预测方法是基于场景的预测。 这种方法的目的是根据合理的场景生成预测。 与之前的两种方法（德尔福法和类比预测）相比，所得到的预测旨在成为可能的结果，每个基于情景的预测可能具有较低的发生概率。 这些情景是通过考虑所有可能的因素或驱动因素、它们的相对影响、它们之间的相互作用以及要预测的目标来生成的。

基于情景构建预测允许生成范围广泛的可能预测并识别一些极端情况。 例如，通常会呈现“最佳”、“中间”和“最差”案例场景，但也会生成许多其他场景。 考虑并记录这些截然不同的极端情况可以导致及早制定应急计划。

通过情景预测，决策者经常参与情景的生成。 虽然这可能会导致一些偏差，但它可以简化基于场景的预测的沟通，并有助于更好地了解结果。

##### 新产品预测

新产品的定义可能会有所不同。 它可能是已推出的全新产品、现有产品的变体（“新的和改进的”）、现有产品定价方案的变化，甚至是现有产品进入新市场。

由于无法获得历史数据，因此判断性预测通常是新产品预测的唯一可用方法。 我们已经概述的方法（Delphi，类比预测和情景预测）都适用于预测新产品的需求。

也可以使用其他更具体的方法。 以下三种在实践中常用的方法。 这些方法没有已经讨论过的方法结构化，因此可能会导致更多有偏差的预测。

* 销售人员综合 略

* 执行意见 略

* 客户意图 

  客户意图可用于预测对新产品或现有产品变体的需求。 问卷由客户填写，了解他们购买产品的意图。 使用结构化问卷，要求客户对他们购买产品的可能性进行评分； 例如，极有可能、可能、可能、不太可能、极不可能。

  需要解决调查设计挑战，例如收集代表性样本、应用具有时间和成本效益的方法以及处理不答复。 此外，在此调查设置中，我们必须牢记购买意愿之间和购买行为的关系 。 客户并不总是按照他们说的去做。 **许多研究发现购买意向和购买行为之间存在正相关关系； 然而，这些相关性的强度差异很大**。 推动这种变化的因素包括数据收集和产品发布的时间、产品“新”的定义以及行业类型。 行为理论告诉我们，如果在行为之前测量意图，则意图可以预测行为。意图和行为之间的时间会有所不同，这取决于它是全新的产品还是现有产品的变体。 此外，**与全新产品相比，现有产品和熟悉产品的变体的意图和行为之间的相关性更强**。

  无论使用哪种新产品预测方法，重要的是要彻底记录所做的预测及其背后的推理，以便在数据可用时能够对其进行评估。 

##### 判断调整

最后，我们考虑历史数据可用并用于生成统计预测的情况。 从业者通常会对这些预测进行判断性调整。 这些调整可以潜在地提供本章前面讨论过的判断性预测的所有优点。 **例如，它们为纳入统计模型中可能未考虑的因素提供了一种途径，例如促销、大型体育赛事、假期或尚未反映在数据中的近期事件**。 然而，这些优势只有在合适的条件下才能实现。 判断性调整，如判断性预测，带有偏见和局限性，我们必须实施有条不紊的策略以将它们最小化

谨慎使用调整:

从业者调整的频率比他们应该的要高得多，而且很多时候都是出于错误的原因。 通过调整统计预测，预测的用户会产生一种主人翁感和可信度。 用户通常不了解或不了解生成统计预测的机制（因为他们通常没有接受过这方面的培训）。 通过实施判断性调整，用户觉得他们对预测做出了贡献并完成了预测，现在他们可以将自己的直觉和解释与这些联系起来。 预测已经成为他们自己的预测。

判断性调整不应旨在纠正被认为被统计模型遗漏的数据中的系统模式。 这已被证明是无效的，因为预测人员倾向于读取嘈杂系列中不存在的模式。 统计模型在考虑数据模式方面要好得多，而判断性调整只会阻碍准确性。

当手头有重要的额外信息或强有力的证据表明需要进行调整时，判断性调整最有效。 只有当我们有重要的额外信息没有包含在统计模型中时，我们才应该进行调整。 因此，当它们的尺寸很大时，调整似乎是最准确的。 已经发现小调整（尤其是在促进乐观错觉的积极方向上）会阻碍准确性，应该避免。

应用结构化方法:

使用结构化和系统化方法将提高判断调整的准确性。 遵循上文中概述的关键原则至关重要。 特别是，必须记录和证明调整的合理性将使覆盖统计预测更具挑战性，并将防止不必要的调整。

由面板执行调整是很常见的。 使用 Delphi 设置具有很大的优势。 但是，如果在小组会议上进行调整，最好先考虑关键市场或产品的预测，因为小组成员在此过程中会感到疲倦。 随着会议的进行，往往会做出更少的调整。

#### 时间序列回归模型

TSLM()

##### 一些有用的预测变量

* 趋势

* 虚拟变量

  这种情况仍然可以在多元回归模型的框架内通过创建一个“虚拟变量”来处理，该虚拟变量取值 1 对应于“是”，取值 0 对应于“否”。 虚拟变量也称为“指标变量”。 虚拟变量也可用于解释数据中的异常值。 虚拟变量不是忽略异常值，而是消除其影响。 在这种情况下，虚拟变量为该观察值取值为 1，其他地方为 0。 一个例子是发生了特殊事件的情况。 例如，在预测到巴西的游客人数时，我们需要考虑 2016 年里约热内卢夏季奥运会的影响。

  如果有两个以上的类别，则可以使用多个虚拟变量（比类别总数少一个）对变量进行编码。 如果您将因子变量指定为预测变量，则 TSLM() 将自动处理这种情况。 通常不需要手动创建相应的虚拟变量。

* 季节性虚拟变量

  请注意，编码七个类别只需要六个虚拟变量。 这是因为第七个类别（在本例中为星期日）由截距捕获，并且在虚拟变量都设置为零时指定。


   许多初学者会尝试为第七类添加第七个虚拟变量。 这被称为“虚拟变量陷阱”，因为它会导致回归失败。 当还包括截距时，将有太多参数需要估计。 一般规则是使用比类别少一个虚拟变量。 所以对于季度数据，使用三个虚拟变量； 对于月度数据，使用 11 个虚拟变量； 对于每日数据，使用六个虚拟变量，依此类推。

   与虚拟变量相关的每个系数的解释是，它是该类别相对于省略类别的影响的度量。

* 干预变量

  通常需要对可能影响要预测的变量的干预进行建模。 例如，竞争对手的活动、广告支出、行业行动等等，都会产生影响。

  当效果仅持续一个时期时，我们使用“尖峰”变量。 这是一个虚拟变量，在干预期间取值为 1，在其他时间取值为 0。 尖峰变量相当于处理异常值的虚拟变量。

  其他干预措施具有直接和永久的效果。 如果干预导致水平移动（即从干预开始，序列的值突然且永久地改变），那么我们使用“阶跃”变量。 步长变量在干预前取值为零，从干预开始后取值为 1。

  另一种形式的永久效应是坡度的变化。 这里的干预是使用分段线性趋势处理的； 一种在干预时弯曲的趋势，因此是非线性的。 #

  1. 交易日

     一个月中的交易日数可能会有很大差异，并对销售数据产生重大影响。 为此，可以将每个月的交易天数作为预测指标。

     考虑到一周中不同天数的影响的替代方案具有以下预测因子： 

     $\begin{align*}  x_{1} &= \text{number of Mondays in month;} \\  x_{2} &= \text{number of Tuesdays in month;} \\        & \vdots \\  x_{7} &= \text{number of Sundays in month.} \end{align*}$

  2. 分布式滞后

     将广告支出作为预测因素通常很有用。 然而，由于广告的效果可以持续超出实际活动，我们需要包括广告支出的滞后值。 因此，可以使用以下预测器。

     $\begin{align*}  x_{1} &= \text{advertising for previous month;} \\  x_{2} &= \text{advertising for two months previously;} \\        & \vdots \\  x_{m} &= \text{advertising for $m$ months previously.} \end{align*}$

     通常要求系数随着滞后的增加而减小，尽管这超出了本章的范围。

  3. 复活节

     与大多数假期不同，因为它不是每年的同一天举行，其影响可持续数天。 在这种情况下，当假期在特定时间段内时，可以使用值为 1 的虚拟变量，否则为 0。

     对于月度数据，如果复活节在 3 月下降，则虚拟变量在 3 月取值为 1，如果在 4 月下降，虚拟变量在 4 月取值为 1。 当复活节从 3 月开始并在 4 月结束时，虚拟变量在月份之间按比例分配。(中国的春节类似)

  4. 傅立叶级数

     使用季节性虚拟变量的另一种方法是使用傅立叶项，尤其是对于**长季节性周期**。 让-巴蒂斯特·傅立叶 (Jean-Baptiste Fourier) 是一位出生于 1700 年代的法国数学家，他证明了一系列正确频率的正弦和余弦项可以近似于任何周期函数。 我们可以将它们用于季节性模式。

      如果 m 是季节性周期，则前几个傅立叶项由下式给出:

     $x_{1,t} = \sin\left(\textstyle\frac{2\pi t}{m}\right),  x_{2,t} = \cos\left(\textstyle\frac{2\pi t}{m}\right),  x_{3,t} = \sin\left(\textstyle\frac{4\pi t}{m}\right),$

     如果我们有每月的季节性，并且我们使用这些预测变量中的前 11 个，那么我们将得到与使用 11 个虚拟变量完全相同的预测。

     **对于傅立叶项，我们通常需要比虚拟变量更少的预测变量，尤其是当 m 很大时**。 这使得它们对于每周数据很有用，例如，其中 m ≈ 52 。 对于较短的季节性周期（例如，季度数据），与季节性虚拟变量相比，使用傅立叶项几乎没有优势。

      如果仅使用前两个傅立叶项$x_{1,t}$和$x_{2,t}$，则季节性模式将遵循简单的正弦波。 包含傅立叶项的回归模型通常称为调和回归，因为连续的傅立叶项代表前两个傅立叶项的谐波。

	##### 选择预测变量

glance()

我们将这些值与其他模型的相应值进行比较。 对于 CV、AIC、AICc 和 BIC 度量，我们希望找到具有最低值的模型； 对于 Adjusted $R^2$ ，我们寻找具有最高值的模型。

虽然$R^{2}$被广泛使用，并且比其他度量存在的时间更长，但它倾向于选择过多的预测变量使其不太适合预测。

许多统计学家喜欢使用 BIC，因为它具有以下特性：如果存在真正的底层模型，BIC 会在给定足够数据的情况下选择该模型。 然而，在现实中，很少有真正的底层模型，即使有真正的底层模型，选择该模型也不一定会给出最好的预测（因为参数估计可能不准确）。

因此，建议使用 AICc、AIC 或 CV 统计数据之一，每个统计数据都以预测为目标。 如果 T 的值足够大，它们都会导致相同的模型。 

##### 回归预测

一些基本知识见回归章节，本节仅罗列与时序回归相关知识

事前与事后预测：

在对时间序列数据使用回归模型时，我们需要区分可以产生的不同类型的预测，这取决于计算预测时假设已知的内容。

事前预测是仅使用事先可获得的信息进行的预测。 例如，对样本结束后几个季度美国消费百分比变化的事前预测，应仅使用截至 2019 年第二季度（包括 2019 年第二季度）的可用信息。 这些是真实的预测，使用当时可用的任何信息提前做出。 因此，为了生成事前预测，该模型需要预测变量的预测。 为了获得这些，我们可以使用第 5.2 节中介绍的一种简单方法或第 8 章和第 9 章中更复杂的纯时间序列方法。或者，可以使用其他来源（例如政府机构）的预测。

事后预测是使用有关预测变量的后期信息进行的预测。 例如，消费的事后预测可以使用预测变量的实际观察，一旦这些已经被观察到。 这些不是真正的预测，但对研究预测模型的行为很有用。

事前预测和事后预测的比较评估有助于区分预测不确定性的来源。 这将显示预测错误是由于预测器的预测不佳还是由于预测模型不佳而出现的。

基于场景的预测：

在此设置中，预报员假设感兴趣的预测变量的可能场景。

 例如，美国政策制定者可能有兴趣比较当收入和储蓄分别持续增长 1% 和 0.5% 而就业率没有变化时，消费的预测变化与分别下降 1% 和 0.5% 的情况。  0.5%，对于样本结束后的四个季度中的每个季度。 结果预测计算如下，如图 7.18 所示。 我们应该注意到，基于情景的预测的预测区间不包括与预测变量的未来值相关的不确定性。 他们假设预测变量的值是预先知道的。

scenairos()

##### 多重共线性和预测

一个密切相关的问题是多重共线性，当多元回归中的两个或多个预测变量提供相似信息时，就会发生多重共线性。

当两个预测变量彼此高度相关（即它们的相关系数接近 +1 或 -1）时，就会发生这种情况。 在这种情况下，知道其中一个变量的值会告诉您很多关于另一个变量的值的信息。 因此，他们提供了类似的信息。 例如，脚的大小可用于预测身高，但在同一模型中包含左脚和右脚的大小不会使预测变得更好，尽管它也不会使预测变得更糟。

当预测变量的线性组合与预测变量的另一个线性组合高度相关时，也会出现多重共线性。 在这种情况下，了解第一组预测变量的值会告诉您很多有关第二组预测变量的值的信息。 因此，他们提供了类似的信息。

 当存在多重共线性时，与单个回归系数相关的不确定性会很大。 这是因为它们很难估计。 因此，对回归系数的统计检验（例如 t 检验）是不可靠的。  （在预测中，我们很少对此类测试感兴趣。）此外，不可能对每个单独的预测变量对预测的贡献做出准确的陈述。

注：**多重共线性**（Multicollinearity）是指[多变量](https://zh.wikipedia.org/wiki/一般线性模型)[线性回归](https://zh.wikipedia.org/wiki/線性回歸)中，[变量](https://zh.wikipedia.org/wiki/变量)之间由于存在高度相关关系而使[回归](https://zh.wikipedia.org/wiki/迴歸分析)估计不准确。在该情况下，多元回归的系数可能会因为模型或数据的微小变化发生剧烈改变。在样本数据集中，多重共线性不会影响模型整体的预测能力或[信度](https://zh.wikipedia.org/wiki/信度)，它只会影响单个预测值（predictor）的结果。**简而言之，一个包含有共线预测值的多元回归模型可以指示出模型整体的预测可靠程度，但可能无法对单个预测值给出有效结果，也可能无法判断哪些预测值是冗余的**。

如果未来预测变量的值超出预测变量的历史值范围，则预测将不可靠。 例如，假设您已经拟合了一个具有相互高度相关的预测变量 x 1 和 x 2 的回归模型，并假设训练数据中 x 1 的值介于 0 和 100 之间。然后基于 x 1 >  100 或 x 1 < 0 将不可靠。 当预测变量的未来值远远超出历史范围时，这总是有点危险，但当存在多重共线性时尤其成问题。

请注意，如果您使用的是优秀的统计软件，如果您对每个预测变量的具体贡献不感兴趣，并且如果您的预测变量的未来值在其历史范围内，则无需担心——多重共线性不是问题，除非存在完美的相关性。

#### 单位根过程

前面的AR、MA、ARMA主要应用于简单收益率和对数收益率。 对于价格序列， 一般其水平是缓慢变化的， 包括缓慢的增长趋势与一定的周期波动。 这样的序列不满足弱平稳的条件， 是非平稳时间序列。

典型的非平稳时间序列模型是**单位根(unit root)**非平稳时间序列。

##### 随机游走

考虑${p_t}$的模型:$\begin{align} p_t = p_{t-1} + \varepsilon_t, \ t=1,2,\dots \tag{7.1} \end{align}$

其中是零均值独立同分布白噪声列。 称是一个**随机游动**(random walk)。

上式表面上看是一个AR（1）模型，但是$\phi_1=1$不满足AR（1）的平稳性条件（$|\phi_1|<1$）,易得此模型不可预测

单位根过程的ACF估计是不相合的， 对单位根过程的样本作ACF图， 其衰减速度很慢很慢。

设$p_0=0$， 单位根过程${p_t}$有如下特点：

- $p_t$期望值等于0；
- 方差等于$\sigma^{2}t$，随线性增长，趋于无穷；
- 历史的扰动（新息）的影响不衰减；
- 预测只能用最后一个观测值作为预测， 预测均方误差趋于无穷。
- 样本ACF表现为基本不衰减，近似等于1。

##### 带漂移的随机游走

上面的随机游动模型的金融意义一般$p_t$是对数价格， 则$\varepsilon_t$是零均值的对数收益率。 实际的对数收益率常常是非零的，正数居多。 所以，模型可以推广为:$p_t = \mu + p_{t-1} + \varepsilon_t, \ t=1,2,\dots$,其中$\{ \varepsilon_t \}$仍为零均值独立同分布白噪声列。 常数$\mu$并不代表均值， 而是对数价格$p_t$的增长速度，称为模型的**漂移**(drift)

##### 固定趋势模型

设$\{ X_t \}$为弱平稳时间序列 令$Y_t = a + b t + X_t$

则$EY_t = (a + \mu_x) + bt$，$\text{Var}(Y_t) = \text{Var}(X_t) = \sigma_x^2$ ， 均值非常数所以$\{ Y_t \}$非平稳。 但是， 减去一个固定趋势$a + bt$后$\{ Y_t \}$就变成了平稳列， 这样的$\{ Y_t \}$与随机游动或者带漂移的随机游动有着本质的区别。

随机游动$p_t = p_{t+1} + \varepsilon_t$与固定趋势加扰动$Y_t = a + bt + X_t$都能呈现出缓慢的趋势变化。 区别在于：

- 随机游动的方差是线性增长的， 固定趋势的观测值方差不变；
- 随机游动的扰动的影响是永久的， 固定趋势的扰动的影响仅在一个时刻（如果扰动是白噪声） 或者很短时间（如果是扰动是线性时间序列）；
- 随机游动的趋势没有固定方向， 固定趋势的变化形状是固定的；
- 固定趋势模型减去一个固定的回归函数就可以变成平稳列， 随机游动减去任意的非随机函数都不能变平稳， 可以用差分运算变成平稳。

在AR和ARMA模型中， 常数项$\phi_0$与平稳均值有关。 但是在带漂移的随机游动模型中， 常数项$\mu$是每一步的平均增量，是固定线性趋势的斜率。 所以时间序列模型中的常数项可能会依模型的不同而具有迥然不同的含义。

将带漂移的随机游动模型中的白噪声替换成一个ARMA平稳列， 其主要的性质仍能保留。即$Y_t = Y_{t-1} + \mu + X_t$,详见：

##### 单位根检验

单位根非平稳列是金融中最常用的非平稳模型， 单位根非平稳列不能使用平稳列的模型来建模。 所以， 要建模的序列应该进行“单位根检验”。

对不带漂移的单位根过程， 考虑如下的基础模型：$\begin{align} p_t = \phi_1 p_{t-1} + \varepsilon_t  \end{align}$

其中$\{\varepsilon_t\}$是零均值独立同分布白噪声列。$|\phi_1| \leq 1$。 考虑如下零假设与对立假设：$H_0: \phi_1 = 1 \longleftrightarrow H_a: \phi_1 < 1$

这样的检验问题称为单位根检验问题。具体检验略 详见书

#### 指数平滑

ETS(R)

指数平滑是在 1950 年代后期提出的（Brown，1959 年；Holt，1957 年；Winters，1960 年），并推动了一些最成功的预测方法。 使用指数平滑方法生成的预测是过去观测值的加权平均值，随着观测值变老，权重呈指数衰减。 换句话说，观察越近，相关的权重就越高。 该框架可以快速生成可靠的预测，适用于广泛的时间序列，这是一个巨大的优势，对工业应用非常重要。

##### 简单指数平滑

最简单的指数平滑方法自然称为简单指数平滑 (SES)13。 这种方法适用于没有明显趋势或季节性模式的预测数据。

我们经常想要介于朴素和平均两个极端之间的东西。 例如，将更大的权重附加到最近的观察而不是来自遥远过去的观察可能是明智的。 这正是简单指数平滑背后的概念。 预测是使用加权平均值计算的，其中权重随着观测值来自更远的过去而呈指数下降——最小的权重与最旧的观测值相关联

$\begin{equation}
  \hat{y}_{T+1|T} = \alpha y_T + \alpha(1-\alpha) y_{T-1} + \alpha(1-\alpha)^2 y_{T-2}+ \cdots,   \tag{8.1}
\end{equation}$

其中 0 ≤ α ≤ 1 是平滑参数。 时间 T + 1 的提前一步预测是 y 1 , … , y T 序列中所有观测值的加权平均值。 权重降低的速率由参数 α 控制。

对于介于 0 和 1 之间的任何 α，随着时间的推移，附加到观测值的权重会呈指数下降，因此得名“指数平滑”。 如果 α 很小（即接近于 0），则对来自更远过去的观测值给予更大的权重。 如果 α 很大（即接近于 1），则对最近的观察给予更多的权重。 对于 α = 1 的极端情况，$\hat{y}_{T+1|T}=y_T$ ，并且预测等于朴素预测。

平坦预测 

简单指数平滑具有“平坦”预测函数：$\hat{y}_{T+h|T} = \hat{y}_{T+1|T}=\ell_T, \qquad h=2,3,\dots.$

也就是说，所有预测都采用相同的值，等于最后一个级别的组件。 请记住，这些预测仅适用于时间序列没有趋势或季节性成分的情况。

可以通过最小化 SSE 来估计任何指数平滑方法的未知参数和初始值,其中SSE:$\begin{equation} \text{SSE}=\sum_{t=1}^T(y_t - \hat{y}_{t|t-1})^2=\sum_{t=1}^Te_t^2. \tag{8.2} \end{equation}$

##### 有趋势方法

霍尔特线性趋势法：

Holt (1957) 扩展了简单指数平滑法以允许预测具有趋势的数据。 该方法涉及一个预测方程和两个平滑方程（一个用于水平，一个用于趋势）：

$\begin{align*}  \text{Forecast equation}&& \hat{y}_{t+h|t} &= \ell_{t} + hb_{t} \\  \text{Level equation}   && \ell_{t} &= \alpha y_{t} + (1 - \alpha)(\ell_{t-1} + b_{t-1})\\  \text{Trend equation}   && b_{t}    &= \beta^*(\ell_{t} - \ell_{t-1}) + (1 -\beta^*)b_{t-1}, \end{align*}$

预测函数不再是平坦的而是趋势的。  h 提前预测等于最后估计的水平加上最后估计的趋势值的 h 倍。 因此，预测是 h 的线性函数。

阻尼趋势法:

Holt 的线性方法生成的预测显示未来无限期的恒定趋势（增加或减少）。 经验证据表明，这些方法往往会过度预测，尤其是对于较长的预测范围。 受这一观察的启发，Gardner & McKenzie (1985) 引入了一个参数，该参数在未来的某个时间将趋势“抑制”为平坦线。 包括阻尼趋势的方法已被证明是非常成功的，并且可以说是当许多系列都需要自动预测时最流行的单个方法。算法：

$$\begin{align*}  \hat{y}_{t+h|t} &= \ell_{t} + (\phi+\phi^2 + \dots + \phi^{h})b_{t} \\  \ell_{t} &= \alpha y_{t} + (1 - \alpha)(\ell_{t-1} + \phi b_{t-1})\\  b_{t} &= \beta^*(\ell_{t} - \ell_{t-1}) + (1 -\beta^*)\phi b_{t-1}. \end{align*}$$

实际上， ϕ 很少小于 0.8，因为阻尼对较小的值有很强的影响。 接近 1 的 ϕ 值意味着无法将阻尼模型与非阻尼模型区分开来。 由于这些原因，我们通常将 ϕ 限制为最小值 0.8 和最大值 0.98。

```R
model(
    SES = ETS(value ~ error("A") + trend("N") + season("N")),
    Holt = ETS(value ~ error("A") + trend("A") + season("N")),
    Damped = ETS(value ~ error("A") + trend("Ad") +
                   season("N"))
  )
```

##### 季节性方法

Holt 和 Winters  扩展了 Holt 的方法来捕捉季节性。  Holt-Winters 季节性方法包括预测方程和三个平滑方程——一个用于水平$\ell_t$，一个用于趋势$b_t$，另一个用于季节性分量$s_t$ ，以及相应的平滑参数 α 、 β ∗ 和 γ 。

这种方法有两种变体，它们在季节性成分的性质上有所不同。 **当季节变化在整个系列中大致恒定时，加法方法是首选，而当季节变化与系列的水平成正比时，乘法方法是首选**。 在加法方法中，季节性分量以观测序列的尺度绝对值表示，而在水平方程中，通过减去季节性分量对序列进行季节性调整。 在每一年中，季节性成分加起来大约为零。 使用乘法方法时，季节性成分以相对项（百分比）表示，并通过除以季节性成分对序列进行季节性调整。 在每一年中，季节性分量的总和约为 m 。

加法公式：

$$\begin{align*}  \hat{y}_{t+h|t} &= \ell_{t} + hb_{t} + s_{t+h-m(k+1)} \\  \ell_{t} &= \alpha(y_{t} - s_{t-m}) + (1 - \alpha)(\ell_{t-1} + b_{t-1})\\  b_{t} &= \beta^*(\ell_{t} - \ell_{t-1}) + (1 - \beta^*)b_{t-1}\\  s_{t} &= \gamma (y_{t}-\ell_{t-1}-b_{t-1}) + (1-\gamma)s_{t-m}, \end{align*}$$

乘法公式：

$$\begin{align*}  \hat{y}_{t+h|t} &= (\ell_{t} + hb_{t})s_{t+h-m(k+1)} \\  \ell_{t} &= \alpha \frac{y_{t}}{s_{t-m}} + (1 - \alpha)(\ell_{t-1} + b_{t-1})\\  b_{t} &= \beta^*(\ell_{t}-\ell_{t-1}) + (1 - \beta^*)b_{t-1}                \\  s_{t} &= \gamma \frac{y_{t}}{(\ell_{t-1} + b_{t-1})} + (1 - \gamma)s_{t-m} \end{align*}$$

```R
model(
    additive = ETS(Trips ~ error("A") + trend("A") +
                                                season("A")),
    multiplicative = ETS(Trips ~ error("M") + trend("A") +
                                                season("M"))
  )
```

##### 指数平滑方法分类

指数平滑方法不限于我们目前介绍的那些。 通过考虑趋势和季节性成分组合的变化，可以使用九种指数平滑方法，如表 8.5 所示。 每种方法都由一对字母 (T,S) 标记，定义了“趋势”和“季节性”组件的类型。 例如，(A,M) 是具有加性趋势和乘性季节性的方法；  (Ad ,N) 是有阻尼趋势且无季节性的方法； 等等。

我们不考虑本书中的乘法趋势方法，因为它们往往会产生较差的预测。

表8.5

| Trend Component       | Seasonal Component |            |                  |
| :-------------------- | :----------------- | :--------- | :--------------- |
|                       | N                  | A          | M                |
|                       | (None)             | (Additive) | (Multiplicative) |
| N (None)              | (N,N)              | (N,A)      | (N,M)            |
| A (Additive)          | (A,N)              | (A,A)      | (A,M)            |
| Add (Additive damped) | (Add,N)            | (Add,A)    | (Add,M)          |

##### 不同状态空间

 每个模型都包含一个描述观测数据的测量方程，以及一些描述未观测到的成分或状态（水平、趋势、季节性）如何随时间变化的状态方程。 因此，这些被称为状态空间模型。

对于每种方法，存在两种模型：一种具有加性误差，另一种具有乘性误差。 如果模型使用相同的平滑参数值，则它们生成的点预测是相同的。 然而，它们会产生不同的预测区间。

 我们将每个状态空间模型标记为 ETS( ⋅ , ⋅ , ⋅ ) for (Error, Trend, Seasonal)。 这个标签也可以被认为是指数平滑。 使用与表 8.5 中相同的符号，每个分量的可能性是：Error = { A,M } ，Trend = { N,A,Ad } 和 Seasonal = { N,A,M } 

![img](https://otexts.com/fpp3/figs/statespacemodels-1.png)

##### 估计和模型选择

估计略

ETS 统计框架的一大优势是信息标准可用于模型选择。 前文中介绍的 AIC、AICc 和 BIC 可用于确定哪个 ETS 模型最适合给定的时间序列。

对于 ETS 模型，Akaike 的信息准则 (AIC) 定义为 ：$\text{AIC} = -2\log(L) + 2k$

修正小样本偏差的 AIC (AICc )定义为$$\text{AIC}_{\text{c}} = \text{AIC} + \frac{2k(k+1)}{T-k-1}$$

贝叶斯信息准则 (BIC) 是:$\text{BIC} = \text{AIC} + k[\log(T)-2].$

可能导致数值不稳定性的模型是 ETS(A,N,M)ETS(A,A,M)和ETS(A,Ad ,M)，由于除以状态方程中可能接近零的值。在选择模型时，我们通常不会考虑这些特定的组合。

 当数据严格为正时，具有乘法误差的模型很有用，但当数据包含零或负值时，模型在数值上不稳定。 因此，如果时间序列不是严格为正的，则不会考虑乘法误差模型。 在这种情况下，将仅应用六个完全可加模型。

 ETS() 函数可通过最小化 AICc 来选择模型

#### ARIMA 模型

ARIMA 模型提供了另一种时间序列预测方法。 指数平滑和 ARIMA 模型是时间序列预测中使用最广泛的两种方法，并为该问题提供了补充方法。 指数平滑模型基于对数据趋势和季节性的描述，而 ARIMA 模型旨在描述数据中的自相关。

在介绍 ARIMA 模型之前，我们必须首先讨论平稳性的概念和差分时间序列的技术。

##### 平稳性和差分

平稳时间序列是其统计属性不依赖于观察序列的时间的序列。 因此，具有趋势或季节性的时间序列不是平稳的——趋势和季节性会影响时间序列的价值 在不同的时间。 另一方面，白噪声序列是静止的——你观察它的时间并不重要，它在任何时间点看起来都应该是一样的。

有些情况可能会令人困惑——具有周期性行为（但没有趋势或季节性）的时间序列是平稳的。 这是因为循环的长度不是固定的，所以在我们观察序列之前，我们无法确定循环的波峰和波谷在哪里。

 **一般来说，一个平稳的时间序列在长期没有可预测的模式。 时间图将显示该系列大致水平（尽管可能存在某些循环行为），并具有恒定方差。**

![Which of these series are stationary? (a) Google closing stock price in 2015; (b) Daily change in the Google stock price in 2015; (c) Annual number of strikes in the US; (d) Monthly sales of new one-family houses sold in the US; (e) Annual price of a dozen eggs in the US (constant dollars); (f) Monthly total of pigs slaughtered in Victoria, Australia; (g) Annual total of Canadian Lynx furs traded by the Hudson Bay Company; (h) Quarterly Australian beer production; (i) Monthly Australian gas production.](https://otexts.com/fpp3/fpp_files/figure-html/stationary-1.png) (b) 和 (g) 作为固定序列。

差分：

在图 9.1 中，请注意（a）中 Google 股票价格是非平稳的，但（b）中每日变化是平稳的。 这显示了使非平稳时间序列平稳的一种方法 - 计算连续观察之间的差异。 这称为差分。

对数等变换有助于稳定时间序列的方差。 差分可以通过消除时间序列水平的变化来帮助稳定时间序列的平均值，从而消除（或减少）趋势和季节性。

除了数据的时间图外，ACF 图对于识别非平稳时间序列也很有用。 对于平稳时间序列，ACF 会相对较快地下降到零，而非平稳数据的 ACF 下降缓慢。 此外，对于非平稳数据，$r_1$的值通常很大且为正。

随机游走模型：

差分序列是原始序列中连续观测值之间的变化，可以写成$y'_t = y_t - y_{t-1}.$。

 差分序列将只有 T − 1 个值，因为不可能为第一次观测计算差异$y_1'$。

 当差分序列是白噪声时，原始序列的模型可以写成$y_t - y_{t-1} = \varepsilon_t,$，其中$\varepsilon_t$表示白噪声。 重新排列这会导致“随机游走”模型$y_t = y_{t-1} + \varepsilon_t.$ 。

随机游走模型广泛用于非平稳数据，尤其是金融和经济数据。 随机游走通常具有： 

* 长期明显的上升或下降趋势 
* 突然且不可预测的方向变化。

随机游走模型的预测与上次观察结果相同，因为未来的运动是不可预测的，并且上升或下降的可能性相同。 因此，随机游走模型支持在前文中提到的的朴素预测。

密切相关的模型允许差异具有非零均值。 然后$y_t - y_{t-1} = c + \varepsilon_t\quad\text{or}\quad {y_t = c + y_{t-1} + \varepsilon_t}\: .$

c 的值是连续观察之间变化的平均值。 如果 c 为正，则平均变化是$y_t$值的增加。 因此，$y_t$将趋于向上漂移。 但是，如果 c 为负，则$y_t$将趋于向下漂移。

这是漂移方法背后的模型，也在[简单预测模型](#简单预测模型)中讨论过。

二阶差分：

有时差分数据看起来不是平稳的，可能需要对数据进行第二次差分以获得平稳序列：$\begin{align*}  y''_{t}  &=  y'_{t}  - y'_{t - 1} \\           &= (y_t - y_{t-1}) - (y_{t-1}-y_{t-2})\\           &= y_t - 2y_{t-1} +y_{t-2}. \end{align*}$。
    

 在这种情况下，y ′′ t 将具有 T − 2 个值。 然后，我们将对原始数据的“变化中的变化”进行建模。 **在实践中，几乎没有必要超越二阶差分**。

季节性差异:

季节性差异是观测值与同一季节的前一个观测值之间的差异。 所以 $y'_t = y_t - y_{t-m},$，其中 m = 季节数。 这些也称为“滞后 m 差”，因为我们在 m 个周期滞后后减去观测值。

如果季节性差异数据似乎是白噪声，那么原始数据的合适模型是

 $y_t = y_{t-m}+\varepsilon_t.$

该模型的预测等于相关季节的最后一次观测。 也就是说，该模型给出了前文中介绍的季节性朴素预测。

在选择应用哪些差异时存在一定程度的主观性。 图 9.3 中的季节性差异数据与图 9.4 中的季节性差异数据没有表现出明显不同的行为。 在后一种情况下，我们本可以决定停止使用季节性差异数据，而不是进行额外的一轮差异化。 在前一种情况下，我们本可以认为数据不够平稳并进行额外一轮的差分。 下面讨论了一些正式的差分测试，但在建模过程中总会有一些选择，不同的分析师可能会做出不同的选择。

如果$y'_t = y_t - y_{t-m}$表示季节性差分序列，则两次差分序列为

$$\begin{align*} y''_t &= y'_t - y'_{t-1} \\      &= (y_t - y_{t-m}) - (y_{t-1} - y_{t-m-1}) \\      &= y_t -y_{t-1} - y_{t-m} + y_{t-m-1}\: \end{align*}$$

当应用季节性差分和一阶差分时，先做没有区别——结果是一样的。 但是，如果数据具有很强的季节性模式，我们建议先进行季节性差分，因为结果序列有时是平稳的，不需要进一步的一阶差分。 如果先进行一阶差分，仍然会存在季节性。

请注意，**应用比所需更多的差异会导致时间序列中并不真正存在的虚假动态或自相关。 因此，尽可能少地进行差异以获得平稳序列**。

重要的是，如果使用差分，差异是可解释的。 第一个差异是一次观察和下一次观察之间的变化。 季节性差异是一年与下一年之间的变化。 其他滞后不太可能有太多可解释的意义，应该避免。  

单位根检验 

更客观地确定是否需要差分的一种方法是使用单位根检验。 这些是平稳性的统计假设检验，旨在确定是否需要差分。

详细理论等见[单位根过程](#单位根过程)

有许多单位根检验可用，它们基于不同的假设，可能会导致相互矛盾的答案。 在我们的分析中，我们使用 Kwiatkowski-Phillips-Schmidt-Shin (KPSS) 测试（Kwiatkowski 等，1992）。 在这个测试中，原假设是数据是平稳的，我们寻找原假设为假的证据。 因此，小的 p 值（例如，小于 0.05）表明需要进行差分。 可以使用 unitroot_kpss() 函数计算测试。


##### 自回归模型

在前文介绍的多元回归模型中，我们使用预测变量的线性组合来预测感兴趣的变量。 在自回归模型中，我们使用变量过去值的线性组合来预测感兴趣的变量。 术语自回归表示它是变量对自身的回归。

因此，一个 p 阶自回归模型可以写成$y_{t} = c + \phi_{1}y_{t-1} + \phi_{2}y_{t-2} + \dots + \phi_{p}y_{t-p} + \varepsilon_{t},$ ，其中$\varepsilon_t$是白噪声。 这类似于多元回归，但使用$y_t$的滞后值作为预测变量。 我们将其称为 AR(p) 模型，即 p 阶自回归模型。

自回归模型在处理各种不同的时间序列模式方面非常灵活。  改变参数 ϕ 1 , … , ϕ p 会产生不同的时间序列模式。 误差项 $\varepsilon_t$的方差只会改变序列的尺度，而不是模式。

对于 AR(1) 模型：

* 当 ϕ 1 = 0 且 c = 0 时，y t 等价于白噪声； 
* 当 ϕ 1 = 1 且 c = 0 时，y t 等价于随机游走； 
* 当 ϕ 1 = 1 且 c ≠ 0 时，y t 等价于有漂移的随机游走； 
* 当 ϕ 1 < 0 时，y t 倾向于围绕均值振荡。

我们通常将自回归模型限制为固定数据，在这种情况下，需要对参数值进行一些限制。

* 对于 AR(1) 模型： − 1 < ϕ 1 < 1 。
* 对于 AR(2) 模型： − 1 < ϕ 2 < 1 , ϕ 1 + ϕ 2 < 1 , ϕ 2 − ϕ 1 < 1 。

当 p ≥ 3 时，限制要复杂得多。 在估计模型时，fable 包会处理这些限制。

##### 移动平均模型

移动平均模型不是在回归中使用预测变量的过去值，而是在类似回归的模型中使用过去的预测误差，$y_{t} = c + \varepsilon_t + \theta_{1}\varepsilon_{t-1} + \theta_{2}\varepsilon_{t-2} + \dots + \theta_{q}\varepsilon_{t-q},$

其中$\varepsilon_t$是白噪声。 我们将其称为 MA( q ) 模型，即 q 阶移动平均模型。 当然，我们没有观察到$\varepsilon_t的值，所以它并不是通常意义上的回归。

请注意，可以将$y_t$的每个值视为过去几个预测误差的加权移动平均值（尽管系数之和通常不会为 1）。 但是，不应将移动平均模型与我们在时序分解中讨论的移动平均平滑混淆。**移动平均模型用于预测未来值，而移动平均平滑用于估计过去值的趋势周期**。

MA模型的可逆性约束类似于平稳性约束。

   * 对于 MA(1) 模型：$-1<\theta_1<1$ 。
   * 对于 MA(2) 模型： $-1<\theta_2,1,~\theta_2+\theta_1 >-1,~\theta_1 -\theta_2 < 1$ 。

更复杂的条件适用于 q ≥ 3。 同样，在估计模型时，fable 包将处理这些约束。

##### 非季节性 ARIMA 模型

如果我们将差分与自回归和移动平均模型结合起来，我们就会得到一个非季节性的 ARIMA 模型。  ARIMA 是自回归积分移动平均线的首字母缩写词（在这种情况下，“积分”是差分的反义词）。 完整的模型可以写成:

$\begin{equation}  y'_{t} = c + \phi_{1}y'_{t-1} + \cdots + \phi_{p}y'_{t-p}     + \theta_{1}\varepsilon_{t-1} + \cdots + \theta_{q}\varepsilon_{t-q} + \varepsilon_{t},  \tag{9.1} \end{equation}$

其中$y_t'$是差分序列（它可能已经被差分多次）。 右侧的“预测器”包括 y t 的滞后值和滞后误差。 我们称其为 ARIMA( p , d , q ) 模型，其中

| p=   | order of the autoregressive part;      |
| ---- | -------------------------------------- |
| d=   | degree of first differencing involved; |
| q=   | order of the moving average part.      |

用于自回归和移动平均模型的相同平稳性和可逆性条件也适用于 ARIMA 模型。我们已经讨论过的许多模型都是 ARIMA 模型的特例，如图所示:

| White noise            | ARIMA(0,0,0) with no constant |
| ---------------------- | ----------------------------- |
| Random walk            | ARIMA(0,1,0) with no constant |
| Random walk with drift | ARIMA(0,1,0) with a constant  |
| Autoregression         | ARIMA(p,0,0)                  |
| Moving average         | ARIMA(0,0,q)                  |

$\begin{equation}   \begin{array}{c c c c}    (1-\phi_1B - \cdots - \phi_p B^p) & (1-B)^d y_{t} &= &c + (1 + \theta_1 B + \cdots + \theta_q B^q)\varepsilon_t\\    {\uparrow} & {\uparrow} & &{\uparrow}\\    \text{AR($p$)} & \text{$d$ differences} & & \text{MA($q$)}\\  \end{array} \end{equation}$

例子：

```R
fit <- global_economy %>%
  filter(Code == "EGY") %>%
  model(ARIMA(Exports))
report(fit)
```

了解 ARIMA 模型:

 ARIMA() 函数很有用，但任何自动化的东西都可能有点危险，即使您依赖自动程序为您选择模型，了解模型的行为也是值得的。

常数 c 对从这些模型获得的长期预测有重要影响。

* 如果 c = 0 和 d = 0 ，长期预测将为零。
* 如果 c = 0 和 d = 1 ，长期预测将变为非零常数。
* 如果 c = 0 和 d = 2 ，长期预测将遵循一条直线。
* 如果 c ≠ 0 且 d = 0 ，则长期预测将趋向于数据的均值。
* 如果 c ≠ 0 且 d = 1 ，则长期预测将遵循一条直线。
* 如果 c ≠ 0 且 d = 2 ，长期预测将遵循二次趋势。  （不推荐这样做，fable也不允许。）

d 的值也对预测区间有影响——d 的值越高，预测区间的大小增加得越快。 对于 d = 0 ，长期预测的标准差会趋向于历史数据的标准差，因此预测区间将基本相同。

如果数据显示循环，p 的值很重要。 要获得循环预测，必须使 p ≥ 2 以及参数的一些附加条件。 对于 AR(2) 模型，如果$\phi_1^2+4\phi_2<0$，就会出现循环行为。 在这种情况下，周期的平均周期为$\dfrac{2\pi}{\text{arc cos}(-\phi_1(1-\phi_2)/(4\phi_2))}.$

ACF 和 PACF 图:

通常无法仅从时间图中判断 p 和 q 的哪些值适合数据。 但是，有时可以使用 ACF 图和密切相关的 PACF 图来确定 p 和 q 的适当值。

回想一下，ACF 图显示了测量 y t 和 y t − k 之间关系的自相关性，其中 k 的不同值。 现在如果 y t 和 y t − 1 是相关的，那么 y t − 1 和 y t − 2 也一定是相关的。 然而，那么y t 和y t − 2 可能是相关的，仅仅因为它们都与y t − 1 相关，而不是因为y t − 2 中包含可用于预测y t 的任何新信息。

为了克服这个问题，我们可以使用偏自相关。 在去除滞后 1、2、3、…、k − 1 的影响后，它们测量 y t 和 y t − k 之间的关系。 所以第一个偏自相关与第一个自相关相同，因为它们之间没有任何东西可以去除。 每个偏自相关都可以估计为自回归模型中的最后一个系数。 具体而言，第 k 个偏自相关系数$\alpha_k$等于 AR( k ) 模型中$\phi k$的估计值。 在实践中，有比拟合所有这些自回归更有效的计算$\alpha_k$的算法，但它们给出相同的结果。偏自相关具有与普通自相关相同的 ± 1.96 / √ T 临界值

在一个命令中生成时间图、ACF 图和 PACF 图的一种便捷方法是使用 gg_tsdisplay()函数和 plot_type = "partial"。

如果数据来自 ARIMA( p , d ,0) 或 ARIMA(0, d , q ) 模型，则 ACF 和 PACF 图有助于确定 p 或 q 的值。 如果 p 和 q 均为正值，则绘图无助于找到合适的 p 和 q 值。

如果差分数据的 ACF 和 PACF 图显示以下模式，则数据可能遵循 ARIMA( p , d ,0) 模型：

* ACF 呈指数衰减或正弦曲线； 
* 在 PACF 的滞后 p 处有一个显着的尖峰，但没有超过滞后 p 。

如果差分数据的 ACF 和 PACF 图显示以下模式，则数据可能遵循 ARIMA(0, d , q ) 模型：

* PACF 呈指数衰减或正弦； 
* 在 ACF 中的滞后 q 处有一个显着的尖峰，但没有超出滞后 q 。

![ACF of Egyptian exports.](https://otexts.com/fpp3/fpp_files/figure-html/egyptacf-1.png)

![PACF of Egyptian exports.](https://otexts.com/fpp3/fpp_files/figure-html/egyptpacf-1.png)

在图 9.9 中，我们看到 ACF 中有一个衰减的正弦模式，在图 9.10 中，PACF 显示了滞后 4 处的最后一个显着峰值。这就是您对 ARIMA(4,0,0) 模型的期望。

我们还可以指定 ARIMA() 可以搜索的 pdq() 的特定值。 例如，要找到具有 p ∈ { 1 , 2 , 3 } , q ∈ { 0 , 1 , 2 } 和 d = 1 的最佳 ARIMA 模型，您可以使用 ARIMA(y ~ pdq(p=1:3, d  =1, q=0:2))。

##### 估计和顺序选择

最大似然估计:

一旦确定了模型阶数（即 p 、 d 和 q 的值），我们需要估计参数 c 、 ϕ 1 、... 、 ϕ p 、 θ 1 、... 、 θ q 。 当fable估计 ARIMA 模型时，它使用最大似然估计 (MLE)。 该技术找到使获得我们观察到的数据的概率最大化的参数值。 对于 ARIMA 模型，MLE 类似于通过最小化$\sum_{t=1}^T\varepsilon_t^2.$获得的最小二乘估计。
     

（对于第 7 章中考虑的回归模型，MLE 给出与最小二乘估计完全相同的参数估计。）请注意，ARIMA 模型的估计比回归模型复杂得多，并且不同的软件会因为使用不同的方法而给出略有不同的答案、估计和不同的优化算法。

在实践中，fable 包会报告数据的对数似然值； 即观测数据来自估计模型的概率的对数。 对于给定的 p 、 d 和 q 值，ARIMA() 将在寻找参数估计值时尝试最大化对数似然。

信息标准：

Akaike 的信息准则 (AIC) 可用于选择回归预测变量，也可用于确定 ARIMA 模型的阶数。 它可以写成 $\text{AIC} = -2 \log(L) + 2(p+q+k+1),$，其中 L 是数据的似然性，如果 c ≠ 0，则 k = 1，如果 c = 0，则 k = 0。 请注意，括号中的最后一项是模型中的参数数量（包括 $\sigma^2$ ，残差的方差）。

对于 ARIMA 模型，修正后的 AIC 可以写为:$\text{AICc} = \text{AIC} + \frac{2(p+q+k+1)(p+q+k+2)}{T-p-q-k-2},$

贝叶斯信息准则可以写成$\text{BIC} = \text{AIC} + [\log(T)-2](p+q+k+1).$

通过最小化 AIC、AICc 或 BIC 可以获得好的模型。 我们更喜欢使用 AICc。

重要的是要注意，这些信息标准往往不是选择模型的适当差分顺序 (d) 的良好指南，而仅适用于选择 p 和 q 的值。 **这是因为差分改变了计算似然的数据，使得具有不同差分阶数的模型之间的 AIC 值不具有可比性**。 所以我们需要使用一些其他的方法来选择 d ，然后我们可以使用 AICc 来选择 p 和 q 。

##### ARIMA建模

将 ARIMA 模型拟合到一组（非季节性）时间序列数据时，以下过程提供了一种有用的通用方法。

1. 绘制数据并识别任何不寻常的观察结果。
2. 如有必要，转换数据（使用 Box-Cox 转换）以稳定方差。
3. 如果数据是非平稳的，则取数据的一阶差分，直到数据平稳。
4. 检查 ACF/PACF：ARIMA( p , d , 0 ) 或 ARIMA( 0 , d , q ) 模型是否合适？
5. 尝试您选择的模型，并使用 AICc 搜索更好的模型。
6. 通过绘制残差的 ACF 并对残差进行组合检验来检查所选模型的残差。 如果它们看起来不像白噪声，请尝试修改模型。
7.  一旦残差看起来像白噪声，计算预测。
      Hyndman-Khandakar 算法（自动程序）只处理步骤 3-5。 因此，即使您使用它，您仍然需要自己处理其他步骤。

下图总结了该过程：

![General process for forecasting using an ARIMA model.](https://otexts.com/fpp3/figs/arimaflowchart.png)

注：

在非平稳 ARIMA 模型中包含一个常数等效于在预测中引入 d 阶多项式趋势。  （如果省略常数，则预测包括阶数为 d − 1 的多项式趋势。）当 d = 0 时，我们有一个特殊情况，即 μ 是 y t 的平均值。


 默认情况下，ARIMA() 函数将自动确定是否应包含常量。 对于 d = 0 或 d = 1 ，如果它提高了 AICc 值，将包括一个常数。 如果 d > 1，则始终忽略常数，因为在预测时二次或更高阶趋势特别危险。


 可以通过在模型公式中包含 0 或 1 来指定常量（如 lm() 中的截距）。 例如，要自动选择具有常量的 ARIMA 模型，您可以使用 ARIMA(y ~ 1 + ...)。 类似地，可以使用 ARIMA(y ~ 0 + ...) 排除常数。

##### 预测

ARIMA 模型的预测区间基于残差不相关且正态分布的假设。 如果这些假设中的任何一个不成立，则预测区间可能不正确。 因此，在生成预测区间之前，始终绘制残差的 ACF 和直方图以检查假设。

如果残差不相关但不是正态分布，则可以获得自举区间，如第 5.5 节所述。 这可以通过简单地在 forecast() 函数中添加 bootstrap=TRUE 来轻松实现。

 一般来说，ARIMA 模型的预测区间随着预测范围的增加而增加。 对于平稳模型（即 d = 0 ），它们会收敛，因此长期范围的预测区间基本上是相同的。 对于 d ≥ 1 ，预测区间将继续增长到未来。

与大多数预测区间计算一样，基于 ARIMA 的区间往往太窄。 发生这种情况是因为只考虑了误差的变化。 参数估计值和模型顺序也存在变化，这些变化未包括在计算中。 此外，计算假设已建模的历史模式将持续到预测期。

##### 季节性 ARIMA 模型

到目前为止，我们已经将注意力限制在非季节性数据和非季节性 ARIMA 模型上。 但是，ARIMA 模型还能够对范围广泛的季节性数据进行建模。

季节性 ARIMA 模型是通过在我们目前看到的 ARIMA 模型中包含额外的季节性项而形成的。 它是这样写的：



其中 m = 季节性周期（例如，每年的观测次数）。 我们对模型的季节性部分使用大写表示法，对模型的非季节性部分使用小写表示法。

 模型的季节性部分由与模型的非季节性组件相似的项组成，但涉及季节性周期的回移。 例如，ARIMA(1,1,1)(1,1,1)4 模型（没有常数）用于季度数据（ m = 4 ），可以写成$(1 - \phi_{1}B)~(1 - \Phi_{1}B^{4}) (1 - B) (1 - B^{4})y_{t} =  (1 + \theta_{1}B)~ (1 + \Theta_{1}B^{4})\varepsilon_{t}.$

ACF/PACF:

AR 或 MA 模型的季节性部分将在 PACF 和 ACF 的季节性滞后中看到。 例如，ARIMA(0,0,0)(0,0,1) 12 模型将显示： ACF 在滞后 12 处出现尖峰，但没有其他显着尖峰；  PACF 的季节性滞后呈指数衰减（即滞后 12、24、36……）。

类似地，ARIMA(0,0,0)(1,0,0) 12 模型将显示： ACF 季节性滞后的指数衰减；  PACF 中滞后 12 的单个显着峰值。

在考虑季节性 ARIMA 模型的适当季节性orders时，应将**注意力限制在季节性滞后上**。

建模过程与非季节性数据几乎相同，只是我们需要选择季节性 AR 和 MA 项以及模型的非季节性组件。 这个过程最好通过例子来说明。

例子：

我们将使用 2000 年 1 月至 2019 年 9 月的美国休闲和酒店业月度就业数据来描述季节性 ARIMA 建模，

```R
leisure <- us_employment %>%
  filter(Title == "Leisure and Hospitality",
         year(Month) > 2000) %>%
  mutate(Employed = Employed/1000) %>%
  select(Month, Employed)
autoplot(leisure, Employed) +
  labs(title = "US employment: leisure and hospitality",
       y="Number of people (millions)")
```

![Monthly US leisure and hospitality employment, 2000-2019.](https://otexts.com/fpp3/fpp_files/figure-html/usemployment1-1.png)

数据显然是非平稳的，具有很强的季节性和非线性趋势，所以我们首先取季节性差异。 

```R
leisure %>%
  gg_tsdisplay(difference(Employed, 12),
               plot_type='partial', lag=36) +
  labs(title="Seasonally differenced", y="")
```

这些显然也是非平稳的，因此我们在图 9.20 中进一步进行第一个差异。

```R
leisure %>%
  gg_tsdisplay(difference(Employed, 12) %>% difference(),
               plot_type='partial', lag=36) +
  labs(title = "Double differenced", y="")
```

![Double differenced Monthly US leisure and hospitality employment.](https://otexts.com/fpp3/fpp_files/figure-html/usemployment3-1.png)

我们现在的目标是根据图 9.20 所示的 ACF 和 PACF 找到合适的 ARIMA 模型。  ACF 滞后 2 处的显着峰值表明存在非季节性 MA(2) 分量。  ACF 滞后 12 处的显着峰值表明存在季节性 MA(1) 分量。 因此，我们从 ARIMA(0,1,2)(0,1,1) 12 模型开始，指示一阶差分、季节性差异以及非季节性 MA(2) 和季节性 MA(1) 分量。 如果我们从 PACF 开始，我们可能已经选择了 ARIMA(2,1,0)(0,1,1) 12 模型——使用 PACF 选择模型的非季节性部分，使用 ACF 选择 模型的季节性部分。 

我们还将包括一个自动选择的模型。 通过设置 stepwise=FALSE 和 approximation=FALSE，我们让 R 更加努力地找到一个好的模型。 这需要更长的时间，但只有一个系列要建模，因此花费的额外时间不是问题。

```R
fit <- leisure %>%
  model(
    arima012011 = ARIMA(Employed ~ pdq(0,1,2) + PDQ(0,1,1)),
    arima210011 = ARIMA(Employed ~ pdq(2,1,0) + PDQ(0,1,1)),
    auto = ARIMA(Employed, stepwise = FALSE, approx = FALSE)
  )
fit %>% pivot_longer(everything(), names_to = "Model name",
                     values_to = "Orders")
glance(fit) %>% arrange(AICc) %>% select(.model:BIC)
```

可以肯定的是，我们使用了 Ljung-Box 测试，它具有很大的 p 值，确认残差类似于白噪声。 请注意，**替代模型也通过了此测试**。

```R
augment(fit) %>% features(.innov, ljung_box, lag=24, dof=4)
forecast(fit, h=36) %>%
  filter(.model=='auto') %>%
  autoplot(leisure) +
  labs(title = "US employment: leisure and hospitality",
       y="Number of people (millions)")
```

注意：

当使用 AICc 值比较模型时，重要的是所有模型都具有相同的差分阶数。 然而，当使用测试集比较模型时，预测是如何产生的并不重要——比较总是有效的。 因此，在上表中，我们可以包括一些仅具有季节性差异的模型和一些具有一阶差分和季节性差分的模型，而在包含 AICc 值的较早表中，我们仅比较了具有季节性差异但没有一阶差分的模型。

 这里考虑的模型都没有通过所有的残差测试。 在实践中，我们通常会使用我们能找到的最好的模型，即使它没有通过所有的测试。

##### ARIMA vs ETS

普遍认为 ARIMA 模型比指数平滑更通用。 虽然线性指数平滑模型都是 ARIMA 模型的特例，但非线性指数平滑模型没有等效的 ARIMA 模型。 另一方面，也有许多没有指数平滑对应项的 ARIMA 模型。 特别是，所有 ETS 模型都是非平稳的，而一些 ARIMA 模型是平稳的。 图 9.27 显示了两个模型类之间的重叠。
![The ETS and ARIMA model classes overlap with the additive ETS models having equivalent ARIMA forms.](https://otexts.com/fpp3/fpp_files/figure-html/venn-1.png)

具有季节性或非阻尼趋势或两者兼有的 ETS 模型有两个单位根（即，它们需要两个差分水平才能使其平稳）。 所有其他 ETS 模型都有一个单位根（它们需要一级差分才能使其平稳）。

**AICc 可用于在同一类中的模型之间进行选择**。 例如，我们可以使用它在候选 ARIMA 模型之间选择 ARIMA 模型或在候选 ETS 模型之间选择 ETS 模型。 但是，它不能用于比较 ETS 和 ARIMA 模型，因为它们属于不同的模型类，并且可能性的计算方式不同。 下面的示例演示了在这些模型类之间进行选择。



#### 动态回归模型

##### 带有 ARIMA 误差的回归

如果公式中包含外生回归量，则函数 ARIMA() 将拟合具有 ARIMA 误差的回归模型。 正如前文中介绍的那样，特殊的 pdq() 指定了 ARIMA 误差模型的顺序。 如果指定了差分，则在估计模型之前将差分应用于回归模型中的所有变量。

ARIMA() 函数还可用于为误差选择最佳 ARIMA 模型。 这是通过不指定 pdq() 特殊来完成的。 是否需要差分是通过对使用普通最小二乘法估计的回归模型的残差应用 KPSS 检验来确定的。 如果需要差分，则对所有变量进行差分，并使用最大似然估计重新估计模型。 最终模型将根据原始变量表示，即使它已使用差分变量进行估计。

AICc 是为最终模型计算的，该值可用于确定最佳预测变量。 也就是说，应对所有要考虑的预测变量子集重复该过程，并选择具有最低 AICc 值的模型。

##### 预测

要使用具有 ARIMA 误差的回归模型进行预测，我们需要对模型的回归部分和模型的 ARIMA 部分进行预测，并将结果结合起来。 与普通回归模型一样，为了获得预测，我们首先需要预测预测变量。 当预测变量在未来已知时（例如，与日历相关的变量，如时间、星期几等），这很简单。 但是当预测变量本身未知时，我们必须对它们分别建模，或者为每个预测变量使用假设的未来值。

##### 随机和确定性趋势

有两种不同的方法可以对线性趋势进行建模。 

使用回归模型 $y_t = \beta_0 + \beta_1 t + \eta_t,$获得确定性趋势，其中 η t 是 ARMA 过程。 

使用模型$y_t = \beta_0 + \beta_1 t + \eta_t,$ 获得随机趋势，其中 η t 是 d = 1 的 ARIMA 过程。 在后一种情况下，我们可以对两边进行差分，使得 $y_t' = \beta_1 + \eta_t'$，其中 η ′ t 是一个 ARMA 过程。 换言之，$y_t = y_{t-1} + \beta_1 + \eta_t'$。

这类似于带有漂移的随机游走，但这里的误差项是一个 ARMA 过程，而不是简单的白噪声。

尽管这些模型看起来非常相似（它们仅在需要应用于 η t 的差异数量上有所不同），但它们的预测特征却大不相同。

有一个具有确定性趋势的隐含假设，即趋势的斜率不会随时间变化。 另一方面，随机趋势可能会发生变化，估计的增长率仅假设为历史时期的平均增长率，不一定是未来观察到的增长率。 因此，使用随机趋势进行预测更安全，尤其是对于较长的预测范围，因为预测区间允许未来增长的更大不确定性。

##### 动态谐波回归

当存在较长的季节性周期时，傅立叶项的动态回归通常比我们在本书中考虑的其他模型更好。例如，每日数据的年度季节性长度为 365，每周数据的季节性周期约为 52，而 半小时数据可以有多个季节性时段，其中最短的是时段 48 的每日模式。

ARIMA 和 ETS 模型的季节性版本设计用于较短的时间段，例如 12 为月度数据或 4 为季度数据。  ETS() 模型将季节性限制为最多 24 个周期，以允许每小时数据，但不允许数据具有更大的季节性周期。 问题是对于初始季节性状态有 m - 1 个参数需要估计，其中 m 是季节性周期。 所以对于大 m ，估计变得几乎不可能。

ARIMA() 函数将允许最多 m = 350 的季节性周期，但在实践中通常会在季节性周期超过 200 时耗尽内存。无论如何，高阶的季节性差分不会产生很多 意义——对于日常数据，它涉及将今天发生的事情与一年前发生的事情进行比较，并且没有限制季节性模式是平滑的。

 因此，对于此类时间序列，我们更喜欢调和回归方法，其中使用傅立叶项对季节性模式进行建模，并使用由 ARMA 误差处理的短期时间序列动态。

这种方法的优点是：

1. 它允许任何长度的季节性； 对于多于一个季节的数据，可以包含不同频率的傅里叶项；
2.  季节性模式的平滑度可以通过 K 控制，即傅立叶正弦和余弦对的数量——对于较小的 K 值，季节性模式更平滑； 
3. 短期动态很容易通过一个简单的 ARMA 误差处理。

 唯一真正的缺点（与季节性 ARIMA 模型相比）是**假设季节性是固定的——季节性模式不允许随时间变化**。 但在实践中，季节性通常非常恒定，因此除了长时间序列外，这不是一个大缺点。

#### 预测分层和分组的时间序列

时间序列通常可以通过各种感兴趣的属性自然地分解。 例如，自行车制造商销售的自行车总数可以按产品类型分类，如公路自行车、山地自行车和混合动力车。 这些中的每一个都可以分解为更细的类别。 例如混合动力自行车可以分为城市自行车、通勤自行车、舒适自行车和徒步自行车； 等等。 这些类别嵌套在较大的组类别中，因此时间序列的集合遵循分层聚合结构。 因此，我们将这些称为“分层时间序列”。 由于地理划分，经常会出现分层时间序列。 例如，自行车总销量可以按国家分类，然后在每个国家按州分类，在每个州按地区分类，依此类推，直到销售点级别。

当感兴趣的属性交叉而不是嵌套时，会出现替代聚合结构。 例如，自行车制造商可能对诸如车架尺寸、性别、价格范围等属性感兴趣。这些属性不会以独特的分层方式自然分解，因为这些属性没有嵌套。 我们将交叉属性的结果时间序列称为“分组时间序列”。 当感兴趣的属性既嵌套又交叉时，会出现更复杂的结构。 例如，自行车制造商自然会对按产品类型和地域划分的销售额感兴趣。 然后将产品分组和地理层次结构混合在一起。 我们在 11.1 节介绍了替代聚合结构。

所有分解和聚合系列通常都需要预测，并且很自然地希望预测以与数据相同的方式累加。 例如，区域销售的预测加起来应该与州销售的预测相加，而州销售的预测加起来又可以给出全国销售的预测。

在本节中，我们讨论预测以某种方式聚合的大量时间序列。 挑战在于我们需要在整个聚合结构中进行一致的预测。 也就是说，我们要求预测以与定义时间序列集合的层次结构或组的聚合结构一致的方式相加。

##### 分层和分组的时间序列

下图显示了一个简单的层次结构。 层次结构的顶部是“总计”，即数据的最聚合级别。  Total 系列的第 t 个观测值由 y t 表示，因为 t = 1 , … , T 。 总计被分解为两个系列，在层次结构的最底层又分别分为三个和两个系列。 在顶层之下，我们使用$y_{j,t}$表示与节点 j 对应的系列的第 t 个观测值。 例如，$y{A}{t}$表示节点 A 对应的序列的第 t 个观测值，$y{AB}{t}$表示节点 AB 对应的序列的第 t 个观测值，依此类推。

<img src="https://otexts.com/fpp3/figs/hts.png" alt="A two level hierarchical tree diagram." style="zoom:50%;" />

对于任何时间 t ，层次结构底层的观测值将与上述系列的观测值相加。

 例如，$\begin{equation}  y_{t}=y{AA}{t}+y{AB}{t}+y{AC}{t}+y{BA}{t}+y{BB}{t},  \tag{11.1} \end{equation}$

$\begin{equation}  y{A}{t}=y{AA}{t}+y{AB}{t}+y{AC}{t}\qquad \text{and} \qquad  y{B}{t}=y{BA}{t}+y{BB}{t}.  \tag{11.2} \end{equation}$

​     将(11.2)代入(11.1)，我们也得到$y_{t}=y{A}{t}+y{B}{t}$。

使用aggregate_key() 函数，我们可以创建层次结构时间序列，其中包含层次结构底部区域的过夜旅行，聚合到州，再聚合到全国总数。 使用父/子规范创建对应于嵌套结构的分层时间序列。

```R
tourism_hts <- tourism %>%
  aggregate_key(State / Region, Trips = sum(Trips))
```

分组时间序列

对于分组时间序列，数据结构不会以独特的分层方式自然分解。 下图显示了一个简单的分组结构。 分组结构的顶部是 Total，即数据的最聚合级别，同样由 y t 表示。  Total 可以按属性 (A, B) 分解，形成系列 y A , t 和 y B , t ，或按属性 (X, Y) 分解，形成系列 y X , t 和 y Y , t 。 在底层，数据按这两个属性进行分解。

<img src="https://otexts.com/fpp3/fpp_files/figure-html/GroupTree-1.png" alt="Alternative representations of a two level grouped structure." style="zoom:50%;" />



此示例显示分组结构存在替代聚合路径。 对于任何时间 t ，与层次结构一样，$\begin{equation*} y_{t}=y{AX}{t}+y{AY}{t}+y{BX}{t}+y{BY}{t}. \end{equation*}$

但是，对于分组结构的第一级，$\begin{equation} y{A}{t}=y{AX}{t}+y{AY}{t}\quad \quad y{B}{t}=y{BX}{t}+y{BY}{t} \tag{11.3} \end{equation}$,

但还有，

$\begin{equation} y{X}{t}=y{AX}{t}+y{BX}{t}\quad \quad y{Y}{t}=y{AY}{t}+y{BY}{t} \tag{11.4}. \end{equation}$

分组时间序列有时可以被认为是不强加唯一层次结构的层次时间序列，因为序列可以分组的顺序不是唯一的。

使用aggregate_key() 创建一个分组时间序列，现在使用语法attribute1*attribute2 交叉感兴趣的属性或分组（与用于分层时间序列的父/子语法相反）。 以下代码为具有交叉属性的监狱数据构建了一个分组的 tsibble：性别、法律地位和状态。

```
prison_gts <- prison %>%
  aggregate_key(Gender * Legal * State, Count = sum(Count)/1e3)
```

在 filter() 中使用 is_aggregated() 有助于探索或绘制图 11.7 底部面板中显示的主要组。 

混合分层和分组结构:

分解因素通常是嵌套的和交叉的。 例如，澳大利亚的旅游数据也可以按照旅游的四个目的进行分类：度假、商务、探亲访友和其他。 此分组变量不嵌套在任何地理变量中。 事实上，我们可以考虑按旅行目的为整个澳大利亚、每个州和每个地区划分过夜旅行。 我们将这种结构描述为与旅行目的“交叉”的“嵌套”地理层次结构。 使用aggregate_key() 可以通过简单地组合因素来指定。

```R
tourism_full <- tourism %>%
  aggregate_key((State/Region) * Purpose, Trips = sum(Trips))
```

##### 单层方法

传统上，分层或分组时间序列的预测涉及选择一个聚合级别并为该级别生成预测。 然后将它们汇总到更高级别，或分解为较低级别，以获得结构其余部分的一组连贯预测。

自下而上的方法:

生成连贯预测的一种简单方法是“自下而上”的方法。 这种方法涉及首先在底层为每个序列生成预测，然后将它们相加以生成结构中所有序列的预测。

 这种方法的一个优点是我们在结构的底层进行预测，因此不会因聚合而丢失信息。 另一方面，底层数据可能非常嘈杂，并且对建模和预测更具挑战性。

我们将使用 reconcile() 函数来指定我们要如何计算相干预测。

```R
data %>% aggregate_key() %>% model() %>%
  reconcile() %>% forecast()
```

从包含各个底层系列的 tsibble 对象（此处标记为数据）开始。

1. 在aggregate_key() 中定义聚合结构并构建一个包含聚合系列的tsibble 对象。
2. 在所有聚合级别为每个系列确定一个模型（）。
3.  在 reconcile() 中指定如何从所选模型生成一致预测。
4. 使用 forecast() 函数为整个聚合结构生成预测。

自上而下的方法:

自上而下的方法涉及首先生成对 Total 系列 y t 的预测，然后在层次结构中向下分解这些预测。

让 p 1 , … , p m 表示一组分解比例，这些比例决定如何分布 Total 系列的预测以获得结构底层每个系列的预测。

一旦生成了底层 h-step-ahead 预测，这些预测就会被聚合起来，为系列的其余部分生成连贯的预测。

可以使用 reconcile() 函数中的 top_down() 生成自上而下的预测。

可以指定几种可能的自顶向下方法。 两种最常见的自上而下方法根据数据的历史比例指定分解比例。 这些在 Gross & Sohl (1990) 的研究中表现良好:

1. 平均历史比例$p_j=\frac{1}{T}\sum_{t=1}^{T}\frac{y_{j,t}}{{y_t}}$
2. 历史平均值的比例$p_j={\sum_{t=1}^{T}\frac{y_{j,t}}{T}}\Big/{\sum_{t=1}^{T}\frac{y_t}{T}}$

这种自上而下的方法的一个便利属性是它们的简单性。 人们只需要为最聚合的顶级系列建模和生成预测。 一般来说，这些方法似乎对总体水平产生了相当可靠的预测，并且它们对于低计数数据很有用。

 另一方面，一个缺点是由于聚合导致信息丢失。 使用这种自上而下的方法，我们无法捕捉和利用各个系列的特征，例如时间动态、特殊事件、不同的季节性模式等。

预测比例:

因为用于分解的历史比例没有考虑这些比例如何随时间变化，基于历史比例的自上而下的方法往往比自下而上的方法在层次结构的较低级别产生更不准确的预测。 为了解决这个问题，可以使用基于预测而不是历史数据的比例（G. Athanasopoulos 等，2009）。

 考虑一个一级层次结构。 我们首先为所有系列生成 h-step-ahead 预测。 我们不直接使用这些预测，而且它们不连贯（它们加起来不正确）。 让我们称这些为“初始”预测。 我们计算每个在底层的提前 h 步初始预测与该级别所有提前 h 步初始预测的总和的比例。 我们将这些称为预测比例，我们使用它们来分解顶级 h 步提前初始预测，以便为整个层次结构生成连贯的预测。

 对于 K 级层次结构，对每个节点重复此过程，从顶层到底层。 应用此过程可得出以下获取预测比例的一般规则：$p_j=\prod^{K-1}_{\ell=0}\frac{\hat{y}_{j,h}^{(\ell)}}{\hat{S}_{j,h}^{(\ell+1)}}$

其中$j=1,2,\dots,m$, $\hat{y}_{j,h}^{(\ell)}$ 是对应于j以上$\ell$级节点的系列的 h 超前初始预测，以及$\hat{S}_{j,h}^{(\ell)}$是在节点 j 上ℓ 层且直接连接到该节点的节点下的 h 步提前初始预测的总和。这些预测比例分解了总序列的 h 步超前初始预测，以获得底层序列的 h 步超前连贯预测。

这种方法是通过设置 method = "forecast_proportions" 在 top_down() 函数中实现的。 因为这种方法往往比其他自顶向下方法更有效，所以当没有指定方法参数时，它是 top_down() 函数中的默认选择。

所有自上而下的方法的一个缺点是，即使基础预测是无偏的，它们也不会产生无偏的连贯预测（Hyndman 等，2011）。

中出方法:

中出方法结合了自下而上和自上而下的方法。 同样，它只能用于严格的分层聚合结构。

首先，选择“中间”级别并为该级别的所有系列生成预测。 对于中层以上的序列，使用自下而上的方法通过向上聚合“中层”预测来生成连贯的预测。 对于“中层”以下的系列，通过向下分解“中层”预测，使用自上而下的方法生成连贯的预测。

这种方法在 middle_out() 函数中通过 level 参数指定适当的中间层并使用 method 参数选择自上而下的方法来实现。

##### 预测协调 

假设我们预测所有序列而忽略任何聚合约束。 我们称这些为基础预测，并用$\hat y_{h}$表示，其中 h 是预测范围。 它们以与数据$y_t$相同的顺序堆叠。

那么对于分层结构或分组结构的所有连贯预测方法都可以表示为:

$\begin{equation}  \tilde{{y}}_h={S}{G}\hat{{y}}_h,   \end{equation}$

迄今为止所考虑的传统方法的局限性在于，它们仅使用来自单一聚合级别的基础预测，这些基础预测已被聚合或分解以获得所有其他级别的预测。 因此，他们使用有限的信息。 然而，一般来说，我们可以使用其他 G 矩阵，然后 S G 组合和协调所有基础预测以产生一致的预测。

 事实上，我们可以找到最优的 G 矩阵来给出最准确的协调预测。

MinT 最优对账方法：

我们需要找出预测中的错误。 维克拉马苏里亚等人 (2019) 表明 h-step-ahead 相干预测误差的方差-协方差矩阵由下式给出:

$\begin{equation*} {V}_h = \text{Var}[{y}_{T+h}-\tilde{{y}}_h]={S}{G}{W}_h{G}'{S}' \end{equation*}$

详细公式略，最佳协调预测：

 MinT 由 reconcile() 函数中的 min_trace() 实现。

 为了在实践中使用它，我们需要估计 W h ，即提前 h 步基础预测的预测误差方差。 这可能很困难，因此提供了四种简化的近似值，这些近似值在模拟和实践中都表现良好。

1. 为所有 h 设置 ${W}_h=k_h{I}$，其中 k h > 0 . 这是最简单的假设，意味着 G 独立于数据，提供了大量的计算节省。 然而，缺点是该规范没有考虑结构级别之间的规模差异，或系列之间的关系。

2. 为所有 h 设置 ${W}_h = k_h {W}_1$ ，其中 k h > 0 。 这里我们只假设误差协方差矩阵彼此成比例，我们直接估计完整的一步协方差矩阵 W 1 。 最明显和最简单的方法是使用样本协方差。 这是通过设置 method = "mint_cov" 在 min_trace() 中实现的。

   但是，对于底层序列 m 的数量与序列 T 的长度比较大的情况，这不是一个好的估计器。 相反，我们使用收缩估计器将样本协方差收缩为对角矩阵。 这是通过设置 method = "mint_shrink" 

method = "ols" method = "wls_var" method = "wls_struct" method = "mint_shrink"

总之，与任何其他现有方法不同，最佳调节预测是使用分层或分组结构中的所有可用信息生成的。 这很重要，因为特定的聚合级别或分组可能会揭示用户感兴趣且对建模很重要的数据特征。 这些特征在其他层次上可能完全隐藏或不易识别。

 例如，考虑第 11.1 节中介绍的澳大利亚旅游数据，其中层次结构遵循一个国家的地理划分，将其划分为州和地区。 一些地区将主要是夏季目的地，而其他地区可能是冬季目的地。 我们在图 11.4 中看到了北部和南部各州之间对比鲜明的季节性模式。 由于汇总，这些差异将在国家层面得到平滑。

与自下而上的方法相比，使用 OLS 和 MinT 协调基础预测会产生更准确的预测。 这种结果在应用中很常见，因为协调方法使用来自结构各个层次的信息，与使用有限信息的旧传统方法相比，可以产生更准确的连贯预测。 此外，调节通常可以改善几乎所有级别的不连贯的基本预测。

##### 一个例子

```R
tourism_full <- tourism %>%
  aggregate_key((State/Region) * Purpose, Trips = sum(Trips))

fit <- tourism_full %>%
  filter(year(Quarter) <= 2015) %>%
  model(base = ETS(Trips)) %>%
  reconcile(
    bu = bottom_up(base),
    ols = min_trace(base, method = "ols"),
    mint = min_trace(base, method = "mint_shrink"),
  )
fc <- fit %>% forecast(h = "2 years")
fc %>%
  filter(is_aggregated(Region), is_aggregated(Purpose)) %>%
  autoplot(
    tourism_full %>% filter(year(Quarter) >= 2011),
    level = NULL
  ) +
  labs(y = "Trips ('000)") +
  facet_wrap(vars(State), scales = "free_y")
fc %>%
  filter(is_aggregated(State), !is_aggregated(Purpose)) %>%
  autoplot(
    tourism_full %>% filter(year(Quarter) >= 2011),
    level = NULL
  ) +
  labs(y = "Trips ('000)") +
  facet_wrap(vars(Purpose), scales = "free_y")
#准确度度量
fc %>%
  filter(is_aggregated(State), is_aggregated(Purpose)) %>%
  accuracy(
    data = tourism_full,
    measures = list(rmse = RMSE, mase = MASE)
  ) %>%
  group_by(.model) %>%
  summarise(rmse = mean(rmse), mase = mean(mase))
```

注：要以这种方式生成自举预测区间，我们只需在 predict() 函数中设置 bootstrap = TRUE。

#### 先进预测方法

##### 复杂季节性

到目前为止，我们主要考虑了相对简单的季节性模式，例如季度和月度数据。 然而，更高频率的时间序列通常表现出更复杂的季节性模式。 例如，每日数据可能具有每周模式和年度模式。 每小时数据通常具有三种类型的季节性：每日模式、每周模式和年度模式。 即使是每周数据也很难预测，因为一年中没有完整的周数，因此年度模式的季节性周期平均为 365.25 / 7 ≈ 52.179。 到目前为止，我们考虑的大多数方法都无法处理这些季节性的复杂性。

我们不一定要在我们的模型中包括所有可能的季节性时期——只是那些可能出现在数据中的时期。 例如，如果我们只有 180 天的数据，我们可能会忽略年度季节性。 如果数据是对自然现象（例如温度）的测量，我们可能可以安全地忽略任何每周季节性。

具有多个季节性周期的 STL：

STL() 函数旨在处理多个季节性。 它将返回多个季节性成分，以及趋势和剩余成分。 在这种情况下，我们需要重新索引 tsibble 以避免缺失值，然后明确给出季节性周期。

具有多个季节性周期的动态谐波回归：

对于多个季节性，我们可以像在前面的章节中那样使用傅立叶项。 因为有多个季节性，我们需要为每个季节性周期添加傅立叶项。 在这种情况下，季节性周期为 169 和 845，因此傅立叶项的形式为

$\sin\left(\frac{2\pi kt}{169}\right), \quad  \cos\left(\frac{2\pi kt}{169}\right), \quad  \sin\left(\frac{2\pi kt}{845}\right), \quad  \text{and} \quad  \cos\left(\frac{2\pi kt}{845}\right),$

我们将拟合具有 ARIMA 误差结构的动态谐波回归模型。 可以选择每个季节期间的傅立叶项总数以最小化 AICc。 但是，对于高季节性时期，这往往会高估所需的术语数量，因此我们将使用更主观的选择，其中 10 个术语用于每日季节性，5 个用于每周季节性。 

例子：电力的预测

##### Prophet model

最近的一个提议是 Prophet 模型，可通过 [fable.prophet] 包获得。 该模型由 Facebook（S. J. Taylor & Letham，2018 年）引入，最初用于预测具有每周和每年季节性以及假日效应的每日数据。 后来扩展到涵盖更多类型的季节性数据。 **它最适用于具有强烈季节性和多个季节历史数据的时间序列**。

Prophet 可以被认为是一个非线性回归模型，形式为$y_t = g(t) + s(t) + h(t) + \varepsilon_t,$

其中 g ( t ) 描述分段线性趋势（或“增长项”）， s ( t ) 描述各种季节性模式， h ( t ) 捕捉假期效应，而 ε t 是白噪声误差项。

* 如果未明确指定，将自动选择分段线性趋势的节点（或变化点）。 或者，可以使用逻辑函数来设置趋势的上限。
* 季节性成分由相关时期的傅立叶项组成。 默认情况下，order 10 用于年度季节性，order 3 用于每周季节性。
* 假日效应被添加为简单的虚拟变量。
* 该模型使用贝叶斯方法进行估计，以允许自动选择变化点和其他模型特征。

Prophet 具有比我们之前考虑的 DHR 模型更快估计的优势，并且它是完全自动化的。 但是，正如这两个示例所说明的那样，它很少能提供比替代方法更好的预测准确性。

##### 向量自回归

到目前为止，我们考虑的模型的一个限制是它们强加了一种单向关系——预测变量受预测变量的影响，但反之则不然。 然而，在很多情况下也应该允许相反的情况——所有变量都会相互影响。 在前文中，根据个人可支配收入 (I t ) 的变化预测了个人消费支出 ( C t ) 的变化。 然而，在这种情况下，双向关系可能更合适：$I_t$的增加将导致$C_t$的增加，反之亦然。

在向量自回归 (VAR) 框架中允许这种反馈关系。 在这个框架中，所有变量都被对称对待。 它们都被建模，就好像它们都平等地相互影响。 在更正式的术语中，所有变量现在都被视为“内生的”。 为了表示这一点，我们现在改变符号并将所有变量写为 y s： $y_{1,t}$表示变量$y_1$的第 t 次观察.$y_{2,t}$表示变量 y 2 的第 t 次观察，依此类推。

VAR 模型是用于预测时间序列向量的单变量自回归模型的推广。 它包括系统中的每个变量一个方程。 每个方程的右侧包括一个常数和系统中所有变量的滞后。 为简单起见，我们将考虑一个滞后的两变量 VAR。 我们将二维 VAR(1) 模型写为

$\begin{align}  y_{1,t} &= c_1+\phi _{11,1}y_{1,t-1}+\phi _{12,1}y_{2,t-1}+\varepsilon_{1,t} \\  y_{2,t} &= c_2+\phi _{21,1}y_{1,t-1}+\phi _{22,1}y_{2,t-1}+\varepsilon_{2,t},  \end{align}$

其中ε 1 , t 和ε 2 , t 是可能同时相关的白噪声过程。 系数 $\phi_{ii,\ell}$捕捉变量 y i 的第 $\ell$个滞后对其自身的影响，而系数 ϕ i j , ℓ 捕捉变量 y j 的第 ℓ 个滞后对 y i 的影响。

如果序列是平稳的，我们通过直接将 VAR 拟合到数据（称为“水平 VAR”）来预测它们。 如果序列是非平稳的，我们取数据的差异以使它们平稳，然后拟合 VAR 模型（称为“差异中的 VAR”）。 在这两种情况下，模型都是使用最小二乘原理逐个方程估计的。 对于每个方程，通过最小化$e_{i,t}$值的平方和来估计参数。

另一种可能性超出了本节的范围，因此我们不在这里探讨，是该系列可能是非平稳但协整的，这意味着它们存在平稳的线性组合。 在这种情况下，应包括包含误差校正机制（通常称为向量误差校正模型）的 VAR 规范，(见下文协整分析)并应使用最小二乘估计的替代估计方法

预测是从 VAR 以递归方式生成的。  VAR 为系统中包含的每个变量生成预测。 为了说明这个过程，假设我们已经拟合了方程 中描述的二维 VAR(1) 模型，适用于时间 T 之前的所有观测值。 然后通过以下方式生成一步预测：

$\begin{align*}  \hat y_{1,T+1|T} &=\hat{c}_1+\hat\phi_{11,1}y_{1,T}+\hat\phi_{12,1}y_{2,T} \\  \hat y_{2,T+1|T} &=\hat{c}_2+\hat\phi _{21,1}y_{1,T}+\hat\phi_{22,1}y_{2,T}. \end{align*}$

使用 VAR 进行预测时，必须做出两个决定，即系统中应包含多少变量（由 K 表示）和多少滞后（由 p 表示）。 要在 VAR 中估计的系数数量等于$K+pK^2$（或每个方程 1 + p K）。 例如，对于 K = 5 个变量和 p = 3 个滞后的 VAR，每个方程有 16 个系数，总共需要估计 80 个系数。 需要估计的系数越多，进入预测的估计误差就越大。

在实践中，通常保持 K 较小并且仅包含彼此相关的变量，因此可用于相互预测。 信息标准通常用于选择要包括的滞后数。 使用 AICc 时应该小心，因为它倾向于选择大量的滞后； 相反，**对于 VAR 模型，我们经常使用 BIC 代替**。 该模型的更复杂版本是“稀疏 VAR”（其中许多系数设置为零）； 另一种方法是使用“收缩估计”（其中系数较小）。

 VAR 面临的一个批评是它们是无理论的； 也就是说，它们不是建立在对方程施加理论结构的经济理论之上。 假设每个变量都会影响系统中的每个其他变量，这使得对估计系数的直接解释变得困难。 尽管如此，VAR 在多种情况下还是很有用的：

1. 预测不需要明确解释的相关变量的集合； 
2. 测试一个变量是否对预测另一个变量有用（格兰杰因果检验的基础）； 
3. 脉冲响应分析，分析一个变量对另一个变量的突然但暂时的变化的响应； 
4. 预测误差方差分解，其中每个变量的预测方差的比例归因于其他变量的影响。

##### Bootstrapping and bagging

Bootstrapping time series：

在前文节中，我们引导时间序列的残差，以便使用模型模拟序列的未来值。

更一般地说，我们可以使用另一种类型的引导程序生成与我们观察到的序列相似的新时间序列。

首先，必要时对时间序列进行转换，然后使用 STL 将其分解为趋势、季节性和剩余部分。 然后我们获得剩余部分的混洗版本以获得引导的剩余系列。 因为 STL 余数序列中可能存在自相关，所以我们不能简单地使用 5.5 节中描述的重绘过程。 相反，我们使用“blocked bootstrap”，其中时间序列的连续部分被随机选择并连接在一起。 这些自举剩余序列被添加到趋势和季节性分量中，并反转转换以给出原始时间序列的变化。

袋装预测：

这些自举时间序列的一种用途是提高预测准确性。 如果我们从每个额外的时间序列中生成预测，并对结果预测进行平均，我们会得到比直接直接预测原始时间序列更好的预测。 这称为“装袋”，代表“引导程序聚合”。 

#### 多元时间序列

多元时间序列的一些计算使用蔡瑞胸(R.S. Tsay)教授的MTS扩展包

经济的全球一体化和信息传播的发展使得各国的金融市场相互关联， 一个市场的价格变动可以很快地扩散到另一个市场。 持有多个资产的投资者也希望了解多个资产的收益率之间的关系。 这些问题属于多元时间序列分析的范畴。

多元时间序列包含多个一元时间序列作为分量， 各个一元时间序列的采样时间点相同， 所以数据可以用矩阵形式表示， 每行为一个时间点， 每列为一个一元时间序列。 在R中可以保存为矩阵、数据框、ts或者xts时间序列对象。 设$\boldsymbol r_t = (r_{1t}, \dots, r_{kt})^T$表示$k$个资产在$t$时刻的对数收益率。

一元时间序列的某些方法可以推广到多元情形， 但是有些问题需要注意。 某些情况下需要提出新的模型和方法。

##### 基础知识

多元时间序列分析中一个重要概念是引导与滞后关系。 为此， 用互相关阵来衡量时间序列之间的线性关系的强度。 元弱平稳列的滞后的互协方差阵定义为

$\begin{aligned} \Gamma_l = (\Gamma_{ij}(l))_{k \times k} = E[ (\boldsymbol r_t - \boldsymbol\mu) (\boldsymbol r_{t-l} - \boldsymbol\mu)^T ] \end{aligned}$

这是一元时间序列的自协方差函数$\gamma_l$的推广. $\Gamma_l$仅依赖于滞后$l$而与时刻$t$无关。

$k$元弱平稳列的滞后的互相关阵 (Cross Correlation Matrix, CCM)定义为:

$\begin{aligned} \boldsymbol\rho_l = (\rho_{ij}(l))_{k\times k} = D^{-1} \Gamma_l D^{-1} \end{aligned}$

其中:$\begin{aligned} \rho_{ij}(l) = \text{corr}(r_{it}, r_{j, t-l}) = \frac{\Gamma_{ij}(l)}{\sqrt{\Gamma_{ii}(0) \Gamma_{jj}(0)}} \end{aligned}$是$r_{it}$和$r_{j,t-1}$的相关系数。

不同于一元时间序列的自协方差满足$\gamma_l = \gamma_{-l}$， 对$k$元时间序列有

$\begin{aligned} \Gamma_{ij}(l) =& \text{Cov}(r_{it}, r_{j,t-l})  = \text{Cov}(r_{j,t-l}, r_{i,t}) = \text{Cov}(r_{j,t}, r_{i,t+l}) \\ =& \text{Cov}(r_{j,t}, r_{i,t-(-l)}) = \Gamma_{ji}(-l) \end{aligned}$

即：$\begin{aligned} \Gamma_{-l} = \Gamma_l^T \end{aligned}$,对互相关阵$\boldsymbol\rho_l$也有$\begin{aligned}
\boldsymbol\rho_{-l} = \boldsymbol\rho_l^T
\end{aligned}$,所以只需要考虑:$\boldsymbol\rho_l, l \geq 0$

##### 时间序列之间线性依存性分类

![image-20210905224019529](数模整理.assets/image-20210905224019529.png)

##### 多元混成检验

Hosking(1980,1981), Li和McLeod(1981) 已经把一元的Ljung-Box白噪声检验推广到了多元的情形。 对一个多元序列，检验零假设：$\begin{aligned} H_0: \boldsymbol\rho_1 = \dots = \boldsymbol\rho_m = \boldsymbol 0 \end{aligned}$

对立假设是不全为零矩阵。 这可以检验多元时间序列$\boldsymbol r_t$为宽白噪声的零假设， 即$\boldsymbol r_t$为弱平稳列且无序列自相关， 可以有同步的分量间相关。

使用检验统计量:$\begin{aligned} Q_k(m) = T^2 \sum_{l=1}^m \frac{1}{T-l} \text{tr}( \hat\Gamma_l^T \hat\Gamma_0^{-1} \hat\Gamma_l \hat\Gamma_0^{-1}) \end{aligned}$

`MTS::mq()`计算多元混成检验：

$Q_k(m)$统计量是对$\boldsymbol {r_t}$的前$m$个互相关阵的一个联合检验， 如果结果显著， 就应该建立多元的均值模型描述序列分量之间的领先–滞后关系。 **最常用的是向量自回归(VAR)模型**

#### 协整分析和向量误差修正模型

线性回归分析是统计学的最常用的模型之一， 但是， 如果回归的自变量和因变量都是时间序列， 回归就不满足回归分析的基本假定： 模型误差项独立同分布。

比如，一元线性回归模型

$y_t = a + b x_t + e_t, \ t=1,2,\dots,n,$

需要假定$e_1, e_2, \dots, e_t$不相关， 零均值，方差同为$\sigma^2$，$x_1, x_2, \dots, x_n$非随机， 这时最小二乘估计是无偏估计。当极限存在， 有正极限时估计相合。

如果$e_t,x_t,y_t$之中有时间序列， 则回归可能不相合， 或者估计相合但是回归结果中的标准误差估计和假设检验有错误。

##### 协整分析概念

对于二元时间序列$\boldsymbol x_{t} = (x_{1t}, x_{2t})^T$， 如果$x_{1t}$和$x_{2t}$都是一元单位根过程， 但存在非零线性组合$\boldsymbol\beta = (\beta_1, \beta_2)$使得$z_t = \beta_1 x_{1t} + \beta_2 x_{2t}$弱平稳， 则称两个分量$x_{1t}$和$x_{2t}$存在**协整**关系（cointegration）， $(\beta_1, \beta_2)^T$称为$\boldsymbol x_t$的**协整向量**。 多个分量的多元时间序列可以类似地定义协整关系， 多元时可以有多个协整向量。

##### Engle和Granger两阶段法

考虑两个分量的多元时间序列$\boldsymbol r_t$。 为了检验协整性， 首先要用一元的单位根检验（如ADF检验）确认两个分量都是单位根过程， 并且差分之后就没有单位根，这样的单位根过程称为“单整”的， 或I(1)序列。

其次，将$x_{1t}$当作因变量，$x_{2t}$当作自变量， 作一元线性回归，得到残差$e_t$序列， 和回归系数$\beta 1$，方程为$x_{1t} = \beta_0 + \beta_1 x_{2t} + e_t$

根据([R. R. Engle and Granger 1987](https://www.math.pku.edu.cn/teachers/lidf/course/fts/ftsnotes/html/_ftsnotes/References.html#ref-EngleGranger1987:cointegration))的研究， 回归在协整关系成立时参数估计相合， 但是系数的估计非正态， 所以用线性最小二乘估计得到的点估计可用， 但是结果中的t检验和F检验结果无效。

为了验证协整关系是否成立， 只要对序列进行一元的单位根检验， 但是因为是回归残差， 其自由度有变化， 所以统计量p值的计算需要进行调整， ([Phillips and Ouliaris 1990](https://www.math.pku.edu.cn/teachers/lidf/course/fts/ftsnotes/html/_ftsnotes/References.html#ref-Phillips1990:coint))给出了利用回归残差进行协整检验的方法， 称为Phillips-Ouliaris协整检验。 如果经检验不存在单位根， 则称两个分量是协整的。

这样的检验方法称为Engle和Granger两阶段法， 利用([Phillips and Ouliaris 1990](https://www.math.pku.edu.cn/teachers/lidf/course/fts/ftsnotes/html/_ftsnotes/References.html#ref-Phillips1990:coint))方法计算这个检验称为Phillips-Ouliaris协整检验。 但是，这里的两阶段， 其实第二阶段指的是在多元情况下需要找出所有的协整向量， 这需要利用向量误差修正模型(VECM)。

R扩展包tseries中`po.test()`可以执行基于EG两阶段法步骤的Phillips-Ouliaris协整检验， 零假设是非协整， 对立假设是存在协整关系。 参见([Phillips and Ouliaris 1990](https://www.math.pku.edu.cn/teachers/lidf/course/fts/ftsnotes/html/_ftsnotes/References.html#ref-Phillips1990:coint))。

##### 误差修正模型

因为在协整系统中， 单位根非平稳分量的个数多于单位根的个数 （通过线性组合可以使得单位根非平稳的分量减少）， 所以如果对每个单位根非平稳分量计算差分， 虽然使得分量都平稳了， 但是会造成过度差分， 使得部分分量的ARMA模型的MA部分有单位根， 这样的模型平稳但不可逆， 不可逆的模型在估计和预测上比较困难。

([R. R. Engle and Granger 1987](https://www.math.pku.edu.cn/teachers/lidf/course/fts/ftsnotes/html/_ftsnotes/References.html#ref-EngleGranger1987:cointegration))讨论了协整系统的误差修正表示， 称为向量误差修正模型(VECM, vector error correction model)。

#### 格兰格因果性

##### 介绍

考虑两个时间序列之间的因果性。 这里的因果性指的是时间顺序上的关系， 如果$X_{t-1}, X_{t-2}, \dots$对有作用， 而$Y_{t-1}, Y_{t-2}, \dots$对$X_t$没有作用， 则称是的格兰格原因， 而不是的格兰格原因。 如果对有作用， 对也有作用， 则在没有进一步信息的情况下无法确定两个时间序列的因果性关系。

注意这种因果性与采样频率有关系， 在日数据或者月度数据中能发现的领先——滞后性质的因果关系， 到年度数据可能就以及混杂在以前变成同步的关系了。

([C. W. J. Granger 1969](https://www.math.pku.edu.cn/teachers/lidf/course/fts/ftsnotes/html/_ftsnotes/References.html#ref-Granger1969:causal))首先提出了时间序列之间因果关系的概念。 时间序列因果关系可以是假设没有因果关系， 然后检验能否否定， 这是([C. W. J. Granger 1969](https://www.math.pku.edu.cn/teachers/lidf/course/fts/ftsnotes/html/_ftsnotes/References.html#ref-Granger1969:causal))的方法； 也可以是首先建立有因果关系的模型， 然后检验其中表示因果关系的参数是否不显著， 这是利用VAR和VECM的方法。 后一种方法首先提出于([Sims 1972](https://www.math.pku.edu.cn/teachers/lidf/course/fts/ftsnotes/html/_ftsnotes/References.html#ref-Sims1972:cause))。

在具有因果性的情况下， 可以用来改善预测。 比如， 如果是的格兰格原因， 则可以利用的现在与过去值、 的现在与过去值去预测的将来值， 会比仅利用的值预测要好， 这是认为的已有值中包含了的已有值中缺少的信息， 而这些信息对预测的将来值是有作用的。 ([C. W. J. Granger 1969](https://www.math.pku.edu.cn/teachers/lidf/course/fts/ftsnotes/html/_ftsnotes/References.html#ref-Granger1969:causal))的检验方法就是针对这一点进行检验。

在经济与金融时间序列建模中考虑对影响的另一个原因是， 许多时间序列具有较强的正自相关性， 比如单位根过程或者特征根接近于单位圆的ARMA模型， 对于这样的两个时间序列， 如果以为因变量， 为自变量作线性回归， 可能发生虚假的回归， 即使两个序列之间独立， 但是回归结果可以是显著的。 这是因为，与之间的强序列相关性。 如果在回归中引入滞后项， 这样的虚假回归就可以被消除。 参见([Clive W. J. Granger and Newbold 1974](https://www.math.pku.edu.cn/teachers/lidf/course/fts/ftsnotes/html/_ftsnotes/References.html#ref-Granger1974:spurious-reg))。

从因果性的角度讲， 只有两个序列的新息（innovation）对另一个序列的影响才是有意义的。 参见([Schwert 1979](https://www.math.pku.edu.cn/teachers/lidf/course/fts/ftsnotes/html/_ftsnotes/References.html#ref-Schwert1979:causality))。

#### 一些实际的预测问题

##### 每周、每日和次日数据

尽管出于不同的原因，每周、每日和次日数据对于预测来说可能具有挑战性。

每周数据 

每周数据很难处理，因为季节性周期（一年中的周数）既大又非整数。 一年中的平均周数为 52.18。 我们考虑过的大多数方法都要求季节性周期为整数。 即使我们将其近似为 52，大多数方法也无法有效地处理如此大的季节性周期。

 最简单的方法是使用 STL 分解以及应用于季节性调整数据的非季节性方法（如第 3 章所述）。 最简单的方法是使用 STL 分解以及应用于季节性调整数据的非季节性方法（如第 3 章所述）。 以下是一个示例，使用了 1991 年 2 月至 2005 年 5 月期间供应的美国成品车用汽油产品（以每天百万桶计）的每周数据。

```R
my_dcmp_spec <- decomposition_model(
  STL(Barrels),
  ETS(season_adjust ~ season("N"))
)
us_gasoline %>%
  model(stl_ets = my_dcmp_spec) %>%
  forecast(h = "2 years") %>%
  autoplot(us_gasoline) +
  labs(y = "Millions of barrels per day",
       title = "Weekly US gasoline production")
```

另一种方法是使用[动态谐波回归模型](#动态谐波回归)。 在以下示例中，通过最小化 AICc 来选择傅立叶项的数量。  ARIMA 模型的阶次也是通过最小化 AICc 来选择的，尽管这是在 ARIMA() 函数中完成的。 **我们使用 PDQ(0,0,0) 来防止 ARIMA() 尝试使用季节性 ARIMA 组件处理季节性**。

```R
gas_dhr <- us_gasoline %>%
  model(dhr = ARIMA(Barrels ~ PDQ(0, 0, 0) + fourier(K = 6)))
  
gas_dhr %>%
  forecast(h = "2 years") %>%
  autoplot(us_gasoline) +
  labs(y = "Millions of barrels per day",
       title = "Weekly US gasoline production")
```

拟合模型有 6 对傅立叶项，可以写成:$y_t = bt + \sum_{j=1}^{6}    \left[      \alpha_j\sin\left(\frac{2\pi j t}{52.18}\right) +      \beta_j\cos\left(\frac{2\pi j t}{52.18}\right)    \right] +    \eta_t$

其中$\eta_t$是 ARIMA(0,1,1) 过程。 因为$\eta_t$是非平稳的，所以模型实际上是根据这个方程两边变量的差异来估计的。 有 12 个参数来捕捉季节性，而总自由度数为 14（另外两个来自 MA 参数和漂移参数）。

选择方法：

当季节性随时间变化时，STL 方法更可取。 

如果存在作为有用预测变量的协变量，则动态谐波回归方法更可取，因为这些变量可以作为额外的回归变量添加。

每日和次日数据：
每日和次日（例如每小时）数据由于不同的原因而具有挑战性——它们通常涉及多种季节性模式，因此我们需要使用一种方法来处理如此复杂的季节性。

当然，如果时间序列相对较短，以至于只存在一种季节性，那么可以使用我们在前几章中讨论过的单季节性方法之一（例如，ETS 或季节性 ARIMA 模型）  . 但是当时间序列足够长以至于某些较长的季节性周期变得明显时，就需要使用 STL、动态谐波回归或 Prophet，如上文所述。

然而，这些方法只允许有规律的季节性。 捕捉与复活节、身份证或农历新年等活动事件相关的季节性更加困难。 即使使用月度数据，这也可能很棘手，因为节日可能在 3 月或 4 月（复活节）、1 月或 2 月（农历新年）或一年中的任何时间（Id）。

处理移动假期效应的最佳方法是在模型中包含虚拟变量。 例如，**这可以在 ARIMA() 或 prophet() 函数中完成，但不能在 ETS() 中完成**。 事实上，prophet() 有一个特殊的holiday() 可以很容易地结合假日效果。

##### 计数的时间序列

本书中讨论的所有方法都假设数据具有连续的样本空间。 但数据通常以计数的形式出现。 例如，我们可能希望预测每天进入商店的顾客数量。 我们可以有 0 , 1 , 2 , ... 客户，但我们不能有 3.45693 个客户。

在实践中，只要我们的计数足够大，这很少有问题。 如果最小客户数至少为 100，那么连续样本空间 [ 100 , ∞ ) 和离散样本空间 { 100 , 101 , 102 , ... } 之间的差异对我们的预测没有明显影响。 但是，如果我们的数据包含小计数（ 0 , 1 , 2 , … ），那么我们需要使用更适合非负整数样本空间的预测方法。

 此类模型超出了本章的范围。 但是，有一种简单的方法可以在这种情况下使用，我们想提一下。 它是“克罗斯顿方法”，以其英国发明者约翰克罗斯顿的名字命名，并在克罗斯顿 (1972) 中首次描述。 其实这个方法也没有很好地处理数据的计数性质，但是它使用的太频繁了，值得了解一下。

使用 Croston 的方法，我们通过注意哪些时间段包含零值以及哪些时间段包含非零值，从原始时间序列构建两个新序列。 令$q_i$为第$i$个非零量，令$a_i$为$q_{i-1}$和 $q_i$之间的时间。  Croston 的方法涉及对两个新序列 a 和 q 进行单独的简单指数平滑预测。 因为该方法通常应用于物品需求的时间序列，所以 q 通常被称为“需求”和“到达间隔时间”。

如果$\hat{q}_{i+1|i}$和$\hat{a}_{i+1|i}$分别是第 (i + 1 ) 次需求和到达间隔时间的一步预测，基于直到需求 i 的数据，那么 Croston 的方法给出:

$\begin{align}  \hat{q}_{i+1|i} & = (1-\alpha_q)\hat{q}_{i|i-1} + \alpha_q q_i\\  \hat{a}_{i+1|i} & = (1-\alpha_a)\hat{a}_{i|i-1} + \alpha_a a_i.  \end{align}$

平滑参数$\alpha_a$和$\alpha_q$取值介于 0 和 1 之间。让 j 是最后观察到的正观察的时间。 那么在时间 T + h 时对需求的 h 步提前预测，由比率$\begin{equation}  \hat{y}_{T+h|T} = \hat{q}_{j+1|j}/\hat{a}_{j+1|j}. \end{equation}$给出

没有代数结果允许我们计算该方法的预测区间，因为该方法不对应于任何统计模型 (Shenstone & Hyndman, 2005)。

CROSTON() 函数使用 Croston 的方法生成预测。 两个平滑参数$\alpha_a$和$\alpha_q$是从数据中估计出来的。 这与克罗斯顿设想的方法不同。

##### 确保预测保持在限制范围内

通常希望预测为正值，或要求它们在某个指定范围 [a , b ] 内。 使用转换处理这两种情况都相对容易。

正向预测：

为了施加正面约束，我们可以简单地在对数尺度上工作。 例如，考虑一打鸡蛋的实际价格（1900-1993 年；以美分计）。 由于对数变换，预测分布被限制为保持正数，因此随着均值的降低，它们将逐渐变得更加偏斜。

```R
egg_prices <- prices %>% filter(!is.na(eggs))
egg_prices %>%
  model(ETS(log(eggs) ~ trend("A"))) %>%
  forecast(h = 50) %>%
  autoplot(egg_prices) +
  labs(title = "Annual egg prices",
       y = "$US (in cents adjusted for inflation) ")
```

预测受限于一个区间:

要了解如何处理受限于区间的数据，假设鸡蛋价格被限制在 a = 50 和 b = 400 之内。 然后我们可以使用缩放 logit 变换来变换数据，该变换将 ( a , b ) 映射到整条实线：$y = \log\left(\frac{x-a}{b-x}\right),$，其中 x 在原始尺度上，y 是变换后的数据。 为了反转变换，我们将使用$x  = \frac{(b-a)e^y}{1+e^y} + a.$。

这不是内置转换，因此我们需要首先设置转换函数。

```R
scaled_logit <- function(x, lower = 0, upper = 1) {
  log((x - lower) / (upper - x))
}
inv_scaled_logit <- function(x, lower = 0, upper = 1) {
  (upper - lower) * exp(x) / (1 + exp(x)) + lower
}
my_scaled_logit <- new_transformation(
                    scaled_logit, inv_scaled_logit)
egg_prices %>%
  model(
    ETS(my_scaled_logit(eggs, lower = 50, upper = 400)
          ~ trend("A"))
  ) %>%
  forecast(h = 50) %>%
  autoplot(egg_prices) +
  labs(title = "Annual egg prices",
       y = "$US (in cents adjusted for inflation) ")
```

此处会自动应用偏差调整，并且这些变换的预测区间具有与变换尺度上相同的覆盖概率，因为分位数在单调递增变换下得以保留。

由于转换，预测区间高于 50。 由于这种人为（且不切实际）的约束，预测分布变得极度偏斜。

##### 预测组合

提高预测准确性的一种简单方法是对同一时间序列使用几种不同的方法，并对结果预测进行平均。  50 多年前，John Bates 和 Clive Granger 撰写了一篇著名的论文（Bates & Granger，1969 年），表明组合预测通常会带来更好的预测准确性。 二十年后，Clemen (1989) 写道，结果几乎是一致的：结合多种预测可以提高预测准确性。 在许多情况下，只需对预测进行平均，就可以显着提高性能。

虽然已经有大量关于使用加权平均或其他一些更复杂的组合方法的研究，但使用简单的平均已经证明很难被击败。

例子：

```R
auscafe <- aus_retail %>%
  filter(stringr::str_detect(Industry, "Takeaway")) %>%
  summarise(Turnover = sum(Turnover))
train <- auscafe %>%
  filter(year(Month) <= 2013)
STLF <- decomposition_model(
  STL(log(Turnover) ~ season(window = Inf)),
  ETS(season_adjust ~ season("N"))
)
cafe_models <- train %>%
  model(
    ets = ETS(Turnover),
    stlf = STLF,
    arima = ARIMA(log(Turnover))
  ) %>%
  mutate(combination = (ets + stlf + arima) / 3)
cafe_fc <- cafe_models %>%
  forecast(h = "5 years")
```

请注意，我们通过简单地采用估计模型的线性函数在 mutate() 函数中形成了一个组合。 这种非常简单的语法将通过考虑所包含模型的预测误差之间的相关性自动适当地处理预测分布。

对区间的预测省略

##### 聚合的预测区间

一个常见的问题是使用适合分解数据的模型来预测多个时间段数据的聚合。 例如，我们可能有月度数据，但希望预测下一年的总数。 或者我们可能有每周数据，并希望预测接下来四个星期的总数。

如果点预测是均值，那么将它们相加可以很好地估计总数。 但是由于预测误差之间的相关性，预测区间更加棘手。

 一般的解决方案是使用模拟。 （例子见原书）

##### 倒推

有时“回溯”时间序列是有用的——即逆时预测。 尽管没有内置的 R 函数来执行此操作，但通过创建新的时间索引很容易实现。

##### 很长很短的时间序列

预测非常短的时间序列：

我们经常被问到可以使用多少数据点来拟合时间序列模型。 与几乎所有样本量问题一样，没有简单的答案。 它取决于要估计的模型参数的数量和数据中的随机性数量。 所需的样本大小随着要估计的参数数量和数据中的噪声量而增加。

 一些教科书提供了经验法则，给出了各种时间序列模型的最小样本量。 这些在理论或实践中具有误导性且未经证实。 此外，他们忽略了数据的潜在可变性，并且经常忽略要估计的参数数量。 例如，对于 ARIMA 建模通常给出的最小值 30 的幻数没有任何理由。 唯一的理论限制是我们需要比预测模型中的参数更多的观察。 然而，在实践中，我们通常需要比这更多的观察。

理想情况下，我们会测试我们选择的模型与一些更简单的方法相比是否在样本外表现良好。 然而，对于短序列，没有足够的数据允许为了测试目的而保留一些观察结果，甚至时间序列交叉验证也很难应用。  AICc 在这里特别有用，因为它是一步预测样本外 MSE 的代理。 选择具有最小 AICc 值的模型可以同时考虑参数数量和噪声量。

短序列往往发生的情况是 AICc 建议使用简单的模型，因为任何具有超过一两个参数的参数都会由于估计错误而产生较差的预测。 

预测很长的时间序列：

大多数时间序列模型不适用于很长的时间序列。 问题是真实数据并非来自我们使用的模型。 当观察的数量不是很大（比如大约 200）时，模型通常可以很好地作为生成数据的任何过程的近似值。 但最终我们将有足够的数据，真实过程和模型之间的差异开始变得更加明显。 另一个问题是参数的优化变得更加耗时，因为所涉及的观察次数较多。

如何处理这些问题取决于模型的目的。 可以使用更灵活和更复杂的模型，但这仍然假设模型结构将在整个数据周期内工作。 更好的方法通常是允许模型本身随时间变化。  **ETS 模型旨在通过允许趋势和季节性术语随时间演变来处理这种情况。 具有差分的 ARIMA 模型具有相似的属性。 但是动态回归模型不允许模型组件的任何演变**。

如果我们只对预测接下来的几次观察感兴趣，一种简单的方法是丢弃最早的观察结果，只对最近的观察结果拟合模型。 然后一个不灵活的模型可以很好地工作，因为没有足够的时间让关系发生实质性变化。

例如，我们将动态谐波回归模型拟合到 26 年的每周汽油产量。 假设季节性模式在近三年内保持不变可能是不现实的。 所以我们可以简单地将模型拟合到最近几年。

##### 预测训练集和测试集

通常，我们计算训练数据（“拟合值”）的一步预测和测试数据的多步预测。 然而，有时我们可能希望计算训练数据的多步预测，或测试数据的一步预测。

对训练数据的多步预测：

我们**通常将拟合值定义为对训练集的一步预测**，但类似的想法也可用于多步预测。 我们将说明使用 ARIMA 模型计算澳大利亚外卖食品支出的方法。 过去五年用于测试集，预测如图 13.9 所示。

```R
training <- auscafe %>% filter(year(Month) <= 2013)
test <- auscafe %>% filter(year(Month) > 2013)
cafe_fit <- training %>%
  model(ARIMA(log(Turnover)))
cafe_fit %>%
  forecast(h = 60) %>%
  autoplot(auscafe) +
  labs(title = "Australian food expenditure",
       y = "$ (billions)")
```

fitted() 函数有一个 h 参数，以允许在训练集上使用 h 步“拟合值”。 图 13.10 是对训练集的 12 步（一年）预测图。 由于该模型同时涉及季节性（滞后 12）和第一（滞后 1）差分，因此无法计算前几个观测值的这些预测。

```R
fits12 <- fitted(cafe_fit, h = 12)
training %>%
  autoplot(Turnover) +
  autolayer(fits12, .fitted, col = "#D55E00") +
  labs(title = "Australian food expenditure",
       y = "$ (billions)")
```

对测试数据的一步预测：

通常的做法是使用训练数据拟合模型，然后在测试数据集上评估其性能。 通常这样做的方式意味着对测试数据的比较使用不同的预测范围。 在上面的例子中，我们使用了测试数据的最后六十个观测值，并在训练数据上估计了我们的预测模型。 那么预测误差将是提前 1 步、2 步、……、60 步。 预测方差通常随着预测范围的增加而增加，因此**如果我们只是对测试集的绝对误差或平方误差进行平均，我们就是在将结果与不同的方差相结合**。

此问题的一种解决方案是在测试数据上获得 1 步错误。 也就是说，我们仍然使用训练数据来估计任何参数，但是当我们计算测试数据的预测时，我们使用每个观测之前的所有数据（训练和测试数据）。 所以我们的训练数据是时间 1, 2, … , T − 60 。 我们在这些数据上估计模型，然后计算$\hat{y}_{T-60+h|T-61+h}$，对于$h=1,\dots,T-1$。 因为没有使用测试数据来估计参数，所以这仍然给了我们一个“公平”的预测。

```R
cafe_fit %>%
  refit(test) %>%
  accuracy()
```

请注意，在这种情况下不会重新估计模型。 相反，先前获得的模型（并存储为 cafe_fit）将应用于测试数据。 因为模型没有重新估计，所以这里得到的“残差”实际上是一步预测误差。 因此，accuracy() 命令产生的结果实际上是在测试集上（尽管输出是“训练集”）。 **这种方法可用于比较来自不同模型的一步预测**。  

##### 处理异常值和缺失值

真实数据通常包含缺失值、异常观测值和其他杂乱的特征。 与他们打交道有时会很麻烦。

异常值:

异常值是与时间序列中的大多数观察结果非常不同的观察结果。 它们可能是错误，也可能只是不寻常。  （有关回归上下文中异常值的讨论，请参见第 7.3 节。）如果数据中存在极端异常值，我们在本书中考虑的任何方法都不会奏效。 在这种情况下，我们可能希望用缺失值或与大多数数据更一致的估计值来替换它们。

简单地替换异常值而不考虑它们发生的原因是一种危险的做法。 它们可能提供有关产生数据的过程的有用信息，在预测时应予以考虑。 但是，如果我们愿意假设异常值确实是错误，或者它们不会在预测期内发生，那么替换它们可以使预测任务更容易。

图 13.11 显示了南澳大利亚阿德莱德山地区的游客人数。  2002 年第四季度似乎有一个不寻常的观察结果。

```R
tourism %>%
  filter(
    Region == "Adelaide Hills", Purpose == "Visiting"
  ) %>%
  autoplot(Trips) +
  labs(title = "Quarterly overnight trips to Adelaide Hills",
       y = "Number of trips")
```

查找异常值的一种有用方法是将 STL() 应用于参数为robust=TRUE 的系列。 然后任何异常值都应该出现在剩余系列中。 图 13.11 中的数据几乎没有明显的季节性，因此我们将通过设置 period=1 来应用没有季节性成分的 STL。

```R
ah_decomp <- tourism %>%
  filter(
    Region == "Adelaide Hills", Purpose == "Visiting"
  ) %>%
  # Fit a non-seasonal STL decomposition
  model(
    stl = STL(Trips ~ season(period = 1), robust = TRUE)
  ) %>%
  components()
ah_decomp %>% autoplot()
```

在上面的例子中，异常值很容易识别。 在更具挑战性的情况下，使用剩余系列的箱线图会很有用。 我们可以从数据的中心 50% 中识别出大于 1.5 四分位距 (IQR) 的异常值。 如果余数呈正态分布，则每 1000 个观测值中将显示 7 个为“异常值”。 **更严格的规则是将离群值定义为距离中心 50% 的数据大于 3 个四分位距 (IQR) 的离群值**，这将使 500,000 个正态分布观测值中只有 1 个为离群值。 这是我们更喜欢使用的规则。

```R
outliers <- ah_decomp %>%
  filter(
    remainder < quantile(remainder, 0.25) - 3*IQR(remainder) |
    remainder > quantile(remainder, 0.75) + 3*IQR(remainder)
  )
outliers
```

这找到了我们从图 13.11 中怀疑的一个异常值。 类似的东西可以应用于完整数据集，以识别其他系列中的异常观察。

缺失值:

数据缺失的原因有很多，值得考虑的是，缺失是否会导致预测模型出现偏差。 例如，假设我们正在研究一家商店的销售数据，当商店关门时，公共假期会出现缺失值。 结果，第二天的销售额可能会增加。 如果我们的预测模型没有考虑到这一点，我们很可能会低估公众假期后第一天的销售额，但高估之后几天的销售额。 处理这种情况的一种方法是使用动态回归模型，其中虚拟变量指示当天是公共假期还是公共假期后的第二天。 没有自动化方法可以处理这种影响，因为它们取决于特定的预测环境。

在其他情况下，缺失可能本质上是随机的。 例如，有人可能忘记记录销售数字，或者数据记录设备可能出现故障。 如果缺失数据的时间不能为预测问题提供信息，则可以更轻松地处理缺失值。

最后，我们可能会删除一些不寻常的观察结果，从而在系列中创建缺失值。

有些方法允许缺失值没有任何问题。 例如，朴素预测方法继续有效，最近的非缺失值提供对未来时间段的预测。 同样，当历史数据中存在缺失值时，第 5.2 节中介绍的其他基准方法都会产生预测。  **ARIMA 模型、动态回归模型和 NNAR 模型等fable函数也将正常工作而不会导致错误**。 但是，其他建模函数不处理缺失值，包括 ETS() 和 STL()。

 当缺失值导致错误时，至少有两种方法可以处理该问题。 首先，**假设有足够长的观察序列来产生有意义的预测，我们可以只取最后一个缺失值之后的数据部分。 或者，我们可以通过首先拟合 ARIMA 模型，然后使用该模型对缺失的观测值进行插值来用估计值替换缺失值**。

我们将用 ARIMA 模型的估计替换图 13.12 中识别的异常值。

```R
ah_miss <- tourism %>%
  filter(
    Region == "Adelaide Hills",
    Purpose == "Visiting"
  ) %>%
  # Remove outlying observations
  anti_join(outliers) %>%
  # Replace with missing values
  fill_gaps()
ah_fill <- ah_miss %>%
  # Fit ARIMA model to the data containing missing values
  model(ARIMA(Trips)) %>%
  # Estimate Trips for all periods
  interpolate(ah_miss)
ah_fill %>%
  # Only show outlying periods
  right_join(outliers %>% select(-Trips))
```

interpolate() 函数使用 ARIMA 模型来估计序列中的任何缺失值。 现在可以使用不允许缺失值的函数对 ah_fill 数据进行建模。

```R
ah_fill %>%
  autoplot(Trips) +
  autolayer(ah_fill %>% filter_index("2002 Q3"~"2003 Q1"),
    Trips, colour="#D55E00") +
  labs(title = "Quarterly overnight trips to Adelaide Hills",
       y = "Number of trips")
```

## 附录A:分类回归集成包caret

### caret包简短介绍

caret 包（Classification And REgression Training 的缩写）包含简化复杂回归和分类问题的模型训练过程的功能。 该包使用了许多 R 包，但尽量不在包启动时加载它们（通过删除正式的包依赖项，包启动时间可以大大减少）。 包“建议”字段包括 32 个包。 插入符号根据需要加载包并假定它们已安装。 如果缺少建模包，则会提示安装。

安装caret使用

```R
install.packages("caret", dependencies = c("Depends", "Suggests"))
```

以确保安装了所有需要的软件包。

该包的主要帮助页面位于 https://topepo.github.io/caret/ 此处，有扩展示例和先前在包小插图中找到的大量信息。

 caret 有几个函数试图简化模型构建和评估过程，以及特征选择和其他技术。包中的主要工具之一是 train 函数，它可用于:

* 评估模型调整参数对性能的影响
* 使用重采样从这些参数中选择“最佳”模型
* 从训练集中估计模型性能

几乎可以自定义此过程的每个步骤（例如重采样技术、选择最佳参数等）。 为了演示此功能，将使用 mlbench 包中的声纳数据。

声纳数据由在 60 个预测器上收集的 208 个数据点组成。 目标是预测金属圆柱体的 M 类或岩石的 R 类）。

首先，我们将数据分成两组：训练集和测试集。 为此，使用 createDataPartition 函数： 

```R
library(caret)
library(mlbench)
data(Sonar)

set.seed(107)
inTrain <- createDataPartition(
  y = Sonar$Class,
  ## the outcome data are needed
  p = .75,
  ## The percentage of data in the
  ## training set
  list = FALSE
)
## The format of the results

## The output is a set of integers for the rows of Sonar
## that belong in the training set.
str(inTrain)
```

默认情况下，createDataPartition 对数据进行分层随机拆分。 对数据进行分区：

```R
training <- Sonar[ inTrain,]
testing  <- Sonar[-inTrain,]

nrow(training)
#> [1] 157
nrow(testing)
#> [1] 51
```

要使用上述算法调整模型，可以使用 train 函数。 有关此功能的更多详细信息，请访问 https://topepo.github.io/caret/model-training-and-tuning.html。 在这里，偏最小二乘判别分析 (PLSDA) 模型将在应保留的 PLS 组件数量上进行调整。 执行此操作的最基本语法是：

```R
plsFit <- train(
  Class ~ .,
  data = training,
  method = "pls", ## 偏最小二乘判别分析
  ## 将训练集和所有未来样本的预测变量居中并进行缩放。
  preProc = c("center", "scale")
)
```

但是，我们可能希望通过几种方式对其进行自定义：

* 扩展函数评估的 PLS 模型集。 默认情况下，该函数将调整每个调整参数的三个值。
* 使用的重采样类型。 默认情况下使用简单的引导程序。 我们将让函数使用 10 倍交叉验证的 3 次重复。
* 衡量绩效的方法。 如果未指定，则计算总体准确度和 Kappa 统计量。 对于回归模型，计算均方根误差和 $R^2$。 在这里，函数将被更改以估计 ROC 曲线下的面积、敏感性和特异性

要更改调整参数的候选值，可以使用 tuneLength 或 tuneGrid 参数。  train 函数可以生成一组候选参数值，tuneLength 参数**控制要评估的参数值**。 在 PLS 的情况下，该函数使用从 1 到 tuneLength 的整数序列。 如果我们想计算 1 到 15 之间的所有整数，设置 tuneLength = 15 可以实现这一点。 当需要特定值时使用 tuneGrid 参数。 使用数据框，其中每行是一个调整参数设置，每列是一个调整参数。 下面用一个例子来说明这一点。

```R
plsFit <- train(
  Class ~ .,
  data = training,
  method = "pls",
  preProc = c("center", "scale"),
  ## added:
  tuneLength = 15
)
```

为了修改重采样方法，使用了 trainControl 函数。  option 方法控制重采样的类型，默认为“boot”。 另一种方法“repeatedcv”用于指定重复的 K 折交叉验证（并且参数 repeats 控制重复次数）。  K 由 number 参数控制，默认为 10。新的语法是：

```R
ctrl <- trainControl(method = "repeatedcv", repeats = 3)
## traubControl控制重采样的方式

plsFit <- train(
  Class ~ .,
  data = training,
  method = "pls",
  preProc = c("center", "scale"),
  tuneLength = 15,
  ## added:
  trControl = ctrl
)
```

最后，为了选择不同的性能度量，trainControl 提供了额外的参数。  summaryFunction 参数用于传入一个函数，该函数采用观察值和预测值并估计一些性能度量。 包中已包含两个这样的函数：defaultSummary 和 twoClassSummary。 后者将计算特定于两类问题的度量，例如 ROC 曲线下的面积、敏感性和特异性。 由于 ROC 曲线基于预测的类别概率（不会自动计算），因此需要另一个选项。  classProbs = TRUE 选项用于包括这些计算。

最后，该函数将选择与最佳结果相关的调整参数。 由于我们使用自定义性能度量，因此还必须指定应该优化的标准。 在训练调用中，我们可以使用 metric = "ROC" 来做到这一点。

```R
ctrl <- trainControl(
  method = "repeatedcv", 
  repeats = 3,
  classProbs = TRUE, 
  summaryFunction = twoClassSummary
)

set.seed(123)
plsFit <- train(
  Class ~ .,
  data = training,
  method = "pls",
  preProc = c("center", "scale"),
  tuneLength = 15,
  trControl = ctrl,
  metric = "ROC"
)
plsFit
#> Partial Least Squares 
#> 
#> 157 samples
#>  60 predictor
#>   2 classes: 'M', 'R' 
#> 
#> Pre-processing: centered (60), scaled (60) 
#> Resampling: Cross-Validated (10 fold, repeated 3 times) 
#> Summary of sample sizes: 141, 141, 142, 142, 141, 142, ... 
#> Resampling results across tuning parameters:
#> 
#>   ncomp  ROC    Sens   Spec 
#>    1     0.805  0.726  0.690
#>    2     0.848  0.750  0.801
#>    3     0.849  0.764  0.748
#>    4     0.836  0.765  0.736
#>    5     0.812  0.748  0.755
#>    6     0.789  0.724  0.699
#>    7     0.794  0.744  0.689
#>    8     0.801  0.739  0.698
#>    9     0.793  0.758  0.677
#>   10     0.790  0.741  0.690
#>   11     0.787  0.742  0.710
#>   12     0.777  0.737  0.715
#>   13     0.772  0.738  0.700
#>   14     0.768  0.718  0.690
#>   15     0.768  0.715  0.690
#> 
#> ROC was used to select the optimal model using
#>  the largest value.
#> The final value used for the model was ncomp = 3.
```

在此输出中，结果网格是对性能的平均重采样估计。 底部的注释告诉用户发现 3 个 PLS 组件是最佳的。 基于此值，最终的 PLS 模型使用此规范拟合整个数据集，这是用于预测未来样本的模型。

该包具有多个用于可视化结果的功能。 这样做的一种方法是训练对象的 ggplot 函数。 命令 ggplot(plsFit) 产生了如图所示的结果，并显示了重新采样的性能值与 PLS 组件数量之间的关系。

```R
ggplot(plsFit)
```

要预测新样本，可以使用 predict.train。 对于分类模型，默认行为是计算预测类。 选项 type = "prob" 可用于从模型计算类概率。 例如：

```R
plsClasses <- predict(plsFit, newdata = testing)
str(plsClasses)
#>  Factor w/ 2 levels "M","R": 2 1 1 1 2 2 1 2 2 2 ...
plsProbs <- predict(plsFit, newdata = testing, type = "prob")
head(plsProbs)
#>        M     R
#> 6  0.288 0.712
#> 8  0.648 0.352
#> 9  0.659 0.341
#> 15 0.529 0.471
#> 26 0.430 0.570
#> 27 0.492 0.508
```

caret 包含一个函数来计算模型拟合的混淆矩阵和相关统计数据：

```R
confusionMatrix(data = plsClasses, testing$Class)
#> Confusion Matrix and Statistics
#> 
#>           Reference
#> Prediction  M  R
#>          M 21  7
#>          R  6 17
#>                                         
#>                Accuracy : 0.745         
#>                  95% CI : (0.604, 0.857)
#>     No Information Rate : 0.529         
#>     P-Value [Acc > NIR] : 0.00131       
#>                                         
#>                   Kappa : 0.487         
#>                                         
#>  Mcnemar's Test P-Value : 1.00000       
#>                                         
#>             Sensitivity : 0.778         
#>             Specificity : 0.708         
#>          Pos Pred Value : 0.750         
#>          Neg Pred Value : 0.739         
#>              Prevalence : 0.529         
#>          Detection Rate : 0.412         
#>    Detection Prevalence : 0.549         
#>       Balanced Accuracy : 0.743         
#>                                         
#>        'Positive' Class : M             
#> 
```

为了将另一个模型拟合到数据中，可以通过最少的更改调用 train。 可用模型列表可以在 https://topepo.github.io/caret/available-models.html 或 https://topepo.github.io/caret/train-models-by-tag.html 找到。 例如，要为这些数据拟合正则化判别模型，可以使用以下语法：

```R
## To illustrate, a custom grid is used
rdaGrid = data.frame(gamma = (0:4)/4, lambda = 3/4)
set.seed(123)
rdaFit <- train(
  Class ~ .,
  data = training,
  method = "rda",
  tuneGrid = rdaGrid,
  trControl = ctrl,
  metric = "ROC"
)
rdaFit
#> Regularized Discriminant Analysis 
#> 
#> 157 samples
#>  60 predictor
#>   2 classes: 'M', 'R' 
#> 
#> No pre-processing
#> Resampling: Cross-Validated (10 fold, repeated 3 times) 
#> Summary of sample sizes: 141, 141, 142, 142, 141, 142, ... 
#> Resampling results across tuning parameters:
#> 
#>   gamma  ROC    Sens   Spec 
#>   0.00   0.778  0.723  0.682
#>   0.25   0.887  0.864  0.786
#>   0.50   0.876  0.851  0.730
#>   0.75   0.863  0.830  0.710
#>   1.00   0.734  0.680  0.636
#> 
#> Tuning parameter 'lambda' was held constant at a
#>  value of 0.75
#> ROC was used to select the optimal model using
#>  the largest value.
#> The final values used for the model were gamma =
#>  0.25 and lambda = 0.75.
rdaClasses <- predict(rdaFit, newdata = testing)
confusionMatrix(rdaClasses, testing$Class)
#> Confusion Matrix and Statistics
#> 
#>           Reference
#> Prediction  M  R
#>          M 25  5
#>          R  2 19
#>                                         
#>                Accuracy : 0.863         
#>                  95% CI : (0.737, 0.943)
#>     No Information Rate : 0.529         
#>     P-Value [Acc > NIR] : 5.01e-07      
#>                                         
#>                   Kappa : 0.723         
#>                                         
#>  Mcnemar's Test P-Value : 0.45          
#>                                         
#>             Sensitivity : 0.926         
#>             Specificity : 0.792         
#>          Pos Pred Value : 0.833         
#>          Neg Pred Value : 0.905         
#>              Prevalence : 0.529         
#>          Detection Rate : 0.490         
#>    Detection Prevalence : 0.588         
#>       Balanced Accuracy : 0.859         
#>                                         
#>        'Positive' Class : M             
#> 
```

这些模型在重采样结果方面如何比较？  resamples 函数可用于收集、汇总和对比重采样结果。 由于随机数种子在调用 `train} 之前被初始化为相同的值，因此每个模型使用相同的折叠。 组装它们：

```R
resamps <- resamples(list(pls = plsFit, rda = rdaFit))
summary(resamps)
#> 
#> Call:
#> summary.resamples(object = resamps)
#> 
#> Models: pls, rda 
#> Number of resamples: 30 
#> 
#> ROC 
#>      Min. 1st Qu. Median  Mean 3rd Qu.  Max. NA's
#> pls 0.679   0.787  0.823 0.849   0.938 0.984    0
#> rda 0.750   0.847  0.889 0.887   0.940 1.000    0
#> 
#> Sens 
#>      Min. 1st Qu. Median  Mean 3rd Qu. Max. NA's
#> pls 0.556   0.625  0.750 0.764   0.875    1    0
#> rda 0.625   0.757  0.875 0.864   1.000    1    0
#> 
#> Spec 
#>      Min. 1st Qu. Median  Mean 3rd Qu. Max. NA's
#> pls 0.429   0.714  0.714 0.748   0.857    1    0
#> rda 0.500   0.714  0.750 0.786   0.875    1    0
```

有几个函数可以将这些结果可视化。 例如，可以使用以下方法创建 Bland-Altman 类型的图:

```R
xyplot(resamps, what = "BlandAltman")
```

结果看起来很相似。 由于对于每个重采样都有成对的结果，因此可以使用配对 t 检验来评估 ROC 曲线下的平均重采样面积是否存在差异。  diff.resamples 函数可用于计算：

```R
diffs <- diff(resamps)
summary(diffs)
#> 
#> Call:
#> summary.diff.resamples(object = diffs)
#> 
#> p-value adjustment: bonferroni 
#> Upper diagonal: estimates of the difference
#> Lower diagonal: p-value for H0: difference = 0
#> 
#> ROC 
#>     pls      rda    
#> pls          -0.0378
#> rda 0.000544        
#> 
#> Sens 
#>     pls      rda 
#> pls          -0.1
#> rda 0.000172     
#> 
#> Spec 
#>     pls   rda    
#> pls       -0.0387
#> rda 0.136
```

结果看起来很相似。由于每次重采样都有配对结果，因此可以使用配对t检验来评估ROC曲线下的平均重采样面积是否存在差异。diff.resamples函数可用于计算：

```R
diffs <- diff(resamps)
summary(diffs)
#> 
#> Call:
#> summary.diff.resamples(object = diffs)
#> 
#> p-value adjustment: bonferroni 
#> Upper diagonal: estimates of the difference
#> Lower diagonal: p-value for H0: difference = 0
#> 
#> ROC 
#>     pls      rda    
#> pls          -0.0378
#> rda 0.000544        
#> 
#> Sens 
#>     pls      rda 
#> pls          -0.1
#> rda 0.000172     
#> 
#> Spec 
#>     pls   rda    
#> pls       -0.0387
#> rda 0.136
```

根据该分析，模型之间的差异为-0.038 ROC单位（RDA模型略高），该差异的双侧p值为5e-04。

### 预处理

#### 零和近零方差预测变量

在某些情况下，数据生成机制可以创建只有一个唯一值的预测变量（即“零方差预测变量”）。 对于许多模型（不包括基于树的模型），这可能会导致模型崩溃或拟合不稳定。

同样，预测变量可能只有少数出现频率非常低的唯一值。 例如，在耐药性数据中，nR11 描述符（11 元环的数量）数据有几个非常不平衡的独特数值：

```R
data(mdrr)
data.frame(table(mdrrDescr$nR11))
##   Var1 Freq
## 1    0  501
## 2    1    4
## 3    2   23
```

当数据被分成交叉验证/引导子样本或少数样本可能对模型产生不当影响时，这些预测变量可能会成为零方差预测变量。 在建模之前，**可能需要识别和消除这些“接近零方差”的预测变量**。

为了识别这些类型的预测变量，可以计算以下两个指标： 

* 最普遍的值在第二个最频繁的值上的频率（称为“频率比”），对于表现良好的预测变量，该频率接近 1，对于高度不平衡的数据
* “唯一值的百分比”非常大 是唯一值的数量除以随着数据粒度增加而接近零的样本总数（乘以 100） 

**如果频率比大于预先指定的阈值并且唯一值百分比小于阈值， 我们可能会认为预测变量接近零方差。**

我们不想错误地识别具有低粒度但均匀分布的数据，例如来自离散均匀分布的数据。 使用这两个标准不会错误地检测到此类预测因子。

查看 MDRR 数据，nearZeroVar 函数可用于识别接近零方差的变量(saveMetrics 参数可用于显示详细信息，通常默认为 FALSE)

```R
nzv <- nearZeroVar(mdrrDescr, saveMetrics= TRUE)
nzv[nzv$nzv,][1:10,]

dim(mdrrDescr)
## 除去近零方差预测变量
nzv <- nearZeroVar(mdrrDescr)
filteredDescr <- mdrrDescr[, -nzv]
dim(filteredDescr)
```

默认情况下，nearZeroVar 将返回标记为有问题的变量的位置。

#### 识别相关预测变量

虽然有一些模型在相关预测变量（例如 pls）上茁壮成长，但其他模型可能会受益于降低预测变量之间的相关性水平。

 给定一个相关矩阵，findCorrelation 函数使用以下算法来标记要移除的预测变量：

```R
descrCor <-  cor(filteredDescr)
highCorr <- sum(abs(descrCor[upper.tri(descrCor)]) > .999)
```

对于之前的 MDRR 数据，有 65 个描述符几乎完全相关（|correlation| > 0.999），例如原子组成的总信息指数（IAC）和总信息含量指数（0阶邻域对称性）（  TIC0)（相关性 = 1）。 下面的代码块显示了删除绝对相关性高于 0.75 的描述符的效果。

```R
descrCor <- cor(filteredDescr)
summary(descrCor[upper.tri(descrCor)])
##删去高相关
highlyCorDescr <- findCorrelation(descrCor, cutoff = .75)
filteredDescr <- filteredDescr[,-highlyCorDescr]
descrCor2 <- cor(filteredDescr)
summary(descrCor2[upper.tri(descrCor2)])
```

#### 线性依赖

函数 findLinearCombos 使用矩阵的 QR 分解来枚举线性组合集（如果存在）。 例如，考虑以下矩阵，它可能由双向实验布局的非满秩参数化产生：

```R
ltfrDesign <- matrix(0, nrow=6, ncol=6)
ltfrDesign[,1] <- c(1, 1, 1, 1, 1, 1)
ltfrDesign[,2] <- c(1, 1, 1, 0, 0, 0)
ltfrDesign[,3] <- c(0, 0, 0, 1, 1, 1)
ltfrDesign[,4] <- c(1, 0, 0, 1, 0, 0)
ltfrDesign[,5] <- c(0, 1, 0, 0, 1, 0)
ltfrDesign[,6] <- c(0, 0, 1, 0, 0, 1)
```

请注意，第二列和第三列加起来就是第一列。 同样，第四列、第五列和第六列加起来就是第一列。  findLinearCombos 将返回一个枚举这些依赖项的列表。 对于每个线性组合，它将从矩阵中逐步删除列并测试是否已解决依赖关系。  findLinearCombos 还将返回一个列位置向量，可以删除列位置以消除线性依赖关系：

```R
comboInfo <- findLinearCombos(ltfrDesign)
comboInfo

## $linearCombos
## $linearCombos[[1]]
## [1] 3 1 2
## 
## $linearCombos[[2]]
## [1] 6 1 4 5
## 
## 
## $remove
## [1] 3 6

ltfrDesign[, -comboInfo$remove]
```

当使用大量二元化学指纹来描述分子结构时，可能会出现这些类型的依赖性。

#### preProcess函数

preProcess 类可用于预测变量的许多操作，包括居中和缩放。 函数 preProcess 估计每个操作所需的参数，predict.preProcess 用于将它们应用于特定的数据集。 这个函数也可以是调用train函数时的接口。
    在接下来的几节中描述了几种类型的技术，然后使用另一个示例来演示如何使用多种方法。 请注意，在所有情况下，preProcess 函数都会从特定数据集（例如训练集）中**估计它需要的任何内容，然后将这些转换应用于任何数据集，而无需重新计算值**

#### 居中和缩放

在下面的示例中，MDRR 数据的一半用于估计预测变量的位置和规模。 函数 preProcess 实际上并不预处理数据。  predict.preProcess 用于**预处理此数据集和其他数据集**。

```R
set.seed(96)
inTrain <- sample(seq(along = mdrrClass), length(mdrrClass)/2)

training <- filteredDescr[inTrain,]
test <- filteredDescr[-inTrain,]
trainMDRR <- mdrrClass[inTrain]
testMDRR <- mdrrClass[-inTrain]

preProcValues <- preProcess(training, method = c("center", "scale"))

trainTransformed <- predict(preProcValues, training)
testTransformed <- predict(preProcValues, test)
```

预处理选项“scale”将数据缩放到零和一之间的区间。

#### 插补

preProcess 可用于仅根据训练集中的信息来估算数据集。 这样做的一种方法是使用 **K 最近邻**。 对于任意样本，在训练集中找到 K 个最近邻，并使用这些值（例如使用平均值）估算预测器的值。 无论method参数中的内容如何，使用这种方法都会自动触发 preProcess 来居中和缩放数据。 或者，**袋装树也可用于插补**。 对于数据中的每个预测变量，使用训练集中的所有其他预测变量创建一个袋装树。 当新样本具有缺失的预测值时，使用袋装模型来预测该值。 虽然理论上这是一种更强大的插补方法，但计算成本远高于最近邻技术。

#### 转换预测变量

在某些情况下，需要使用主成分分析 (PCA) 将数据转换为较小的子空间，其中新变量彼此不相关。  preProcess 类可以通过在方法参数中包含“pca”来应用此转换。 这样做也会强制缩放预测变量。 请注意，当请求 PCA 时，predict.preProcess 会将列名称更改为 PC1、PC2 等。

类似地，独立分量分析 (ICA) 也可用于查找新变量，这些变量是原始集合的线性组合，因此分量是独立的（而不是 PCA 中的不相关）。 新变量将被标记为 IC1、IC2 等。

“空间符号”转换（Serneels 等人，2006 年）将预测变量的数据投影到 p 维的单位圆，其中 p 是预测变量的数量。 本质上，数据向量除以其范数。 在应用此转换之前，应将预测变量居中并按比例缩放。

```R
library(AppliedPredictiveModeling)
transparentTheme(trans = .4)

plotSubset <- data.frame(scale(mdrrDescr[, c("nC", "X4v")])) 
xyplot(nC ~ X4v,
       data = plotSubset,
       groups = mdrrClass, 
       auto.key = list(columns = 2))  
```

在空间符号之后：

```R
transformed <- spatialSign(plotSubset)
transformed <- as.data.frame(transformed)
xyplot(nC ~ X4v, 
       data = transformed, 
       groups = mdrrClass, 
       auto.key = list(columns = 2)) 
```

如果数据大于零，另一个选项“BoxCox”将估计预测变量上的 Box-Cox 变换。

```R
preProcValues2 <- preProcess(training, method = "BoxCox")
trainBC <- predict(preProcValues2, training)
testBC <- predict(preProcValues2, test)
preProcValues2
```

NA 值对应于无法转换的预测变量。 此转换要求数据大于零。 两个类似的变换，Manly (1976) 的 Yeo-Johnson 和指数变换也可以用于 preProcess。

#### 放一起

在应用预测建模中有一个案例研究，其中预测了高性能计算环境中作业的执行时间。 数据是：

```R
library(AppliedPredictiveModeling)
data(schedulingData)
str(schedulingData)
```

数据是分类和数字预测变量的混合。 假设我们想对连续预测变量使用 Yeo-Johnson 变换，然后将它们居中并进行缩放。 **我们还假设我们将运行一个基于树的模型，因此我们可能希望将因子保留为因子（而不是创建虚拟变量）**。 我们在除最后一列之外的所有列上运行该函数，这是结果。

```R
pp_hpc <- preProcess(schedulingData[, -8], 
                     method = c("center", "scale", "YeoJohnson"))
pp_hpc

## Created from 4331 samples and 7 variables
## 
## Pre-processing:
##   - centered (5)
##   - ignored (2)
##   - scaled (5)
##   - Yeo-Johnson transformation (5)
## 
## Lambda estimates for Yeo-Johnson transformation:
## -0.08, -0.03, -1.05, -1.1, 1.44

transformed <- predict(pp_hpc, newdata = schedulingData[, -8])
head(transformed)

##   Protocol  Compounds InputFields Iterations NumPending         Hour Day
## 1        E  1.2289592  -0.6324580 -0.0615593  -0.554123  0.004586516 Tue
## 2        E -0.6065826  -0.8120473 -0.0615593  -0.554123 -0.043733201 Tue
## 3        E -0.5719534  -1.0131504 -2.7894869  -0.554123 -0.034967177 Thu
## 4        E -0.6427737  -1.0047277 -0.0615593  -0.554123 -0.964170752 Fri
## 5        E -0.5804713  -0.9564504 -0.0615593  -0.554123 -0.902085020 Fri
## 6        E -0.5804713  -0.9564504 -0.0615593  -0.554123  0.698108782 Wed
```

输出中标记为“已忽略”的两个预测变量是两个因子预测变量。 这些没有改变，但数字预测变量被转换。 但是，待处理作业数量的预测变量具有非常稀疏且不平衡的分布：

```
mean(schedulingData$NumPending == 0)
## [1] 0.7561764
```

对于其他一些模型，这可能是一个问题（特别是如果我们重新采样或下采样数据）。 在运行预处理计算之前，我们可以添加一个过滤器来检查零方差或接近零方差的预测变量：

```R
pp_no_nzv <- preProcess(schedulingData[, -8], 
                        method = c("center", "scale", "YeoJohnson", "nzv"))
pp_no_nzv
##结果：
## Created from 4331 samples and 7 variables
## 
## Pre-processing:
##   - centered (4)
##   - ignored (2)
##   - removed (1)
##   - scaled (4)
##   - Yeo-Johnson transformation (4)
## 
## Lambda estimates for Yeo-Johnson transformation:
## -0.08, -0.03, -1.05, 1.44

predict(pp_no_nzv, newdata = schedulingData[1:6, -8])
```

请注意，一个预测变量被标记为“已删除”，并且处理后的数据缺少稀疏预测变量。

#### 类别距离计算

caret 包含根据到类质心的距离生成新的预测变量的函数（类似于线性判别分析的工作原理）。 对于因子变量的每个级别，计算类质心和协方差矩阵。 对于新样本，计算到每个类质心的马哈拉诺比斯距离，**并可用作额外的预测变量。 当真正的决策边界实际上是线性的时，这对非线性模型很有帮助**。

如果类中的预测变量多于样本，则 classDist 函数具有称为 pca 的参数，并保留允许使用每个类中的主成分分析的参数，以避免奇异协方差矩阵的问题。

 然后使用 predict.classDist 生成类距离。 默认情况下，会记录距离，但这可以通过 predict.classDist 的 trans 参数进行更改。

例如，我们可以使用 MDRR 数据。

```R
centroids <- classDist(trainBC, trainMDRR)
distances <- predict(centroids, testBC)
distances <- as.data.frame(distances)
head(distances)

##                dist.Active dist.Inactive
## ACEPROMAZINE      3.787139      3.941234
## ACEPROMETAZINE    4.306137      3.992772
## MESORIDAZINE      3.707296      4.324115
## PERIMETAZINE      4.079938      4.117170
## PROPERICIAZINE    4.174101      4.430957
## DUOPERONE         4.355328      6.000025
```

此图显示了保留样本的类距离的散点图矩阵：

```R
xyplot(dist.Active ~ dist.Inactive,
       data = distances, 
       groups = testMDRR, 
       auto.key = list(columns = 2))
```

![img](https://topepo.github.io/caret/preprocess/pp_splom-1.svg)

#### 补充：preProcess的细节

在所有情况下，使用 x 中的数据估计转换和操作，并使用这些值将这些操作应用于新数据； 使用 predict 函数时**不会重新计算任何内容**。

Box-Cox (method = "BoxCox")、Yeo-Johnson (method = "YeoJohnson") 和指数变换 (method = "expoTrans") 在这里被“重新利用”：它们被用来转换预测变量。  Box-Cox 变换是为变换响应变量而开发的，而另一种方法 Box-Tidwell 变换是用于估计预测变量数据的变换。 然而，Box-Cox 方法更简单，计算效率更高，并且对于估计幂变换同样有效。  Yeo-Johnson 变换类似于 Box-Cox 模型，但可以容纳具有零和/或负值的预测变量（而 Box-Cox 变换的预测变量值必须严格为正）。  Manly (1976) 的指数变换也可用于正数据或负数据。

method = "center" 从预测变量值中减去预测变量数据的平均值（再次从 x 中的数据），而 method = "scale" 除以标准偏差。

“范围”转换将数据缩放到范围边界内。 如果新样本的值大于或小于训练集中的值，则值将超出此范围。

在计算中忽略非数字的预测变量（包括方法“zv'”和“nzv'”）。

method = "zv" 标识具有单个值（即具有零方差）的数字预测器列，并将它们从进一步的计算中排除。 类似地，method = "nzv" 通过应用 nearZeroVar 排除“接近零方差”预测变量来执行相同的操作。 选项 freqCut 和 uniqueCut 可用于修改过滤器。

method = "corr" 试图过滤掉高度相关的预测变量。 请参阅查找相关性。

对于分类，method = "conditionalX" 检查以结果为条件的每个预测变量的分布。 如果任何类别中只有一个唯一值，则预测变量将被排除在进一步的计算之外（请参阅 checkConditionalX 示例）。 当结果不是一个因素时，不执行此计算。 当在通过train重采样时使用此操作可能会很耗时。

这些操作按以下顺序应用：零方差滤波器、近零方差滤波器、相关滤波器、Box-Cox/Yeo-Johnson/指数变换、居中、缩放、范围、插补、PCA、ICA 然后是空间符号。 这与 4.76 版之前的插入符号版本（首先进行插补）不同，如果使用装袋进行插补，则不向后兼容。

如果请求 PCA 但没有居中和缩放，则值仍将居中和缩放。 同样，当请求 ICA 时，数据会自动居中和缩放。

k-最近邻插补是通过在训练集中找到k个最近的样本（欧几里得距离）来进行的。 通过装袋进行的插补适合每个预测器的装袋树模型（作为所有其他预测器的函数）。 这种方法简单、准确并且可以接受缺失值，但计算成本要高得多。 通过中位数进行插补采用训练集中每个预测变量的中位数，并使用它们来填充缺失值。 这种方法简单、快速并且接受缺失值，但独立处理每个预测变量，并且可能不准确。

如果同时请求 PCA 和 ICA，则会引发警告。 由 fastICA 包实现的 ICA 在找到 ICA 分数之前自动进行 PCA 分解。

除非调用 method = "zv" 或 method = "nzv"，否则该函数将抛出 x 中任何数值变量少于两个唯一值的错误。

非数字数据不会被预处理，它们的值将在预测函数生成的数据框中。 请注意，当使用 PCA 或 ICA 时，非数字列在预测时可能处于不同的位置。

### 数据拆分

#### 基于结果的简单拆分

函数 createDataPartition 可用于创建数据的平衡拆分。 如果此函数的 y 参数是一个因子，则**随机抽样发生在每个类中，并应保留数据的整体类分布**。 例如，要创建虹膜数据的单个 80/20% 拆分：

```R
library(caret)
set.seed(3456)
trainIndex <- createDataPartition(iris$Species, p = .8, 
                                  list = FALSE, 
                                  times = 1)
head(trainIndex)
##      Resample1
## [1,]         1
## [2,]         2
## [3,]         3
## [4,]         5
## [5,]         6
## [6,]         7

irisTrain <- iris[ trainIndex,]
irisTest  <- iris[-trainIndex,]
```

list = FALSE 避免将数据作为列表返回。 这个函数还有一个参数，times，可以一次创建多个分割； 数据索引在整数向量列表中返回。 同样，createResample 可用于制作简单的bootstrap样本，createFolds 可用于从一组数据生成平衡的交叉验证分组。

#### 基于预测变量的拆分

此外，函数 maxDissim 可用于使用最大相异性方法（Willett，1999）创建子样本。 假设有一个有 m 个样本的数据集 A 和一个有 n 个样本的更大的数据集 B。 我们可能想要从 B 创建一个与 A 相比(内容)不同的子样本。为此，对于 B 中的每个样本，该函数计算 A 中每个点之间的 m 个不相似性。 B 中最不相似的点被添加到 A 并且该过程继续。  R中有很多方法可以计算相异度。  caret 使用proxy包。 有关可用措施的列表，请参阅该包的手册。 此外，有很多方法可以计算哪个样本“最不相似”。 参数 obj 可用于指定任何返回标量度量的函数。  caret 包括两个函数 minDiss 和 sumDiss，分别可用于最大化最小差异和总差异。

例如，下图显示了 Cox2 数据的两个化学描述符的散点图。 使用 5 种化合物的初始随机样本，我们可以从数据中再选择 20 种化合物，以便新化合物与指定的最初 5 种化合物最不相似。 图中的面板显示了使用距离度量和评分函数的几种组合的结果。 对于这些数据，距离测量比确定哪些化合物最不相似的评分方法的影响要小。

```R
library(mlbench)
data(BostonHousing)

testing <- scale(BostonHousing[, c("age", "nox")])
set.seed(5)
## A random sample of 5 data points
startSet <- sample(1:dim(testing)[1], 5)
samplePool <- testing[-startSet,]
start <- testing[startSet,]
newSamp <- maxDissim(start, samplePool, n = 20)
head(newSamp)
## [1] 460 142 491 156 498  82
```

下面的可视化显示了数据集（小点）、起始样本（较大的蓝点）以及其他 20 个样本的添加顺序。

![img](https://topepo.github.io/caret/premade/MaxDissim.gif)

#### 时间序列的数据拆分

在某些情况下，在（重新）采样期间应考虑数据中的重要定性因素。 例如：

* 在临床试验中，纵向或重复测量数据可能存在医院间差异
* 对于纵向或重复测量数据，受试者（或一般独立实验单元）在数据集中可能有多行等。

可能有兴趣确保这些组不包含在训练和测试集中，因为这可能会使测试集性能更乐观。 此外，当一个或多个特定组被保留时，重新采样可能会捕获模型的“坚固性”。 **在多个站点记录临床数据的示例中，重采样性能估计部分衡量模型跨站点的可扩展性**。

要根据组拆分数据，可以使用 groupKFold：

```R
set.seed(3527)
subjects <- sample(1:20, size = 80, replace = TRUE)
table(subjects)

## subjects
##  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 
##  2  3  2  5  3  5  4  5  4  4  2  5  4  2  3  3  6  7  8  3

folds <- groupKFold(subjects, k = 15) 
```

folds 中的结果可以用作 trainControl 函数的 index 参数的输入。

该图显示了每个主题如何在建模集和保持集之间进行划分。 请注意，由于在创建折叠时 k 小于 20，因此有一些模型的坚持不是一个主题。

![img](https://topepo.github.io/caret/splitting/Split_group_plot-1.svg)

### 模型训练和调优

#### 模型训练和参数调优

caret 包有几个试图简化模型构建和评估过程的功能。

train 函数可用于评估，使用重采样，模型调整参数对性能的影响在这些参数中选择“最佳”模型从训练集中估计模型性能首先，必须选择特定模型。 目前，有 238 个可以使用caret符号； 有关详细信息，请参阅[训练模型列表](https://topepo.github.io/caret/available-models.html)或[按标签训练模型](https://topepo.github.io/caret/train-models-by-tag.html)。 在这些页面上，列出了可以优化的调整参数。 也可以创建用户定义的模型。

调整模型的第一步（下面算法中的第 1 行）是选择一组要评估的参数。 例如，如果拟合偏最小二乘 (PLS) 模型，则必须指定要评估的 PLS 分量数。

一旦定义了模型和调整参数值，还应指定重采样的类型。 目前，train 可以使用 k 折交叉验证（一次或重复）、留一法交叉验证和bootstrap（简单估计或 632 规则）重采样方法。 重采样后，该过程会生成性能测量的配置文件，可用于指导用户选择应选择哪些调整参数值。 默认情况下，该函数会自动选择与最佳值相关的调整参数，尽管可以使用不同的算法（请参阅下面的详细信息）。

#### 一个例子

声纳数据在 mlbench 包中可用。 在这里，我们加载数据：

```R
library(mlbench)
data(Sonar)
str(Sonar[, 1:10])
```

函数 createDataPartition 可用于将数据的分层随机样本创建为训练集和测试集：

```R
library(caret)
set.seed(998)
inTraining <- createDataPartition(Sonar$Class, p = .75, list = FALSE)
training <- Sonar[ inTraining,]
testing  <- Sonar[-inTraining,]
```

#### 基本参数调整

默认情况下，简单bootstrap重采样用于上述算法中的第 3 行。 其他可用的，例如重复 K 折交叉验证，留一法等。 函数 trainControl 可用于指定重采样的类型：

```R
fitControl <- trainControl(## 10-fold CV
                           method = "repeatedcv",
                           number = 10,
                           ## repeated ten times
                           repeats = 10)
```

有关 trainControl 的更多信息在下面的部分中给出。

训练的前两个参数分别是预测数据对象和结果数据对象。 第三个参数 method 指定模型的类型（请参阅[训练模型列表](https://topepo.github.io/caret/available-models.html)或[按标签训练模型](https://topepo.github.io/caret/train-models-by-tag.html)）。 为了说明这一点，我们将通过 gbm 包拟合一个提升树模型。 使用重复交叉验证拟合此模型的基本语法如下所示：

```R
set.seed(825)
gbmFit1 <- train(Class ~ ., data = training, 
                 method = "gbm", 
                 trControl = fitControl,
                 ## This last option is actually one
                 ## for gbm() that passes through
                 verbose = FALSE)
gbmFit1
```

对于梯度提升机 (GBM) 模型，主要有三个调优参数： 

* 迭代次数，即树，（gbm 函数中称为 n.trees）
* 树的复杂度，称为interaction.depth
* 学习率：算法的速度 适应，称为shrinkage
* 在节点中开始分裂的最小训练集样本数 (n.minobsinnode) 该模型测试的默认值显示在前两列中（shrinkage和 n.minobsinnode 未显示，因为网格集 候选模型都对这些调整参数使用单个值）。 标有“Accuracy”的列是交叉验证迭代的平均总体一致率。 一致性标准偏差也是从交叉验证结果中计算出来的。  “Kappa”列是 Cohen 的（未加权的）Kappa 统计量在重采样结果中的平均值。  train 适用于特定模型（请参阅 train Model List 或 train Models By Tag）。 对于这些模型，train 可以自动创建调整参数网格。 默认情况下，如果 p 是调整参数的数量，则网格大小为 3^p。 再举一个例子，正则化判别分析 (RDA) 模型有两个参数（gamma 和 lambda），这两个参数都在 0 和 1 之间。 默认训练网格将在这个二维空间中产生九种组合。

​    下一节将介绍 train 中的其他功能。

#### 关于再现性的说明

许多模型在估计参数的阶段使用随机数。 此外，重采样索引是使用随机数选择的。 有两种主要方法可以控制随机性以确保可重复的结果。

* 有两种方法可以确保在训练调用之间使用相同的重采样。 第一个是在调用 train 之前使用 set.seed。 随机数的第一个用途是创建重采样信息。 或者，如果您想使用数据的特定拆分，可以使用 trainControl 函数的 index 参数。 这将在下面简要讨论。
* 在重采样中创建模型时，还可以设置种子。 虽然在调用 train 之前设置种子可以保证使用相同的随机数，但在使用并行处理时不太可能出现这种情况（取决于使用的技术）。 为了设置模型拟合种子，trainControl 有一个名为seeds的附加参数可以使用。 此参数的值是用作种子的整数向量列表。  trainControl 的帮助页面描述了此选项的适当格式。

   如何使用随机数在很大程度上取决于包作者。 在极少数情况下，底层模型函数不控制随机数种子，尤其是在使用 C 代码进行计算的情况下。 另外，请注意某些包在加载时会加载随机数（直接或通过命名空间），这可能会影响可重复性。

#### 自定义调整过程

有几种方法可以自定义选择调整/复杂性参数和构建最终模型的过程。

##### 预处理选项

如前所述，train 可以在模型拟合之前以各种方式对数据进行预处理。 自动使用功能 preProcess。 此函数可用于居中和缩放、插补（参见下文详细信息）、通过主成分分析或独立成分分析应用空间符号变换和特征提取。

了指定应该进行什么预处理，train 函数有一个名为 preProcess 的参数。 此参数采用通常会传递给 preProcess 函数的方法参数的方法字符串。  preProcess 函数的附加选项可以通过 trainControl 函数传递。

这些处理步骤将在使用 predict.train、extractPrediction 或 extractProbs 生成的任何预测期间应用（请参阅本文档后面的详细信息）。 预处理不会应用于直接使用 object$finalModel 对象的预测。

对于插补，目前实现了三种方法：

* k-最近邻采用具有缺失值的样本，并在训练集中找到 k 个最接近的样本。 该预测器的 k 个训练集值的平均值用作原始数据的替代。 在计算到训练集样本的距离时，计算中使用的预测变量是该样本没有缺失值且训练集中没有缺失值的预测变量。
* 另一种方法是使用训练集样本为每个预测器拟合一个袋装树模型。 这通常是一个相当准确的模型，可以处理缺失值。 当样本的预测变量需要插补时，其他预测变量的值通过袋装树馈送，并将预测用作新值。 该模型可能具有显着的计算成本。
* 预测器训练集值的中位数可用于估计缺失数据。

如果训练集中存在缺失值，PCA 和 ICA 模型仅使用完整样本。

##### 交替调谐网格

用户可以指定调谐参数网格。 参数 tuneGrid 可以采用包含每个调整参数列的数据框。 列名应该与拟合函数的参数相同。 对于前面提到的 RDA 示例，名称将是 gamma 和 lambda。  train 将在行中的每个值组合上调整模型。

对于 boosted 树模型，我们可以固定学习率并评估 n.trees 的三个以上值：

```R
gbmGrid <-  expand.grid(interaction.depth = c(1, 5, 9), 
                        n.trees = (1:30)*50, 
                        shrinkage = 0.1,
                        n.minobsinnode = 20)
                        
nrow(gbmGrid)

set.seed(825)
gbmFit2 <- train(Class ~ ., data = training, 
                 method = "gbm", 
                 trControl = fitControl, 
                 verbose = FALSE, 
                 ## Now specify the exact models 
                 ## to evaluate:
                 tuneGrid = gbmGrid)
gbmFit2
```

另一种选择是使用可能的调整参数组合的随机样本，即“随机搜索”[(pdf)](http://www.jmlr.org/papers/volume13/bergstra12a/bergstra12a.pdf). This functionality is described on [this page](https://topepo.github.io/caret/random-hyperparameter-search.html).

要使用随机搜索，请在调用 trainControl 时使用选项 search = "random"。 在这种情况下，tuneLength 参数定义了将被评估的参数组合的总数。

##### 绘制重采样配置文件

plot 函数可用于检查性能估计与调整参数之间的关系。 例如，函数的简单调用显示了第一个性能度量的结果：

```R
trellis.par.set(caretTheme())
plot(gbmFit2)  
```

可以使用 metric 选项显示其他性能指标：

```R
trellis.par.set(caretTheme())
plot(gbmFit2, metric = "Kappa")
```

也可以使用其他类型的绘图。 有关更多详细信息，请参阅 ?plot.train。 下面的代码显示了结果的热图：

```R
trellis.par.set(caretTheme())
plot(gbmFit2, metric = "Kappa", plotType = "level",
     scales = list(x = list(rot = 90)))
```

也可以使用 ggplot 方法：

```R
ggplot(gbmFit2)  
```

还有一些绘图函数可以更详细地表示重新采样的估计值。 有关更多详细信息，请参阅 ?xyplot.train。

从这些图中，可能需要一组不同的调谐参数。 要在不重新启动整个过程的情况下更改最终值，可以使用 update.train 重新拟合最终模型。 见 ?update.train

##### trainControl 函数

函数 trainControl 生成进一步控制模型创建方式的参数，可能的方法：

* 重采样方法：“boot”、“cv”、“LOOCV”、“LGOCV”、“repeatedcv”、“timeslice”、“none”和“oob”。 最后一个值，即袋外估计，只能用于随机森林、袋装树、袋装地球、袋装灵活判别分析或条件树森林模型。 不包括 GBM 模型（gbm 包维护者表示，根据模型 OOB 误差估计和提升树来选择调整参数值不是一个好主意）。 此外，对于留一法交叉验证，重采样的性能度量没有给出不确定性估计。
* number 和 repeats：数字控制 K 折交叉验证中的折叠次数或用于引导和离开组交叉验证的重采样迭代次数。 重复仅适用于重复的 K 折交叉验证。 假设method = "repeatedcv", number = 10 and repeats = 3, 那么三个单独的10折交叉验证被用作重采样方案。
* verboseIter：打印训练日志的逻辑。
* returnData：将数据保存到名为 trainingData 的槽中的逻辑。
*  p：对于离开组交叉验证：训练百分比 
* 对于 method = "timeslice"，trainControl 具有选项 initialWindow、horizon 和 fixedWindow，用于控制交叉验证如何用于时间序列数据。
* classProbs：一个逻辑值，确定在重新采样期间是否应该为保留的样本计算类概率。
* index 和 indexOut：包含每个重采样迭代元素的可选列表。 每个列表元素都是在该迭代中用于训练或应该保留的样本行。 当未指定这些值时，train 将生成它们。
* summaryFunction：用于计算替代性能摘要的函数。
*  selectionFunction：选择最佳调整参数的函数。 和例子
* PCAthresh、ICAcomp 和 k：这些都是传递给 preProcess 函数（使用时）的选项。
* returnResamp：包含以下值之一的字符串：“all”、“final”或“none”。 这指定了要保存多少重新采样的性能度量。
* allowParallel：控制train是否应使用并行处理的逻辑（如果可用）。

这里没有讨论其他几个选项。

##### 替代性能指标

用户可以更改用于确定最佳设置的指标。 默认情况下，为回归计算 RMSE、R2 和平均绝对误差 (MAE)，而为分类计算准确度和 Kappa。 同样默认情况下，参数值是分别使用 RMSE 和准确性选择的，分别用于回归和分类。  train 函数的 metric 参数允许用户控制使用哪个最优标准。 例如，**在一类中样本百分比较低的问题中，使用 metric = "Kappa" 可以提高最终模型的质量。**

如果这些参数都不令人满意，用户还可以计算自定义性能指标。  trainControl 函数有一个名为 summaryFunction 的参数，它指定一个用于计算性能的函数。 该函数应具有以下参数：

data 是数据框或矩阵的参考，其中列称为 obs 和 pred 用于观察和预测的结果值（回归的数字数据或分类的字符值）。 目前，类概率不会传递给函数。 数据中的值是单个调整参数组合的保留预测（及其相关参考值）。 如果 trainControl 对象的 classProbs 参数设置为 TRUE，则数据中将出现包含类概率的附加列。 这些列的名称与类级别相同。 此外，如果在调用 train 中指定了权重，则数据集中也会有一个名为 weights 的列。 此外，如果使用了 train 的recipe方法（参见文档的这一部分），模型中未使用的其他变量也将包括在内。 这可以通过在“"performance var" recipe中添加一个角色来实现。 本网站的recipe部分给出了一个示例。

lev 是一个字符串，其中包含从训练数据中提取的结果因子级别。 对于回归，NULL 值被传递到函数中。

model 是正在使用的模型的字符串（即传递给 train 的方法参数的值）。

函数的输出应该是具有非空名称的数字汇总度量向量。 默认情况下，train 根据预测的类别评估分类模型。 可选地，类概率也可用于衡量性能。 要在重采样过程中获得预测的类概率，trainControl 中的参数 classProbs 必须设置为 TRUE。 这将概率列合并到每个重采样生成的预测中（每个类有一列，列名是类名）。

如上一节所示，自定义函数可用于计算重采样的平均性能分数。 另一个内置函数 twoClassSummary 将计算 ROC 曲线下的**灵敏度、特异性和面积**：

```R
head(twoClassSummary)
##                                                                                                                   ## 1 function (data, lev = NULL, model = NULL)             ## 2 {                                                      ## 3     lvls <- levels(data$obs)                          ## 4     if (length(lvls) > 2)                             ## 5         stop(paste("Your outcome has", length(lvls), "levels. The twoClassSummary() function isn't appropriate."))
## 6     requireNamespaceQuietStop("ModelMetrics")
```

要使用此标准重建提升树模型，我们可以使用以下代码查看调整参数与 ROC 曲线下面积之间的关系：

```R
fitControl <- trainControl(method = "repeatedcv",
                           number = 10,
                           repeats = 10,
                           ## Estimate class probabilities
                           classProbs = TRUE,
                           ## Evaluate performance using 
                           ## the following function
                           summaryFunction = twoClassSummary)

set.seed(825)
gbmFit3 <- train(Class ~ ., data = training, 
                 method = "gbm", 
                 trControl = fitControl, 
                 verbose = FALSE, 
                 tuneGrid = gbmGrid,
                 ## 指定要优化的指标
                 metric = "ROC")
gbmFit3
```

在这种情况下，与最佳调整参数相关的 ROC 曲线下的平均面积在 100 次重采样中为 0.922。

##### 选择最终模型

自定义调整过程的另一种方法是修改用于选择“最佳”参数值的算法，给定性能数字。 默认情况下，train 函数选择具有最大性能值（或最小，对于回归模型中的均方误差）的模型。 可以使用其他选择模型的方案。  Breiman 等人 (1984) 为简单的基于树的模型提出了“一个标准错误规则”。 在这种情况下，识别出具有最佳性能值的模型，并使用重采样来估计性能的标准误差。 **使用的最终模型是（经验上的）最佳模型的一个标准误差范围内的最简单模型**。 对于简单的树，这是有道理的，因为随着这些模型越来越针对训练数据，它们将开始过度拟合。

train 允许用户指定用于选择最终模型的替代规则。 参数 selectionFunction 可用于提供一个函数来通过算法确定最终模型。 包中有三个现有函数：best 是选择最大/最小值，oneSE 试图捕捉 Breiman 等人 (1984) 的精神，并且tolerance选择在最佳值的某个百分比容差范围内最不复杂的模型。 有关更多详细信息，请参阅 ?best。

可以使用用户定义的函数，只要它们具有以下参数：

* x 是包含调整参数及其相关性能指标的数据框。 每行对应一个不同的调整参数组合。
* metric 一个字符串，指示应该优化哪个性能指标（这是直接从 train.metric 参数传入的）。
* maximize是一个单一的逻辑值，指示性能指标的较大值是否更好（这也直接从调用传递到训练）。

该函数应输出一个整数，指示选择了 x 中的哪一行。

举个例子，如果我们根据整体精度选择之前的 boosted 树模型，我们会选择：n.trees = 1450，interaction.depth = 5，shrinkage = 0.1，n.minobsinnode = 20。 该图相当紧凑，准确度值从 0.863 到 0.922 不等。 一个不太复杂的模型（例如更少、更浅的树）也可能产生可接受的准确性。

 tolerance函数可用于基于 $ (x-x_{best})/x_{best}\times 100$（百分比差异）找到不太复杂的模型(返回坐标索引)。 例如，要根据 2% 的性能损失选择参数值： 

```R
whichTwoPct <- tolerance(gbmFit3$results, metric = "ROC", 
                         tol = 2, maximize = TRUE)  
cat("best model within 2 pct of best:\n")
## best model within 2 pct of best:
gbmFit3$results[whichTwoPct,1:6]
##    shrinkage interaction.depth n.minobsinnode n.trees       ROC      Sens
## 32       0.1                 5             20     100 0.9139707 0.8645833
```

这表明我们可以得到一个不太复杂的模型，其 ROC 曲线下的面积为 0.914（与“选择最佳”值 0.922 相比）。

这些函数的主要问题与从最简单到复杂的模型排序有关。 在某些情况下，这很容易（例如简单的树、偏最小二乘法），但在这种模型的情况下，模型的排序是主观的。 例如，使用 100 次迭代且树深度为 2 的提升树模型是否比使用 50 次迭代且深度为 8 的模型更复杂？ 该包对ordering做出了一些选择。 在提升树的情况下，该包假设增加迭代次数比增加树深度更快地增加复杂性，因此模型按迭代次数排序，然后按深度排序。 有关特定模型的更多示例，请参阅 ?best。

##### 提取预测和类别概率

如前所述，train 函数生成的对象在 finalModel 子对象中包含“优化”模型。 可以像往常一样根据这些对象进行预测。 在某些情况下，例如 pls 或 gbm 对象，可能需要**指定优化拟合的附加参数**。 在这些情况下，训练对象使用参数优化的结果来预测新样本。 例如，如果使用 predict.gbm 创建预测，则用户必须直接指定树的数量（没有默认值）。 此外，对于二元分类，此函数的预测采用类别之一的概率的形式，因此需要额外的步骤将其转换为因子向量。  predict.train 自动处理这些细节（和其他模型）。

此外，R 中模型预测的标准语法很少。例如，为了获得类概率，许多预测方法都有一个名为 type 的参数，用于指定是否应该生成类或概率。 不同的包使用不同的类型值，例如“prob”、“posterior”、“response”、“probability”或“raw”。 在其他情况下，使用完全不同的语法。

对于predict.train，类型选项被标准化为“class”和“prob”（底层代码将这些选项与每个模型的适当选项相匹配）。例如：

```R
predict(gbmFit3, newdata = head(testing))
## [1] R M R M R M
## Levels: M R
predict(gbmFit3, newdata = head(testing), type = "prob")
##              M            R
## 1 3.215213e-02 9.678479e-01
## 2 1.000000e+00 3.965815e-08
## 3 6.996088e-13 1.000000e+00
## 4 9.070652e-01 9.293483e-02
## 5 2.029754e-03 9.979702e-01
## 6 9.999662e-01 3.377548e-05
```

##### 探索和比较重采样分布

###### 模型内

有几个lattice函数可用于探索特定模型的调整参数与重采样结果之间的关系：

* xyplot 和 stripplot 可用于绘制重采样统计数据与（数字）调整参数的关系。
* 直方图和密度图也可用于查看调整参数中调整参数的分布。

例如，以下语句创建一个密度图：

```R
trellis.par.set(caretTheme())# lattice中的语法
densityplot(gbmFit3, pch = "|")
```

请注意，如果您有兴趣绘制跨多个调整参数的重采样结果，则应在控制对象中使用选项 resamples = "all"。

###### 模型间

caret 包还包括通过重采样分布来表征模型（使用 train、sbf 或 rfe 生成）之间差异的函数。 这些功能基于 Hothorn 等人的工作。  (2005) 和 Eugster 等人 (2008)。

首先，支持向量机模型适合声纳数据。 使用 preProc 参数对数据进行居中和缩放。 请注意，在与用于提升树模型的种子相同的模型之前设置了相同的随机数种子。 这确保使用相同的重采样集，这在我们比较模型之间的重采样配置文件时会派上用场。

```R
set.seed(825)
svmFit <- train(Class ~ ., data = training, 
                 method = "svmRadial", 
                 trControl = fitControl, 
                 preProc = c("center", "scale"),
                 tuneLength = 8,
                 metric = "ROC")
svmFit     

## Support Vector Machines with Radial Basis Function Kernel 
## 
## 157 samples
##  60 predictor
##   2 classes: 'M', 'R' 
## 
## Pre-processing: centered (60), scaled (60) 
## Resampling: Cross-Validated (10 fold, repeated 10 times) 
## Summary of sample sizes: 141, 142, 141, 142, 141, 142, ... 
## Resampling results across tuning parameters:
## 
##   C      ROC        Sens       Spec     
##    0.25  0.8438318  0.7373611  0.7230357
##    0.50  0.8714459  0.8083333  0.7316071
##    1.00  0.8921354  0.8031944  0.7653571
##    2.00  0.9116171  0.8358333  0.7925000
##    4.00  0.9298934  0.8525000  0.8201786
##    8.00  0.9318899  0.8684722  0.8217857
##   16.00  0.9339658  0.8730556  0.8205357
##   32.00  0.9339658  0.8776389  0.8276786
## 
## Tuning parameter 'sigma' was held constant at a value of 0.01181293
## ROC was used to select the optimal model using the largest value.
## The final values used for the model were sigma = 0.01181293 and C = 16.
```

此外，还拟合了正则化判别分析模型。

```R
set.seed(825)
rdaFit <- train(Class ~ ., data = training, 
                 method = "rda", 
                 trControl = fitControl, 
                 tuneLength = 4,
                 metric = "ROC")
rdaFit    
## Regularized Discriminant Analysis 
## 
## 157 samples
##  60 predictor
##   2 classes: 'M', 'R' 
## 
## No pre-processing
## Resampling: Cross-Validated (10 fold, repeated 10 times) 
## Summary of sample sizes: 141, 142, 141, 142, 141, 142, ... 
## Resampling results across tuning parameters:
## 
##   gamma      lambda     ROC        Sens       Spec     
##   0.0000000  0.0000000  0.6426029  0.9311111  0.3364286
##   0.0000000  0.3333333  0.8543564  0.8076389  0.7585714
##   0.0000000  0.6666667  0.8596577  0.8083333  0.7766071
##   0.0000000  1.0000000  0.7950670  0.7677778  0.6925000
##   0.3333333  0.0000000  0.8509276  0.8502778  0.6914286
##   0.3333333  0.3333333  0.8650372  0.8676389  0.6866071
##   0.3333333  0.6666667  0.8698115  0.8604167  0.6941071
##   0.3333333  1.0000000  0.8336930  0.7597222  0.7542857
##   0.6666667  0.0000000  0.8600868  0.8756944  0.6482143
##   0.6666667  0.3333333  0.8692981  0.8794444  0.6446429
##   0.6666667  0.6666667  0.8678547  0.8355556  0.6892857
##   0.6666667  1.0000000  0.8277133  0.7445833  0.7448214
##   1.0000000  0.0000000  0.7059797  0.6888889  0.6032143
##   1.0000000  0.3333333  0.7098313  0.6830556  0.6101786
##   1.0000000  0.6666667  0.7129489  0.6672222  0.6173214
##   1.0000000  1.0000000  0.7193031  0.6626389  0.6296429
## 
## ROC was used to select the optimal model using the largest value.
## The final values used for the model were gamma = 0.3333333 and lambda
##  = 0.6666667.
```

鉴于这些模型，我们能否对它们的性能差异做出统计陈述？ 为此，我们首先使用resamples收集重采样结果。

```R
resamps <- resamples(list(GBM = gbmFit3,
                          SVM = svmFit,
                          RDA = rdaFit))
resamps
## 
## Call:
## resamples.default(x = list(GBM = gbmFit3, SVM = svmFit, RDA = rdaFit))
## 
## Models: GBM, SVM, RDA 
## Number of resamples: 100 
## Performance metrics: ROC, Sens, Spec 
## Time estimates for: everything, final model fit
summary(resamps)
## 
## Call:
## summary.resamples(object = resamps)
## 
## Models: GBM, SVM, RDA 
## Number of resamples: 100 
## 
## ROC 
##          Min.  1st Qu.    Median      Mean   3rd Qu. Max. NA's
## GBM 0.6964286 0.874504 0.9375000 0.9216270 0.9821429    1    0
## SVM 0.7321429 0.905878 0.9464286 0.9339658 0.9821429    1    0
## RDA 0.5625000 0.812500 0.8750000 0.8698115 0.9392361    1    0
## 
## Sens 
##          Min.   1st Qu.    Median      Mean 3rd Qu. Max. NA's
## GBM 0.5555556 0.7777778 0.8750000 0.8776389       1    1    0
## SVM 0.5000000 0.7777778 0.8888889 0.8730556       1    1    0
## RDA 0.4444444 0.7777778 0.8750000 0.8604167       1    1    0
## 
## Spec 
##          Min.   1st Qu.    Median      Mean   3rd Qu. Max. NA's
## GBM 0.4285714 0.7142857 0.8571429 0.8133929 1.0000000    1    0
## SVM 0.4285714 0.7142857 0.8571429 0.8205357 0.9062500    1    0
## RDA 0.1428571 0.5714286 0.7142857 0.6941071 0.8571429    1    0
```

请注意，在这种情况下，选项 resamples = "final" 应该是用户在控制对象中定义的。

有几种点阵图方法可用于可视化重采样分布：密度图、盒须图、散点图矩阵和汇总统计的散点图。 例如： 

```R
theme1 <- trellis.par.get()
theme1$plot.symbol$col = rgb(.2, .2, .2, .4)
theme1$plot.symbol$pch = 16
theme1$plot.line$col = rgb(1, 0, 0, .7)
theme1$plot.line$lwd <- 2
trellis.par.set(theme1)
bwplot(resamps, layout = c(3, 1))
```

![img](https://topepo.github.io/caret/basic/train_resample_box-1.svg)

```R
trellis.par.set(caretTheme())
dotplot(resamps, metric = "ROC")
```

![img](https://topepo.github.io/caret/basic/train_resample_ci-1.svg)

```R
trellis.par.set(theme1)
xyplot(resamps, what = "BlandAltman")
```

![img](https://topepo.github.io/caret/basic/train_resample_ba-1.svg)

```R
splom(resamps)
```

![img](https://topepo.github.io/caret/basic/train_resample_scatmat-1.svg)

其他可视化在 densityplot.resamples 和 parallel.resamples 中可用 

由于模型适用于相同版本的训练数据(预先设定好种子就行)，因此推断模型之间的差异是有意义的。 通过这种方式，我们减少了可能存在的重采样内相关性。 我们可以计算差异，然后**使用简单的 t 检验来评估模型之间没有差异的零假设**。

```R
difValues <- diff(resamps)
difValues
## 
## Call:
## diff.resamples(x = resamps)
## 
## Models: GBM, SVM, RDA 
## Metrics: ROC, Sens, Spec 
## Number of differences: 3 
## p-value adjustment: bonferroni
summary(difValues)
## 
## Call:
## summary.diff.resamples(object = difValues)
## 
## p-value adjustment: bonferroni 
## Upper diagonal: estimates of the difference
## Lower diagonal: p-value for H0: difference = 0
## 
## ROC 
##     GBM       SVM       RDA     
## GBM           -0.01234   0.05182
## SVM 0.3388               0.06415
## RDA 5.988e-07 2.638e-10         
## 
## Sens 
##     GBM    SVM      RDA     
## GBM        0.004583 0.017222
## SVM 1.0000          0.012639
## RDA 0.5187 1.0000           
## 
## Spec 
##     GBM       SVM       RDA      
## GBM           -0.007143  0.119286
## SVM 1                    0.126429
## RDA 5.300e-07 1.921e-10

trellis.par.set(theme1)
bwplot(difValues, layout = c(3, 1))
```

![img](https://topepo.github.io/caret/basic/train_diff_box-1.svg)

```R
trellis.par.set(caretTheme())
dotplot(difValues)
```

![img](https://topepo.github.io/caret/basic/train_diff_ci-1.svg)

##### 没有参数调整的拟合模型

在模型调整值已知的情况下，train 可用于将模型拟合到整个训练集，而无需任何重采样或参数调整。 可以使用 trainControl 中的 method = "none" 选项。 例如：

```R
fitControl <- trainControl(method = "none", classProbs = TRUE)

set.seed(825)
gbmFit4 <- train(Class ~ ., data = training, 
                 method = "gbm", 
                 trControl = fitControl, 
                 verbose = FALSE, 
                 ## Only a single model can be passed to the
                 ## function when no resampling is used:
                 tuneGrid = data.frame(interaction.depth = 4,
                                       n.trees = 100,
                                       shrinkage = .1,
                                       n.minobsinnode = 20),
                 metric = "ROC")
gbmFit4

## Stochastic Gradient Boosting 
## 
## 157 samples
##  60 predictor
##   2 classes: 'M', 'R' 
## 
## No pre-processing
## Resampling: None
```

请注意，plot.train、resample、confusionMatrix.train 和其他几个函数将不适用于此对象，但 predict.train 和其他函数将适用：

```R
predict(gbmFit4, newdata = head(testing))
## [1] R M R R M M
## Levels: M R
predict(gbmFit4, newdata = head(testing), type = "prob")
## 1 0.264671996 0.73532800
## 2 0.960445979 0.03955402
## 3 0.005731862 0.99426814
## 4 0.298628996 0.70137100
## 5 0.503935367 0.49606463
## 6 0.813716635 0.18628336
```

### 按标签的训练模型

以下是模型类型或相关特征的基本列表。 这些列表中的所有内容都值得商榷。 例如：随机森林理论上使用特征选择但实际上可能不会，支持向量机使用 L2 正则化等。

- [接受案例权重](https://topepo.github.io/caret/train-models-by-tag.html#Accepts_Case_Weights)
- [Bagging](https://topepo.github.io/caret/train-models-by-tag.html#Bagging)
- [贝叶斯模型](https://topepo.github.io/caret/train-models-by-tag.html#Bayesian_Model)
- [仅二进制预测变量](https://topepo.github.io/caret/train-models-by-tag.html#Binary_Predictors_Only)
- [Boosting](https://topepo.github.io/caret/train-models-by-tag.html#Boosting)
- [仅分类预测变量](https://topepo.github.io/caret/train-models-by-tag.html#Categorical_Predictors_Only)
- [成本敏感学习](https://topepo.github.io/caret/train-models-by-tag.html#Cost_Sensitive_Learning)
- [判别分析](https://topepo.github.io/caret/train-models-by-tag.html#Discriminant_Analysis)
- [距离加权判别](https://topepo.github.io/caret/train-models-by-tag.html#Distance_Weighted_Discrimination)
- [集成模型](https://topepo.github.io/caret/train-models-by-tag.html#Ensemble_Model)
- [特征提取](https://topepo.github.io/caret/train-models-by-tag.html#Feature_Extraction)
- [特征选择包装器](https://topepo.github.io/caret/train-models-by-tag.html#Feature_Selection_Wrapper)
- [高斯过程](https://topepo.github.io/caret/train-models-by-tag.html#Gaussian_Process)
- [广义加性模型](https://topepo.github.io/caret/train-models-by-tag.html#Generalized_Additive_Model)
- [广义线性模型](https://topepo.github.io/caret/train-models-by-tag.html#Generalized_Linear_Model)
- [处理丢失的预测数据](https://topepo.github.io/caret/train-models-by-tag.html#Handle_Missing_Predictor_Data)
- [隐式特征选择](https://topepo.github.io/caret/train-models-by-tag.html#Implicit_Feature_Selection)
- [核方法](https://topepo.github.io/caret/train-models-by-tag.html#Kernel_Method)
- [L1 正则化](https://topepo.github.io/caret/train-models-by-tag.html#L1_Regularization)
- [L2 正则化](https://topepo.github.io/caret/train-models-by-tag.html#L2_Regularization)
- [线性分类器](https://topepo.github.io/caret/train-models-by-tag.html#Linear_Classifier)
- [线性回归](https://topepo.github.io/caret/train-models-by-tag.html#Linear_Regression)
- [逻辑回归](https://topepo.github.io/caret/train-models-by-tag.html#Logic_Regression)
- [逻辑斯蒂回归](https://topepo.github.io/caret/train-models-by-tag.html#Logistic_Regression)
- [混合模型](https://topepo.github.io/caret/train-models-by-tag.html#Mixture_Model)
- [模型树](https://topepo.github.io/caret/train-models-by-tag.html#Model_Tree)
- [多元自适应回归样条](https://topepo.github.io/caret/train-models-by-tag.html#Multivariate_Adaptive_Regression_Splines)
- [神经网络](https://topepo.github.io/caret/train-models-by-tag.html#Neural_Network)
- [斜树](https://topepo.github.io/caret/train-models-by-tag.html#Oblique_Tree)
- [顺序结果](https://topepo.github.io/caret/train-models-by-tag.html#Ordinal_Outcomes)
- [偏最小二乘法](https://topepo.github.io/caret/train-models-by-tag.html#Partial_Least_Squares)
- [病人规则归纳法](https://topepo.github.io/caret/train-models-by-tag.html#Patient_Rule_Induction_Method)
- [多项式模型](https://topepo.github.io/caret/train-models-by-tag.html#Polynomial_Model)
- [原型模型](https://topepo.github.io/caret/train-models-by-tag.html#Prototype_Models)
- [分位数回归](https://topepo.github.io/caret/train-models-by-tag.html#Quantile_Regression)
- [径向基函数](https://topepo.github.io/caret/train-models-by-tag.html#Radial_Basis_Function)
- [随机森林](https://topepo.github.io/caret/train-models-by-tag.html#Random_Forest)
- [正则化](https://topepo.github.io/caret/train-models-by-tag.html#Regularization)
- [相关向量机](https://topepo.github.io/caret/train-models-by-tag.html#Relevance_Vector_Machines)
- [岭回归](https://topepo.github.io/caret/train-models-by-tag.html#Ridge_Regression)
- [稳健的方法](https://topepo.github.io/caret/train-models-by-tag.html#Robust_Methods)
- [稳健模型](https://topepo.github.io/caret/train-models-by-tag.html#Robust_Model)
- [ROC 曲线](https://topepo.github.io/caret/train-models-by-tag.html#ROC_Curves)
- [基于规则的模型](https://topepo.github.io/caret/train-models-by-tag.html#Rule_Based_Model)
- [自组织映射](https://topepo.github.io/caret/train-models-by-tag.html#Self_Organising_Maps)
- [字符串内核](https://topepo.github.io/caret/train-models-by-tag.html#String_Kernel)
- [支持向量机](https://topepo.github.io/caret/train-models-by-tag.html#Support_Vector_Machines)
- [支持类概率](https://topepo.github.io/caret/train-models-by-tag.html#Supports_Class_Probabilities)
- [文本挖掘](https://topepo.github.io/caret/train-models-by-tag.html#Text_Mining)
- [基于树的模型](https://topepo.github.io/caret/train-models-by-tag.html#Tree_Based_Model)
- [仅限两类](https://topepo.github.io/caret/train-models-by-tag.html#Two_Class_Only)

#### 按标签相似性聚类的模型

此页面显示了train可以访问的所有模型的网络图。 有关如何制作此可视化的详细信息，请参阅 Revolutions 博客（此页面已使用 networkD3 包更新了代码）。 总之，该包通过一组标签（例如“Bagging”、“L1 正则化”等）对每个模型进行注释。 使用这些信息，我们可以对彼此相似的模型进行聚类。

绿色圆圈是仅用于回归的模型，蓝色仅用于分类，橙色是“双重用途”。 将鼠标悬停在圆圈上以获取 caret 包使用的模型名称和模型代码，刷新屏幕将重新配置布局。 您可能需要向左移动一个节点才能看到整个名称。 图中未显示 43 个没有连接的模型。

### 并行处理

在这个包中，重采样是使用调整参数优化预测模型的主要方法。 为此，使用训练集的许多替代版本来训练模型并预测保留集。 此过程会重复多次，以获得可推广到新数据集的性能估计。 每个重采样数据集都独立于其他数据集，因此没有正式要求模型必须按顺序运行。 如果具有多个处理器或内核的计算机可用，则计算可以分布在这些“工人”之间以提高计算效率。  caret 利用 R 中的并行处理框架之一来做到这一点。  foreach 包允许使用多种不同的技术顺序或并行运行 R 代码，例如多核或 Rmpi 包（有关可用选项的摘要和描述，请参见 Schmidberger 等，2009）。 有几个 R 包与 foreach 一起使用来实现这些技术，例如 doMC（用于多核）或 doMPI（用于 Rmpi）。

这篇博文对并行处理的好处进行了相当全面的研究。

 要使用多个 worker 调整预测模型，插入caret包函数（例如 train、rfe 或 sbf）中的函数语法不会改变。 一个单独的函数用于“注册”并行处理技术并指定要使用的工人数量。 例如，要在同一台机器上使用具有五个内核的 doParallel) 包，需要加载包并注册它们：

```R
library(doParallel)
cl <- makePSOCKcluster(5)
registerDoParallel(cl)

## 然后所有后续模型并行运行
model <- train(y ~ ., data = training, method = "rf")

## 完成后：
stopCluster(cl)
```

与 foreach 关联的其他包的语法非常相似。 请注意，随着工作人员数量的增加，所需的内存也会增加。 例如，使用 5 个 worker 将在内存中保留总共六个版本的数据。 如果数据很大或计算模型要求很高，如果所需的内存量超过可用的物理量，则性能可能会受到影响。 此外，对于 rfe 和 sbf，这些函数可能会为某些模型调用 train。 在这种情况下，注册 $M$ 个工人实际上会调用 $M^2$个总进程。

这是否有助于减少拟合模型的时间？ 一个中等大小的数据集（4331 行和 8 行）使用不同数量的工人对多个模型进行了多次建模。 随机森林与 2000 棵树一起使用，并调整了超过 10 个 mtry 值。 在每个模型拟合期间也进行了变量重要性计算。 还运行了线性判别分析，以及对成本敏感的径向基函数支持向量机（调整了 15 个成本值）。 所有模型都使用 10 倍交叉验证的 5 次重复进行调整。 结果如下图所示。  y 轴对应于总执行时间（包括模型调整和最终模型拟合）与工作人员数量的关系。 随机森林显然花费了最长的训练时间，并且 LDA 模型的计算效率非常高。 总时间（以分钟为单位）随着工人数量的增加而减少，但稳定在七名工人左右。 

该图的数据以随机方式生成，因此运行顺序不应有偏差。 右下面板显示加速，即连续时间除以并行时间。 例如，加速为 3 表示并行版本比顺序版本快三倍。 并行化充其量可以实现线性加速； 也就是说，对于 M 个 worker，并行时间为 1/M。 对于这些模型，在使用四五个工人之前，加速接近线性。 在此之后，性能略有提高。 由于 LDA 的计算效率已经很高，因此与其他模型相比，加速趋于平稳。 虽然不是线性的，但执行时间的减少是有帮助的 - 近 10 小时的模型拟合减少到大约 90 分钟。

![img](https://topepo.github.io/caret/premade/parallel.png)

请注意，由于底层代码结构，某些模型，尤其是使用 RWeka 包的模型，可能无法并行运行。

train、rfe、sbf、bag 和 avNNet 在它们各自的控制文件中被赋予了一个额外的参数，称为 allowParallel，默认为 TRUE。 当为 TRUE 时，如果注册了并行后端（例如 doMC），则代码将并行执行。 当allowParallel = FALSE 时，并行后端总是被忽略。 用例是当 rfe 或 sbf 调用 train. 如果使用具有 P 个处理器的并行后端，则这些功能的组合将创建 $P^2$进程。 由于某些操作比其他操作更能从并行化中受益，因此用户可以将计算资源集中用于特定功能。

train用来提高计算效率的另一个“技巧”是使用子模型；单个模型拟合可以产生多个调谐参数的预测。例如，在大多数增强模型的实现中，在B增强迭代上训练的模型可以为小于B的迭代生成模型预测。假设在以下网格上调整了gbm模型：

```R
## 生成参数网格
gbmGrid <-  expand.grid(interaction.depth = c(1, 5, 9),
                        n.trees = (1:15)*100,
                        shrinkage = 0.1,
                        n.minobsinnode = 20)
```

实际上，仅训练 3 个模型的创建对象，并从这些对象导出其他预测。 此技巧用于以下模型：ada、AdaBag、AdaBoost.M1、bagEarth、blackboost、blasso、BstLm、bstSm、bstTree、C5.0、C5.0Cost、cubist、earth、enet、foba、gamboost、gbm、glmboost  ，glmnet，kernelpls，lars，lars2，套索，lda2，leapBackward，leapForward，leapSeq，LogitBoost，pam，partDSA，pcr，PenalizedLDA，pls，relaxo，rfRules，rotationForest，rotationForestCp，rpart，rpart2，simplspcost，spikeCost  ，widekernelpls，xgbTree。

### 随机超参数搜索

在 train 中优化调整参数的默认方法是使用网格搜索。 这种方法通常是有效的，但在有许多调整参数的情况下，它可能效率低下。 **另一种方法是结合使用网格搜索和racing。 另一种方法是使用随机选择的调整参数组合来在较小程度上覆盖参数空间**。

在许多模型中，这有助于在相对较短的时间内找到合理的调整参数值。 但是，在某些模型中，小搜索字段中的效率可以抵消其他优化。 例如，caret中的许多模型利用“子模型技巧”，其中评估 M 个调整参数组合，可能远少于 M 个模型拟合所需的数量。 当使用简单的网格搜索时，最好利用这种方法。 因此，**对以下型号代码使用随机搜索可能效率低下**：

`ada`, `AdaBag`, `AdaBoost.M1`, `bagEarth`, `blackboost`, `blasso`, `BstLm`, `bstSm`, `bstTree`, `C5.0`, `C5.0Cost`, `cubist`, `earth`, `enet`, `foba`, `gamboost`, `gbm`, `glmboost`, `glmnet`, `kernelpls`, `lars`, `lars2`, `lasso`, `lda2`, `leapBackward`, `leapForward`, `leapSeq`, `LogitBoost`, `pam`, `partDSA`, `pcr`, `PenalizedLDA`, `pls`, `relaxo`, `rfRules`, `rotationForest`, `rotationForestCp`, `rpart`, `rpart2`, `rpartCost`, `simpls`, `spikeslab`, `superpc`, `widekernelpls`, `xgbDART`, `xgbTree`.

最后，很多被train包裹的模型参数很少。 参数的平均数量为 2。

要使用随机搜索，trainControl 中提供了另一个称为search的选项。 此参数的可能值为“grid”和“random”。 caret中包含的内置模型包含生成随机调整参数组合的代码。 唯一组合的总数由要训练的 tuneLength 选项指定。

同样，我们将使用来自上一个训练页面的声纳数据，通过查看总共 30 个调整参数组合来演示具有正则化判别分析的方法：

```R
library(mlbench)
data(Sonar)

library(caret)
set.seed(998)
inTraining <- createDataPartition(Sonar$Class, p = .75, list = FALSE)
training <- Sonar[ inTraining,]
testing  <- Sonar[-inTraining,]

fitControl <- trainControl(method = "repeatedcv",
                           number = 10,
                           repeats = 10,
                           classProbs = TRUE,
                           summaryFunction = twoClassSummary,
                           search = "random")

set.seed(825)
rda_fit <- train(Class ~ ., data = training, 
                  method = "rda",
                  metric = "ROC",
                  tuneLength = 30,
                  trControl = fitControl)
rda_fit

## Regularized Discriminant Analysis 
## 
## 157 samples
##  60 predictor
##   2 classes: 'M', 'R' 
## 
## No pre-processing
## Resampling: Cross-Validated (10 fold, repeated 10 times) 
## Summary of sample sizes: 141, 142, 141, 142, 141, 142, ... 
## Resampling results across tuning parameters:
## 
##   gamma       lambda       ROC        Sens       Spec     
##   0.03177874  0.767664044  0.8662029  0.7983333  0.7600000
##   0.03868192  0.499283304  0.8526513  0.8120833  0.7600000
##   0.11834801  0.974493793  0.8379266  0.7780556  0.7428571
##   0.12391186  0.018063038  0.8321825  0.8112500  0.7233929
##   0.13442487  0.868918547  0.8590501  0.8122222  0.7528571
##   0.19249104  0.335761243  0.8588070  0.8577778  0.7030357
##   0.23568481  0.064135040  0.8465402  0.8372222  0.7026786
##   0.23814584  0.986270274  0.8363070  0.7623611  0.7532143
##   0.25082994  0.674919744  0.8700918  0.8588889  0.7010714
##   0.28285931  0.576888058  0.8706250  0.8650000  0.6871429
##   0.29099029  0.474277013  0.8681548  0.8687500  0.6844643
##   0.29601805  0.002963208  0.8465476  0.8419444  0.6973214
##   0.31717364  0.943120266  0.8440030  0.7863889  0.7444643
##   0.33633553  0.283586169  0.8650794  0.8626389  0.6878571
##   0.41798776  0.881581948  0.8540253  0.8076389  0.7346429
##   0.45885413  0.701431940  0.8704588  0.8413889  0.7026786
##   0.48684373  0.545997273  0.8713442  0.8638889  0.6758929
##   0.48845661  0.377704420  0.8700818  0.8783333  0.6566071
##   0.51491517  0.592224877  0.8705903  0.8509722  0.6789286
##   0.53206420  0.339941226  0.8694320  0.8795833  0.6523214
##   0.54020648  0.253930177  0.8673239  0.8747222  0.6546429
##   0.56009903  0.183772303  0.8652059  0.8709722  0.6573214
##   0.56472058  0.995162379  0.8354911  0.7550000  0.7489286
##   0.58045730  0.773613530  0.8612922  0.8262500  0.7089286
##   0.67085142  0.287354882  0.8686062  0.8781944  0.6444643
##   0.69503284  0.348973440  0.8694742  0.8805556  0.6417857
##   0.72206263  0.653406920  0.8635937  0.8331944  0.6735714
##   0.76035804  0.183676074  0.8642560  0.8769444  0.6303571
##   0.86234436  0.272931617  0.8545412  0.8588889  0.6030357
##   0.98847635  0.580160726  0.7383358  0.7097222  0.6169643
## 
## ROC was used to select the optimal model using the largest value.
## The final values used for the model were gamma = 0.4868437 and lambda
##  = 0.5459973.
```

目前只有 ggplot 方法（而不是基本的绘图方法）。 此函数随机搜索的结果取决于调整参数的数量和类型。 在这种情况下，它会生成连续参数的散点图。

```R
ggplot(rda_fit) + theme(legend.position = "top")
```

![img](https://topepo.github.io/caret/random/random_plot-1.svg)

### 类不平衡的子抽样

在分类问题中，观察到的类别频率的差异会对模型拟合产生重大的负面影响。 解决这种类不平衡的一种技术是以减轻问题的方式对训练数据进行子采样。 用于此目的的抽样方法示例如下：

* 下采样：随机子集训练集中的所有类，以便它们的类频率与最不流行的类相匹配。 例如，假设训练集样本的 80% 是第一类，其余 20% 是第二类。 下采样将随机采样第一个类，使其与第二个类的大小相同（因此只有总训练集的 40% 用于拟合模型）。 caret包含一个函数 (downSample) 来执行此操作。
* 上采样：随机抽样（替换）少数类，使其与多数类的大小相同。 caret包含一个函数 (upSample) 来执行此操作。
* 混合方法：SMOTE 和 ROSE 等技术对多数类进行下采样并在少数类中合成新数据点。 有两个包（DMwR 和 ROSE）可以实现这些程序。

请注意，这种类型的抽样**不同于将数据拆分为训练集和测试集**。 你永远不会想要人为地平衡测试集； 它的类别频率应该与人们在“野外”看到的一致。 此外，上述过程**独立于重采样方法，例如交叉验证和bootstrap**。

在实践中，可以采用训练集，并在模型拟合之前对数据进行采样。 这种方法有两个问题:

* 首先，在模型调整期间，重采样期间生成的保持样本也会被浏览，并且可能无法反映未来预测将遇到的类别不平衡。 这可能会导致对性能的过度乐观估计。
* 其次，二次抽样过程可能会导致更多的模型不确定性。 在不同的子样本下，模型结果会有所不同吗？ 如上所述，重采样统计更有可能使模型看起来比实际更有效。

另一种方法是在通常的**重采样过程中包含二次采样**。 这也被提倡用于预处理和特征选择步骤。 这两个缺点是它可能会增加计算时间，并且还可能以其他方式使分析复杂化（请参阅下面有关陷阱的部分）。

#### 子采样技术

为了说明这些方法，让我们使用此方法模拟一些类不平衡的数据。 我们将模拟一个训练和测试集，其中每个包含 10000 个样本和大约 5.9% 的少数类率：

```R
library(caret)

set.seed(2969)
imbal_train <- twoClassSim(10000, intercept = -20, linearVars = 20)
imbal_test  <- twoClassSim(10000, intercept = -20, linearVars = 20)
table(imbal_train$Class)

## intercept控制类别不平衡程度
## Class1 Class2 
##   9411    589
```

让我们在模型调整之前创建不同版本的训练集：

```R
set.seed(9560)
down_train <- downSample(x = imbal_train[, -ncol(imbal_train)],
                         y = imbal_train$Class)
table(down_train$Class)   
## 
## Class1 Class2 
##    589    589

set.seed(9560)
up_train <- upSample(x = imbal_train[, -ncol(imbal_train)],
                     y = imbal_train$Class)                         
table(up_train$Class) 
## 
## Class1 Class2 
##   9411   9411
library(DMwR)

set.seed(9560)
smote_train <- SMOTE(Class ~ ., data  = imbal_train)                         
table(smote_train$Class) 
## 
## Class1 Class2 
##   2356   1767
library(ROSE)

set.seed(9560)
rose_train <- ROSE(Class ~ ., data  = imbal_train)$data                         
table(rose_train$Class) 
## 
## Class1 Class2 
##   4939   5061
```

对于这些数据，我们将使用袋装分类法，并使用5个重复的10倍CV估计ROC曲线下的面积。

```R
ctrl <- trainControl(method = "repeatedcv", repeats = 5,
                     classProbs = TRUE,
                     summaryFunction = twoClassSummary)

set.seed(5627)
orig_fit <- train(Class ~ ., data = imbal_train, 
                  method = "treebag",
                  nbagg = 50,
                  metric = "ROC",
                  trControl = ctrl)

set.seed(5627)
down_outside <- train(Class ~ ., data = down_train, 
                      method = "treebag",
                      nbagg = 50,
                      metric = "ROC",
                      trControl = ctrl)

set.seed(5627)
up_outside <- train(Class ~ ., data = up_train, 
                    method = "treebag",
                    nbagg = 50,
                    metric = "ROC",
                    trControl = ctrl)

set.seed(5627)
rose_outside <- train(Class ~ ., data = rose_train, 
                      method = "treebag",
                      nbagg = 50,
                      metric = "ROC",
                      trControl = ctrl)

set.seed(5627)
smote_outside <- train(Class ~ ., data = smote_train, 
                       method = "treebag",
                       nbagg = 50,
                       metric = "ROC",
                       trControl = ctrl
```

我们将整理重采样结果并创建一个包装器来估计测试集性能：

```R
outside_models <- list(original = orig_fit,
                       down = down_outside,
                       up = up_outside,
                       SMOTE = smote_outside,
                       ROSE = rose_outside)

outside_resampling <- resamples(outside_models)

test_roc <- function(model, data) {
  library(pROC)
  roc_obj <- roc(data$Class, 
                 predict(model, data, type = "prob")[, "Class1"],
                 levels = c("Class2", "Class1"))
  ci(roc_obj)
  }

outside_test <- lapply(outside_models, test_roc, data = imbal_test)
outside_test <- lapply(outside_test, as.vector)
outside_test <- do.call("rbind", outside_test)
colnames(outside_test) <- c("lower", "ROC", "upper")
outside_test <- as.data.frame(outside_test)

summary(outside_resampling, metric = "ROC")

## 
## Call:
## summary.resamples(object = outside_resampling, metric = "ROC")
## 
## Models: original, down, up, SMOTE, ROSE 
## Number of resamples: 50 
## 
## ROC 
##               Min.   1st Qu.    Median      Mean   3rd Qu.      Max. NA's
## original 0.9098237 0.9298348 0.9386021 0.9394130 0.9493394 0.9685873    0
## down     0.9095558 0.9282175 0.9453907 0.9438384 0.9596021 0.9836254    0
## up       0.9989350 0.9999980 1.0000000 0.9998402 1.0000000 1.0000000    0
## SMOTE    0.9697171 0.9782214 0.9834234 0.9817476 0.9857071 0.9928255    0
## ROSE     0.8782985 0.8941488 0.8980313 0.8993135 0.9056404 0.9203092    0

inside_test
##              lower       ROC     upper
## original 0.9130010 0.9247957 0.9365905
## down     0.9354534 0.9419704 0.9484875
## up       0.9353945 0.9431074 0.9508202
## SMOTE    0.9465262 0.9524213 0.9583164
## ROSE     0.9369170 0.9448367 0.9527563
```

ROC曲线下区域的训练集和测试集估计值似乎没有相关性。根据重采样结果，可以推断，向上采样几乎是完美的，而ROSE的表现相对较差。上采样表现如此出色的原因是，多数类中的样本是重复的，并且在模型构建和保持集中都有很大的潜力。本质上，这里的坚持并不是真正独立的样本。

实际上，所有的采样方法都是一样的（基于测试集）。无抽样的基本模型拟合的统计数据彼此相当一致（重抽样为0.939，测试集为0.925）。

#### 重采样期间的子采样

最新版本的 caret 允许用户在使用 train 时**指定子采样，以便在重采样内进行**。 上面显示的所有四种方法都可以使用简单的语法通过基本包访问。 如果您想使用自己的技术，或者想更改 SMOTE 或 ROSE 的某些参数，下面的最后一节将展示如何使用自定义子采样。

启用子采样的方法是在 trainControl 中使用另一个称为sampling的选项。 最基本的语法是使用带有采样方法名称的字符串，可以是“down”、“up”、“smote”或“rose”。 请注意，您需要安装 DMwR 和 ROSE 软件包才能分别使用 SMOTE 和 ROSE。

 一种复杂情况与预处理有关。 子采样应该在预处理之前还是之后？ 例如，如果您对数据进行下采样并使用 PCA 进行信号提取，是否应该从整个训练集估计负载？ 由于正在使用整个训练集，因此估计可能会更好，**但子样本可能会捕获 PCA 空间的一小部分。 没有任何明显的答案**。

默认行为是在预处理之前对数据进行二次采样。 这可以很容易地改变，下面给出了一个例子。

现在让我们重新运行我们的袋装树模型，同时在交叉验证内部进行采样：

```R
ctrl <- trainControl(method = "repeatedcv", repeats = 5,
                     classProbs = TRUE,
                     summaryFunction = twoClassSummary,
                     ## 新的选项:
                     sampling = "down")

set.seed(5627)
down_inside <- train(Class ~ ., data = imbal_train,
                     method = "treebag",
                     nbagg = 50,
                     metric = "ROC",
                     trControl = ctrl)

## 现在只需更改该选项
ctrl$sampling <- "up"

set.seed(5627)
up_inside <- train(Class ~ ., data = imbal_train,
                   method = "treebag",
                   nbagg = 50,
                   metric = "ROC",
                   trControl = ctrl)

ctrl$sampling <- "rose"

set.seed(5627)
rose_inside <- train(Class ~ ., data = imbal_train,
                     method = "treebag",
                     nbagg = 50,
                     metric = "ROC",
                     trControl = ctrl)

ctrl$sampling <- "smote"

set.seed(5627)
smote_inside <- train(Class ~ ., data = imbal_train,
                      method = "treebag",
                      nbagg = 50,
                      metric = "ROC",
                      trControl = ctrl)

## 
## Call:
## summary.resamples(object = inside_resampling, metric = "ROC")
## 
## Models: original, down, up, SMOTE, ROSE 
## Number of resamples: 50 
## 
## ROC 
##               Min.   1st Qu.    Median      Mean   3rd Qu.      Max. NA's
## original 0.9098237 0.9298348 0.9386021 0.9394130 0.9493394 0.9685873    0
## down     0.9140294 0.9381766 0.9453610 0.9438490 0.9492917 0.9684522    0
## up       0.8887678 0.9308075 0.9393226 0.9392084 0.9517913 0.9679569    0
## SMOTE    0.9203876 0.9453453 0.9520074 0.9508721 0.9596354 0.9746933    0
## ROSE     0.9305013 0.9442821 0.9489859 0.9511117 0.9572416 0.9756750    0

inside_test

##              lower       ROC     upper
## original 0.9130010 0.9247957 0.9365905
## down     0.9354534 0.9419704 0.9484875
## up       0.9353945 0.9431074 0.9508202
## SMOTE    0.9465262 0.9524213 0.9583164
## ROSE     0.9369170 0.9448367 0.9527563
```

 下图显示了ROC曲线下区域的差异以及此处所示方法的测试集结果。对每个重采样重复子采样过程，产生与测试集更一致的结果。

![img](https://topepo.github.io/caret/sampling/samp_insode_plot-1.svg)

#### 难题

用户应该意识到，在进行二次采样时，可能会发生一些事情，从而导致代码中出现问题。如前所述，**与预处理相关的采样时间就是这样一个问题**。其他的是：

* 因子变量中稀疏表示的类别可能变成零方差预测值，或者可能完全从模型中抽样。
* 进行采样的基本功能（例如SMOTE、downSample等）以非常不同的方式运行，这可能会影响结果。例如，SMOTE和ROSE将把预测变量输入参数转换为数据帧（即使从矩阵开始）。
* 目前，子采样不支持样本权重。
* 如果使用tuneLength指定搜索网格，请了解用于确定网格的数据尚未采样。在大多数情况下，这无关紧要，但如果网格创建过程受样本大小的影响，则最终可能会使用次优的调整网格。
* 对于某些需要更多样本而非参数的模型，减少样本大小可能会使您无法拟合模型。

#### 使用自定义子采样技术

用户可以创建自己类型的子采样过程。为此，可在trainControl的采样参数中使用替代语法。之前，我们使用了一个简单的字符串作为此参数的值。指定参数的另一种方法是使用具有三个（命名）元素的列表：

* name值是打印train对象时使用的字符串。它可以是任何字符串。
* func元素是执行子采样的函数。它应该有称为x和y的参数，分别包含预测值和结果数据。函数应该返回一个包含同名元素的列表。
* first元素是单个逻辑值，指示相对于预处理是否应首先进行子采样。值FALSE表示子采样函数将接收x和y的采样版本。

例如，使用简单向下采样时，采样参数的列表版本如下所示：

```R
down_inside$control$sampling
## $name
## [1] "down"
## 
## $func
## function(x, y)
##     downSample(x, y, list = TRUE)
## 
## $first
## [1] TRUE
```

作为另一个示例，假设我们希望使用SMOTE，但使用10个最近邻，而不是默认的5个。为此，我们可以围绕SMOTE函数创建一个简单的包装器，并调用此函数：

```R
smotest <- list(name = "SMOTE with more neighbors!",
                func = function (x, y) {
                  library(DMwR)
                  dat <- if (is.data.frame(x)) x else as.data.frame(x)
                  dat$.y <- y
                  dat <- SMOTE(.y ~ ., data = dat, k = 10)
                  list(x = dat[, !grepl(".y", colnames(dat), fixed = TRUE)], 
                       y = dat$.y)
                  },
                first = TRUE)
```

然后，控制对象将是：

```R
ctrl <- trainControl(method = "repeatedcv", repeats = 5,
                     classProbs = TRUE,
                     summaryFunction = twoClassSummary,
                     sampling = smotest)
```

### 在训练集中使用recipes

R 中的建模函数让您可以使用公式、x/y 接口或两者来指定模型。 公式很好，因为它们会为您处理很多细节（例如虚拟变量、交互等），因此您不必弄脏手。 它们工作得很好，但也有局限性。 他们最大的问题是并非所有建模函数都有公式接口（尽管 train 有助于解决这个问题）。

recipes是指定模型项的第三种方法，但也允许用于编码、操作和转换数据的一组广泛的预处理选项。 它们涵盖了许多公式无法自然完成的技术。

可以以类似于创建 dplyr 或 ggplot2 的方式逐步构建recipes。 包网站提供了如何使用包的示例并列出了可能的技术（称为步骤）。 然后可以使用recipes代替formula进行训练。

#### 为什么要学习这个？

这里有两个原因： 

* 更通用的数据预处理工具 插入符号的预处理工具有很多选项，但列表并不详尽，它们只会按特定顺序调用。 如果您想要更广泛的选项集，能够编写自己的预处理工具，或者按照您想要的顺序调用它们，那么您可以使用配方来做到这一点。

* 使用附加数据来衡量性能 在大多数建模函数中，包括train，大多数变量被指定为预测变量或结果。 对于recipes，有更多选择。 例如，当您计算模型的执行情况时，您可能希望数据集的特定列可用，例如：

  * 如果需要不同的分层变量（例如患者、邮政编码等）来进行正确的汇总或辅助 
  * 可能需要数据来根据模型结果计算预期的损益。

  为了正确获取这些数据，需要以与所有其他数据相同的方式提供和处理它们。 这意味着它们应该像所有其他数据一样被子或重新采样。 recipes让你做到这一点。

#### 一个例子

QSARdata 包包含几个化学数据集。 这些数据集包含不同潜在药物（此处称为“化合物”）的行。 对于每种化合物，都会测量一些重要的特性。 此插图将使用 AquaticTox 数据。 结果被称为“活动”，是**衡量化合物对人的危害程度的指标**。 我们希望在研发的药物发现阶段预测这一点。为此，根据化合物分子式计算一组分子描述符。 这些有很多不同类型，我们将使用二维 MOE 描述符集。 首先，让我们加载包并将数据放在一起：

```R
library(caret)
library(recipes)
library(dplyr)
library(QSARdata)

data(AquaticTox)
tox <- AquaticTox_moe2D
ncol(tox)
## [1] 221
## 将结果变量添加到数据框
tox$Activity <- AquaticTox_Outcome$Activity
```

我们将根据这些数据建立一个模型来预测活动。 一些注意事项：

* 化学描述符的一个共同方面是它们高度相关。 许多描述符通常测量同一事物的某些变化。 例如，在这些数据中，有 56 个潜在的预测因子可以测量不同的表面积。 通过**预过滤预测变量和/或使用降维技术来降低这些数据的维数可能是一个好主意**。
* 其他描述符是对分子某些类型方面的计数。 例如，一个预测变量是溴原子的数量。 绝大多数化合物缺乏溴，**这导致前面讨论的接近零方差的情况。 预先过滤这些可能是个好主意**。

此外，为了证明recipes的实用性，假设我们可以根据潜在药物的可制造性对它们进行评分。 我们可能想在整个数据集上建立一个模型，但**只对可以合理制造的化合物进行评估**。 为了说明，我们假设，随着化合物分子量的增加，其可制造性会降低。 为此，我们创建了一个新变量（可制造性manufacturability），它既不是结果也不是预测变量，但需要计算性能。

```R
tox <- tox %>%
  select(-Molecule) %>%
  ## 假设可制造性与化合物的分子量有关##
  mutate(manufacturability  = 1/moe2D_Weight) %>%
  mutate(manufacturability = manufacturability/sum(manufacturability))
```

对于此分析，我们将**使用基于可制造性列的权重来计算 RMSE，以便难处理的化合物对 RMSE 的影响较小**。

```R
model_stats <- function(data, lev = NULL, model = NULL) {
  
  stats <- defaultSummary(data, lev = lev, model = model)
  
  wt_rmse <- function (pred, obs, wts, na.rm = TRUE) 
  sqrt(weighted.mean((pred - obs)^2, wts, na.rm = na.rm))
  
  res <- wt_rmse(pred = data$pred,
                 obs = data$obs, 
                 wts = data$manufacturability)
  c(wRMSE = res, stats)
}
```

没有办法使用默认的 train 方法或使用 train.formula 来包含这个额外的变量。

现在，让我们逐步创建一个recipe。 首先，我们将使用公式方法来声明结果和预测变量，但更改可制造性变量的分析角色，使其仅在总结模型拟合时可用。

```R
tox_recipe <- recipe(Activity ~ ., data = tox) %>%
  add_role(manufacturability, new_role = "performance var")

tox_recipe

## Data Recipe
## 
## Inputs:
## 
##             role #variables
##          outcome          1
##  performance var          1
##        predictor        221
```

使用这个新角色，可制造性列将在执行汇总函数时可用，并且数据集的适当行将在重采样期间公开。 例如，如果要在执行模型期间调试 model_stats 函数，则data对象可能如下所示：

```
Browse[1]> head(data)
    obs manufacturability rowIndex     pred
1  3.40       0.002770707        3 3.376488
2  3.75       0.002621364       27 3.945456
3  3.57       0.002697900       33 3.389999
4  3.84       0.002919528       39 4.023662
5  4.41       0.002561416       53 4.482736
6  3.98       0.002838804       54 3.965465
```

多个变量可以具有此角色，以便可以使用多个列。

现在让我们在recipe中添加一些步骤.首先，我们删除稀疏和不平衡的预测变量：

### 自适应重采样

模型可以从调整中显着受益，但事先很少知道最佳值。  train 可用于定义可能点的网格，重采样可用于为每个调整参数组合生成良好的性能估计。 然而，在标称重采样过程中，在选择哪些参数好哪些参数差之前，会为所有重采样计算所有调整参数组合。

 caret包含以一种专注于最佳设置附近的值的方式自适应地重新采样调整参数网格的能力。 See [this paper](http://arxiv.org/abs/1405.6974) for the details.

为了说明这一点，我们将使用前一页中的声纳数据。

```R
library(mlbench)
data(Sonar)
library(caret)
set.seed(998)
inTraining <- createDataPartition(Sonar$Class, p = .75, list = FALSE)
training <- Sonar[ inTraining,]
testing  <- Sonar[-inTraining,]
```

我们将使用与之前相同的调整策略但随机搜索来调整支持向量机模型：

```R
svmControl <- trainControl(method = "repeatedcv",
                           number = 10, repeats = 10,
                           classProbs = TRUE,
                           summaryFunction = twoClassSummary,
                           search = "random")
set.seed(825)
svmFit <- train(Class ~ ., data = training,
                method = "svmRadial", 
                trControl = svmControl, 
                preProc = c("center", "scale"),
                metric = "ROC",
                tuneLength = 15)
```

使用这种方法，最佳调整参数是 RBF 内核参数为 0.0301，成本值为 9.091958。 要使用自适应过程，trainControl 选项需要一些额外的参数：

* min 是将用于每个调整参数的最小重采样数。 默认值为 5，增加它会降低自适应重采样产生的加速，但也会增加找到好的模型的可能性
* alpha 是用于删除参数设置的置信水平。 迄今为止，该值还没有显示出太大的影响。
* method是线性模型的“gls”或布拉德利-特里模型的“BT”。 当您期望模型做得很好（例如，ROC 曲线下的区域接近 1）或有大量调整参数设置时，后者可能更有用。
* complete 是一个逻辑值，它指定如果 train 在重采样结束之前找到最佳解决方案，它是否应该生成完整的重采样集。 如果您想知道最佳参数设置并且不太关心估计的性能值，则此处的值 FALSE 是合适的。

 新代码如下。 回想一下，在模型拟合之前设置随机数种子将确保相同的重采样以及相同的随机网格。

```R
adaptControl <- trainControl(method = "adaptive_cv",
                             number = 10, repeats = 10,
                             adaptive = list(min = 5, alpha = 0.05, 
                                             method = "gls", complete = TRUE),
                             classProbs = TRUE,
                             summaryFunction = twoClassSummary,
                             search = "random")

set.seed(825)
svmAdapt <- train(Class ~ ., data = training,
                  method = "svmRadial", 
                  trControl = adaptControl, 
                  preProc = c("center", "scale"),
                  metric = "ROC",
                  tuneLength = 15)
```

搜索在重采样的第 14 次迭代中完成了调整参数，并且比原始分析快 1.5 倍。 此处，最佳调整参数是 RBF 内核参数为 0.0301，成本值为 9.091958。 这些与之前的设置很接近，导致 ROC 曲线下面积的差异为 0，而自适应方法使用的模型少了 1295 个。

**请记住，此方法是实验性的**，因此请将任何问题或错误报告发送给包维护者。

### 变量重要性

可变重要性评估函数可以分为两组：使用模型信息的和不使用模型信息的。 使用基于模型的方法的优点是与模型性能更紧密地联系在一起，并且它可能能够将预测变量之间的相关结构合并到重要性计算中。 不管重要性是如何计算的：对于大多数分类模型，每个预测器对每个类别都有一个单独的变量重要性（分类树、袋装树和提升树除外。

除非将 varImp.train 的 scale 参数设置为 FALSE，否则所有重要度量都将缩放到最大值 100。

#### 模型特定指标

以下方法可用于估算每个变量对模型的贡献：

线性模型：使用每个模型参数的t统计量的绝对值。

随机森林：来自R软件包：“对于每棵树，记录数据包外部分的预测精度。然后，在排列每个预测变量之后也会执行相同的操作。然后在所有树上平均两个精度之间的差异，并用标准误差进行标准化。对于回归，MSE根据每个树的现成数据计算，然后在排列变量后计算相同的MSE。通过标准误差对差异进行平均和归一化。如果变量的标准误差等于0，则不进行除法。”

偏最小二乘法：此处的变量重要性度量基于绝对回归系数的加权和。权重是PLS组件数量平方和减少的函数，并针对每个结果单独计算。因此，系数的贡献与平方和的减少成比例加权。

递归分区：将归因于每次拆分的每个变量的损失函数（例如均方误差）的减少量制成表格，并返回总和。 此外，由于可能存在重要但未在拆分中使用的候选变量，因此也会在每个拆分中列出排名靠前的竞争变量。 这可以使用 rpart.control 中的 maxcompete 参数关闭。 当响应是一个因素时，此方法当前不提供特定于类的重要性度量。

袋装树：将与单个树相同的方法应用于所有自举树，并返回总重要性提升树：此方法使用与单个树相同的方法，但对每次提升迭代的重要性求和（请参阅 gbm 包小插图 ）。

多元自适应回归样条：MARS模型包括一个向后消除特征选择例程，用于查看广义交叉验证（GCV）估计误差的减少情况。varImp函数跟踪每个预测值的模型统计数据（如GCV）的变化，并在每个预测值的特征添加到模型时累积统计数据的减少。此总减少量用作可变重要性度量。如果预测变量从未在任何MARS基函数中使用过，则其重要性值为零。有三种统计数据可用于估算MARS模型中的可变重要性。使用varImp（object，value=“gcv”）跟踪添加术语时广义交叉验证统计数据的减少。然而，在某些情况下，模型中保留的术语会导致GCV增加。MARS的负变量重要性值设置为零。未包含在最终修剪模型中的具有非零重要性的术语也列为零。或者，使用varImp（object，value=“rss”）在添加项时监视剩余平方和（rss）的变化，这永远不会是负数。此外，选项varImp（object，value=“nsubsets”）返回每个变量在子集中涉及的次数（在最终的修剪模型中）。2008年6月之前，varImp使用内部函数来估计MARS模型的重要性。目前，它是earth包中evimp函数的包装器。

最近收缩质心：类质心和整体质心之间的差异用于衡量变量影响（请参阅 pamr.predict）。 类质心与数据整体中心的差异越大，类之间的间隔就越大。 当将 pamrtrained 类的对象提供给 varImp 时，必须提供训练集预测。

Cubist： Cubist 输出包含变量使用统计信息。 它给出了在条件和/或线性模型中使用每个变量的次数百分比。 请注意，此输出可能与 summary.cubist 的输出中显示的规则不一致。 在树的每次拆分时，Cubist 都会保存一个线性模型（在特征选择之后），该模型允许包含当前拆分中使用的每个变量或它上面的任何拆分的项。  Quinlan (1992) 讨论了一种平滑算法，其中每个模型预测都是父模型和子模型沿树的线性组合。 因此，最终预测是从初始节点到终端节点的所有线性模型的函数。  Cubist 输出中显示的百分比反映了预测中涉及的所有模型（与输出中显示的终端模型相反）。 这里使用的变量重要性是规则条件和模型中使用的线性组合。

#### 独立于模型的指标

如果没有模型特定的方法来估计重要性（或在 varImp 中使用参数 useModel = FALSE），则使用“过滤器”方法单独评估每个预测变量的重要性。

对于分类，对每个预测变量进行 ROC 曲线分析。 对于两类问题，对预测变量数据应用一系列截止值来预测类别。 计算每个临界值的灵敏度和特异性，并计算 ROC 曲线。 梯形规则用于计算 ROC 曲线下的面积。 该区域用作变量重要性的度量。 对于多类结果，问题被分解为所有成对问题，并为每个类对计算曲线下面积（即第 1 类与第 2 类、第 2 类与第 3 类等）。 对于特定类别，相关成对 AUC 曲线下的最大面积用作变量重要性度量。

对于回归，评估每个预测变量与结果之间的关系。 参数 nonpara 用于选择模型拟合技术。 当 nonpara = FALSE 时，拟合线性模型并使用预测变量斜率的 t 值的绝对值。 否则，loess平滑器将在结果和预测变量之间拟合。 该模型的 $R^2$统计量是针对仅截距空模型计算的。 该数字作为变量重要性的相对度量返回。

#### 例子

在模型训练网站上，有几个模型适合示例数据。 **提升树模型有一个内置的变量重要性分数，但支持向量机或正则化判别分析模型都没有**。

```R
gbmImp <- varImp(gbmFit3, scale = FALSE)
gbmImp

## 
##   only 20 most important variables shown (out of 60)
## 
##     Overall
## V11  21.308
## V12  11.896
## V36   9.810
## V52   9.793
## V51   9.324
## V46   5.536
## V13   5.005
## V9    4.396
## V31   4.356
## V37   4.233
## V48   4.109
## V3    3.814
## V23   3.554
## V5    3.544
## V1    3.491
## V43   3.347
## V45   3.110
## V17   3.064
## V27   2.941
## V54   2.819
```

该函数会自动将重要性分数缩放到 0 到 100 之间。使用 scale = FALSE 可避免此标准化步骤。

要获得每个预测变量的 ROC 曲线下面积，可以使用 filterVarImp 函数。 为每个类计算 ROC 曲线下的面积。

```R
roc_imp <- filterVarImp(x = training[, -ncol(training)], y = training$Class)
head(roc_imp)
```

或者，对于没有实现（或存在）内置重要性分数的模型，仍然可以使用 varImp 来获取分数。 对于 SVM 分类模型，默认行为是计算 ROC 曲线下的面积。

```R
roc_imp2 <- varImp(svmFit, scale = FALSE)
roc_imp2

## ROC curve variable importance
## 
##   only 20 most important variables shown (out of 60)
## 
##     Importance
## V11     0.7758
## V12     0.7586
## V9      0.7320
## V13     0.7291
## V10     0.7187
## V52     0.7074
## V46     0.7034
## V49     0.7022
## V51     0.6892
## V45     0.6813
## V47     0.6806
## V48     0.6704
## V1      0.6695
## V4      0.6636
## V5      0.6601
## V6      0.6511
## V2      0.6470
## V36     0.6460
## V3      0.6443
## V44     0.6417
```

对于从 varImp.train 生成的重要性分数，可以使用绘图方法来**可视化**结果。 在下图中，顶部选项用于使图像更具可读性。

```R
plot(gbmImp, top = 20)
```

![img](https://topepo.github.io/caret/varimp/varImp_gbm_plot-1.svg)

### 其他模型函数

#### 另一个 k-最近邻函数

knn3 是用于 k-近邻分类的函数。 这个特定的实现是对 knn C 代码的修改，并返回所有类的投票信息（knn 只返回获胜类的概率）。 有一个公式界面通过

```R
knn3(formula, data)
## or by passing the training data directly
##x 是矩阵或数据框，y 是因子向量
knn3(x, y)
```

还有print和predict方法。

对于 mlbench 包中的 Sonar 数据，我们可以拟合一个 11-最近邻模型：

```R
library(caret)
library(mlbench)
data(Sonar)
set.seed(808)
inTrain <- createDataPartition(Sonar$Class, p = 2/3, list = FALSE)
## 将预测变量和类保存在不同的对象中
sonarTrain <- Sonar[ inTrain, -ncol(Sonar)]
sonarTest  <- Sonar[-inTrain, -ncol(Sonar)]

trainClass <- Sonar[ inTrain, "Class"]
testClass  <- Sonar[-inTrain, "Class"]

centerScale <- preProcess(sonarTrain)
centerScale

## 由 139 个样本和 60 个变量创建
## 
## Pre-processing:
##   - centered (60)
##   - ignored (0)
##   - scaled (60)

training <- predict(centerScale, sonarTrain)
testing <- predict(centerScale, sonarTest)

knnFit <- knn3(training, trainClass, k = 11)
knnFit

## 11-nearest neighbor model
## Training set outcome distribution:
## 
##  M  R 
## 74 65

predict(knnFit, head(testing), type = "prob")

##               M         R
## [1,] 0.45454545 0.5454545
## [2,] 0.81818182 0.1818182
## [3,] 0.63636364 0.3636364
## [4,] 0.09090909 0.9090909
## [5,] 0.54545455 0.4545455
## [6,] 0.45454545 0.5454545
```

类似地，caret 包含一个 k 最近邻回归函数 knnreg。 它返回邻居的平均结果。

#### 偏最小二乘判别分析

plsda 函数是 pls 包中 plsr 函数的包装器，它不需要公式接口并且**可以将因子结果作为参数**。 这些类被分解为虚拟变量（每个类一个）。 这些 0/1 虚拟变量通过偏最小二乘法建模。

从这个模型中，有两种方法可以计算类别预测和概率：

* 可以在每个样本的基础上使用 softmax 技术对分数进行归一化，使它们更像“概率”（即它们总和为 1 并且介于 0 和 1 之间）。对于每个类 X 的模型预测向量 , softmax 类概率计算为. 预测类只是具有最大模型预测的类, 或者等效地, 最大类概率. 这是 plsda 的默认行为.
* 贝叶斯规则可以应用于模型预测以形成后验概率。 在这里，训练集的模型预测与训练集结果一起用于为每个类别创建条件分布。 当预测新样本时，原始模型预测会通过这些条件分布运行，以生成每个类（以及先验）的后验概率。 可以通过指定 probModel = "Bayes" 来使用贝叶斯规则。 附加参数prior，可用于设置类的先验概率。

使用贝叶斯规则的优点是使用完整的训练集直接计算类别概率（与仅使用当前样本分数的 softmax 函数不同）。 这创建了更现实的概率估计，但缺点是必须为 ncomp 的每个值创建单独的贝叶斯模型，这更耗时。

对于声纳数据集，我们可以使用每种技术拟合两个 PLS 模型并预测测试集的类别概率。

```R
plsFit <- plsda(training, trainClass, ncomp = 20)
plsFit

## 偏最小二乘分类，采用核算法。
## softmax 函数用于计算类概率。
plsBayesFit <- plsda(training, trainClass, ncomp = 20,
                     probMethod = "Bayes")
plsBayesFit

## 偏最小二乘分类，采用核算法。
## 贝叶斯规则用于计算类概率。

predict(plsFit, head(testing), type = "prob")

## , , ncomp20
## 
##             M         R
## 2  0.02774255 0.9722574
## 5  0.47710154 0.5228985
## 8  0.89692329 0.1030767
## 11 0.06002366 0.9399763
## 13 0.07292981 0.9270702
## 14 0.60530446 0.3946955
```

与 plsda 类似，caret 也包含一个允许使用稀疏 PLS 进行分类的函数 splsda。 为每个类创建一个虚拟矩阵，并与 spls 包中的 spls 函数一起使用。  plsda 和 splsda 使用相同的方法来估计类别概率。

#### 袋装 MARS 和 FDA

多元自适应回归样条 (MARS) 模型，如分类/回归树，是不稳定的预测变量 (Breiman, 1996)。 这意味着训练数据中的小扰动可能会导致显着不同的模型。 袋装树和随机森林是利用这些不稳定性改进树模型的有效方法。  caret 包含一个函数 bagEarth，它通过 Earth 函数拟合 MARS 模型。 有公式和非公式接口。

此外，灵活的判别分析是线性判别分析的推广，可以使用非线性特征作为输入。 一种方法是使用 MARS 类型的特征对样本进行分类。 函数 bagFDA 拟合一组bootstrap样本的 FDA 模型，并聚合预测以减少噪声。

此函数已被弃用，取而代之的是 bag 函数。

#### 装袋

bag 函数为装袋分类和回归模型提供了一个通用平台。 与 rfe 和 sbf 一样，它是开放的，模型是通过声明模型拟合和预测代码的函数来指定的（并且包中存在几个内置函数集）。 功能 bagControl 具有指定功能的选项（更多详细信息如下）。

该函数还有一些非标准特性：

* 参数 var 可以在每次装袋迭代时启用预测变量的随机采样。 这是为了以与随机森林相同的精神去关联袋装模型（尽管这里对整个模型进行了一次采样）。 默认是使用每个模型的所有预测变量。
* bagControl 函数有一个名为 downSample 的逻辑参数，它对于具有严重类不平衡的分类模型很有用。  Bootstrapped 数据集被减少，以便频率较大的类的样本大小与少数类的样本大小相同。

* 如果 foreach 包的并行后端已加载并注册，则可以并行训练袋装模型。

该函数的控制函数需要以下参数：

The `fit` Function：

输入： 

x：训练集预测数据的数据框。

y：训练集结果。

... 从 train 传递给此函数的参数 输出是与训练模型和预测所需的任何其他对象对应的对象。 来自 MASS 包的线性判别分析模型的一个简单示例是：

```R
function(x, y, ...) {
   library(MASS)
   lda(x, y, ...)
}
```

The `pred` Function

这应该是一个为新样本生成预测变量的函数。
    输入： 

object：由 fit 模块生成的对象。

x：预测数据的矩阵或数据框。

输出是数字向量（用于回归）、用于分类的因子（或字符）向量或类概率的矩阵/数据框。 对于分类，最好平均类概率而不是使用类预测的投票。 再次使用 lda 示例：

```R
## predict.lda returns the class and the class probabilities
## We will average the probabilities, so these are saved
function(object, x) predict(object, x)$posterior

## function(object, x) predict(object, x)$posterior
```

The `aggregate` Function

这应该是一个函数，它从组成模型中获取预测并将它们转换为每个样本的单个预测。略

### 衡量模型效果

#### 回归衡量

函数 postResample 可用于估计数值结果的均方根误差 (RMSE)、简单 $R^2$ 和平均绝对误差 (MAE)。 例如：

```R
library(mlbench)
data(BostonHousing)

set.seed(280)
bh_index <- createDataPartition(BostonHousing$medv, p = .75, list = FALSE)
bh_tr <- BostonHousing[ bh_index, ]
bh_te <- BostonHousing[-bh_index, ]

set.seed(7279)
lm_fit <- train(medv ~ . + rm:lstat,
                data = bh_tr, 
                method = "lm")
bh_pred <- predict(lm_fit, bh_te)

lm_fit
## Linear Regression 
## 
## 381 samples
##  13 predictor
## 
## No pre-processing
## Resampling: Bootstrapped (25 reps) 
## Summary of sample sizes: 381, 381, 381, 381, 381, 381, ... 
## Resampling results:
## 
##   RMSE      Rsquared   MAE     
##   4.374098  0.7724562  2.963927
## 
## Tuning parameter 'intercept' was held constant at a value of TRUE
```

```r
postResample(pred = bh_pred, obs = bh_te$medv)
##      RMSE  Rsquared       MAE 
## 4.0927043 0.8234427 2.8163731
```

关于如何通过caret计算 R2 的说明：它采用直接方法计算观察值和预测值（即 R）之间的相关性并对值求平方。 当模型较差时，这可能导致该估计量与从线性回归模型导出的更广为人知的估计值之间存在差异。 最值得注意的是，相关方法不会产生 $R^2$ 的负值（理论上无效）。 可以在 Kvalseth 1985 中找到这些和其他估计量的比较。

#### 预测类别的衡量

在继续之前，让我们组成一些测试集数据：

```
set.seed(144)
true_class <- factor(sample(paste0("Class", 1:2), 
                            size = 1000,
                            prob = c(.2, .8), replace = TRUE))
true_class <- sort(true_class)
class1_probs <- rbeta(sum(true_class == "Class1"), 4, 1)
class2_probs <- rbeta(sum(true_class == "Class2"), 1, 2.5)
test_set <- data.frame(obs = true_class,
                       Class1 = c(class1_probs, class2_probs))
test_set$Class2 <- 1 - test_set$Class1
test_set$pred <- factor(ifelse(test_set$Class1 >= .5, "Class1", "Class2"))
```

我们希望这个模型能够很好地处理这些数据：

```R
ggplot(test_set, aes(x = Class1)) + 
  geom_histogram(binwidth = .05) + 
  facet_wrap(~obs) + 
  xlab("Probability of Class #1")
```

根据概率的典型 50% 截止值生成预测类，我们可以计算混淆矩阵，它显示了观察到的和预测的类的交叉表。 confusionMatrix函数可用于生成这些结果：

```
confusionMatrix(data = test_set$pred, reference = test_set$obs)

## Confusion Matrix and Statistics
## 
##           Reference
## Prediction Class1 Class2
##     Class1    183    141
##     Class2     13    663
##                                           
##                Accuracy : 0.846           
##                  95% CI : (0.8221, 0.8678)
##     No Information Rate : 0.804           
##     P-Value [Acc > NIR] : 0.0003424       
##                                           
##                   Kappa : 0.6081          
##                                           
##  Mcnemar's Test P-Value : < 2.2e-16       
##                                           
##             Sensitivity : 0.9337          
##             Specificity : 0.8246          
##          Pos Pred Value : 0.5648          
##          Neg Pred Value : 0.9808          
##              Prevalence : 0.1960          
##          Detection Rate : 0.1830          
##    Detection Prevalence : 0.3240          
##       Balanced Accuracy : 0.8792          
##                                           
##        'Positive' Class : Class1          
## 
```

对于两个类，此函数假定与事件对应的类是第一类级别（但这可以使用positive参数进行更改。

请注意，此处显示了许多统计数据。  “无信息率”是最大比例的观察类（在这个测试集中，2 类数据比 1 类数据多）。 还计算假设检验以评估整体准确率是否大于最大类别的准确率。 此外，“阳性事件”的流行率是根据数据（除非作为参数传入）、检测率（真实事件也被预测为事件的比率）和检测流行率（预测事件的流行率）计算的 .

如果事件的流行与测试集中看到的不同，则可以使用prevalence选项对此进行调整。

![img](https://topepo.github.io/caret/premade/cm.jpg)

当有三个或更多类时，confusionMatrix 会显示混淆矩阵和一组“**一对多**”的结果。 例如，在三类问题中，第一类的敏感性是针对第二类和第三类（以此类推）中的所有样本计算的。

混淆矩阵矩阵根据敏感性和特异性来确定错误。 在信息检索的情况下，准确率和召回率可能更合适。 在这种情况下，可以使用选项mode来获取这些统计信息：

```R
confusionMatrix(data = test_set$pred, reference = test_set$obs, mode = "prec_recall")

## Confusion Matrix and Statistics
## 
##           Reference
## Prediction Class1 Class2
##     Class1    183    141
##     Class2     13    663
##                                           
##                Accuracy : 0.846           
##                  95% CI : (0.8221, 0.8678)
##     No Information Rate : 0.804           
##     P-Value [Acc > NIR] : 0.0003424       
##                                           
##                   Kappa : 0.6081          
##                                           
##  Mcnemar's Test P-Value : < 2.2e-16       
##                                           
##               Precision : 0.5648          
##                  Recall : 0.9337          
##                      F1 : 0.7038          
##              Prevalence : 0.1960          
##          Detection Rate : 0.1830          
##    Detection Prevalence : 0.3240          
##       Balanced Accuracy : 0.8792          
##                                           
##        'Positive' Class : Class1          
## 
```

同样，positive参数可用于控制哪个因子水平与“找到”或“重要”文档或样本相关联。

有单独的函数称为`sensitivity`, `specificity`, `posPredValue`, `negPredValue`, `precision`, `recall`, and `F_meas`.。

此外，还可以使用confusionMatrix.train 获得训练集的重采样估计。 对于每次重采样迭代，都会从保留样本中创建一个混淆矩阵，并且可以汇总这些值以诊断模型拟合问题。

这些值是重采样期间保留样本落在混淆矩阵中的百分比。 有几种方法可以对这些值进行归一化。 有关详细信息，请参阅 ?confusionMatrix.train。

train 使用的默认性能函数是 postResample，它生成准确率和 Kappa 统计信息：

```R
postResample(pred = test_set$pred, obs = test_set$obs)

##  Accuracy     Kappa 
## 0.8460000 0.6081345
```

如下所示，另一个名为 twoClassSummary 的函数可**用于使用默认概率截止值获取灵敏度和特异性**。 另一个函数 multiClassSummary 可以在有三个或更多类但都需要每个类的类概率时进行类似的计算。

##### 类概率的衡量

对于具有两个类别的数据，有专门的函数来衡量模型性能。 首先，twoClassSummary 函数计算 ROC 曲线下的面积以及 50% 截止值下的特异性和灵敏度。 请注意：

* 此函数使用第一类级别来定义感兴趣的“事件”。 要改变这一点，请使用函数的 lev 选项
* 每个类别概率的数据中必须有列（与结果的类别级别命名相同）

```R
twoClassSummary(test_set, lev = levels(test_set$obs))

##       ROC      Sens      Spec 
## 0.9560044 0.9336735 0.8246269
```

一个类似的函数可以用来得到类似的precision-recall值和precision-recall曲线下的面积：

```R
prSummary(test_set, lev = levels(test_set$obs))
```

此功能需要安装 MLmetrics 包。

 对于多类问题，还有其他函数可用于计算性能。 一，mnLogLoss 根据**类别概率计算多项式对数似然的负值（越小越好）**。 这可用于优化调整参数，但可能导致结果与其他度量（例如精度或 ROC 曲线下的面积）不一致，尤其是当其他度量接近其最佳可能值时。 该函数具有与上述其他函数类似的参数。 这是上面的两类数据：

```R
mnLogLoss(test_set, lev = levels(test_set$obs))
##  logLoss 
## 0.370626
```

此外，函数 multiClassSummary 计算许多相关指标： 

* 使用预测类别的总体准确度和 Kappa 统计量 
* 多项式对数损失的负数（如果类概率可用） 
* “one versus all”统计量的平均值，例如敏感性、特异性 、ROC 曲线下的面积等。

##### 提升曲线(Lift Curves)

![[公式]](https://www.zhihu.com/equation?tex=Lift%3D%5Cfrac%7B%5Cfrac%7BTP%7D%7BTP%2BFP%7D%7D%7B%5Cfrac%7BTP%2BFN%7D%7BTP%2BFP%2BTN%2BFN%7D%7D%3D%5Cfrac%7BPRE%7D%7B%E6%AD%A3%E4%BE%8B%E5%8D%A0%E6%AF%94%7D%5C%5C)

根据以上公式可知，**Lift指标可以这样理解：**在不使用模型的情况下，我们用先验概率估计正例的比例，即上式子分母部分，以此作为正例的命中率；利用模型后，我们不需要从整个样本中来挑选正例，只需要从我们预测为正例的那个样本的子集 ![[公式]](https://www.zhihu.com/equation?tex=TP%2BFP) 中挑选正例，这时正例的命中率为 ![[公式]](https://www.zhihu.com/equation?tex=PRE) ，后者除以前者即可得提升值**Lift。**

另一方面，lift函数可用于评估可以捕获一定百分比的命中的概率阈值。 该函数需要一组样本概率预测（不是来自训练集）和真实的类别标签。 例如，我们可以使用 twoClassSim 函数模拟两类样本，并将一组模型拟合到训练集：

```R
set.seed(2)
lift_training <- twoClassSim(1000)
lift_testing  <- twoClassSim(1000)

ctrl <- trainControl(method = "cv", classProbs = TRUE,
                     summaryFunction = twoClassSummary)

set.seed(1045)
fda_lift <- train(Class ~ ., data = lift_training,
                  method = "fda", metric = "ROC",
                  tuneLength = 20,
                  trControl = ctrl)
set.seed(1045)
lda_lift <- train(Class ~ ., data = lift_training,
                  method = "lda", metric = "ROC",
                  trControl = ctrl)

library(C50)
set.seed(1045)
c5_lift <- train(Class ~ ., data = lift_training,
                 method = "C5.0", metric = "ROC",
                 tuneLength = 10,
                 trControl = ctrl,
                 control = C5.0Control(earlyStopping = FALSE))

## Generate the test set results
lift_results <- data.frame(Class = lift_testing$Class)
lift_results$FDA <- predict(fda_lift, lift_testing, type = "prob")[,"Class1"]
lift_results$LDA <- predict(lda_lift, lift_testing, type = "prob")[,"Class1"]
lift_results$C5.0 <- predict(c5_lift, lift_testing, type = "prob")[,"Class1"]
head(lift_results)
```

lift函数进行计算，相应的plot函数用于绘制升力曲线（尽管有些人称之为增益曲线）。  value 参数创建参考线：

```R
trellis.par.set(caretTheme())
lift_obj <- lift(Class ~ FDA + LDA + C5.0, data = lift_results)
plot(lift_obj, values = 60, auto.key = list(columns = 3,
                                            lines = TRUE,
                                            points = FALSE))
```

还有一个用于lift对象的 ggplot 方法：

```R
ggplot(lift_obj, values = 60)
```

![img](https://topepo.github.io/caret/performance/perf_lift_obj_gg-1.svg)

从中我们可以看到，要找到 60% 的命中，可以对略多于 30% 的数据进行采样（按概率预测排序时）。  LDA 模型的表现比其他两个模型差一些。

##### 校准曲线(Calibration Curves)

校准曲线可用于表征预测的类别概率与观察到的事件率的一致性。

  gbm 包、rms 包（和其他）中的其他函数也可以生成校准曲线。 该函数的格式与lift函数非常相似： 

```R
trellis.par.set(caretTheme())
cal_obj <- calibration(Class ~ FDA + LDA + C5.0,
                       data = lift_results,
                       cuts = 13)
plot(cal_obj, type = "l", auto.key = list(columns = 3,
                                          lines = TRUE,
                                          points = FALSE))
```

![img](https://topepo.github.io/caret/performance/perf_calib_obj-1.svg)

还有一个 ggplot 方法可以显示子集内部比例的置信区间：

```R
ggplot(cal_obj)
```

![img](https://topepo.github.io/caret/performance/perf_calib_gg-1.svg)

### 特征选择概述

#### Models with Built-In Feature Selection

许多可以使用 caret 的 train 函数访问的模型生成的预测方程不一定使用所有预测变量。 这些模型被认为具有内置特征选择：

```R
ada`, `AdaBag`, `AdaBoost.M1`, `adaboost`, `bagEarth`, `bagEarthGCV`, `bagFDA`, `bagFDAGCV`, `bartMachine`, `blasso`, `BstLm`, `bstSm`, `C5.0`, `C5.0Cost`, `C5.0Rules`, `C5.0Tree`, `cforest`, `chaid`, `ctree`, `ctree2`, `cubist`, `deepboost`, `earth`, `enet`, `evtree`, `extraTrees`, `fda`, `gamboost`, `gbm_h2o`, `gbm`, `gcvEarth`, `glmnet_h2o`, `glmnet`, `glmStepAIC`, `J48`, `JRip`, `lars`, `lars2`, `lasso`, `LMT`, `LogitBoost`, `M5`, `M5Rules`, `msaenet`, `nodeHarvest`, `OneR`, `ordinalNet`, `ordinalRF`, `ORFlog`, `ORFpls`, `ORFridge`, `ORFsvm`, `pam`, `parRF`, `PART`, `penalized`, `PenalizedLDA`, `qrf`, `ranger`, `Rborist`, `relaxo`, `rf`, `rFerns`, `rfRules`, `rotationForest`, `rotationForestCp`, `rpart`, `rpart1SE`, `rpart2`, `rpartCost`, `rpartScore`, `rqlasso`, `rqnc`, `RRF`, `RRFglobal`, `sdwd`, `smda`, `sparseLDA`, `spikeslab`, `wsrf`, `xgbDART`, `xgbLinear`, `xgbTree
```

 许多函数都有一个称为predictors的辅助方法，该方法返回一个向量，指示最终模型中使用了哪些预测器。

**在许多情况下，使用具有内置特征选择的这些模型将比在模型外部搜索正确预测变量的算法更有效**。 内置特征选择通常将预测器搜索算法与参数估计相结合，并且通常使用单个目标函数（例如错误率或可能性）进行优化。

##### 特征选择方法

除了具有内置特征选择的模型外，大多数减少预测变量数量的方法可以分为两大类。 使用 John、Kohavi 和 Pfleger (1994) 的术语：

* 包装方法使用添加和/或删除预测变量的过程评估多个模型，以找到最大化模型性能的最佳组合。 本质上，包装器方法是一种搜索算法，它将预测器视为输入，并利用模型性能作为要优化的输出。  caret 具有基于递归特征消除、遗传算法和模拟退火的包装方法。
* 过滤器方法评估预测模型之外的预测变量的相关性，然后仅对通过某些标准的预测变量进行建模。 例如，对于分类问题，可以单独评估每个预测器，以检查它与观察到的类之间是否存在合理的关系。 只有具有重要关系的预测变量才会包含在分类模型中。  Saeys、Inza 和 Larranaga (2007) 调查了过滤方法。  caret 有一个使用单变量过滤器的通用框架。

这两种方法都有优点和缺点。 过滤器方法通常比包装器方法计算效率更高，但选择标准与模型的有效性没有直接关系。 此外，大多数过滤器方法分别评估每个预测器，因此，可能会选择冗余（即高度相关）的预测器，并且变量之间的重要相互作用将无法量化。 包装器方法的缺点是评估了许多模型（这可能还需要参数调整），从而增加了计算时间。 与包装器过度配合的风险也增加了。

#### 外部验证

重要的是要认识到特征选择是模型构建过程的一部分，因此应该进行外部验证。 正如参数调整会导致过度拟合一样，特征选择也会过度拟合预测变量（尤其是在使用搜索包装器时）。 在用于特征选择的每个 **caret**函数中，选择过程都包含在任何重采样循环中。 有关此问题的演示，请参见 Ambroise 和 McLachlan (2002)。

### 使用单变量过滤器的特征选择

#### 单变量过滤器

特征选择的另一种方法是使用简单的单变量统计方法预先筛选预测变量，然后仅使用那些在后续模型步骤中通过某些标准的预测变量。 **与递归选择类似，后续模型的交叉验证将有偏差，因为剩余的预测变量已经在数据集上进行了评估。 通过重采样进行的正确性能估计应包括特征选择步骤**。

例如，有人建议对于分类模型，可以通过进行某种 k 样本测试（其中 k 是类别数）来过滤预测变量，以查看预测变量的平均值是否在类别之间不同。 有时会使用 Wilcoxon 检验、t 检验和方差分析模型。 然后将在类别之间具有统计显着差异的预测变量用于建模。

caret函数 sbf（用于过滤器选择）可用于交叉验证此类特征选择方案。 与 rfe 类似，函数可以传递到 sbf 中用于计算组件：单变量过滤、模型拟合、预测和性能摘要（详细信息如下）。

该函数应用于整个训练集以及数据集的不同重采样版本。 由此，可以计算出适当考虑到特征选择步骤的可概括的性能估计。 此外，可以通过重采样跟踪预测器过滤器的结果，以了解过滤中的不确定性。

#### 基本语法

与 rfe 函数类似，sbf 的语法是：

```R
sbf(predictors, outcome, sbfControl = sbfControl(), ...)
## or
sbf(formula, data, sbfControl = sbfControl(), ...)
```

在这种情况下，使用 sbfControl 函数指定详细信息。 在这里，参数函数决定了不同的组件应该做什么。 这个参数应该有名为 filter、fit、pred 和 summary 的元素。

##### score function

该函数将预测变量和结果分别作为 x 和 y 对象的输入。 默认情况下，x 中的每个预测变量都单独传递给评分函数。 在这种情况下，该函数应该返回一个分数。 或者，可以使用 sbfControl 的多变量参数将所有预测变量暴露给函数。 在这种情况下，输出应该是一个命名的分数向量，其中名称对应于 x 的列名称。

有两个内置函数，称为 anovaScores 和 gamScores。  anovaScores 将结果视为自变量，将预测变量视为结果。 这样，零假设是不同类别的平均预测值相等。 对于回归，gamScores 使用广义可加模型将预测变量中的平滑样条拟合到结果，并测试以查看两者之间是否存在任何函数关系。 在每个函数中，p 值用作分数。

##### filter function

此函数将来自 score 函数的分数作为输入（在名为 score 的参数中）。 该函数还将训练集数据作为输入（参数称为 x 和 y）。 输出应该是一个命名的逻辑向量，其中的名称对应于 x 的列名。 值为 TRUE 的列将在后续模型中使用。

##### fit function

该组件与上述 rfe 特定功能非常相似。 对于 sbf，没有第一个或最后一个参数。 该函数应具有参数 x、y 和 ...。 x 中的数据已使用上述过滤器函数进行过滤。 拟合函数的输出应该是拟合模型。

对于某些数据集，没有预测器会在过滤器中幸存下来。 在这些情况下，无法计算带有预测变量的模型，但在最终结果中不应忽略缺乏可行的预测变量。 为了解决这个问题，caret 包含一个名为 nullModel 的模型函数，它拟合一个独立于任何预测变量的简单模型。 对于结果为数字的问题，该函数使用训练集结果的简单平均值来预测每个样本。 对于分类，模型使用训练数据中最普遍的类别来预测所有样本。

此函数可用于拟合组件函数，以在未选择预测变量的情况下“错误陷阱”。 例如，某些模型有几个内置函数。 对象 rfSBF 是一组函数，可用于拟合带有过滤的随机森林模型。 这里的 fit 函数使用 nullModel 来检查没有预测变量的情况：

```R
rfSBF$fit
## function (x, y, ...) 
## {
##     if (ncol(x) > 0) {
##         loadNamespace("randomForest")
##         randomForest::randomForest(x, y, ...)
##     }
##     else nullModel(y = y)
## }
## <bytecode: 0x7fa6cc2db540>
## <environment: namespace:caret>
```

##### summary and pred function

summary函数用于计算保留样本的模型性能。  pred 函数用于使用当前预测器集预测新样本。 这两个函数的参数和输出与前面描述的部分中讨论的汇总和预测函数相同。

#### 例子

回到 (Friedman, 1991) 中的示例，我们可以将另一个随机森林模型与使用前面描述的广义加性模型方法预先过滤的预测变量进行拟合。

```R
filterCtrl <- sbfControl(functions = rfSBF, method = "repeatedcv", repeats = 5)
set.seed(10)
rfWithFilter <- sbf(x, y, sbfControl = filterCtrl)
rfWithFilter

## 
## Selection By Filter
## 
## Outer resampling method: Cross-Validated (10 fold, repeated 5 times) 
## 
## Resampling performance:
## 
##   RMSE Rsquared  MAE RMSESD RsquaredSD  MAESD
##  3.407   0.5589 2.86 0.5309     0.1782 0.5361
## 
## Using the training set, 6 variables were selected:
##    real2, real4, real5, bogus2, bogus17...
## 
## During resampling, the top 5 selected variables (out of a possible 13):
##    real2 (100%), real4 (100%), real5 (100%), bogus44 (76%), bogus2 (44%)
## 
## On average, 5.5 variables were selected (min = 4, max = 8)
```

在这种情况下，训练集表明应该在随机森林模型中使用 6，但重采样结果表明这个数字存在一些变化。 使用了一些信息性预测变量，但保留了其他一些错误的预测变量。

与 rfe 类似，也有predictors`, `densityplot`, `histogram` and `varImp的方法。

### 递归特征消除

#### 向后选择

首先，该算法使模型适合所有预测变量。 每个预测器都使用它对模型的重要性进行排名。 令 S 是一系列有序数字，这些数字是要保留的预测变量数量的候选值（S1 > S2，...）。 在特征选择的每次迭代中，Si 排名靠前的预测器被保留，模型被重新拟合并评估性能。 确定具有最佳性能的 Si 值，并使用顶部 Si 预测变量来拟合最终模型。 算法 1 有更完整的定义。

该算法有一个可选步骤（第 1.9 行），在该步骤中，预测器排名在缩减特征集的模型上重新计算。  Svetnik 等人 (2004) 表明，对于随机森林模型，在每一步重新计算排名时，性能都会下降。 但是，在初始排名不好的其他情况下（例如具有高度共线预测变量的线性模型），重新计算可以稍微提高性能。

![img](https://topepo.github.io/caret/premade/Algo1.png)

一个潜在的问题是对预测变量过度拟合，使得包装程序可以关注未来样本中未发现的训练数据的细微差别（即对预测器和样本过度拟合）。

例如，假设收集了大量无信息预测变量，并且其中一个这样的预测变量与结果随机相关。  RFE 算法会给这个变量一个很好的排名，并且预测误差（在同一数据集上）会降低。 需要进行不同的测试/验证才能发现该预测器没有提供信息。  Ambroise 和 McLachlan (2002) 将其称为“选择偏差”。

在当前的 RFE 算法中，训练数据至少用于三个目的：预测变量选择、模型拟合和性能评估。 除非样本数量很大，特别是与变量数量有关，否则一个静态训练集可能无法满足这些需求。

#### 重采样和外部验证

由于特征选择是模型构建过程的一部分，重采样方法（例如交叉验证、引导程序）应该在计算性能时考虑特征选择引起的可变性。 例如，算法 1 中的 RFE 过程可以在选择过程中估计第 1.7 行的模型性能。  Ambroise 和 McLachlan (2002) 以及 Svetnik 等人 (2004) 表明，不正确地使用重采样来衡量性能将导致模型在新样本上表现不佳。

为了获得包含由于特征选择引起的变化的性能估计，建议将算法 1 中的步骤封装在重采样的外层内（例如 10 倍交叉验证）。 算法 2 显示了使用重采样的算法版本。

 虽然这将提供更好的性能估计，但计算量更大。 对于可以访问具有多个处理器的机器的用户，算法 2（第 2.1 行）中的第一个 For 循环可以轻松并行化。 使用重采样的另一个复杂因素是每次迭代都会生成多个“最佳”预测变量列表。 乍一看，这似乎是一个缺点，但与基于单个固定数据集的排名相比，它确实提供了对预测变量重要性的更多概率评估。 在算法结束时，可以使用共识排名来确定要保留的最佳预测因子。

![img](https://topepo.github.io/caret/premade/Algo2.png)

#### 通过caret的递归特征消除

在caret中，算法 1 由函数 rfeIter 实现。 基于重采样的算法 2 在 rfe 函数中。 鉴于潜在的选择偏差问题，本文档重点介绍 rfe。 有几个参数：

* x，预测变量的矩阵或数据框，
* y,结果大小的向量（数字或因子），
* 大小，应测试的特定子集大小的整数向量（不需要包含 ncol(x)）
* rfeControl，可用于指定模型和预测、排名等方法的选项列表。

对于特定模型，必须在 rfeControl$functions 中指定一组函数。 下面的部分描述了这些子功能。 多个模型有许多预定义的函数集，包括：线性回归（在对象 lmFuncs 中）、随机森林 (rfFuncs)、朴素贝叶斯 (nbFuncs)、袋装树 (treebagFuncs) 和可用于 caret 的训练函数 (caretFuncs)。 如果模型具有必须在每次迭代时确定的调整参数，则后者很有用。

#### 一个例子

```R
library(caret)
library(mlbench)
library(Hmisc)
library(randomForest)
```

为了测试算法，使用了“Friedman 1”基准（Friedman，1991）。 方程产生了五个信息变量

![img](https://topepo.github.io/caret/premade/FEq.png)

在此处使用的模拟中：

```R
n <- 100
p <- 40
sigma <- 1
set.seed(1)
sim <- mlbench.friedman1(n, sd = sigma)
colnames(sim$x) <- c(paste("real", 1:5, sep = ""),
                     paste("bogus", 1:5, sep = ""))
bogus <- matrix(rnorm(n * p), nrow = n)
colnames(bogus) <- paste("bogus", 5+(1:ncol(bogus)), sep = "")
x <- cbind(sim$x, bogus)
y <- sim$y
```

在 50 个预测变量中，有 45 个纯噪声变量：5 个在 0 和1上是一致的 40 个是随机单变量标准正态。 预测变量居中并按比例缩放：

```R
normalization <- preProcess(x)
x <- predict(normalization, x)
x <- as.data.frame(x)
subsets <- c(1:5, 10, 15, 20, 25)
```

模拟将拟合子集大小为 25、20、15、10、5、4、3、2、1 的模型。

如前所述，为了拟合线性模型，可以使用 lmFuncs 函数集。 为此，使用 rfeControl 函数创建一个控制对象。 我们还指定应在算法 2 的第 2.1 行中使用重复的 10 折交叉验证。可以通过 rfeControl 的 number 参数（默认为 10）更改折叠数。 详细选项可防止产生大量输出。

```R
set.seed(10)

ctrl <- rfeControl(functions = lmFuncs,
                   method = "repeatedcv",
                   repeats = 5,
                   verbose = FALSE)

lmProfile <- rfe(x, y,
                 sizes = subsets,
                 rfeControl = ctrl)

lmProfile

## 
## Recursive feature selection
## 
## Outer resampling method: Cross-Validated (10 fold, repeated 5 times) 
## 
## Resampling performance over subset size:
## 
##  Variables  RMSE Rsquared   MAE RMSESD RsquaredSD  MAESD Selected
##          1 3.950   0.3790 3.381 0.6379     0.2149 0.5867         
##          2 3.552   0.4985 3.000 0.5820     0.2007 0.5807         
##          3 3.069   0.6107 2.593 0.6022     0.1582 0.5588         
##          4 2.889   0.6658 2.319 0.8208     0.1969 0.5852        *
##          5 2.949   0.6566 2.349 0.8012     0.1856 0.5599         
##         10 3.252   0.5965 2.628 0.8256     0.1781 0.6016         
##         15 3.405   0.5712 2.709 0.8862     0.1985 0.6603         
##         20 3.514   0.5562 2.799 0.9162     0.2048 0.7334         
##         25 3.700   0.5313 2.987 0.9095     0.1972 0.7500         
##         50 4.067   0.4756 3.268 0.8819     0.1908 0.7315         
## 
## The top 4 variables (out of 4):
##    real4, real5, real2, real1
```

输出显示最佳子集大小估计为 4 个预测变量。 该集合包括信息变量，但并未包括所有变量。  predictors 函数可用于获取在最终模型中选取的变量名称的文本字符串。  lmProfile 是一个“rfe”类的列表，它包含一个对象fit，它是具有剩余项的最终线性模型。 该模型可用于获得对未来或测试样本的预测。

```R
predictors(lmProfile)
## [1] "real4" "real5" "real2" "real1"
lmProfile$fit
## 
## Call:
## lm(formula = y ~ ., data = tmp)
## 
## Coefficients:
## (Intercept)        real4        real5        real2        real1  
##      14.613        2.857        1.965        1.625        1.359
head(lmProfile$resample)
##    Variables     RMSE  Rsquared      MAE    Resample
## 4          4 1.923763 0.9142474 1.640438 Fold01.Rep1
## 14         4 2.212266 0.8403133 1.845878 Fold02.Rep1
## 24         4 4.074172 0.5052766 3.095980 Fold03.Rep1
## 34         4 3.938895 0.3250410 2.992700 Fold04.Rep1
## 44         4 3.311426 0.6652186 2.195083 Fold05.Rep1
## 54         4 2.286320 0.6974626 1.840118 Fold06.Rep1
```

还有几种绘图方法可以将结果可视化。  plot(lmProfile) 生成跨不同子集大小的性能配置文件，如下图所示。

```R
trellis.par.set(caretTheme())
plot(lmProfile, type = c("g", "o"))
```

![img](https://topepo.github.io/caret/rfe/rfe_lmprofile-1.svg)

此外，重采样结果存储在子对象 lmProfile$resample 中，可以与多个lattice函数一起使用。 单变量点阵函数（densityplot`, `histogram）可用于绘制重采样分布，而双变量函数（xyplot、stripplot）可用于绘制不同子集大小的分布。 在后一种情况下，可以使用 rfeControl 中的选项 returnResamp`` = "all" 来保存所有重采样结果。 下面显示了随机森林模型的示例图像。

#### 辅助函数

要对任意模型使用特征消除，必须为算法 2 中的每个步骤将一组函数传递给 rfe。

本节定义这些函数并使用现有的随机森林函数作为说明性示例。  caret 包含一个名为 rfFuncs 的列表，但本文档将使用更简单的版本，以便更好地说明这些想法。 这里使用了一组简化的函数，称为 rfRFE。

##### summary

summary函数采用观察值和预测值并计算一个或多个性能指标（参见第 2.14 行）。 输入是一个包含 obs 和 pred 列的数据框。 输出应该是数字变量的命名向量。 请注意， rfe 函数的 metric 参数应引用 summary 输出的名称之一。 

#### fit

此函数基于当前数据集（第 2.3、2.9 和 2.17 行）构建模型。 函数的参数必须是：

x：具有适当变量子集的当前预测变量数据训练集 

y：当前结果数据（数字或因子向量）

 first：当前预测变量集是否具有所有可能变量的单个逻辑值（例如第 2.3 行） 

 last：类似于 first，但当最后一个模型与最终子集大小和预测变量相匹配时为 TRUE。  （第 2.17 行）...：在调用 rfe 时传递给 fit 函数的可选参数

该函数应返回一个可用于生成预测的模型对象。 对于随机森林，拟合函数很简单：

对于在每次迭代时不重新排序的特征选择，当所有预测变量都在模型中时，只需在第一次迭代时计算随机森林变量的重要性。 这可以使用importance``= first来完成。

#### pred function

此函数从当前模型（第 2.4 和 2.10 行）返回一个预测向量（数字或因子）。 输入参数必须是对象：拟合函数生成的模型 x：为保留样本设置的当前预测变量集

对于随机森林，该函数是 predict 函数的一个简单包装器：对于分类，确保预测的结果因子变量与输入数据具有相同的水平可能是一个好主意。

#### rank function

此函数用于按最重要到最不重要的顺序返回预测变量（第 2.5 行和第 2.11 行）。 输入是： 

object：拟合函数生成的模型

 x：训练样本的当前预测变量集 

y：当前训练结果 

该函数应该返回一个数据框，其中包含一个名为 var 的列，该列具有当前变量名称。 第一行应该是最重要的预测器等。其他列可以包含在输出中，并将在最终的 rfe 对象中返回。

对于随机森林，下面的函数使用 caret 的 varImp 函数来提取随机森林的重要性并对它们进行排序。 对于分类，randomForest 将为每个类生成一列重要性。 在这种情况下，默认排名函数按类别的平均重要性对预测变量进行排序。

#### selectSize function

此函数根据重采样输出（第 2.15 行）确定最佳预测变量数。 该函数的输入是： 

x：一个矩阵，其中包含性能指标和变量数量的列，称为Variables 

metric：要优化的性能指标的字符串（例如 RMSE、准确度） 

maximize：衡量指标是否存在的单个逻辑 应该最大化 这个函数应该返回一个对应于最优子集大小的整数。

caret为此提供了两个示例函数：pickSizeBest 和 pickSizeTolerance。 前者只是选择具有最佳值的子集大小。 后者考虑了整个配置文件，并尝试在不牺牲太多性能的情况下选择较小的子集大小。 例如，假设我们已经计算了一系列变量大小的 RMSE：

```R
example <- data.frame(RMSE = c(3.215, 2.819, 2.414, 2.144, 
                               2.014, 1.997, 2.025, 1.987, 
                               1.971, 2.055, 1.935, 1.999, 
                               2.047, 2.002, 1.895, 2.018),
                               Variables = 1:16)
```

这些如下图所示。 实心圆圈标识具有绝对最小 RMSE 的子集大小。 但是，有许多较小的子集产生大致相同的性能，但预测变量较少。 在这种情况下，对于较少的预测变量，我们可能能够接受稍大的误差。

pickSizeTolerance 确定绝对最佳值，然后确定其他点与该值的百分比差异。 在 RMSE 的情况下，这将是

![img](https://topepo.github.io/caret/premade/tol.png) 

 *RMSE{opt}*是绝对最佳错误率。 这些“公差”值绘制在底部面板中。 实心三角形是最佳值的 10% 以内的最小子集大小。

这种方法可以为许多基于树的模型产生良好的结果，例如随机森林，其中对于较大的子集大小存在良好性能的平台。 对于树，这通常是因为不重要的变量很少用于拆分并且不会显着影响性能。

```R
## 找到具有绝对最小 RMSE 的行
smallest <- pickSizeBest(example, metric = "RMSE", maximize = FALSE)
smallest
## [1] 5
## 现在是最小的 10% 以内的
within10Pct <- pickSizeTolerance(example, metric = "RMSE", tol = 10, maximize = FALSE)
within10Pct
## [1] 5

minRMSE <- min(example$RMSE)
example$Tolerance <- (example$RMSE - minRMSE)/minRMSE * 100   

## Plot the profile and the subsets selected using the 
## two different criteria

par(mfrow = c(2, 1), mar = c(3, 4, 1, 2))

plot(example$Variables[-c(smallest, within10Pct)], 
     example$RMSE[-c(smallest, within10Pct)],
     ylim = extendrange(example$RMSE),
     ylab = "RMSE", xlab = "Variables")

points(example$Variables[smallest], 
       example$RMSE[smallest], pch = 16, cex= 1.3)

points(example$Variables[within10Pct], 
       example$RMSE[within10Pct], pch = 17, cex= 1.3)
 
with(example, plot(Variables, Tolerance))
abline(h = 10, lty = 2, col = "darkgrey")
```

![img](https://topepo.github.io/caret/rfe/rfe_lmdens-1.svg)

#### selectVar  function

确定最佳子集大小后，此函数将用于计算所有重采样迭代中每个变量的最佳排名（第 2.16 行）。 该函数的输入是：

 y：每个重采样迭代和每个子集大小（由用户定义的秩函数生成）的变量重要性列表。 在该示例中，对于 10 个子集大小（包括原始子集）中的每一个，每个交叉验证组都保存了秩函数的输出。 如果没有在每次迭代时重新计算排名，则每次交叉验证迭代中的值将相同。

size：selectSize 函数返回的整数 该函数应该按照最重要到最不重要的顺序返回预测变量名称的字符串（长度大小）对于随机森林，仅使用第一个重要性计算（第 2.5 行），因为这些 是对全套预测变量的排名。 这些重要性被平均并返回最高的预测值。

请注意，如果在每次迭代时重新计算预测器排名（第 2.11 行），用户将需要编写自己的选择函数以使用其他排名。

#### 例子

对于随机森林，我们拟合了与线性模型相同的一系列模型大小。 此模型更改了跨子集大小保存所有重采样结果的选项，用于显示下图中的点阵图函数功能。

```R
ctrl$functions <- rfRFE
ctrl$returnResamp <- "all"
set.seed(10)
rfProfile <- rfe(x, y, sizes = subsets, rfeControl = ctrl)
rfProfile

## 
## Recursive feature selection
## 
## Outer resampling method: Cross-Validated (10 fold, repeated 5 times) 
## 
## Resampling performance over subset size:
## 
##  Variables  RMSE Rsquared   MAE RMSESD RsquaredSD  MAESD Selected
##          1 4.667   0.2159 3.907 0.8779    0.20591 0.7889         
##          2 3.801   0.4082 3.225 0.5841    0.21832 0.5858         
##          3 3.157   0.6005 2.650 0.5302    0.14847 0.5156         
##          4 2.696   0.7646 2.277 0.4044    0.08625 0.3962        *
##          5 2.859   0.7553 2.385 0.4577    0.10529 0.4382         
##         10 3.061   0.7184 2.570 0.4378    0.13898 0.4106         
##         15 3.170   0.7035 2.671 0.4423    0.15140 0.4110         
##         20 3.327   0.6826 2.812 0.4469    0.16074 0.4117         
##         25 3.356   0.6729 2.843 0.4634    0.16947 0.4324         
##         50 3.525   0.6437 3.011 0.4597    0.17207 0.4196         
## 
## The top 4 variables (out of 4):
##    real4, real5, real2, real1
```

可以将重采样配置文件与单个重采样结果的图一起可视化：

```R
trellis.par.set(caretTheme())
plot1 <- plot(rfProfile, type = c("g", "o"))
plot2 <- plot(rfProfile, type = c("g", "o"), metric = "Rsquared")
print(plot1, split=c(1,1,1,2), more=TRUE)
print(plot2, split=c(1,2,1,2))
```

```R
plot1 <- xyplot(rfProfile, 
                type = c("g", "p", "smooth"), 
                ylab = "RMSE CV Estimates")
plot2 <- densityplot(rfProfile, 
                     subset = Variables < 5, 
                     adjust = 1.25, 
                     as.table = TRUE, 
                     xlab = "RMSE CV Estimates", 
                     pch = "|")
print(plot1, split=c(1,1,1,2), more=TRUE)
print(plot2, split=c(1,2,1,2))
```

![img](https://topepo.github.io/caret/rfe/rfe_rf_plot2-1.svg)

#### 使用recipe

recipe可用于指定模型项和可能需要的任何预处理。 而不是使用

```R
rfe(x = predictors, y = outcome)
```

现有recipe可以与包含预测变量和结果的数据框一起使用：

```R
rfe(recipe, data)
```

recipe在每个重采样中以与 train 执行 preProc 选项相同的方式准备。 但是，由于recipe可以执行各种不同的操作，因此存在一些潜在的复杂因素。 主要的缺陷是recipe可能涉及预测变量的创建和删除。 有许多步骤可以减少预测变量的数量，例如将因子合并到“其他”类别中的步骤、PCA 信号提取，以及用于接近零方差预测变量和高度相关预测变量的过滤器。 因此，可能很难知道有多少预测变量可用于完整模型。 此外，这个数字可能会在重采样的迭代之间有所不同。

为了说明，让我们使用血脑屏障数据，其中预测变量之间存在高度相关性。 一个简单的recipe可能是

```R
library(recipes)
library(tidyverse)

data(BloodBrain)

# combine into a single data frame
bbb <- bbbDescr
bbb$y <- logBBB

bbb_rec <- recipe(y ~ ., data = bbb) %>%
  step_center(all_predictors()) %>%
  step_scale(all_predictors()) %>%
  step_nzv(all_predictors()) %>%
  step_pca(all_predictors(), threshold = .95) 
```

最初，有 134 个预测变量，对于整个数据集，处理后的版本有：

```
prep(bbb_rec, training = bbb, retain = TRUE) %>% 
  juice(all_predictors()) %>% 
  ncol()
  
  ## [1] 28
```

调用 rfe 时，让我们从 28 开始最大子集大小：

```R
bbb_ctrl <- rfeControl(
  method = "repeatedcv",
  repeats = 5,
  functions = lmFuncs, 
  returnResamp = "all"
)

set.seed(36)
lm_rfe <- rfe(
  bbb_rec,
  data = bbb,
  sizes = 2:28,
  rfeControl = bbb_ctrl
)

ggplot(lm_rfe) + theme_bw()
```

![img](https://topepo.github.io/caret/rfe/rfe-rec-1.svg)

最大术语数的分布是什么：

```R
term_dist <- 
  lm_rfe$resample %>% 
  group_by(Resample) %>% 
  dplyr::summarize(max_terms = max(Variables))
table(term_dist$max_terms)

## 
## 27 28 29 
##  7 40  3
```

### 使用遗传算法进行特征选择

#### 遗传算法

遗传算法 (GA) 模仿达尔文自然选择的力量来寻找某些函数的最佳值 (Mitchell, 1998)。 创建一组初始候选解决方案并计算其相应的适应度值（其中值越大越好）。 这组解决方案称为总体，每个解决方案称为个体。 具有最佳适应度值的个体被随机组合以产生构成下一个种群的后代。 为此，个体被选择并进行交叉（模仿基因繁殖），并且还受到随机突变的影响。 这个过程一次又一次地重复，并且产生了许多代（即搜索过程的迭代），这些代应该创造出越来越好的解决方案。

对于特征选择，个体是编码为二进制的预测变量的子集； 一个特征要么包含在子集中，要么不包含在子集中。 适应度值是模型性能的某种度量，例如 RMSE 或分类准确度。 使用 GA 进行特征选择的一个问题是优化过程可能非常激进，并且它们有可能使 GA 过拟合预测器（很像之前针对 RFE 的讨论）。

#### 内部和外部效率评估

caret中的遗传算法代码在重采样迭代中重复进行特征空间的搜索。 首先，训练数据被拆分为控制函数中指定的任何重采样方法。 例如，如果选择 10 折交叉验证，则整个遗传算法将进行 10 次单独的验证。 对于第一折，十分之九的数据用于搜索，而剩余的十分之一用于估计外部性能，因为这些数据点未用于搜索。

 在遗传算法过程中，需要一个适应度的度量来指导搜索。 这是绩效的内部衡量标准。 在搜索过程中，可用的数据是顶级重采样选择的实例（例如上面提到的十分之九）。 一种常见的方法是进行另一个重采样程序。 另一种选择是使用一组保持样本来确定性能的内部估计（请参阅控制函数的保持参数）。 虽然速度更快，但更容易导致特征过度拟合，因此只能在有大量训练数据可用时使用。 另一个想法是使用惩罚指标（例如 AIC 统计量），但对于某些指标（例如 ROC 曲线下的面积），这可能不存在。

性能的内部估计最终会使子集过度拟合数据。 但是，由于搜索不使用外部估计，因此可以更好地评估过度拟合。 重采样后，此函数确定 GA 的最佳代数。

最后，在最后一次执行遗传算法搜索时使用整个数据集，最终模型建立在预测子集上，该预测子集与通过重采样确定的最佳代数相关（尽管更新函数可用于手动设置代数）。

#### 基本语法

该函数最基本的用法是：

```R
obj <- gafs(x = predictors, 
            y = outcome,
            iters = 100)
```

其中 

x：预测值的数据框或矩阵

 y：结果的因子或数值向量 

iters：GA 的代数 

这不是很具体。 所有的动作都在控制功能中。 这可用于指定要拟合的模型、如何进行预测和总结以及遗传操作。

假设我们想要拟合一个线性回归模型。 为此，我们可以使用 train 作为接口并通过 gafs 将参数传递给该函数：

```R
ctrl <- gafsControl(functions = caretGA)
obj <- gafs(x = predictors, 
            y = outcome,
            iters = 100,
            gafsControl = ctrl,
            ## 现在将选项传递给`train`
            method = "lm")
```

也可以传入其他选项，例如 preProcess。

gafsControl 的一些重要选项是：method、number、repeats、index、indexOut 等：类似于 train 顶部控制重采样

metric：这类似于 train 的选项，但在这种情况下，该值应该是一个命名向量，其中包含内部和外部指标的值。 如果未指定，则使用汇总函数返回的第一个值（请参阅下面的详细信息）并发出警告。 选项最大化也需要一个类似的二元素向量。 有关说明，请参阅此处的最后一个示例。

holdout：这是一个介于 [0, 1) 之间的数字，可用于保留样本以计算内部适应度值。 请注意，这与外部重采样步骤无关。 假设正在使用 10 倍的 CV。 在重采样迭代中，holdout 可用于对 90% 重采样数据的额外比例进行采样，以用于估计适应度。 这可能不是一个好主意，除非你有一个非常大的训练集并且想要避免内部重采样过程来估计适应度。

 allowParallel 和 genParallel：这些是控制应该在何处使用并行处理（如果有的话）的逻辑。 前者将并行化外部重采样，而后者并行化一代内的适应度计算。  allowParallel 几乎总是更有利。

有几组内置函数可用于 gafs：caretGA、rfGA 和 treebagGA。 第一个是简单的训练界面。 使用它时，如上所示，可以使用 ... 结构将参数传递给训练，并且性能的重采样估计可以用作内部适应度值。  rfGA 和 treebagGA 提供的函数避免使用 train ，它们的内部适应度估计来自使用模型生成的袋外估计。

caret中的 GA 实现使用来自 GA 包的底层代码（Scrucca，2013）。

#### 遗传算法示例

使用上一页的示例，其中有 5 个真实预测变量和 40 个噪声预测变量：

```R
library(mlbench)
n <- 100
p <- 40
sigma <- 1
set.seed(1)
sim <- mlbench.friedman1(n, sd = sigma)
colnames(sim$x) <- c(paste("real", 1:5, sep = ""),
                     paste("bogus", 1:5, sep = ""))
bogus <- matrix(rnorm(n * p), nrow = n)
colnames(bogus) <- paste("bogus", 5+(1:ncol(bogus)), sep = "")
x <- cbind(sim$x, bogus)
y <- sim$y
normalization <- preProcess(x)
x <- predict(normalization, x)
x <- as.data.frame(x)
```

我们将拟合随机森林模型并使用袋外 RMSE 估计作为内部性能指标，并使用与搜索相同的重复 10 倍交叉验证过程。 为此，我们将使用内置的 rfGA 对象。 将使用默认的 GA 运算符并执行 200 代算法。

```R
ga_ctrl <- gafsControl(functions = rfGA,
                       method = "repeatedcv",
                       repeats = 5)

## 使用与 RFE 过程相同的随机数种子，以便相同的 CV 折叠用于外部
## 重采样 
set.seed(10)
rf_ga <- gafs(x = x, y = y,
              iters = 200,
              gafsControl = ga_ctrl)
rf_ga

## 
## Genetic Algorithm Feature Selection
## 
## 100 samples
## 50 predictors
## 
## Maximum generations: 200 
## Population per generation: 50 
## Crossover probability: 0.8 
## Mutation probability: 0.1 
## Elitism: 0 
## 
## Internal performance values: RMSE, Rsquared
## Subset selection driven to minimize internal RMSE 
## 
## External performance values: RMSE, Rsquared, MAE
## Best iteration chose by minimizing external RMSE 
## External resampling method: Cross-Validated (10 fold, repeated 5 times) 
## 
## During resampling:
##   * the top 5 selected variables (out of a possible 50):
##     real1 (100%), real2 (100%), real4 (100%), real5 (100%), real3 (92%)
##   * on average, 9.3 variables were selected (min = 6, max = 15)
## 
## In the final search using the entire training set:
##    * 12 features selected at iteration 195 including:
##      real1, real2, real3, real4, real5 ... 
##    * external performance at this iteration is
## 
##        RMSE    Rsquared         MAE 
##      2.8056      0.7607      2.3640
```

10 折交叉验证重复 5 次，GA 执行 50 次。 跨重采样计算平均外部性能，这些结果用于确定最终 GA 的最佳迭代次数，以避免过度拟合。 在重采样中，每个算法结束时平均选择了 9.3 个预测变量。

 plot 函数用于监控内部袋外 RMSE 估计值的平均值以及根据 50 个样本外预测计算的外部性能估计值的平均值。 默认情况下，此函数使用 ggplot2 包。 可以将黑白主题“添加”到输出对象中：

```R
plot(rf_ga) + theme_bw()
```

![img](https://topepo.github.io/caret/ga/ga_rf_profile-1.svg)

根据这些结果，与最佳外部 RMSE 估计值相关的代为 2.81。

使用整个训练集，进行最终的 GA，在第 195 代，选择了 12 个：real1、real2、real3、real4、real5、bogus3、bogus5、bogus7、bogus8、bogus14、bogus17、bogus29。 带有这些预测器的随机森林模型是使用整个训练集创建的，这是在执行 predict.gafs 时使用的模型。

注意：对于大多数现实世界的问题，内部和外部适应度值之间的相关性有些不典型。 这是模拟性质的函数（少量不相关的信息预测变量），随机森林的 OOB 误差估计是数百棵树的产物。 你的旅费可能会改变。

#### 自定义搜索

略

#### 使用recipe

与其他特征选择例程一样，gafs 可以将数据配方作为输入。 当您的数据需要在模型之前进行预处理时，这是有利的，例如：

* 根据相互作用的规范创建虚拟变量 缺失数据插补 
* 更复杂的特征工程方法 像训练一样，配方的预处理步骤是在每个重采样中计算的。 
* 这可确保重采样统计信息捕获预处理对模型的变化和影响。

例如，使用艾姆斯住房数据。 这些数据包含许多需要转换为指标的分类预测变量以及需要处理的其他变量。 要加载（和拆分）数据：

和 train 一样，配方的预处理步骤是在每个重采样中计算的。 这可确保重采样统计信息捕获预处理对模型的变化和影响。

例如，使用艾姆斯住房数据。 这些数据包含许多需要转换为指标的分类预测变量以及需要处理的其他变量。 要加载（和拆分）数据：

```R
library(AmesHousing)
library(rsample)

# 创建数据并删除一列更多的结果。
ames <- make_ames() %>%
  select(-Overall_Qual)

ncol(ames)

## [1] 80

# 有多少因子变量？
sum(vapply(ames, is.factor, logical(1)))

## [1] 45

# 我们将使用 `rsample` 使初始分割与这些数据的其他分析保持一致。 首先设置种子以确保您获得相同的随机数
set.seed(4595)
data_split <- initial_split(ames, strata = "Sale_Price", prop = 3/4)

ames_train <- training(data_split) %>% as.data.frame()
ames_test  <- testing(data_split) %>% as.data.frame()
```

这是一个对预测器集进行不同类型预处理的recipe：

```R
library(recipes)

ames_rec <- recipe(Sale_Price ~ ., data = ames_train) %>% 
  step_log(Sale_Price, base = 10) %>%
  step_other(Neighborhood, threshold = 0.05)  %>%
  step_dummy(all_nominal(), -Bldg_Type) %>%
  step_interact(~ starts_with("Central_Air"):Year_Built) %>%
  step_zv(all_predictors())%>%
  step_bs(Longitude, Latitude, options = list(df = 5))
```

如果在训练集上执行此操作，它将在原始 79 个预测器列中生成 280 个预测器列。

 让我们用 gafs 调整一些线性模型，为了计算时间，只使用 10 代算法：

```R
lm_ga_ctrl <- gafsControl(functions = caretGA, method = "cv", number = 10)

set.seed(23555)
lm_ga_search <- gafs(
  ames_rec, 
  data = ames_train,
  iters = 10, 
  gafsControl = lm_ga_ctrl,
  # now options to `train` for caretGA
  method = "lm",
  trControl = trainControl(method = "cv", allowParallel = FALSE)
) 
lm_ga_search
## 
## Genetic Algorithm Feature Selection
## 
## 2199 samples
## 273 predictors
## 
## Maximum generations: 10 
## Population per generation: 50 
## Crossover probability: 0.8 
## Mutation probability: 0.1 
## Elitism: 0 
## 
## Internal performance values: RMSE, Rsquared, MAE
## Subset selection driven to minimize internal RMSE 
## 
## External performance values: RMSE, Rsquared, MAE
## Best iteration chose by minimizing external RMSE 
## External resampling method: Cross-Validated (10 fold) 
## 
## During resampling:
##   * the top 5 selected variables (out of a possible 273):
##     Bldg_Type (100%), Bsmt_Exposure_No (100%), First_Flr_SF (100%), MS_Zoning_Residential_High_Density (100%), Neighborhood_Gilbert (100%)
##   * on average, 171.7 variables were selected (min = 150, max = 198)
## 
## In the final search using the entire training set:
##    * 155 features selected at iteration 9 including:
##      Lot_Frontage, Year_Built, Year_Remod_Add, BsmtFin_SF_2, Gr_Liv_Area ... 
##    * external performance at this iteration is
## 
##         RMSE     Rsquared          MAE 
##      0.06923      0.84659      0.04260
```

### 使用模拟退火的特征选择

#### 模拟退火

模拟退火 (SA) 是一种全局搜索方法，它对初始候选解进行小的随机变化（即扰动）。 如果扰动值的性能值优于先前的解决方案，则接受新的解决方案。 如果不是，则基于两个性能值之间的差异和搜索的当前迭代确定接受概率。 由此，可以接受次优解决方案，它可能最终在后续迭代中产生更好的解决方案。 请参阅 Kirkpatrick (1984) 或 Rutenbar (1989) 以获得更好的描述。
    

在特征选择的上下文中，解决方案是描述当前子集的二元向量。 通过随机改变子集中的少量成员来扰乱子集。

#### 内部和外部绩效评估

遗传算法页面中关于此主题的大部分讨论都与此处相关，尽管 SA 搜索不如 GA 搜索积极。 在任何情况下，这里的实现都会在重采样循环内进行 SA 搜索，并使用外部性能估计来选择合适的搜索迭代次数。

#### 基本语法

该函数的语法与之前遗传算法搜索的信息非常相似。

该函数最基本的用法是：

```R
obj <- safs(x = predictors, 
            y = outcome,
            iters = 100)
```

其中：

 x：预测变量值的数据框或矩阵 

y：结果的因子或数值向量 

iters：SA 的迭代次数 

这不是很具体。 所有的动作都在控制功能中。 这可用于指定要拟合的模型、如何进行预测和总结以及遗传操作。

假设我们想要拟合一个线性回归模型。 为此，我们可以使用 train 作为接口并通过 safs 将参数传递给该函数：

```R
ctrl <- safsControl(functions = caretSA)
obj <- safs(x = predictors, 
            y = outcome,
            iters = 100,
            safsControl = ctrl,
            ## Now pass options to `train`
            
            method = "lm")
```

也可以传入其他选项，例如 preProcess。

safsControl 的一些重要选项是：method、number、repeats、index、indexOut 等：类似于train顶部控制重采样的选项。

metric：这类似于 train 的选项，但在这种情况下，该值应该是一个命名向量，其中包含内部和外部指标的值。 如果未指定，则使用汇总函数返回的第一个值（请参阅下面的详细信息）并发出警告。 选项最大化也需要一个类似的二元素向量。 有关说明，请参阅此处的最后一个示例。

holdout：这是一个介于 [0, 1) 之间的数字，可用于保留样本以计算内部适应度值。 请注意，这与外部重采样步骤无关。 假设正在使用 10 倍的 CV。 在重采样迭代中，holdout 可用于对 90% 重采样数据的额外比例进行采样，以用于估计适应度。 这可能不是一个好主意，除非你有一个非常大的训练集并且想要避免内部重采样过程来估计适应度。

improve：一个整数（或无穷大），定义在当前子集重置为最后一次已知改进之前应该通过多少迭代而不改进适应度。

allowParallel：外部重采样循环是否应该并行运行？

有一些内置函数可以与 safs 一起使用：caretSA、rfSA 和 treebagSA。 第一个是简单的训练界面。 使用它时，如上所示，可以使用 ... 结构将参数传递给训练，并且性能的重采样估计可以用作内部适应度值。  rfSA 和 treebagSA 提供的函数避免使用 train ，它们的内部适应度估计**来自使用模型生成的袋外估计**。

#### 模拟退火示例

使用上一页中的示例，其中有 5 个真实预测变量和 40 个噪声预测变量。

我们将拟合随机森林模型并使用袋外 RMSE 估计作为内部性能指标，并使用与搜索相同的重复 10 倍交叉验证过程。 为此，我们将使用内置的 rfSA 对象。 默认 SA 运算符将用于算法的 1000 次迭代。

```R
sa_ctrl <- safsControl(functions = rfSA,
                       method = "repeatedcv",
                       repeats = 5,
                       improve = 50)

set.seed(10)
rf_sa <- safs(x = x, y = y,
              iters = 250,
              safsControl = sa_ctrl)
rf_sa
## 
## 模拟退火特征选择
## 
## 100 samples
## 50 predictors
## 
## Maximum search iterations: 250 
## Restart after 50 iterations without improvement (2.1 restarts on average)
## 
## 内部性能值：RMSE、Rsquared 
## 驱动子集选择以最小化内部 RMSE 
## 
##外部性能值：RMSE、Rsquared、MAE 
## 通过最小化外部 RMSE 选择的最佳迭代 
## 外部重采样方法：交叉验证（10 倍，重复 5 次）
## 
## 在重采样期间：
## * 前 5 个选定变量（可能的 50 个）：
##     real1 (100%), real2 (100%), real4 (100%), real5 (98%), bogus17 (88%)
##   * on average, 20.7 variables were selected (min = 12, max = 30)
## 
## 在使用整个训练集的最终搜索中：
## * 212 次迭代中选择的 21 个特征包括：
## real1、real2、real5、bogus1、bogus3 ...
## * 本次迭代的外部性能为
## 
##        RMSE    Rsquared         MAE 
##      3.3147      0.6625      2.8369
```

与 GA 一样，我们可以绘制迭代过程中的内部和外部性能。

```R
plot(rf_sa) + theme_bw()
```

这里的性能不如以前的 GA 或 RFE 解决方案。 根据这些结果，与最佳外部 RMSE 估计相关的迭代为 212，相应的 RMSE 估计为 3.31。

使用整个训练集，进行最终的 SA，在迭代 212 时，选择了 21 个：real1、real2、real5、bogus1、bogus3、bogus9、bogus10、bogus13、bogus14、bogus15、bogus19、bogus20、bogus23、bogus24、  bogus25、bogus26、bogus28、bogus31、bogus33、bogus38、bogus44。 带有这些预测器的随机森林模型是使用整个训练集创建的，这是在执行 predict.safs 时使用的模型。

#### 自定义搜索

略

#### 使用recipe

与前面关于遗传算法的部分类似，recipe可以与 safs 一起使用。 使用与之前相同的数据：

```R
library(AmesHousing)
library(rsample)

# Create the data and remove one column that is more of 
# an outcome. 
ames <- make_ames() %>%
  select(-Overall_Qual)

ncol(ames)
## [1] 80
# How many factor variables?
sum(vapply(ames, is.factor, logical(1)))
# We'll use `rsample` to make the initial split to be consistent with other
# analyses of these data. Set the seed first to make sure that you get the 
# same random numbers
set.seed(4595)
data_split <- initial_split(ames, strata = "Sale_Price", prop = 3/4)

ames_train <- training(data_split) %>% as.data.frame()
ames_test  <- testing(data_split) %>% as.data.frame()

library(recipes)

ames_rec <- recipe(Sale_Price ~ ., data = ames_train) %>% 
  step_log(Sale_Price, base = 10) %>%
  step_other(Neighborhood, threshold = 0.05)  %>%
  step_dummy(all_nominal(), -Bldg_Type) %>%
  step_interact(~ starts_with("Central_Air"):Year_Built) %>%
  step_zv(all_predictors())%>%
  step_bs(Longitude, Latitude, options = list(df = 5))
## 让我们再次使用带有函数的线性模型：
lm_sa_ctrl <- safsControl(functions = caretSA,
                          method = "cv",
                          number = 10)

set.seed(23555)
lm_sa_search <- safs(
  ames_rec, 
  data = ames_train,
  iters = 10, # we probably need thousands of iterations
  safsControl = lm_sa_ctrl,
  # now options to `train` for caretSA
  method = "lm",
  trControl = trainControl(method = "cv", allowParallel = FALSE)
) 
lm_sa_search
## 
## Simulated Annealing Feature Selection
## 
## 2199 samples
## 273 predictors
## 
## Maximum search iterations: 10 
## 
## Internal performance values: RMSE, Rsquared, MAE
## Subset selection driven to minimize internal RMSE 
## 
## External performance values: RMSE, Rsquared, MAE
## Best iteration chose by minimizing external RMSE 
## External resampling method: Cross-Validated (10 fold) 
## 
## During resampling:
##   * the top 5 selected variables (out of a possible 273):
##     Roof_Style_Gambrel (70%), Latitude_bs_2 (60%), Bsmt_Full_Bath (50%), BsmtFin_Type_1_Rec (50%), Condition_1_Norm (50%)
##   * on average, 59.1 variables were selected (min = 56, max = 63)
## 
## In the final search using the entire training set:
##    * 56 features selected at iteration 4 including:
##      Year_Remod_Add, Half_Bath, TotRms_AbvGrd, Garage_Area, Enclosed_Porch ... 
##    * external performance at this iteration is
## 
##         RMSE     Rsquared          MAE 
##      0.09518      0.69840      0.07033
```

## 附录B caret的tidy表示——tidymodels包

了解略，代码可见tidymodels.R,[网址](https://www.tidymodels.org/)

在了解了开始使用 tidymodels 需要什么之后，您可以了解更多信息并走得更远。 在此处查找文章以帮助您使用 tidymodels 框架解决特定问题。 文章分为四类： 

* [执行统计分析](https://www.tidymodels.org/learn/statistics/)

  * 具有整洁数据原则的相关性和回归基础

    同时分析多个数据集的相关测试和简单回归模型的结果。

  * 使用 tidy 数据原则进行 K-means 聚类

    总结聚类特征并估计数据集的最佳聚类数。

  * 自举重采样和整齐的回归模型

    应用bootstrap重采样估计模型参数的不确定性。

  * 使用重采样和整齐数据的假设检验

    使用灵活的函数进行统计推断的常见假设检验

  * 列联表的统计分析

    使用独立性和拟合优度测试来分析计数表。

* [创建稳健的模型 ](https://www.tidymodels.org/learn/models/)

  * 回归模型的两种方法
  * 基于神经网络的分类模型
  * 阶级失衡的二次抽样
  * 具有整齐重采样的时间序列建模
  * 使用模型系数
  * 偏最小二乘多元分析

* 调整、比较和使用您的模型 

  * 通过网格搜索进行模型

    调整通过在包含许多可能参数值的网格上进行训练，为模型选择超参数。

  * 嵌套重采样

    使用嵌套重采样估计模型的最佳超参数。

  * 分类模型的迭代贝叶斯优化

    使用迭代搜索的贝叶斯优化确定模型的最佳超参数。

  * 调整文本模型

    为预测建模准备文本数据，并使用网格和迭代搜索进行调整。

* 开发自定义建模工具

  * 创建自己的recipe步骤函数

    为数据预处理编写新的配方步骤。

  * 如何构建parsnip模型

    从现有模型实现创建parsnip模型功能。

  * 自定义性能指标

    创建新的性能指标，并将其与标尺功能集成。

  * 如何创建调整参数函数

    构建用于调整定量和定性参数的函数。

  * 为新模型对象创建自己的broom整洁方法

    Write tidy（）、glance（）和augment（）方法。

recipes列表：

| Adaptive Synthetic Sampling Approach                         | [`step_adasyn`](https://tidymodels.github.io/themis/reference/step_adasyn.html) | themis      |
| ------------------------------------------------------------ | ------------------------------------------------------------ | ----------- |
| 使用dplyr对行进行排序                                        | [`step_arrange`](https://tidymodels.github.io/recipes/reference/step_arrange.html) | recipes     |
| 通过袋装树木进行插补                                         | [`step_bagimpute`](https://tidymodels.github.io/recipes/reference/step_bagimpute.html) | recipes     |
| 从虚拟变量创建一个因子                                       | [`step_bin2factor`](https://tidymodels.github.io/recipes/reference/step_bin2factor.html) | recipes     |
| 非负数据的Box-Cox变换                                        | [`step_BoxCox`](https://tidymodels.github.io/recipes/reference/step_BoxCox.html) | recipes     |
| B样条基函数                                                  | [`step_bs`](https://tidymodels.github.io/recipes/reference/step_bs.html) | recipes     |
| 应用边界SMOTE算法                                            | [`step_bsmote`](https://tidymodels.github.io/themis/reference/step_bsmote.html) | themis      |
| 对中数字数据                                                 | [`step_center`](https://tidymodels.github.io/recipes/reference/step_center.html) | recipes     |
| 到类质心的距离                                               | [`step_classdist`](https://tidymodels.github.io/recipes/reference/step_classdist.html) | recipes     |
| 高相关滤波器                                                 | [`step_corr`](https://tidymodels.github.io/recipes/reference/step_corr.html) | recipes     |
| 使用正则表达式创建模式计数                                   | [`step_count`](https://tidymodels.github.io/recipes/reference/step_count.html) | recipes     |
| 日期特征生成器                                               | [`step_date`](https://tidymodels.github.io/recipes/reference/step_date.html) | recipes     |
| 数据深度                                                     | [`step_depth`](https://tidymodels.github.io/recipes/reference/step_depth.html) | recipes     |
| 离散数值变量                                                 | [`step_discretize`](https://tidymodels.github.io/recipes/reference/step_discretize.html) | recipes     |
| 基于一个因子变量对数据集进行下采样                           | [`step_downsample`](https://tidymodels.github.io/recipes/reference/step_downsample.html) | recipes     |
| Down-Sample a Data Set Based on a Factor Variable            | [`step_downsample`](https://tidymodels.github.io/themis/reference/step_downsample.html) | themis      |
| 创建虚拟变量                                                 | [`step_dummy`](https://tidymodels.github.io/recipes/reference/step_dummy.html) | recipes     |
| 将因子编码为多列                                             | [`step_embed`](https://tidymodels.github.io/embed/reference/step_embed.html) | embed       |
| 将因子转换为字符串                                           | [`step_factor2string`](https://tidymodels.github.io/recipes/reference/step_factor2string.html) | recipes     |
| Filter rows using dplyr                                      | [`step_filter`](https://tidymodels.github.io/recipes/reference/step_filter.html) | recipes     |
| Distance between two locations                               | [`step_geodist`](https://tidymodels.github.io/recipes/reference/step_geodist.html) | recipes     |
| 假日特征生成器                                               | [`step_holiday`](https://tidymodels.github.io/recipes/reference/step_holiday.html) | recipes     |
| 双曲变换                                                     | [`step_hyperbolic`](https://tidymodels.github.io/recipes/reference/step_hyperbolic.html) | recipes     |
| ICA信号提取                                                  | [`step_ica`](https://tidymodels.github.io/recipes/reference/step_ica.html) | recipes     |
| 将值转换为预定义的整数                                       | [`step_integer`](https://tidymodels.github.io/recipes/reference/step_integer.html) | recipes     |
| 创建交互变量                                                 | [`step_interact`](https://tidymodels.github.io/recipes/reference/step_interact.html) | recipes     |
| 添加截距（或常数）列                                         | [`step_intercept`](https://tidymodels.github.io/recipes/reference/step_intercept.html) | recipes     |
| 逆变换                                                       | [`step_inverse`](https://tidymodels.github.io/recipes/reference/step_inverse.html) | recipes     |
| 逆 Logit 变换                                                | [`step_invlogit`](https://tidymodels.github.io/recipes/reference/step_invlogit.html) | recipes     |
| Isomap 嵌入                                                  | [`step_isomap`](https://tidymodels.github.io/recipes/reference/step_isomap.html) | recipes     |
| 通过 K 近邻进行插补                                          | [`step_knnimpute`](https://tidymodels.github.io/recipes/reference/step_knnimpute.html) | recipes     |
| 内核 PCA 信号提取                                            | [`step_kpca`](https://tidymodels.github.io/recipes/reference/step_kpca.html) | recipes     |
| 多项式核 PCA 信号提取                                        | [`step_kpca_poly`](https://tidymodels.github.io/recipes/reference/step_kpca_poly.html) | recipes     |
| Radial Basis Function Kernel PCA Signal Extraction           | [`step_kpca_rbf`](https://tidymodels.github.io/recipes/reference/step_kpca_rbf.html) | recipes     |
| 创建滞后预测器                                               | [`step_lag`](https://tidymodels.github.io/recipes/reference/step_lag.html) | recipes     |
| 计算 lda 尺寸估计                                            | [`step_lda`](https://tidymodels.github.io/textrecipes/reference/step_lda.html) | textrecipes |
| 令牌列表变量的词形还原                                       | [`step_lemma`](https://tidymodels.github.io/textrecipes/reference/step_lemma.html) | textrecipes |
| 使用贝叶斯似然编码将监督因子转换为线性函数                   | [`step_lencode_bayes`](https://tidymodels.github.io/embed/reference/step_lencode_bayes.html) | embed       |
| Supervised Factor Conversions into Linear Functions using Likelihood Encodings | [`step_lencode_glm`](https://tidymodels.github.io/embed/reference/step_lencode_glm.html) | embed       |
| Supervised Factor Conversions into Linear Functions using Bayesian Likelihood Encodings | [`step_lencode_mixed`](https://tidymodels.github.io/embed/reference/step_lencode_mixed.html) | embed       |
| 线性组合滤波器                                               | [`step_lincomb`](https://tidymodels.github.io/recipes/reference/step_lincomb.html) | recipes     |
| 对数变换                                                     | [`step_log`](https://tidymodels.github.io/recipes/reference/step_log.html) | recipes     |
| 罗吉特变换                                                   | [`step_logit`](https://tidymodels.github.io/recipes/reference/step_logit.html) | recipes     |
| 将数值数据插补到测量阈值以下                                 | [`step_lowerimpute`](https://tidymodels.github.io/recipes/reference/step_lowerimpute.html) | recipes     |
| 使用平均值估算数值数据                                       | [`step_meanimpute`](https://tidymodels.github.io/recipes/reference/step_meanimpute.html) | recipes     |
| 使用中位数估算数值数据                                       | [`step_medianimpute`](https://tidymodels.github.io/recipes/reference/step_medianimpute.html) | recipes     |
| 使用最常见的值估算名义数据                                   | [`step_modeimpute`](https://tidymodels.github.io/recipes/reference/step_modeimpute.html) | recipes     |
| Add new variables using `mutate`                             | [`step_mutate`](https://tidymodels.github.io/recipes/reference/step_mutate.html) | recipes     |
| Mutate multiple columns                                      | [`step_mutate_at`](https://tidymodels.github.io/recipes/reference/step_mutate_at.html) | recipes     |
| 删除具有缺失值的观测值                                       | [`step_naomit`](https://tidymodels.github.io/recipes/reference/step_naomit.html) | recipes     |
| 通过删除其他类附近的点进行欠采样。                           | [`step_nearmiss`](https://tidymodels.github.io/themis/reference/step_nearmiss.html) | themis      |
| 从 tokenlist 生成 ngram                                      | [`step_ngram`](https://tidymodels.github.io/textrecipes/reference/step_ngram.html) | textrecipes |
| NNMF 信号提取                                                | [`step_nnmf`](https://tidymodels.github.io/recipes/reference/step_nnmf.html) | recipes     |
| 居中并缩放数值数据                                           | [`step_normalize`](https://tidymodels.github.io/recipes/reference/step_normalize.html) | recipes     |
| 新因子水平的简单赋值                                         | [`step_novel`](https://tidymodels.github.io/recipes/reference/step_novel.html) | recipes     |
| 自然样条基函数                                               | [`step_ns`](https://tidymodels.github.io/recipes/reference/step_ns.html) | recipes     |
| 将数字转换为因子                                             | [`step_num2factor`](https://tidymodels.github.io/recipes/reference/step_num2factor.html) | recipes     |
| 近零方差滤波器                                               | [`step_nzv`](https://tidymodels.github.io/recipes/reference/step_nzv.html) | recipes     |
| 将序数因子转换为数字分数                                     | [`step_ordinalscore`](https://tidymodels.github.io/recipes/reference/step_ordinalscore.html) | recipes     |
| 折叠一些分类级别                                             | [`step_other`](https://tidymodels.github.io/recipes/reference/step_other.html) | recipes     |
| PCA 信号提取                                                 | [`step_pca`](https://tidymodels.github.io/recipes/reference/step_pca.html) | recipes     |
| 偏最小二乘特征提取                                           | [`step_pls`](https://tidymodels.github.io/recipes/reference/step_pls.html) | recipes     |
| 正交多项式基函数                                             | [`step_poly`](https://tidymodels.github.io/recipes/reference/step_poly.html) | recipes     |
| tokenlist变量的词性过滤                                      | [`step_pos_filter`](https://tidymodels.github.io/textrecipes/reference/step_pos_filter.html) | textrecipes |
| 创建数据集的分析版本                                         | [`step_profile`](https://tidymodels.github.io/recipes/reference/step_profile.html) | recipes     |
| 将数值数据缩放到特定范围                                     | [`step_range`](https://tidymodels.github.io/recipes/reference/step_range.html) | recipes     |
| 比率变量创建                                                 | [`step_ratio`](https://tidymodels.github.io/recipes/reference/step_ratio.html) | recipes     |
| 使用正则表达式创建虚拟变量                                   | [`step_regex`](https://tidymodels.github.io/recipes/reference/step_regex.html) | recipes     |
| 将因子重新调整到所需水平                                     | [`step_relevel`](https://tidymodels.github.io/recipes/reference/step_relevel.html) | recipes     |
| 应用（平滑）校正线性变换                                     | [`step_relu`](https://tidymodels.github.io/recipes/reference/step_relu.html) | recipes     |
| Rename variables by name                                     | [`step_rename`](https://tidymodels.github.io/recipes/reference/step_rename.html) | recipes     |
| Rename multiple columns                                      | [`step_rename_at`](https://tidymodels.github.io/recipes/reference/step_rename_at.html) | recipes     |
| 通用变量过滤器                                               | [`step_rm`](https://tidymodels.github.io/recipes/reference/step_rm.html) | recipes     |
| 使用滚动窗口统计量估算数值数据                               | [`step_rollimpute`](https://tidymodels.github.io/recipes/reference/step_rollimpute.html) | recipes     |
| 应用 ROSE 算法                                               | [`step_rose`](https://tidymodels.github.io/themis/reference/step_rose.html) | themis      |
| Sample rows using dplyr                                      | [`step_sample`](https://tidymodels.github.io/recipes/reference/step_sample.html) | recipes     |
| 缩放数值数据                                                 | [`step_scale`](https://tidymodels.github.io/recipes/reference/step_scale.html) | recipes     |
| 生成基本的文本特征集                                         | [`step_sequence_onehot`](https://tidymodels.github.io/textrecipes/reference/step_sequence_onehot.html) | textrecipes |
| 随机变量                                                     | [`step_shuffle`](https://tidymodels.github.io/recipes/reference/step_shuffle.html) | recipes     |
| 使用 dplyr 按位置过滤行                                      | [`step_slice`](https://tidymodels.github.io/recipes/reference/step_slice.html) | recipes     |
| 应用 SMOTE 算法                                              | [`step_smote`](https://tidymodels.github.io/themis/reference/step_smote.html) | themis      |
| 空间符号预处理                                               | [`step_spatialsign`](https://tidymodels.github.io/recipes/reference/step_spatialsign.html) | recipes     |
| 平方根变换                                                   | [`step_sqrt`](https://tidymodels.github.io/recipes/reference/step_sqrt.html) | recipes     |
| 令牌列表变量的词干                                           | [`step_stem`](https://tidymodels.github.io/textrecipes/reference/step_stem.html) | textrecipes |
| 从 tokenlist 变量中过滤停用词                                | [`step_stopwords`](https://tidymodels.github.io/textrecipes/reference/step_stopwords.html) | textrecipes |
| 将字符串转换为因子                                           | [`step_string2factor`](https://tidymodels.github.io/recipes/reference/step_string2factor.html) | recipes     |
| 生成基本的文本特征集                                         | [`step_textfeature`](https://tidymodels.github.io/textrecipes/reference/step_textfeature.html) | textrecipes |
| 代币的词频                                                   | [`step_texthash`](https://tidymodels.github.io/textrecipes/reference/step_texthash.html) | textrecipes |
| Term frequency of tokens                                     | [`step_tf`](https://tidymodels.github.io/textrecipes/reference/step_tf.html) | textrecipes |
| 词频-令牌的逆文档频率                                        | [`step_tfidf`](https://tidymodels.github.io/textrecipes/reference/step_tfidf.html) | textrecipes |
| 时间序列特征（签名）生成器                                   | [`step_timeseries_signature`](https://business-science.github.io/timetk/reference/step_timeseries_signature.html) | timetk      |
| 根据词频过滤标记                                             | [`step_tokenfilter`](https://tidymodels.github.io/textrecipes/reference/step_tokenfilter.html) | textrecipes |
| 字符变量的标记化                                             | [`step_tokenize`](https://tidymodels.github.io/textrecipes/reference/step_tokenize.html) | textrecipes |
